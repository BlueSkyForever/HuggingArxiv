# 2024年02月

2024年02月29日

- [The All-Seeing Project V2: Towards General Relation Comprehension of the Open World](2024年02月29日/The_All-Seeing_Project_V2_Towards_General_Relation_Comprehension_of_the_Open_World.md)

    - [翻译: 《全知计划V2》：旨在攻克开放世界的通用关系理解难题，探索更全面的关系认知能力。](2024年02月29日/The_All-Seeing_Project_V2_Towards_General_Relation_Comprehension_of_the_Open_World.md)

- [Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models](2024年02月29日/Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre-training_Period_of_Large_Language_Models.md)

    - [翻译: 为探究大型语言模型（LLM）可信度动态变化，我们再次聚焦其预训练阶段，旨在深入理解这一关键阶段对其后续表现和可信度的影响。](2024年02月29日/Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre-training_Period_of_Large_Language_Models.md)

- [Curiosity-driven Red-teaming for Large Language Models](2024年02月29日/Curiosity-driven_Red-teaming_for_Large_Language_Models.md)

    - [翻译: 为探究大型语言模型的安全性与潜在漏洞，我们引入了“好奇心驱动的红队”策略，通过模拟攻击者对大型语言模型进行挑战和检验，以挖掘其可能存在的问题。](2024年02月29日/Curiosity-driven_Red-teaming_for_Large_Language_Models.md)

- [Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models](2024年02月29日/Heavy-Tailed_Class_Imbalance_and_Why_Adam_Outperforms_Gradient_Descent_on_Language_Models.md)

    - [翻译: 在语言模型训练中，Adam 优化器相较于梯度下降法展现出更优性能，这一现象与重尾类别不平衡问题密切相关。本研究探讨了这一特性背后的原因，并揭示了 Adam 如何更好地应对重尾类别不平衡对语言模型训练的影响。](2024年02月29日/Heavy-Tailed_Class_Imbalance_and_Why_Adam_Outperforms_Gradient_Descent_on_Language_Models.md)

- [ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL](2024年02月29日/ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi-Turn_RL.md)

    - [翻译: ArCHer 是一种创新方法，通过运用分层多轮强化学习技术来训练语言模型智能体，使其在复杂对话场景中更具交互性和适应性。](2024年02月29日/ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi-Turn_RL.md)

- [Compositional API Recommendation for Library-Oriented Code Generation](2024年02月29日/Compositional_API_Recommendation_for_Library-Oriented_Code_Generation.md)

    - [翻译: 为实现高效库导向的代码生成，我们提出了一种组合式API推荐方法。该方法旨在探索和推荐适用于此类任务的恰当API组合，以提升编程效率及代码质量。](2024年02月29日/Compositional_API_Recommendation_for_Library-Oriented_Code_Generation.md)

- [Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines](2024年02月29日/Crafting_Knowledge_Exploring_the_Creative_Mechanisms_of_Chat-Based_Search_Engines.md)

    - [翻译: 精心打造知识：深入探索聊天式搜索引擎背后的创新运作机制](2024年02月29日/Crafting_Knowledge_Exploring_the_Creative_Mechanisms_of_Chat-Based_Search_Engines.md)

- [On the Scaling Laws of Geographical Representation in Language Models](2024年02月29日/On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models.md)

    - [翻译: 探究语言模型中地理表示随模型规模变化的规律](2024年02月29日/On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models.md)

- [Entity-Aware Multimodal Alignment Framework for News Image Captioning](2024年02月29日/Entity-Aware_Multimodal_Alignment_Framework_for_News_Image_Captioning.md)

    - [翻译: 我们提出了一种针对新闻图片描述任务的“实体感知多模态对齐框架”，该框架旨在更好地整合和利用图文信息，以提升新闻图片自动描述的质量与准确性。](2024年02月29日/Entity-Aware_Multimodal_Alignment_Framework_for_News_Image_Captioning.md)

- [Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy](2024年02月29日/Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy.md)

    - [翻译: 在“硅智慧群体”中，大型语言模型（LLM）集成预测的准确性已达到与人类群体相当的水平，展示了强大的智能集成预测能力。](2024年02月29日/Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy.md)

- [OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models](2024年02月29日/OpenMedLM_Prompt_engineering_can_out-perform_fine-tuning_in_medical_question-answering_with_open-source_large_language_models.md)

    - [翻译: OpenMedLM 显示，在使用开源大型语言模型处理医疗问答场景时，通过巧妙的提示工程技术，其表现甚至可以优于传统的微调方法。](2024年02月29日/OpenMedLM_Prompt_engineering_can_out-perform_fine-tuning_in_medical_question-answering_with_open-source_large_language_models.md)

- [SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency](2024年02月29日/SoK_Exploring_the_Potential_of_Large_Language_Models_for_Improving_Digital_Forensic_Investigation_Efficiency.md)

    - [翻译: 探究 SoK：大型语言模型如何助力提升数字取证调查效率](2024年02月29日/SoK_Exploring_the_Potential_of_Large_Language_Models_for_Improving_Digital_Forensic_Investigation_Efficiency.md)

- [Watermark Stealing in Large Language Models](2024年02月29日/Watermark_Stealing_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型（LLM）中探讨水印窃取问题](2024年02月29日/Watermark_Stealing_in_Large_Language_Models.md)

- [Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook](2024年02月29日/Deep_Learning_for_Cross-Domain_Data_Fusion_in_Urban_Computing_Taxonomy,_Advances,_and_Outlook.md)

    - [翻译: 在城市计算领域，深度学习驱动的跨域数据融合技术正崭露头角。本文旨在梳理这一领域的分类体系，概述最新的技术进展，并展望未来的研究方向。](2024年02月29日/Deep_Learning_for_Cross-Domain_Data_Fusion_in_Urban_Computing_Taxonomy,_Advances,_and_Outlook.md)

- [Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge](2024年02月29日/Here's_a_Free_Lunch_Sanitizing_Backdoored_Models_with_Model_Merge.md)

    - [翻译: 惊喜呈现：运用模型融合技术，轻松净化遭后门侵入的模型，实现安全“白吃午餐”](2024年02月29日/Here's_a_Free_Lunch_Sanitizing_Backdoored_Models_with_Model_Merge.md)

- [Compact Speech Translation Models via Discrete Speech Units Pretraining](2024年02月29日/Compact_Speech_Translation_Models_via_Discrete_Speech_Units_Pretraining.md)

    - [翻译: 我们提出了一种利用离散语音单元预训练技术打造紧凑型语音翻译模型的方法，该方法能够有效压缩模型体积的同时保持较高的翻译性能。](2024年02月29日/Compact_Speech_Translation_Models_via_Discrete_Speech_Units_Pretraining.md)

- [Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction](2024年02月29日/Generalizable_Whole_Slide_Image_Classification_with_Fine-Grained_Visual-Semantic_Interaction.md)

    - [翻译: 通过细粒度视觉与语义互动实现全切片图像分类的泛化能力](2024年02月29日/Generalizable_Whole_Slide_Image_Classification_with_Fine-Grained_Visual-Semantic_Interaction.md)

- [Solucion exacta para un modelo simplificado de un sistema cuantico abierto](2024年02月29日/Solucion_exacta_para_un_modelo_simplificado_de_un_sistema_cuantico_abierto.md)

    - [翻译: 我们提供了一个简化开放量子系统模型的精确解决方案。这个结果为理解和操控此类复杂系统的动态行为提供了关键洞见。](2024年02月29日/Solucion_exacta_para_un_modelo_simplificado_de_un_sistema_cuantico_abierto.md)

- [RL-GPT: Integrating Reinforcement Learning and Code-as-policy](2024年02月29日/RL-GPT_Integrating_Reinforcement_Learning_and_Code-as-policy.md)

    - [翻译: RL-GPT：融汇强化学习与“代码即策略”思想，实现两者深度整合。](2024年02月29日/RL-GPT_Integrating_Reinforcement_Learning_and_Code-as-policy.md)

- [WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset](2024年02月29日/WanJuan-CC_A_Safe_and_High-Quality_Open-sourced_English_Webtext_Dataset.md)

    - [翻译: WanJuan-CC 是一个公开发布的高品质英文网络文本数据集，注重安全性和高质量标准。](2024年02月29日/WanJuan-CC_A_Safe_and_High-Quality_Open-sourced_English_Webtext_Dataset.md)

- [PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval](2024年02月29日/PlanGPT_Enhancing_Urban_Planning_with_Tailored_Language_Model_and_Efficient_Retrieval.md)

    - [翻译: PlanGPT：针对城市规划领域打造的专属语言模型与高效信息检索技术，旨在显著优化城市规划实践。](2024年02月29日/PlanGPT_Enhancing_Urban_Planning_with_Tailored_Language_Model_and_Efficient_Retrieval.md)

- [GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers](2024年02月29日/GSM-Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers.md)

    - [翻译: GSM-Plus 是一套全面的评测基准，旨在深入检验大型语言模型在解决数学问题时的鲁棒性表现。](2024年02月29日/GSM-Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers.md)

- [Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark](2024年02月29日/Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark.md)

    - [翻译: 面对最新挑战，让大型语言模型 (LLMs) 大显身手！本研究提出了一项针对中文动态问题回答的权威基准。](2024年02月29日/Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark.md)

- [Memory-Augmented Generative Adversarial Transformers](2024年02月29日/Memory-Augmented_Generative_Adversarial_Transformers.md)

    - [翻译: 记忆强化的生成对抗Transformer模型](2024年02月29日/Memory-Augmented_Generative_Adversarial_Transformers.md)

- [PeLLE: Encoder-based language models for Brazilian Portuguese based on open data](2024年02月29日/PeLLE_Encoder-based_language_models_for_Brazilian_Portuguese_based_on_open_data.md)

    - [翻译: PeLLE 是一款以开放数据为基础、专为巴西葡萄牙语设计的编码器式语言模型。](2024年02月29日/PeLLE_Encoder-based_language_models_for_Brazilian_Portuguese_based_on_open_data.md)

- [PRSA: Prompt Reverse Stealing Attacks against Large Language Models](2024年02月29日/PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models.md)

    - [翻译: PRSA：一种针对大型语言模型的新型攻击手段——Prompt Reverse Stealing，通过逆向窃取提示信息对LLM发起挑战。](2024年02月29日/PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models.md)

- [StarCoder 2 and The Stack v2: The Next Generation](2024年02月29日/StarCoder_2_and_The_Stack_v2_The_Next_Generation.md)

    - [翻译: StarCoder 2 与 The Stack v2：引领下一代创新潮流](2024年02月29日/StarCoder_2_and_The_Stack_v2_The_Next_Generation.md)

- [Teaching Large Language Models an Unseen Language on the Fly](2024年02月29日/Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly.md)

    - [翻译: 实时教授大型语言模型掌握新语言](2024年02月29日/Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly.md)

- [Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination](2024年02月29日/Conversational_Language_Models_for_Human-in-the-Loop_Multi-Robot_Coordination.md)

    - [翻译: 针对人参与循环的多机器人协同场景，我们研发了对话式语言模型，以实现高效的沟通与协调。](2024年02月29日/Conversational_Language_Models_for_Human-in-the-Loop_Multi-Robot_Coordination.md)

- [Typographic Attacks in Large Multimodal Models Can be Alleviated by More Informative Prompts](2024年02月29日/Typographic_Attacks_in_Large_Multimodal_Models_Can_be_Alleviated_by_More_Informative_Prompts.md)

    - [翻译: 针对大型多模态模型中出现的排版攻击问题，研究表明提供更多信息量的提示能够有效缓解这一现象。](2024年02月29日/Typographic_Attacks_in_Large_Multimodal_Models_Can_be_Alleviated_by_More_Informative_Prompts.md)

- [Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool](2024年02月29日/Think_Fast,_Think_Slow,_Think_Critical_Designing_an_Automated_Propaganda_Detection_Tool.md)

    - [翻译: 《快思、慢思与批判思考：打造自动化宣传识别工具》](2024年02月29日/Think_Fast,_Think_Slow,_Think_Critical_Designing_an_Automated_Propaganda_Detection_Tool.md)

- [VIXEN: Visual Text Comparison Network for Image Difference Captioning](2024年02月29日/VIXEN_Visual_Text_Comparison_Network_for_Image_Difference_Captioning.md)

    - [翻译: VIXEN——一款专为图像差异描述而设计的视觉文本比较网络，能够精准捕捉并用语言表达图像间的细微差异。](2024年02月29日/VIXEN_Visual_Text_Comparison_Network_for_Image_Difference_Captioning.md)

- [A SOUND APPROACH: Using Large Language Models to generate audio descriptions for egocentric text-audio retrieval](2024年02月29日/A_SOUND_APPROACH_Using_Large_Language_Models_to_generate_audio_descriptions_for_egocentric_text-audio_retrieval.md)

    - [翻译: 采用大模型巧解之道：为基于第一人称视角的文本-音频检索任务自动生成音频描述](2024年02月29日/A_SOUND_APPROACH_Using_Large_Language_Models_to_generate_audio_descriptions_for_egocentric_text-audio_retrieval.md)

- [Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models](2024年02月29日/Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models.md)

    - [翻译: 针对大型语言模型中出现的“虚假前提幻觉”问题，本研究深入剖析并探讨相应的缓解策略，这一现象犹如根基动摇的低语，挑战着我们对人工智能语言理解能力的认知边界。](2024年02月29日/Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models.md)

- [TEncDM: Understanding the Properties of Diffusion Model in the Space of Language Model Encodings](2024年02月29日/TEncDM_Understanding_the_Properties_of_Diffusion_Model_in_the_Space_of_Language_Model_Encodings.md)

    - [翻译: TEncDM项目旨在深入理解扩散模型在语言模型编码空间中的独特性质，研究其内在机制及影响效果。](2024年02月29日/TEncDM_Understanding_the_Properties_of_Diffusion_Model_in_the_Space_of_Language_Model_Encodings.md)

- [A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration](2024年02月29日/A_Protein_Structure_Prediction_Approach_Leveraging_Transformer_and_CNN_Integration.md)

    - [翻译: 我们提出了一种创新的方法，结合了Transformer和CNN技术，以提升蛋白质结构预测的精准度。](2024年02月29日/A_Protein_Structure_Prediction_Approach_Leveraging_Transformer_and_CNN_Integration.md)

- [Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials](2024年02月29日/Pointing_out_the_Shortcomings_of_Relation_Extraction_Models_with_Semantically_Motivated_Adversarials.md)

    - [翻译: 本研究采用语义导向的对抗性手段，精准揭示了关系抽取模型存在的不足之处。](2024年02月29日/Pointing_out_the_Shortcomings_of_Relation_Extraction_Models_with_Semantically_Motivated_Adversarials.md)

- [Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study](2024年02月29日/Exploring_the_Efficacy_of_Large_Language_Models_in_Summarizing_Mental_Health_Counseling_Sessions_A_Benchmark_Study.md)

    - [翻译: 本研究旨在探究大型语言模型在摘要心理健康咨询会谈内容方面的效能，通过设立基准进行深入研究。](2024年02月29日/Exploring_the_Efficacy_of_Large_Language_Models_in_Summarizing_Mental_Health_Counseling_Sessions_A_Benchmark_Study.md)

- [Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models](2024年02月29日/Enhancing_Visual_Document_Understanding_with_Contrastive_Learning_in_Large_Visual-Language_Models.md)

    - [翻译: 针对大型视觉-语言模型，本研究采用对比学习方法以增强对视觉文档的深入理解和解析能力。](2024年02月29日/Enhancing_Visual_Document_Understanding_with_Contrastive_Learning_in_Large_Visual-Language_Models.md)

- [Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding](2024年02月29日/Generating,_Reconstructing,_and_Representing_Discrete_and_Continuous_Data_Generalized_Diffusion_with_Learnable_Encoding-Decoding.md)

    - [翻译: 探究一种能同时处理离散和连续数据的新型广义扩散模型，其具备可学习的编解码结构，能够实现数据的高效生成、精确重建及有效表示。](2024年02月29日/Generating,_Reconstructing,_and_Representing_Discrete_and_Continuous_Data_Generalized_Diffusion_with_Learnable_Encoding-Decoding.md)

- [PopALM: Popularity-Aligned Language Models for Social Media Trendy Response Prediction](2024年02月29日/PopALM_Popularity-Aligned_Language_Models_for_Social_Media_Trendy_Response_Prediction.md)

    - [翻译: PopALM 是一款针对社交媒体趋势回应预测设计的流行度匹配语言模型，它致力于通过结合流行度信息提升对社交媒体热点话题响应预测的准确性。](2024年02月29日/PopALM_Popularity-Aligned_Language_Models_for_Social_Media_Trendy_Response_Prediction.md)

- [Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale Speech Recognition](2024年02月29日/Inappropriate_Pause_Detection_In_Dysarthric_Speech_Using_Large-Scale_Speech_Recognition.md)

    - [翻译: 本研究利用大型语音识别技术，专注于在失语症患者的言语中识别并分析不适当的停顿现象。](2024年02月29日/Inappropriate_Pause_Detection_In_Dysarthric_Speech_Using_Large-Scale_Speech_Recognition.md)

- [AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging](2024年02月29日/AdaMergeX_Cross-Lingual_Transfer_with_Large_Language_Models_via_Adaptive_Adapter_Merging.md)

    - [翻译: AdaMergeX 技术借助自适应适配器融合，实现在大型语言模型中有效进行跨语言迁移。这一方法针对不同语言间的知识转移进行了优化，使得大型语言模型能够在多种语言间灵活应用。](2024年02月29日/AdaMergeX_Cross-Lingual_Transfer_with_Large_Language_Models_via_Adaptive_Adapter_Merging.md)

- [Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning](2024年02月29日/Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning.md)

    - [翻译: 本研究聚焦于深入分析并有效缓解参数高效微调过程中的灾难性遗忘现象。](2024年02月29日/Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning.md)

- [Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling](2024年02月29日/Loose_LIPS_Sink_Ships_Asking_Questions_in_Battleship_with_Language-Informed_Program_Sampling.md)

    - [翻译: 一句老话“口风不紧，沉船千里”，巧妙地借用到战舰游戏中。通过运用语言信息指导的程序采样技术，我们在战舰游戏中提出了创新的提问策略。](2024年02月29日/Loose_LIPS_Sink_Ships_Asking_Questions_in_Battleship_with_Language-Informed_Program_Sampling.md)

- [Gender Bias in Large Language Models across Multiple Languages](2024年02月29日/Gender_Bias_in_Large_Language_Models_across_Multiple_Languages.md)

    - [翻译: 在多种语言环境下，大规模语言模型普遍存在性别偏见问题。](2024年02月29日/Gender_Bias_in_Large_Language_Models_across_Multiple_Languages.md)

- [Extracting Polymer Nanocomposite Samples from Full-Length Documents](2024年02月29日/Extracting_Polymer_Nanocomposite_Samples_from_Full-Length_Documents.md)

    - [翻译: 本研究旨在从全文档中精准抽提聚合物纳米复合材料样本信息，以深入探究其特性与应用。](2024年02月29日/Extracting_Polymer_Nanocomposite_Samples_from_Full-Length_Documents.md)

- [Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models](2024年02月29日/Multimodal_ArXiv_A_Dataset_for_Improving_Scientific_Comprehension_of_Large_Vision-Language_Models.md)

    - [翻译: Multimodal ArXiv 数据集，旨在助力大型视觉-语言模型深化对科学内容的理解与解析。](2024年02月29日/Multimodal_ArXiv_A_Dataset_for_Improving_Scientific_Comprehension_of_Large_Vision-Language_Models.md)

- [Multi-modal Attribute Prompting for Vision-Language Models](2024年02月29日/Multi-modal_Attribute_Prompting_for_Vision-Language_Models.md)

    - [翻译: 针对视觉-语言模型，我们提出多模态属性提示方法，旨在通过融合多种模态信息以提升模型的表现力和理解力。](2024年02月29日/Multi-modal_Attribute_Prompting_for_Vision-Language_Models.md)

- [Improving Socratic Question Generation using Data Augmentation and Preference Optimization](2024年02月29日/Improving_Socratic_Question_Generation_using_Data_Augmentation_and_Preference_Optimization.md)

    - [翻译: 运用数据增强与偏好优化策略提升苏格拉底式问题生成效果，本研究致力于优化和完善该技术在生成高质量、启发性问题方面的表现。](2024年02月29日/Improving_Socratic_Question_Generation_using_Data_Augmentation_and_Preference_Optimization.md)

- [AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs](2024年02月29日/AXOLOTL_Fairness_through_Assisted_Self-Debiasing_of_Large_Language_Model_Outputs.md)

    - [翻译: AXOLOTL项目致力于借助协助大型语言模型进行自我去偏，从而在输出中实现公平性。它聚焦于通过自我校正手段减轻大型语言模型潜在的偏见问题。](2024年02月29日/AXOLOTL_Fairness_through_Assisted_Self-Debiasing_of_Large_Language_Model_Outputs.md)

- [TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision](2024年02月29日/TELEClass_Taxonomy_Enrichment_and_LLM-Enhanced_Hierarchical_Text_Classification_with_Minimal_Supervision.md)

    - [翻译: TELEClass 是一种创新方法，通过最小程度的监督实现对分类法的丰富和完善，并利用大型语言模型（LLM）提升层次文本分类的效果。](2024年02月29日/TELEClass_Taxonomy_Enrichment_and_LLM-Enhanced_Hierarchical_Text_Classification_with_Minimal_Supervision.md)

- [LLMs in Political Science: Heralding a New Era of Visual Analysis](2024年02月29日/LLMs_in_Political_Science_Heralding_a_New_Era_of_Visual_Analysis.md)

    - [翻译: LLMs 正在政治科学领域开启视觉分析新篇章](2024年02月29日/LLMs_in_Political_Science_Heralding_a_New_Era_of_Visual_Analysis.md)

- [FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition](2024年02月29日/FAC$^2$E_Better_Understanding_Large_Language_Model_Capabilities_by_Dissociating_Language_and_Cognition.md)

    - [翻译: FAC$^2$E 方法致力于通过区分语言与认知机制，以更深入地探究大型语言模型的能力。](2024年02月29日/FAC$^2$E_Better_Understanding_Large_Language_Model_Capabilities_by_Dissociating_Language_and_Cognition.md)

- [Resonance RoPE: Improving Context Length Generalization of Large Language Models](2024年02月29日/Resonance_RoPE_Improving_Context_Length_Generalization_of_Large_Language_Models.md)

    - [翻译: Resonance RoPE技术致力于增强大型语言模型对不同上下文长度的适应与泛化能力。](2024年02月29日/Resonance_RoPE_Improving_Context_Length_Generalization_of_Large_Language_Models.md)

- [Artwork Explanation in Large-scale Vision Language Models](2024年02月29日/Artwork_Explanation_in_Large-scale_Vision_Language_Models.md)

    - [翻译: 在大规模视觉语言模型中探究艺术品阐释能力](2024年02月29日/Artwork_Explanation_in_Large-scale_Vision_Language_Models.md)

- [Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization](2024年02月29日/Query-OPT_Optimizing_Inference_of_Large_Language_Models_via_Multi-Query_Instructions_in_Meeting_Summarization.md)

    - [翻译: Query-OPT 方法旨在通过在会议摘要场景下运用多查询指令，提升大型语言模型推理效率。这项研究针对大型语言模型，在会议内容总结任务中探究如何借助多查询指令进行优化推理过程。](2024年02月29日/Query-OPT_Optimizing_Inference_of_Large_Language_Models_via_Multi-Query_Instructions_in_Meeting_Summarization.md)

- [SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation](2024年02月29日/SEED_Customize_Large_Language_Models_with_Sample-Efficient_Adaptation_for_Code_Generation.md)

    - [翻译: SEED 方法致力于通过高效适应的方式定制大规模语言模型，以优化其在代码生成任务中的表现。](2024年02月29日/SEED_Customize_Large_Language_Models_with_Sample-Efficient_Adaptation_for_Code_Generation.md)

- [FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use](2024年02月29日/FhGenie_A_Custom,_Confidentiality-preserving_Chat_AI_for_Corporate_and_Scientific_Use.md)

    - [翻译: FhGenie，一款专门针对企业和科研场景定制的、具备隐私保护功能的聊天 AI 助手](2024年02月29日/FhGenie_A_Custom,_Confidentiality-preserving_Chat_AI_for_Corporate_and_Scientific_Use.md)

- [SoftTiger: A Clinical Foundation Model for Healthcare Workflows](2024年02月29日/SoftTiger_A_Clinical_Foundation_Model_for_Healthcare_Workflows.md)

    - [翻译: SoftTiger，作为一款专为医疗工作流程打造的临床基础模型，旨在提升医疗服务效率与质量。](2024年02月29日/SoftTiger_A_Clinical_Foundation_Model_for_Healthcare_Workflows.md)

- [Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes](2024年02月29日/Gradient_Cuff_Detecting_Jailbreak_Attacks_on_Large_Language_Models_by_Exploring_Refusal_Loss_Landscapes.md)

    - [翻译: Gradient Cuff 技术，通过深入探究大型语言模型中拒绝损失的地形特征，来实现对模型遭受越狱攻击的有效识别。](2024年02月29日/Gradient_Cuff_Detecting_Jailbreak_Attacks_on_Large_Language_Models_by_Exploring_Refusal_Loss_Landscapes.md)

- [LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction](2024年02月29日/LLM-Ensemble_Optimal_Large_Language_Model_Ensemble_Method_for_E-commerce_Product_Attribute_Value_Extraction.md)

    - [翻译: LLM-Ensemble 是一种针对电商领域的产品属性值抽取任务设计出的最优大型语言模型集成方案。](2024年02月29日/LLM-Ensemble_Optimal_Large_Language_Model_Ensemble_Method_for_E-commerce_Product_Attribute_Value_Extraction.md)

- [NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications](2024年02月29日/NewsBench_Systematic_Evaluation_of_LLMs_for_Writing_Proficiency_and_Safety_Adherence_in_Chinese_Journalistic_Editorial_Applications.md)

    - [翻译: NewsBench 是一个系统评估工具，旨在对大型语言模型在中文新闻编辑场景下的写作水平和安全性遵守情况进行深入考察。](2024年02月29日/NewsBench_Systematic_Evaluation_of_LLMs_for_Writing_Proficiency_and_Safety_Adherence_in_Chinese_Journalistic_Editorial_Applications.md)

- [Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs](2024年02月29日/Direct_Alignment_of_Draft_Model_for_Speculative_Decoding_with_Chat-Fine-Tuned_LLMs.md)

    - [翻译: 研究者尝试将草稿模型直接与经聊天数据优化后的大型语言模型对齐，以提升推测解码性能。](2024年02月29日/Direct_Alignment_of_Draft_Model_for_Speculative_Decoding_with_Chat-Fine-Tuned_LLMs.md)

- [Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning](2024年02月29日/Enhancing_Long-Term_Recommendation_with_Bi-level_Learnable_Large_Language_Model_Planning.md)

    - [翻译: 通过运用双层可学习大型语言模型规划技术，提升长期推荐效果。这项研究致力于探索如何借助大型语言模型进行前瞻性的策划，以改善长期推荐性能。](2024年02月29日/Enhancing_Long-Term_Recommendation_with_Bi-level_Learnable_Large_Language_Model_Planning.md)

- [EyeGPT: Ophthalmic Assistant with Large Language Models](2024年02月29日/EyeGPT_Ophthalmic_Assistant_with_Large_Language_Models.md)

    - [翻译: EyeGPT——借助大型语言模型打造的眼科智能助手](2024年02月29日/EyeGPT_Ophthalmic_Assistant_with_Large_Language_Models.md)

- [Retrieval-Augmented Generation for AI-Generated Content: A Survey](2024年02月29日/Retrieval-Augmented_Generation_for_AI-Generated_Content_A_Survey.md)

    - [翻译: 本篇综述聚焦于“检索增强生成”这一技术在AI生成内容领域的应用与发展，深度剖析了该技术如何通过整合检索与生成过程，提升AI内容创作的质量与智能性。](2024年02月29日/Retrieval-Augmented_Generation_for_AI-Generated_Content_A_Survey.md)

- [RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval](2024年02月29日/RNNs_are_not_Transformers_(Yet)_The_Key_Bottleneck_on_In-context_Retrieval.md)

    - [翻译: RNN 仍未进化为 Transformers：揭示 In-context 检索面临的核心难题](2024年02月29日/RNNs_are_not_Transformers_(Yet)_The_Key_Bottleneck_on_In-context_Retrieval.md)

- [Retrieval is Accurate Generation](2024年02月29日/Retrieval_is_Accurate_Generation.md)

    - [翻译: 检索，实现精准生成](2024年02月29日/Retrieval_is_Accurate_Generation.md)

- [Language Models Represent Beliefs of Self and Others](2024年02月29日/Language_Models_Represent_Beliefs_of_Self_and_Others.md)

    - [翻译: 语言模型能够体现自身及他人观念](2024年02月29日/Language_Models_Represent_Beliefs_of_Self_and_Others.md)

2024年02月28日

- [Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence](2024年02月28日/Enhancing_Steganographic_Text_Extraction_Evaluating_the_Impact_of_NLP_Models_on_Accuracy_and_Semantic_Coherence.md)

    - [翻译: 提升隐写文本抽取效果：通过探究NLP模型对抽取准确度及语义连贯性的影响，本研究旨在优化隐写文本提取技术。](2024年02月28日/Enhancing_Steganographic_Text_Extraction_Evaluating_the_Impact_of_NLP_Models_on_Accuracy_and_Semantic_Coherence.md)

- [Dual Operating Modes of In-Context Learning](2024年02月28日/Dual_Operating_Modes_of_In-Context_Learning.md)

    - [翻译: ICL 的双重工作模式解读](2024年02月28日/Dual_Operating_Modes_of_In-Context_Learning.md)

- [How do Large Language Models Handle Multilingualism?](2024年02月28日/How_do_Large_Language_Models_Handle_Multilingualism.md)

    - [翻译: 探究大型语言模型如何应对多语言场景](2024年02月28日/How_do_Large_Language_Models_Handle_Multilingualism.md)

- [On the Decision-Making Abilities in Role-Playing using Large Language Models](2024年02月28日/On_the_Decision-Making_Abilities_in_Role-Playing_using_Large_Language_Models.md)

    - [翻译: 探究大型语言模型在角色扮演场景中的决策制定能力](2024年02月28日/On_the_Decision-Making_Abilities_in_Role-Playing_using_Large_Language_Models.md)

- [MOSAIC: A Modular System for Assistive and Interactive Cooking](2024年02月28日/MOSAIC_A_Modular_System_for_Assistive_and_Interactive_Cooking.md)

    - [翻译: MOSAIC——一款模块化设计的智能烹饪系统，旨在提供辅助与互动式的烹饪体验。](2024年02月28日/MOSAIC_A_Modular_System_for_Assistive_and_Interactive_Cooking.md)

- [Learning to Deliver: a Foundation Model for the Montreal Capacitated Vehicle Routing Problem](2024年02月28日/Learning_to_Deliver_a_Foundation_Model_for_the_Montreal_Capacitated_Vehicle_Routing_Problem.md)

    - [翻译: 致力于解决实际问题，《学习交付：构建蒙特利尔载货车辆路径问题的基础模型》一文，旨在探索并提出一种针对载货车辆在蒙特利尔地区进行高效路线规划的基础模型。](2024年02月28日/Learning_to_Deliver_a_Foundation_Model_for_the_Montreal_Capacitated_Vehicle_Routing_Problem.md)

- [ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph](2024年02月28日/ToolNet_Connecting_Large_Language_Models_with_Massive_Tools_via_Tool_Graph.md)

    - [翻译: ToolNet 利用工具图这一桥梁，巧妙地将大型语言模型与海量工具紧密相连。](2024年02月28日/ToolNet_Connecting_Large_Language_Models_with_Massive_Tools_via_Tool_Graph.md)

- [CLLMs: Consistency Large Language Models](2024年02月28日/CLLMs_Consistency_Large_Language_Models.md)

    - [翻译: CLLMs，即一致性大型语言模型，是针对提升模型输出稳定性和可靠性的新型研究方向。](2024年02月28日/CLLMs_Consistency_Large_Language_Models.md)

- [MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices](2024年02月28日/MedAide_Leveraging_Large_Language_Models_for_On-Premise_Medical_Assistance_on_Edge_Devices.md)

    - [翻译: MedAide项目旨在利用大型语言模型，在边缘设备上实现即时的本地医疗辅助功能。](2024年02月28日/MedAide_Leveraging_Large_Language_Models_for_On-Premise_Medical_Assistance_on_Edge_Devices.md)

- [Grounding Language Models for Visual Entity Recognition](2024年02月28日/Grounding_Language_Models_for_Visual_Entity_Recognition.md)

    - [翻译: 为视觉实体识别而进行的语言模型接地技术，旨在探究如何使语言模型更好地理解和利用视觉信息，从而提升识别图像中特定实体的能力。](2024年02月28日/Grounding_Language_Models_for_Visual_Entity_Recognition.md)

- [Approaching Human-Level Forecasting with Language Models](2024年02月28日/Approaching_Human-Level_Forecasting_with_Language_Models.md)

    - [翻译: 运用语言模型以期在预测能力上接近人类水准](2024年02月28日/Approaching_Human-Level_Forecasting_with_Language_Models.md)

- [Cutting Off the Head Ends the Conflict: A Mechanism for Interpreting and Mitigating Knowledge Conflicts in Language Models](2024年02月28日/Cutting_Off_the_Head_Ends_the_Conflict_A_Mechanism_for_Interpreting_and_Mitigating_Knowledge_Conflicts_in_Language_Models.md)

    - [翻译: 斩断“首因”，化解冲突：探寻语言模型中知识冲突的解读与调和机制](2024年02月28日/Cutting_Off_the_Head_Ends_the_Conflict_A_Mechanism_for_Interpreting_and_Mitigating_Knowledge_Conflicts_in_Language_Models.md)

- [Unsupervised Information Refinement Training of Large Language Models for Retrieval-Augmented Generation](2024年02月28日/Unsupervised_Information_Refinement_Training_of_Large_Language_Models_for_Retrieval-Augmented_Generation.md)

    - [翻译: 针对增强检索式生成任务，我们对大型语言模型进行无监督的信息提炼训练，旨在提升其从海量数据中自动提炼关键信息的能力，并将其应用于生成过程以提高输出质量。](2024年02月28日/Unsupervised_Information_Refinement_Training_of_Large_Language_Models_for_Retrieval-Augmented_Generation.md)

- [FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability](2024年02月28日/FOFO_A_Benchmark_to_Evaluate_LLMs'_Format-Following_Capability.md)

    - [翻译: FOFO 是一个专门针对大型语言模型（LLMs）格式跟随能力评估的基准测试工具，旨在衡量和比较不同模型在遵循预设格式要求方面的表现。](2024年02月28日/FOFO_A_Benchmark_to_Evaluate_LLMs'_Format-Following_Capability.md)

- [Beyond Natural Language: LLMs Leveraging Alternative Formats for Enhanced Reasoning and Communication](2024年02月28日/Beyond_Natural_Language_LLMs_Leveraging_Alternative_Formats_for_Enhanced_Reasoning_and_Communication.md)

    - [翻译: 不止步于自然语言，LLMs 正探索利用其他格式以提升推理与沟通表现步骤 1 翻译：在自然语言之外：大型语言模型 (LLMs) 利用替代格式来增强推理和交流的能力步骤 2 优化： LLMS 不再局限于自然语言范畴，而是开始借助其他格式资源以提升其推理和沟通效率。](2024年02月28日/Beyond_Natural_Language_LLMs_Leveraging_Alternative_Formats_for_Enhanced_Reasoning_and_Communication.md)

2024年02月27日

- [Prioritizing Informative Features and Examples for Deep Learning from Noisy Data](2024年02月27日/Prioritizing_Informative_Features_and_Examples_for_Deep_Learning_from_Noisy_Data.md)

    - [翻译: 在嘈杂数据中进行深度学习时，我们致力于优先挖掘并利用富含信息的特征及代表性示例。](2024年02月27日/Prioritizing_Informative_Features_and_Examples_for_Deep_Learning_from_Noisy_Data.md)

- [Follow My Instruction and Spill the Beans: Scalable Data Extraction from Retrieval-Augmented Generation Systems](2024年02月27日/Follow_My_Instruction_and_Spill_the_Beans_Scalable_Data_Extraction_from_Retrieval-Augmented_Generation_Systems.md)

    - [翻译: 跟随我的指引，揭开谜底：在检索增强型生成系统中实现大规模数据抽取](2024年02月27日/Follow_My_Instruction_and_Spill_the_Beans_Scalable_Data_Extraction_from_Retrieval-Augmented_Generation_Systems.md)

- [Evaluating Very Long-Term Conversational Memory of LLM Agents](2024年02月27日/Evaluating_Very_Long-Term_Conversational_Memory_of_LLM_Agents.md)

    - [翻译: 本研究致力于考察LLM（大型语言模型）在对话场景下的非常长期记忆能力。](2024年02月27日/Evaluating_Very_Long-Term_Conversational_Memory_of_LLM_Agents.md)

- [REAR: A Relevance-Aware Retrieval-Augmented Framework for Open-Domain Question Answering](2024年02月27日/REAR_A_Relevance-Aware_Retrieval-Augmented_Framework_for_Open-Domain_Question_Answering.md)

    - [翻译: REAR 是一个专为解决开放领域问题而设计的智能框架，它融合了相关性感知检索技术以增强其功能。这个新颖的框架通过利用相关性意识提升信息检索能力，在开放领域问题回答任务中展现出卓越性能。](2024年02月27日/REAR_A_Relevance-Aware_Retrieval-Augmented_Framework_for_Open-Domain_Question_Answering.md)

- [Deep Learning Based Named Entity Recognition Models for Recipes](2024年02月27日/Deep_Learning_Based_Named_Entity_Recognition_Models_for_Recipes.md)

    - [翻译: 本研究探讨了利用深度学习技术构建的食谱命名实体识别模型，以实现对食谱中各类实体信息的精准识别与提取。](2024年02月27日/Deep_Learning_Based_Named_Entity_Recognition_Models_for_Recipes.md)

- [Self-Refinement of Language Models from External Proxy Metrics Feedback](2024年02月27日/Self-Refinement_of_Language_Models_from_External_Proxy_Metrics_Feedback.md)

    - [翻译: 通过利用外部代理指标的反馈，语言模型能够实现自我优化和提升。](2024年02月27日/Self-Refinement_of_Language_Models_from_External_Proxy_Metrics_Feedback.md)

- [MEGAnno+: A Human-LLM Collaborative Annotation System](2024年02月27日/MEGAnno+_A_Human-LLM_Collaborative_Annotation_System.md)

    - [翻译: MEGAnno+ 是一款创新的人类与大型语言模型协同标注工具，旨在通过整合人类智慧与先进AI技术的力量，共同提升数据标注效率与质量。](2024年02月27日/MEGAnno+_A_Human-LLM_Collaborative_Annotation_System.md)

- [Pragmatic Instruction Following and Goal Assistance via Cooperative Language-Guided Inverse Planning](2024年02月27日/Pragmatic_Instruction_Following_and_Goal_Assistance_via_Cooperative_Language-Guided_Inverse_Planning.md)

    - [翻译: 借助于合作性的、以语言指导的逆向规划方法，我们能够实现对实用指令的有效遵循及目标辅助功能。](2024年02月27日/Pragmatic_Instruction_Following_and_Goal_Assistance_via_Cooperative_Language-Guided_Inverse_Planning.md)

2024年02月26日

- [Retrieval Augmented Generation Systems: Automatic Dataset Creation, Evaluation and Boolean Agent Setup](2024年02月26日/Retrieval_Augmented_Generation_Systems_Automatic_Dataset_Creation,_Evaluation_and_Boolean_Agent_Setup.md)

    - [翻译: 检索增强生成系统通过自动构建数据集、进行系统评估及配置布尔代理，助力提升模型性能。](2024年02月26日/Retrieval_Augmented_Generation_Systems_Automatic_Dataset_Creation,_Evaluation_and_Boolean_Agent_Setup.md)

- [Fact-and-Reflection (FaR) Improves Confidence Calibration of Large Language Models](2024年02月26日/Fact-and-Reflection_(FaR)_Improves_Confidence_Calibration_of_Large_Language_Models.md)

    - [翻译: FaR 策略能够有效提升大型语言模型在输出时的信心校准度，让模型对自身预测的准确性有更好的把握。](2024年02月26日/Fact-and-Reflection_(FaR)_Improves_Confidence_Calibration_of_Large_Language_Models.md)

- [A Fine-tuning Enhanced RAG System with Quantized Influence Measure as AI Judge](2024年02月26日/A_Fine-tuning_Enhanced_RAG_System_with_Quantized_Influence_Measure_as_AI_Judge.md)

    - [翻译: 我们提出了一种改进版的RAG系统，通过Fine-tuning技术加强，并引入了量化影响力指标作为智能评判机制。](2024年02月26日/A_Fine-tuning_Enhanced_RAG_System_with_Quantized_Influence_Measure_as_AI_Judge.md)

- [GISTEmbed: Guided In-sample Selection of Training Negatives for Text Embedding Fine-tuning](2024年02月26日/GISTEmbed_Guided_In-sample_Selection_of_Training_Negatives_for_Text_Embedding_Fine-tuning.md)

    - [翻译: GISTEmbed 是一种创新方法，旨在通过引导式的样本内负例选择策略优化文本嵌入微调过程。该技术专为提升文本embedding在训练阶段的效果而设计，尤其关注有效筛选和利用训练集中内在的负样本。](2024年02月26日/GISTEmbed_Guided_In-sample_Selection_of_Training_Negatives_for_Text_Embedding_Fine-tuning.md)

- [Long-Context Language Modeling with Parallel Context Encoding](2024年02月26日/Long-Context_Language_Modeling_with_Parallel_Context_Encoding.md)

    - [翻译: 通过并行上下文编码技术实现长文本上下文的语言模型构建](2024年02月26日/Long-Context_Language_Modeling_with_Parallel_Context_Encoding.md)

- [RetrievalQA: Assessing Adaptive Retrieval-Augmented Generation for Short-form Open-Domain Question Answering](2024年02月26日/RetrievalQA_Assessing_Adaptive_Retrieval-Augmented_Generation_for_Short-form_Open-Domain_Question_Answering.md)

    - [翻译: RetrievalQA 项目旨在测评适应性检索增强技术在短篇开放领域问答任务上的表现。这项研究关注于利用检索技术提升生成式模型解答问题的能力，在开放式问题回答场景下，探索检索增强生成的有效性和适用性。](2024年02月26日/RetrievalQA_Assessing_Adaptive_Retrieval-Augmented_Generation_for_Short-form_Open-Domain_Question_Answering.md)

- [From RAGs to riches: Using large language models to write documents for clinical trials](2024年02月26日/From_RAGs_to_riches_Using_large_language_models_to_write_documents_for_clinical_trials.md)

    - [翻译: 通过运用大型语言模型，我们开启了从 RAGs 迈向丰富内容的旅程，致力于借助这一技术为临床试验撰写高质量文档。](2024年02月26日/From_RAGs_to_riches_Using_large_language_models_to_write_documents_for_clinical_trials.md)

2024年02月25日

- [CFRet-DVQA: Coarse-to-Fine Retrieval and Efficient Tuning for Document Visual Question Answering](2024年02月25日/CFRet-DVQA_Coarse-to-Fine_Retrieval_and_Efficient_Tuning_for_Document_Visual_Question_Answering.md)

    - [翻译: CFRet-DVQA 是一种创新的方法，应用于文档视觉问答任务中，通过粗到细的检索策略和高效的模型微调技术，旨在提升问题解答的准确性和效率。](2024年02月25日/CFRet-DVQA_Coarse-to-Fine_Retrieval_and_Efficient_Tuning_for_Document_Visual_Question_Answering.md)

- [Evaluating Robustness of Generative Search Engine on Adversarial Factual Questions](2024年02月25日/Evaluating_Robustness_of_Generative_Search_Engine_on_Adversarial_Factual_Questions.md)

    - [翻译: 本研究致力于评估生成式搜索引擎在应对具有挑战性的对抗性事实问题时的稳定性和可靠性。](2024年02月25日/Evaluating_Robustness_of_Generative_Search_Engine_on_Adversarial_Factual_Questions.md)

2024年02月24日

- [Bootstrapping Cognitive Agents with a Large Language Model](2024年02月24日/Bootstrapping_Cognitive_Agents_with_a_Large_Language_Model.md)

    - [翻译: 通过运用大型语言模型，实现认知智能体的自举学习之旅](2024年02月24日/Bootstrapping_Cognitive_Agents_with_a_Large_Language_Model.md)

- [Enhanced User Interaction in Operating Systems through Machine Learning Language Models](2024年02月24日/Enhanced_User_Interaction_in_Operating_Systems_through_Machine_Learning_Language_Models.md)

    - [翻译: 运用机器学习语言模型优化操作系统，以增强用户互动性](2024年02月24日/Enhanced_User_Interaction_in_Operating_Systems_through_Machine_Learning_Language_Models.md)

- [MemeCraft: Contextual and Stance-Driven Multimodal Meme Generation](2024年02月24日/MemeCraft_Contextual_and_Stance-Driven_Multimodal_Meme_Generation.md)

    - [翻译: MemeCraft 是一种融合了上下文理解和立场驱动机制的多模态表情包生成方法。](2024年02月24日/MemeCraft_Contextual_and_Stance-Driven_Multimodal_Meme_Generation.md)

2024年02月23日

- [The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)](2024年02月23日/The_Good_and_The_Bad_Exploring_Privacy_Issues_in_Retrieval-Augmented_Generation_(RAG).md)

    - [翻译: 深入剖析 RAG 中的隐私议题，既揭示其优点也关注存在的隐患。](2024年02月23日/The_Good_and_The_Bad_Exploring_Privacy_Issues_in_Retrieval-Augmented_Generation_(RAG).md)

- [Causal Graph Discovery with Retrieval-Augmented Generation based Large Language Models](2024年02月23日/Causal_Graph_Discovery_with_Retrieval-Augmented_Generation_based_Large_Language_Models.md)

    - [翻译: 借助大规模检索增强型生成语言模型，探索和揭示因果图结构](2024年02月23日/Causal_Graph_Discovery_with_Retrieval-Augmented_Generation_based_Large_Language_Models.md)

2024年02月22日

- [Large Language Models as Urban Residents: An LLM Agent Framework for Personal Mobility Generation](2024年02月22日/Large_Language_Models_as_Urban_Residents_An_LLM_Agent_Framework_for_Personal_Mobility_Generation.md)

    - [翻译: 将大型语言模型视为都市生活者，我们提出了一种全新的LLM代理框架，应用于个性化出行方案生成。](2024年02月22日/Large_Language_Models_as_Urban_Residents_An_LLM_Agent_Framework_for_Personal_Mobility_Generation.md)

- [UFO: a Unified and Flexible Framework for Evaluating Factuality of Large Language Models](2024年02月22日/UFO_a_Unified_and_Flexible_Framework_for_Evaluating_Factuality_of_Large_Language_Models.md)

    - [翻译: UFO，作为一款统一且颇具灵活性的框架，专注于对大型语言模型的事实性进行精准评估。](2024年02月22日/UFO_a_Unified_and_Flexible_Framework_for_Evaluating_Factuality_of_Large_Language_Models.md)

- [MeTMaP: Metamorphic Testing for Detecting False Vector Matching Problems in LLM Augmented Generation](2024年02月22日/MeTMaP_Metamorphic_Testing_for_Detecting_False_Vector_Matching_Problems_in_LLM_Augmented_Generation.md)

    - [翻译: MeTMaP是一种应用于LLM增强生成场景的变形测试技术，旨在有效发现并解决其中的虚假向量匹配问题。](2024年02月22日/MeTMaP_Metamorphic_Testing_for_Detecting_False_Vector_Matching_Problems_in_LLM_Augmented_Generation.md)

- [Assessing generalization capability of text ranking models in Polish](2024年02月22日/Assessing_generalization_capability_of_text_ranking_models_in_Polish.md)

    - [翻译: 本研究旨在深入探讨波兰语环境下文本排名模型的泛化性能，以期对其在不同场景下的适用性有更全面的理解和评价。](2024年02月22日/Assessing_generalization_capability_of_text_ranking_models_in_Polish.md)

2024年02月21日

- [Assisting in Writing Wikipedia-like Articles From Scratch with Large Language Models](2024年02月21日/Assisting_in_Writing_Wikipedia-like_Articles_From_Scratch_with_Large_Language_Models.md)

    - [翻译: 本研究探讨如何借助大型语言模型，助力用户从头创作出类似维基百科风格的文章。](2024年02月21日/Assisting_in_Writing_Wikipedia-like_Articles_From_Scratch_with_Large_Language_Models.md)

- [MORE: Multi-mOdal REtrieval Augmented Generative Commonsense Reasoning](2024年02月21日/MORE_Multi-mOdal_REtrieval_Augmented_Generative_Commonsense_Reasoning.md)

    - [翻译: MORE，一种创新方法，通过引入多模态检索增强技术，提升生成性常识推理的表现力和准确性。](2024年02月21日/MORE_Multi-mOdal_REtrieval_Augmented_Generative_Commonsense_Reasoning.md)

- [ActiveRAG: Revealing the Treasures of Knowledge via Active Learning](2024年02月21日/ActiveRAG_Revealing_the_Treasures_of_Knowledge_via_Active_Learning.md)

    - [翻译: ActiveRAG——借助主动学习挖掘知识宝库](2024年02月21日/ActiveRAG_Revealing_the_Treasures_of_Knowledge_via_Active_Learning.md)

- [ARL2: Aligning Retrievers for Black-box Large Language Models via Self-guided Adaptive Relevance Labeling](2024年02月21日/ARL2_Aligning_Retrievers_for_Black-box_Large_Language_Models_via_Self-guided_Adaptive_Relevance_Labeling.md)

    - [翻译: ARL2 方法旨在通过自我指导适应性相关性标注技术，实现对黑盒式大型语言模型检索器的精准对齐，以提升其性能。](2024年02月21日/ARL2_Aligning_Retrievers_for_Black-box_Large_Language_Models_via_Self-guided_Adaptive_Relevance_Labeling.md)

- [CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing](2024年02月21日/CRITIC_Large_Language_Models_Can_Self-Correct_with_Tool-Interactive_Critiquing.md)

    - [翻译: CRITIC 研究：大型语言模型能通过与工具的互动批评实现自我修正。](2024年02月21日/CRITIC_Large_Language_Models_Can_Self-Correct_with_Tool-Interactive_Critiquing.md)

2024年02月16日

- [LLMs in the Heart of Differential Testing: A Case Study on a Medical Rule Engine](2024年02月16日/LLMs_in_the_Heart_of_Differential_Testing_A_Case_Study_on_a_Medical_Rule_Engine.md)

    - [翻译: 大型语言模型成为差异测试的核心：探索医学规则引擎的案例分析](2024年02月16日/LLMs_in_the_Heart_of_Differential_Testing_A_Case_Study_on_a_Medical_Rule_Engine.md)

2024年02月15日

- [X-lifecycle Learning for Cloud Incident Management using LLMs](2024年02月15日/X-lifecycle_Learning_for_Cloud_Incident_Management_using_LLMs.md)

    - [翻译: 通过大型语言模型实现云事件管理的全生命周期学习策略。](2024年02月15日/X-lifecycle_Learning_for_Cloud_Incident_Management_using_LLMs.md)

2024年02月07日

- [Continual Learning for Large Language Models: A Survey](2024年02月07日/Continual_Learning_for_Large_Language_Models_A_Survey.md)

    - [翻译: 针对大型语言模型的持续学习，本文进行了全面调查。](2024年02月07日/Continual_Learning_for_Large_Language_Models_A_Survey.md)

2024年02月06日

- [Enhancing Retrieval Processes for Language Generation with Augmented Queries](2024年02月06日/Enhancing_Retrieval_Processes_for_Language_Generation_with_Augmented_Queries.md)

    - [翻译: 我们提出了一种增强查询方法，旨在改进语言生成任务中的检索过程，从而提高整体性能和效果。](2024年02月06日/Enhancing_Retrieval_Processes_for_Language_Generation_with_Augmented_Queries.md)

2024年02月04日

- [Improving Assessment of Tutoring Practices using Retrieval-Augmented Generation](2024年02月04日/Improving_Assessment_of_Tutoring_Practices_using_Retrieval-Augmented_Generation.md)

    - [翻译: 借助于“检索增强生成”技术，我们旨在提升对辅导实践效果的精准评估。](2024年02月04日/Improving_Assessment_of_Tutoring_Practices_using_Retrieval-Augmented_Generation.md)