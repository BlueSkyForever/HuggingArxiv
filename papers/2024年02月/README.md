# 2024年02月

- [Prioritizing Informative Features and Examples for Deep Learning from Noisy Data](papers/2024年02月/2024年02月27日/Prioritizing_Informative_Features_and_Examples_for_Deep_Learning_from_Noisy_Data.md)

    - [翻译: 在嘈杂数据中进行深度学习时，我们致力于优先挖掘并利用富含信息的特征及代表性示例。](papers/2024年02月/2024年02月27日/Prioritizing_Informative_Features_and_Examples_for_Deep_Learning_from_Noisy_Data.md)

- [Enhancing Steganographic Text Extraction: Evaluating the Impact of NLP Models on Accuracy and Semantic Coherence](papers/2024年02月/2024年02月28日/Enhancing_Steganographic_Text_Extraction_Evaluating_the_Impact_of_NLP_Models_on_Accuracy_and_Semantic_Coherence.md)

    - [翻译: 提升隐写文本抽取效果：通过探究NLP模型对抽取准确度及语义连贯性的影响，本研究旨在优化隐写文本提取技术。](papers/2024年02月/2024年02月28日/Enhancing_Steganographic_Text_Extraction_Evaluating_the_Impact_of_NLP_Models_on_Accuracy_and_Semantic_Coherence.md)

- [Dual Operating Modes of In-Context Learning](papers/2024年02月/2024年02月28日/Dual_Operating_Modes_of_In-Context_Learning.md)

    - [翻译: ICL 的双重工作模式解读](papers/2024年02月/2024年02月28日/Dual_Operating_Modes_of_In-Context_Learning.md)

- [How do Large Language Models Handle Multilingualism?](papers/2024年02月/2024年02月28日/How_do_Large_Language_Models_Handle_Multilingualism.md)

    - [翻译: 探究大型语言模型如何应对多语言场景](papers/2024年02月/2024年02月28日/How_do_Large_Language_Models_Handle_Multilingualism.md)

- [On the Decision-Making Abilities in Role-Playing using Large Language Models](papers/2024年02月/2024年02月28日/On_the_Decision-Making_Abilities_in_Role-Playing_using_Large_Language_Models.md)

    - [翻译: 探究大型语言模型在角色扮演场景中的决策制定能力](papers/2024年02月/2024年02月28日/On_the_Decision-Making_Abilities_in_Role-Playing_using_Large_Language_Models.md)

- [MOSAIC: A Modular System for Assistive and Interactive Cooking](papers/2024年02月/2024年02月28日/MOSAIC_A_Modular_System_for_Assistive_and_Interactive_Cooking.md)

    - [翻译: MOSAIC——一款模块化设计的智能烹饪系统，旨在提供辅助与互动式的烹饪体验。](papers/2024年02月/2024年02月28日/MOSAIC_A_Modular_System_for_Assistive_and_Interactive_Cooking.md)

- [Learning to Deliver: a Foundation Model for the Montreal Capacitated Vehicle Routing Problem](papers/2024年02月/2024年02月28日/Learning_to_Deliver_a_Foundation_Model_for_the_Montreal_Capacitated_Vehicle_Routing_Problem.md)

    - [翻译: 致力于解决实际问题，《学习交付：构建蒙特利尔载货车辆路径问题的基础模型》一文，旨在探索并提出一种针对载货车辆在蒙特利尔地区进行高效路线规划的基础模型。](papers/2024年02月/2024年02月28日/Learning_to_Deliver_a_Foundation_Model_for_the_Montreal_Capacitated_Vehicle_Routing_Problem.md)

- [ToolNet: Connecting Large Language Models with Massive Tools via Tool Graph](papers/2024年02月/2024年02月28日/ToolNet_Connecting_Large_Language_Models_with_Massive_Tools_via_Tool_Graph.md)

    - [翻译: ToolNet 利用工具图这一桥梁，巧妙地将大型语言模型与海量工具紧密相连。](papers/2024年02月/2024年02月28日/ToolNet_Connecting_Large_Language_Models_with_Massive_Tools_via_Tool_Graph.md)

- [CLLMs: Consistency Large Language Models](papers/2024年02月/2024年02月28日/CLLMs_Consistency_Large_Language_Models.md)

    - [翻译: CLLMs，即一致性大型语言模型，是针对提升模型输出稳定性和可靠性的新型研究方向。](papers/2024年02月/2024年02月28日/CLLMs_Consistency_Large_Language_Models.md)

- [MedAide: Leveraging Large Language Models for On-Premise Medical Assistance on Edge Devices](papers/2024年02月/2024年02月28日/MedAide_Leveraging_Large_Language_Models_for_On-Premise_Medical_Assistance_on_Edge_Devices.md)

    - [翻译: MedAide项目旨在利用大型语言模型，在边缘设备上实现即时的本地医疗辅助功能。](papers/2024年02月/2024年02月28日/MedAide_Leveraging_Large_Language_Models_for_On-Premise_Medical_Assistance_on_Edge_Devices.md)

- [The All-Seeing Project V2: Towards General Relation Comprehension of the Open World](papers/2024年02月/2024年02月29日/The_All-Seeing_Project_V2_Towards_General_Relation_Comprehension_of_the_Open_World.md)

    - [翻译: 《全知计划V2》：旨在攻克开放世界的通用关系理解难题，探索更全面的关系认知能力。](papers/2024年02月/2024年02月29日/The_All-Seeing_Project_V2_Towards_General_Relation_Comprehension_of_the_Open_World.md)

- [Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models](papers/2024年02月/2024年02月29日/Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre-training_Period_of_Large_Language_Models.md)

    - [翻译: 为探究大型语言模型（LLM）可信度动态变化，我们再次聚焦其预训练阶段，旨在深入理解这一关键阶段对其后续表现和可信度的影响。](papers/2024年02月/2024年02月29日/Towards_Tracing_Trustworthiness_Dynamics_Revisiting_Pre-training_Period_of_Large_Language_Models.md)

- [Curiosity-driven Red-teaming for Large Language Models](papers/2024年02月/2024年02月29日/Curiosity-driven_Red-teaming_for_Large_Language_Models.md)

    - [翻译: 为探究大型语言模型的安全性与潜在漏洞，我们引入了“好奇心驱动的红队”策略，通过模拟攻击者对大型语言模型进行挑战和检验，以挖掘其可能存在的问题。](papers/2024年02月/2024年02月29日/Curiosity-driven_Red-teaming_for_Large_Language_Models.md)

- [Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models](papers/2024年02月/2024年02月29日/Heavy-Tailed_Class_Imbalance_and_Why_Adam_Outperforms_Gradient_Descent_on_Language_Models.md)

    - [翻译: 在语言模型训练中，Adam 优化器相较于梯度下降法展现出更优性能，这一现象与重尾类别不平衡问题密切相关。本研究探讨了这一特性背后的原因，并揭示了 Adam 如何更好地应对重尾类别不平衡对语言模型训练的影响。](papers/2024年02月/2024年02月29日/Heavy-Tailed_Class_Imbalance_and_Why_Adam_Outperforms_Gradient_Descent_on_Language_Models.md)

- [ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL](papers/2024年02月/2024年02月29日/ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi-Turn_RL.md)

    - [翻译: ArCHer 是一种创新方法，通过运用分层多轮强化学习技术来训练语言模型智能体，使其在复杂对话场景中更具交互性和适应性。](papers/2024年02月/2024年02月29日/ArCHer_Training_Language_Model_Agents_via_Hierarchical_Multi-Turn_RL.md)

- [Compositional API Recommendation for Library-Oriented Code Generation](papers/2024年02月/2024年02月29日/Compositional_API_Recommendation_for_Library-Oriented_Code_Generation.md)

    - [翻译: 为实现高效库导向的代码生成，我们提出了一种组合式API推荐方法。该方法旨在探索和推荐适用于此类任务的恰当API组合，以提升编程效率及代码质量。](papers/2024年02月/2024年02月29日/Compositional_API_Recommendation_for_Library-Oriented_Code_Generation.md)

- [Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines](papers/2024年02月/2024年02月29日/Crafting_Knowledge_Exploring_the_Creative_Mechanisms_of_Chat-Based_Search_Engines.md)

    - [翻译: 精心打造知识：深入探索聊天式搜索引擎背后的创新运作机制](papers/2024年02月/2024年02月29日/Crafting_Knowledge_Exploring_the_Creative_Mechanisms_of_Chat-Based_Search_Engines.md)

- [On the Scaling Laws of Geographical Representation in Language Models](papers/2024年02月/2024年02月29日/On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models.md)

    - [翻译: 探究语言模型中地理表示随模型规模变化的规律](papers/2024年02月/2024年02月29日/On_the_Scaling_Laws_of_Geographical_Representation_in_Language_Models.md)

- [Entity-Aware Multimodal Alignment Framework for News Image Captioning](papers/2024年02月/2024年02月29日/Entity-Aware_Multimodal_Alignment_Framework_for_News_Image_Captioning.md)

    - [翻译: 我们提出了一种针对新闻图片描述任务的“实体感知多模态对齐框架”，该框架旨在更好地整合和利用图文信息，以提升新闻图片自动描述的质量与准确性。](papers/2024年02月/2024年02月29日/Entity-Aware_Multimodal_Alignment_Framework_for_News_Image_Captioning.md)

- [Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy](papers/2024年02月/2024年02月29日/Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy.md)

    - [翻译: 在“硅智慧群体”中，大型语言模型（LLM）集成预测的准确性已达到与人类群体相当的水平，展示了强大的智能集成预测能力。](papers/2024年02月/2024年02月29日/Wisdom_of_the_Silicon_Crowd_LLM_Ensemble_Prediction_Capabilities_Match_Human_Crowd_Accuracy.md)

- [OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models](papers/2024年02月/2024年02月29日/OpenMedLM_Prompt_engineering_can_out-perform_fine-tuning_in_medical_question-answering_with_open-source_large_language_models.md)

    - [翻译: OpenMedLM 显示，在使用开源大型语言模型处理医疗问答场景时，通过巧妙的提示工程技术，其表现甚至可以优于传统的微调方法。](papers/2024年02月/2024年02月29日/OpenMedLM_Prompt_engineering_can_out-perform_fine-tuning_in_medical_question-answering_with_open-source_large_language_models.md)

- [SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency](papers/2024年02月/2024年02月29日/SoK_Exploring_the_Potential_of_Large_Language_Models_for_Improving_Digital_Forensic_Investigation_Efficiency.md)

    - [翻译: 探究 SoK：大型语言模型如何助力提升数字取证调查效率](papers/2024年02月/2024年02月29日/SoK_Exploring_the_Potential_of_Large_Language_Models_for_Improving_Digital_Forensic_Investigation_Efficiency.md)

- [Watermark Stealing in Large Language Models](papers/2024年02月/2024年02月29日/Watermark_Stealing_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型（LLM）中探讨水印窃取问题](papers/2024年02月/2024年02月29日/Watermark_Stealing_in_Large_Language_Models.md)

- [Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook](papers/2024年02月/2024年02月29日/Deep_Learning_for_Cross-Domain_Data_Fusion_in_Urban_Computing_Taxonomy,_Advances,_and_Outlook.md)

    - [翻译: 在城市计算领域，深度学习驱动的跨域数据融合技术正崭露头角。本文旨在梳理这一领域的分类体系，概述最新的技术进展，并展望未来的研究方向。](papers/2024年02月/2024年02月29日/Deep_Learning_for_Cross-Domain_Data_Fusion_in_Urban_Computing_Taxonomy,_Advances,_and_Outlook.md)

- [Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge](papers/2024年02月/2024年02月29日/Here's_a_Free_Lunch_Sanitizing_Backdoored_Models_with_Model_Merge.md)

    - [翻译: 惊喜呈现：运用模型融合技术，轻松净化遭后门侵入的模型，实现安全“白吃午餐”](papers/2024年02月/2024年02月29日/Here's_a_Free_Lunch_Sanitizing_Backdoored_Models_with_Model_Merge.md)

- [Compact Speech Translation Models via Discrete Speech Units Pretraining](papers/2024年02月/2024年02月29日/Compact_Speech_Translation_Models_via_Discrete_Speech_Units_Pretraining.md)

    - [翻译: 我们提出了一种利用离散语音单元预训练技术打造紧凑型语音翻译模型的方法，该方法能够有效压缩模型体积的同时保持较高的翻译性能。](papers/2024年02月/2024年02月29日/Compact_Speech_Translation_Models_via_Discrete_Speech_Units_Pretraining.md)

- [Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction](papers/2024年02月/2024年02月29日/Generalizable_Whole_Slide_Image_Classification_with_Fine-Grained_Visual-Semantic_Interaction.md)

    - [翻译: 通过细粒度视觉与语义互动实现全切片图像分类的泛化能力](papers/2024年02月/2024年02月29日/Generalizable_Whole_Slide_Image_Classification_with_Fine-Grained_Visual-Semantic_Interaction.md)

- [Solucion exacta para un modelo simplificado de un sistema cuantico abierto](papers/2024年02月/2024年02月29日/Solucion_exacta_para_un_modelo_simplificado_de_un_sistema_cuantico_abierto.md)

    - [翻译: 我们提供了一个简化开放量子系统模型的精确解决方案。这个结果为理解和操控此类复杂系统的动态行为提供了关键洞见。](papers/2024年02月/2024年02月29日/Solucion_exacta_para_un_modelo_simplificado_de_un_sistema_cuantico_abierto.md)

- [RL-GPT: Integrating Reinforcement Learning and Code-as-policy](papers/2024年02月/2024年02月29日/RL-GPT_Integrating_Reinforcement_Learning_and_Code-as-policy.md)

    - [翻译: RL-GPT：融汇强化学习与“代码即策略”思想，实现两者深度整合。](papers/2024年02月/2024年02月29日/RL-GPT_Integrating_Reinforcement_Learning_and_Code-as-policy.md)

- [WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset](papers/2024年02月/2024年02月29日/WanJuan-CC_A_Safe_and_High-Quality_Open-sourced_English_Webtext_Dataset.md)

    - [翻译: WanJuan-CC 是一个公开发布的高品质英文网络文本数据集，注重安全性和高质量标准。](papers/2024年02月/2024年02月29日/WanJuan-CC_A_Safe_and_High-Quality_Open-sourced_English_Webtext_Dataset.md)

- [PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval](papers/2024年02月/2024年02月29日/PlanGPT_Enhancing_Urban_Planning_with_Tailored_Language_Model_and_Efficient_Retrieval.md)

    - [翻译: PlanGPT：针对城市规划领域打造的专属语言模型与高效信息检索技术，旨在显著优化城市规划实践。](papers/2024年02月/2024年02月29日/PlanGPT_Enhancing_Urban_Planning_with_Tailored_Language_Model_and_Efficient_Retrieval.md)

- [GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers](papers/2024年02月/2024年02月29日/GSM-Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers.md)

    - [翻译: GSM-Plus 是一套全面的评测基准，旨在深入检验大型语言模型在解决数学问题时的鲁棒性表现。](papers/2024年02月/2024年02月29日/GSM-Plus_A_Comprehensive_Benchmark_for_Evaluating_the_Robustness_of_LLMs_as_Mathematical_Problem_Solvers.md)

- [Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark](papers/2024年02月/2024年02月29日/Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark.md)

    - [翻译: 面对最新挑战，让大型语言模型 (LLMs) 大显身手！本研究提出了一项针对中文动态问题回答的权威基准。](papers/2024年02月/2024年02月29日/Let_LLMs_Take_on_the_Latest_Challenges!_A_Chinese_Dynamic_Question_Answering_Benchmark.md)

- [Memory-Augmented Generative Adversarial Transformers](papers/2024年02月/2024年02月29日/Memory-Augmented_Generative_Adversarial_Transformers.md)

    - [翻译: 记忆强化的生成对抗Transformer模型](papers/2024年02月/2024年02月29日/Memory-Augmented_Generative_Adversarial_Transformers.md)

- [PeLLE: Encoder-based language models for Brazilian Portuguese based on open data](papers/2024年02月/2024年02月29日/PeLLE_Encoder-based_language_models_for_Brazilian_Portuguese_based_on_open_data.md)

    - [翻译: PeLLE 是一款以开放数据为基础、专为巴西葡萄牙语设计的编码器式语言模型。](papers/2024年02月/2024年02月29日/PeLLE_Encoder-based_language_models_for_Brazilian_Portuguese_based_on_open_data.md)

- [PRSA: Prompt Reverse Stealing Attacks against Large Language Models](papers/2024年02月/2024年02月29日/PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models.md)

    - [翻译: PRSA：一种针对大型语言模型的新型攻击手段——Prompt Reverse Stealing，通过逆向窃取提示信息对LLM发起挑战。](papers/2024年02月/2024年02月29日/PRSA_Prompt_Reverse_Stealing_Attacks_against_Large_Language_Models.md)

- [StarCoder 2 and The Stack v2: The Next Generation](papers/2024年02月/2024年02月29日/StarCoder_2_and_The_Stack_v2_The_Next_Generation.md)

    - [翻译: StarCoder 2 与 The Stack v2：引领下一代创新潮流](papers/2024年02月/2024年02月29日/StarCoder_2_and_The_Stack_v2_The_Next_Generation.md)

- [Teaching Large Language Models an Unseen Language on the Fly](papers/2024年02月/2024年02月29日/Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly.md)

    - [翻译: 实时教授大型语言模型掌握新语言](papers/2024年02月/2024年02月29日/Teaching_Large_Language_Models_an_Unseen_Language_on_the_Fly.md)

- [Conversational Language Models for Human-in-the-Loop Multi-Robot Coordination](papers/2024年02月/2024年02月29日/Conversational_Language_Models_for_Human-in-the-Loop_Multi-Robot_Coordination.md)

    - [翻译: 针对人参与循环的多机器人协同场景，我们研发了对话式语言模型，以实现高效的沟通与协调。](papers/2024年02月/2024年02月29日/Conversational_Language_Models_for_Human-in-the-Loop_Multi-Robot_Coordination.md)

- [Typographic Attacks in Large Multimodal Models Can be Alleviated by More Informative Prompts](papers/2024年02月/2024年02月29日/Typographic_Attacks_in_Large_Multimodal_Models_Can_be_Alleviated_by_More_Informative_Prompts.md)

    - [翻译: 针对大型多模态模型中出现的排版攻击问题，研究表明提供更多信息量的提示能够有效缓解这一现象。](papers/2024年02月/2024年02月29日/Typographic_Attacks_in_Large_Multimodal_Models_Can_be_Alleviated_by_More_Informative_Prompts.md)

- [Think Fast, Think Slow, Think Critical: Designing an Automated Propaganda Detection Tool](papers/2024年02月/2024年02月29日/Think_Fast,_Think_Slow,_Think_Critical_Designing_an_Automated_Propaganda_Detection_Tool.md)

    - [翻译: 《快思、慢思与批判思考：打造自动化宣传识别工具》](papers/2024年02月/2024年02月29日/Think_Fast,_Think_Slow,_Think_Critical_Designing_an_Automated_Propaganda_Detection_Tool.md)

- [VIXEN: Visual Text Comparison Network for Image Difference Captioning](papers/2024年02月/2024年02月29日/VIXEN_Visual_Text_Comparison_Network_for_Image_Difference_Captioning.md)

    - [翻译: VIXEN——一款专为图像差异描述而设计的视觉文本比较网络，能够精准捕捉并用语言表达图像间的细微差异。](papers/2024年02月/2024年02月29日/VIXEN_Visual_Text_Comparison_Network_for_Image_Difference_Captioning.md)

- [A SOUND APPROACH: Using Large Language Models to generate audio descriptions for egocentric text-audio retrieval](papers/2024年02月/2024年02月29日/A_SOUND_APPROACH_Using_Large_Language_Models_to_generate_audio_descriptions_for_egocentric_text-audio_retrieval.md)

    - [翻译: 采用大模型巧解之道：为基于第一人称视角的文本-音频检索任务自动生成音频描述](papers/2024年02月/2024年02月29日/A_SOUND_APPROACH_Using_Large_Language_Models_to_generate_audio_descriptions_for_egocentric_text-audio_retrieval.md)

- [Whispers that Shake Foundations: Analyzing and Mitigating False Premise Hallucinations in Large Language Models](papers/2024年02月/2024年02月29日/Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models.md)

    - [翻译: 针对大型语言模型中出现的“虚假前提幻觉”问题，本研究深入剖析并探讨相应的缓解策略，这一现象犹如根基动摇的低语，挑战着我们对人工智能语言理解能力的认知边界。](papers/2024年02月/2024年02月29日/Whispers_that_Shake_Foundations_Analyzing_and_Mitigating_False_Premise_Hallucinations_in_Large_Language_Models.md)

- [TEncDM: Understanding the Properties of Diffusion Model in the Space of Language Model Encodings](papers/2024年02月/2024年02月29日/TEncDM_Understanding_the_Properties_of_Diffusion_Model_in_the_Space_of_Language_Model_Encodings.md)

    - [翻译: TEncDM项目旨在深入理解扩散模型在语言模型编码空间中的独特性质，研究其内在机制及影响效果。](papers/2024年02月/2024年02月29日/TEncDM_Understanding_the_Properties_of_Diffusion_Model_in_the_Space_of_Language_Model_Encodings.md)

- [A Protein Structure Prediction Approach Leveraging Transformer and CNN Integration](papers/2024年02月/2024年02月29日/A_Protein_Structure_Prediction_Approach_Leveraging_Transformer_and_CNN_Integration.md)

    - [翻译: 我们提出了一种创新的方法，结合了Transformer和CNN技术，以提升蛋白质结构预测的精准度。](papers/2024年02月/2024年02月29日/A_Protein_Structure_Prediction_Approach_Leveraging_Transformer_and_CNN_Integration.md)

- [Pointing out the Shortcomings of Relation Extraction Models with Semantically Motivated Adversarials](papers/2024年02月/2024年02月29日/Pointing_out_the_Shortcomings_of_Relation_Extraction_Models_with_Semantically_Motivated_Adversarials.md)

    - [翻译: 本研究采用语义导向的对抗性手段，精准揭示了关系抽取模型存在的不足之处。](papers/2024年02月/2024年02月29日/Pointing_out_the_Shortcomings_of_Relation_Extraction_Models_with_Semantically_Motivated_Adversarials.md)

- [Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: A Benchmark Study](papers/2024年02月/2024年02月29日/Exploring_the_Efficacy_of_Large_Language_Models_in_Summarizing_Mental_Health_Counseling_Sessions_A_Benchmark_Study.md)

    - [翻译: 本研究旨在探究大型语言模型在摘要心理健康咨询会谈内容方面的效能，通过设立基准进行深入研究。](papers/2024年02月/2024年02月29日/Exploring_the_Efficacy_of_Large_Language_Models_in_Summarizing_Mental_Health_Counseling_Sessions_A_Benchmark_Study.md)

- [Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models](papers/2024年02月/2024年02月29日/Enhancing_Visual_Document_Understanding_with_Contrastive_Learning_in_Large_Visual-Language_Models.md)

    - [翻译: 针对大型视觉-语言模型，本研究采用对比学习方法以增强对视觉文档的深入理解和解析能力。](papers/2024年02月/2024年02月29日/Enhancing_Visual_Document_Understanding_with_Contrastive_Learning_in_Large_Visual-Language_Models.md)

- [Generating, Reconstructing, and Representing Discrete and Continuous Data: Generalized Diffusion with Learnable Encoding-Decoding](papers/2024年02月/2024年02月29日/Generating,_Reconstructing,_and_Representing_Discrete_and_Continuous_Data_Generalized_Diffusion_with_Learnable_Encoding-Decoding.md)

    - [翻译: 探究一种能同时处理离散和连续数据的新型广义扩散模型，其具备可学习的编解码结构，能够实现数据的高效生成、精确重建及有效表示。](papers/2024年02月/2024年02月29日/Generating,_Reconstructing,_and_Representing_Discrete_and_Continuous_Data_Generalized_Diffusion_with_Learnable_Encoding-Decoding.md)

- [PopALM: Popularity-Aligned Language Models for Social Media Trendy Response Prediction](papers/2024年02月/2024年02月29日/PopALM_Popularity-Aligned_Language_Models_for_Social_Media_Trendy_Response_Prediction.md)

    - [翻译: PopALM 是一款针对社交媒体趋势回应预测设计的流行度匹配语言模型，它致力于通过结合流行度信息提升对社交媒体热点话题响应预测的准确性。](papers/2024年02月/2024年02月29日/PopALM_Popularity-Aligned_Language_Models_for_Social_Media_Trendy_Response_Prediction.md)

- [Inappropriate Pause Detection In Dysarthric Speech Using Large-Scale Speech Recognition](papers/2024年02月/2024年02月29日/Inappropriate_Pause_Detection_In_Dysarthric_Speech_Using_Large-Scale_Speech_Recognition.md)

    - [翻译: 本研究利用大型语音识别技术，专注于在失语症患者的言语中识别并分析不适当的停顿现象。](papers/2024年02月/2024年02月29日/Inappropriate_Pause_Detection_In_Dysarthric_Speech_Using_Large-Scale_Speech_Recognition.md)

- [AdaMergeX: Cross-Lingual Transfer with Large Language Models via Adaptive Adapter Merging](papers/2024年02月/2024年02月29日/AdaMergeX_Cross-Lingual_Transfer_with_Large_Language_Models_via_Adaptive_Adapter_Merging.md)

    - [翻译: AdaMergeX 技术借助自适应适配器融合，实现在大型语言模型中有效进行跨语言迁移。这一方法针对不同语言间的知识转移进行了优化，使得大型语言模型能够在多种语言间灵活应用。](papers/2024年02月/2024年02月29日/AdaMergeX_Cross-Lingual_Transfer_with_Large_Language_Models_via_Adaptive_Adapter_Merging.md)

- [Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning](papers/2024年02月/2024年02月29日/Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning.md)

    - [翻译: 本研究聚焦于深入分析并有效缓解参数高效微调过程中的灾难性遗忘现象。](papers/2024年02月/2024年02月29日/Analyzing_and_Reducing_Catastrophic_Forgetting_in_Parameter_Efficient_Tuning.md)

- [Loose LIPS Sink Ships: Asking Questions in Battleship with Language-Informed Program Sampling](papers/2024年02月/2024年02月29日/Loose_LIPS_Sink_Ships_Asking_Questions_in_Battleship_with_Language-Informed_Program_Sampling.md)

    - [翻译: 一句老话“口风不紧，沉船千里”，巧妙地借用到战舰游戏中。通过运用语言信息指导的程序采样技术，我们在战舰游戏中提出了创新的提问策略。](papers/2024年02月/2024年02月29日/Loose_LIPS_Sink_Ships_Asking_Questions_in_Battleship_with_Language-Informed_Program_Sampling.md)

- [Gender Bias in Large Language Models across Multiple Languages](papers/2024年02月/2024年02月29日/Gender_Bias_in_Large_Language_Models_across_Multiple_Languages.md)

    - [翻译: 在多种语言环境下，大规模语言模型普遍存在性别偏见问题。](papers/2024年02月/2024年02月29日/Gender_Bias_in_Large_Language_Models_across_Multiple_Languages.md)

- [Extracting Polymer Nanocomposite Samples from Full-Length Documents](papers/2024年02月/2024年02月29日/Extracting_Polymer_Nanocomposite_Samples_from_Full-Length_Documents.md)

    - [翻译: 本研究旨在从全文档中精准抽提聚合物纳米复合材料样本信息，以深入探究其特性与应用。](papers/2024年02月/2024年02月29日/Extracting_Polymer_Nanocomposite_Samples_from_Full-Length_Documents.md)

- [Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models](papers/2024年02月/2024年02月29日/Multimodal_ArXiv_A_Dataset_for_Improving_Scientific_Comprehension_of_Large_Vision-Language_Models.md)

    - [翻译: Multimodal ArXiv 数据集，旨在助力大型视觉-语言模型深化对科学内容的理解与解析。](papers/2024年02月/2024年02月29日/Multimodal_ArXiv_A_Dataset_for_Improving_Scientific_Comprehension_of_Large_Vision-Language_Models.md)

- [Multi-modal Attribute Prompting for Vision-Language Models](papers/2024年02月/2024年02月29日/Multi-modal_Attribute_Prompting_for_Vision-Language_Models.md)

    - [翻译: 针对视觉-语言模型，我们提出多模态属性提示方法，旨在通过融合多种模态信息以提升模型的表现力和理解力。](papers/2024年02月/2024年02月29日/Multi-modal_Attribute_Prompting_for_Vision-Language_Models.md)

- [Improving Socratic Question Generation using Data Augmentation and Preference Optimization](papers/2024年02月/2024年02月29日/Improving_Socratic_Question_Generation_using_Data_Augmentation_and_Preference_Optimization.md)

    - [翻译: 运用数据增强与偏好优化策略提升苏格拉底式问题生成效果，本研究致力于优化和完善该技术在生成高质量、启发性问题方面的表现。](papers/2024年02月/2024年02月29日/Improving_Socratic_Question_Generation_using_Data_Augmentation_and_Preference_Optimization.md)

- [AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs](papers/2024年02月/2024年02月29日/AXOLOTL_Fairness_through_Assisted_Self-Debiasing_of_Large_Language_Model_Outputs.md)

    - [翻译: AXOLOTL项目致力于借助协助大型语言模型进行自我去偏，从而在输出中实现公平性。它聚焦于通过自我校正手段减轻大型语言模型潜在的偏见问题。](papers/2024年02月/2024年02月29日/AXOLOTL_Fairness_through_Assisted_Self-Debiasing_of_Large_Language_Model_Outputs.md)

- [TELEClass: Taxonomy Enrichment and LLM-Enhanced Hierarchical Text Classification with Minimal Supervision](papers/2024年02月/2024年02月29日/TELEClass_Taxonomy_Enrichment_and_LLM-Enhanced_Hierarchical_Text_Classification_with_Minimal_Supervision.md)

    - [翻译: TELEClass 是一种创新方法，通过最小程度的监督实现对分类法的丰富和完善，并利用大型语言模型（LLM）提升层次文本分类的效果。](papers/2024年02月/2024年02月29日/TELEClass_Taxonomy_Enrichment_and_LLM-Enhanced_Hierarchical_Text_Classification_with_Minimal_Supervision.md)

- [LLMs in Political Science: Heralding a New Era of Visual Analysis](papers/2024年02月/2024年02月29日/LLMs_in_Political_Science_Heralding_a_New_Era_of_Visual_Analysis.md)

    - [翻译: LLMs 正在政治科学领域开启视觉分析新篇章](papers/2024年02月/2024年02月29日/LLMs_in_Political_Science_Heralding_a_New_Era_of_Visual_Analysis.md)

- [FAC$^2$E: Better Understanding Large Language Model Capabilities by Dissociating Language and Cognition](papers/2024年02月/2024年02月29日/FAC$^2$E_Better_Understanding_Large_Language_Model_Capabilities_by_Dissociating_Language_and_Cognition.md)

    - [翻译: FAC$^2$E 方法致力于通过区分语言与认知机制，以更深入地探究大型语言模型的能力。](papers/2024年02月/2024年02月29日/FAC$^2$E_Better_Understanding_Large_Language_Model_Capabilities_by_Dissociating_Language_and_Cognition.md)

- [Resonance RoPE: Improving Context Length Generalization of Large Language Models](papers/2024年02月/2024年02月29日/Resonance_RoPE_Improving_Context_Length_Generalization_of_Large_Language_Models.md)

    - [翻译: Resonance RoPE技术致力于增强大型语言模型对不同上下文长度的适应与泛化能力。](papers/2024年02月/2024年02月29日/Resonance_RoPE_Improving_Context_Length_Generalization_of_Large_Language_Models.md)

- [Artwork Explanation in Large-scale Vision Language Models](papers/2024年02月/2024年02月29日/Artwork_Explanation_in_Large-scale_Vision_Language_Models.md)

    - [翻译: 在大规模视觉语言模型中探究艺术品阐释能力](papers/2024年02月/2024年02月29日/Artwork_Explanation_in_Large-scale_Vision_Language_Models.md)

- [Query-OPT: Optimizing Inference of Large Language Models via Multi-Query Instructions in Meeting Summarization](papers/2024年02月/2024年02月29日/Query-OPT_Optimizing_Inference_of_Large_Language_Models_via_Multi-Query_Instructions_in_Meeting_Summarization.md)

    - [翻译: Query-OPT 方法旨在通过在会议摘要场景下运用多查询指令，提升大型语言模型推理效率。这项研究针对大型语言模型，在会议内容总结任务中探究如何借助多查询指令进行优化推理过程。](papers/2024年02月/2024年02月29日/Query-OPT_Optimizing_Inference_of_Large_Language_Models_via_Multi-Query_Instructions_in_Meeting_Summarization.md)

- [SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation](papers/2024年02月/2024年02月29日/SEED_Customize_Large_Language_Models_with_Sample-Efficient_Adaptation_for_Code_Generation.md)

    - [翻译: SEED 方法致力于通过高效适应的方式定制大规模语言模型，以优化其在代码生成任务中的表现。](papers/2024年02月/2024年02月29日/SEED_Customize_Large_Language_Models_with_Sample-Efficient_Adaptation_for_Code_Generation.md)

- [FhGenie: A Custom, Confidentiality-preserving Chat AI for Corporate and Scientific Use](papers/2024年02月/2024年02月29日/FhGenie_A_Custom,_Confidentiality-preserving_Chat_AI_for_Corporate_and_Scientific_Use.md)

    - [翻译: FhGenie，一款专门针对企业和科研场景定制的、具备隐私保护功能的聊天 AI 助手](papers/2024年02月/2024年02月29日/FhGenie_A_Custom,_Confidentiality-preserving_Chat_AI_for_Corporate_and_Scientific_Use.md)

- [SoftTiger: A Clinical Foundation Model for Healthcare Workflows](papers/2024年02月/2024年02月29日/SoftTiger_A_Clinical_Foundation_Model_for_Healthcare_Workflows.md)

    - [翻译: SoftTiger，作为一款专为医疗工作流程打造的临床基础模型，旨在提升医疗服务效率与质量。](papers/2024年02月/2024年02月29日/SoftTiger_A_Clinical_Foundation_Model_for_Healthcare_Workflows.md)

- [Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes](papers/2024年02月/2024年02月29日/Gradient_Cuff_Detecting_Jailbreak_Attacks_on_Large_Language_Models_by_Exploring_Refusal_Loss_Landscapes.md)

    - [翻译: Gradient Cuff 技术，通过深入探究大型语言模型中拒绝损失的地形特征，来实现对模型遭受越狱攻击的有效识别。](papers/2024年02月/2024年02月29日/Gradient_Cuff_Detecting_Jailbreak_Attacks_on_Large_Language_Models_by_Exploring_Refusal_Loss_Landscapes.md)

- [LLM-Ensemble: Optimal Large Language Model Ensemble Method for E-commerce Product Attribute Value Extraction](papers/2024年02月/2024年02月29日/LLM-Ensemble_Optimal_Large_Language_Model_Ensemble_Method_for_E-commerce_Product_Attribute_Value_Extraction.md)

    - [翻译: LLM-Ensemble 是一种针对电商领域的产品属性值抽取任务设计出的最优大型语言模型集成方案。](papers/2024年02月/2024年02月29日/LLM-Ensemble_Optimal_Large_Language_Model_Ensemble_Method_for_E-commerce_Product_Attribute_Value_Extraction.md)

- [NewsBench: Systematic Evaluation of LLMs for Writing Proficiency and Safety Adherence in Chinese Journalistic Editorial Applications](papers/2024年02月/2024年02月29日/NewsBench_Systematic_Evaluation_of_LLMs_for_Writing_Proficiency_and_Safety_Adherence_in_Chinese_Journalistic_Editorial_Applications.md)

    - [翻译: NewsBench 是一个系统评估工具，旨在对大型语言模型在中文新闻编辑场景下的写作水平和安全性遵守情况进行深入考察。](papers/2024年02月/2024年02月29日/NewsBench_Systematic_Evaluation_of_LLMs_for_Writing_Proficiency_and_Safety_Adherence_in_Chinese_Journalistic_Editorial_Applications.md)

- [Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs](papers/2024年02月/2024年02月29日/Direct_Alignment_of_Draft_Model_for_Speculative_Decoding_with_Chat-Fine-Tuned_LLMs.md)

    - [翻译: 研究者尝试将草稿模型直接与经聊天数据优化后的大型语言模型对齐，以提升推测解码性能。](papers/2024年02月/2024年02月29日/Direct_Alignment_of_Draft_Model_for_Speculative_Decoding_with_Chat-Fine-Tuned_LLMs.md)

- [Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning](papers/2024年02月/2024年02月29日/Enhancing_Long-Term_Recommendation_with_Bi-level_Learnable_Large_Language_Model_Planning.md)

    - [翻译: 通过运用双层可学习大型语言模型规划技术，提升长期推荐效果。这项研究致力于探索如何借助大型语言模型进行前瞻性的策划，以改善长期推荐性能。](papers/2024年02月/2024年02月29日/Enhancing_Long-Term_Recommendation_with_Bi-level_Learnable_Large_Language_Model_Planning.md)

- [EyeGPT: Ophthalmic Assistant with Large Language Models](papers/2024年02月/2024年02月29日/EyeGPT_Ophthalmic_Assistant_with_Large_Language_Models.md)

    - [翻译: EyeGPT——借助大型语言模型打造的眼科智能助手](papers/2024年02月/2024年02月29日/EyeGPT_Ophthalmic_Assistant_with_Large_Language_Models.md)