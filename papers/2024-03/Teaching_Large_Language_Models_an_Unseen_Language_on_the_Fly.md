#### [《全知计划V2》：旨在攻克开放世界的通用关系理解难题，探索更全面的关系认知能力。](https://arxiv.org/abs/2402.19474)
#### The All-Seeing Project V2: Towards General Relation Comprehension of the Open World
发布时间：2024年02月29日
> 现在呈献给大家的是全新升级的 All-Seeing Project V2，该项目研发出一款专用于理解图像中物体间关系的模型及配套数据集。我们创新性地提出了All-Seeing Model V2 (ASMv2)，巧妙地将文本生成、物体定位和关系理解融入一个名为“关系对话”(ReC)的任务中。得益于这一集成化任务，ASMv2 不仅能敏锐捕捉到图片中所有物体并精准识别，更能深入解析这些物体间的错综复杂关系网络，有效缓解了当前多模态大型语言模型(MMLMs)常面临的“关系臆断”难题。为了促进MMLMs在关系理解领域的训练与评测，我们精心打造了首个高标准的ReC数据集 AS-V2，其格式严格遵循标准指令调优数据的要求。此外，我们还创新设计了一项名为“循环关系探测评估”(CRPE)的新基准测试，以便全面检验MMLMs在关系理解上的实力。尤为突出的是，ASMv2在这一关系认知基准上取得了高达52.04的整体准确率，远超LLaVA-1.5的43.14，展现了显著的优势。我们期待本项目的研究成果能激发更多后续探索，并有力推动通向人工智能普遍智能的步伐。您可访问https://github.com/OpenGVLab/all-seeing获取我们的项目资源。
> We present the All-Seeing Project V2: a new model and dataset designed for understanding object relations in images. Specifically, we propose the All-Seeing Model V2 (ASMv2) that integrates the formulation of text generation, object localization, and relation comprehension into a relation conversation (ReC) task. Leveraging this unified task, our model excels not only in perceiving and recognizing all objects within the image but also in grasping the intricate relation graph between them, diminishing the relation hallucination often encountered by Multi-modal Large Language Models (MLLMs). To facilitate training and evaluation of MLLMs in relation understanding, we created the first high-quality ReC dataset ({AS-V2) which is aligned with the format of standard instruction tuning data. In addition, we design a new benchmark, termed Circular-based Relation Probing Evaluation (CRPE) for comprehensively evaluating the relation comprehension capabilities of MLLMs. Notably, our ASMv2 achieves an overall accuracy of 52.04 on this relation-aware benchmark, surpassing the 43.14 of LLaVA-1.5 by a large margin. We hope that our work can inspire more future research and contribute to the evolution towards artificial general intelligence. Our project is released at https://github.com/OpenGVLab/all-seeing.
Agent
#### [为探究大型语言模型（LLM）可信度动态变化，我们再次聚焦其预训练阶段，旨在深入理解这一关键阶段对其后续表现和可信度的影响。](https://arxiv.org/abs/2402.19465)
#### Towards Tracing Trustworthiness Dynamics: Revisiting Pre-training Period of Large Language Models
发布时间：2024年02月29日
> 对于LLMs来说，确保其可信性是至关重要的。当前多数研究聚焦于完全预训练阶段的LLMs，以求深化理解并改进其可信性。在这篇论文中，我们独辟蹊径，首度探讨了LLMs在预训练阶段潜在的可信性表现，尤其关注五个核心维度：可靠性、隐私保护、无害性、公正性和稳健性。实验初期，我们采用线性探测方法对LLMs进行分析，发现高探测精度意味着LLMs在预训练早期就能识别出各可信维度中的概念差异。因此，为进一步挖掘预训练过程中的潜在可能性，我们从LLM的预训练检查点提取导向向量来提升其可信性。此外，借鉴\citet{choi2023understanding}关于互信息估计受限于线性探测精度的观点，我们运用互信息探测手段，研究LLMs在预训练期间可信性动态变化规律。我们首次揭示了一种类似“拟合与压缩”双阶段的现象~\citep{shwartz2017opening}。此研究开创性地剖析了LLM预训练阶段的可信性建模问题，旨在揭示更多新见解，并激励该领域的后续进展。我们的代码将在GitHub上公开，网址为 \url{https://github.com/ChnQ/TracingLLM}。
> Ensuring the trustworthiness of large language models (LLMs) is crucial. Most studies concentrate on fully pre-trained LLMs to better understand and improve LLMs' trustworthiness. In this paper, to reveal the untapped potential of pre-training, we pioneer the exploration of LLMs' trustworthiness during this period, focusing on five key dimensions: reliability, privacy, toxicity, fairness, and robustness. To begin with, we apply linear probing to LLMs. The high probing accuracy suggests that \textit{LLMs in early pre-training can already distinguish concepts in each trustworthiness dimension}. Therefore, to further uncover the hidden possibilities of pre-training, we extract steering vectors from a LLM's pre-training checkpoints to enhance the LLM's trustworthiness. Finally, inspired by~\citet{choi2023understanding} that mutual information estimation is bounded by linear probing accuracy, we also probe LLMs with mutual information to investigate the dynamics of trustworthiness during pre-training. We are the first to observe a similar two-phase phenomenon: fitting and compression~\citep{shwartz2017opening}. This research provides an initial exploration of trustworthiness modeling during LLM pre-training, seeking to unveil new insights and spur further developments in the field. We will make our code publicly accessible at \url{https://github.com/ChnQ/TracingLLM}.
LLM理论
#### [为探究大型语言模型的安全性与潜在漏洞，我们引入了“好奇心驱动的红队”策略，通过模拟攻击者对大型语言模型进行挑战和检验，以挖掘其可能存在的问题。](https://arxiv.org/abs/2402.19464)
#### Curiosity-driven Red-teaming for Large Language Models
发布时间：2024年02月29日
> 尽管LLMs在各类自然语言应用中蕴含无限可能，却有误生不当或有毒内容的风险。目前，检测LLM何时生成不受欢迎内容的方法是组织一支人类测试团队，即“红队”，来设计能触发LLM不良回应的输入提示。然而，单靠人力测试成本高昂且耗时。近期研究借助强化学习（RL），训练了一个专门的红队LLM，自动寻找最可能诱发目标LLM不良反应的测试案例。不过，现存的RL技术只能产出少量有效的测试案例，难以全面覆盖可能导致LLM输出不良信息的所有提示情境。为此，我们借鉴了广受研究的好奇心驱动探索原理——追求新颖性的方法，以此提升生成测试案例的覆盖率。我们提出的好奇心驱动红队策略（CRT）在扩大测试案例覆盖面的同时，保证甚至提升了它们的有效性。实验表明，CRT成功激发出已深度优化并依据人类偏好调整以避免毒性输出的LLaMA2模型产生毒性回应。相关代码已发布于 \url{https://github.com/Improbable-AI/curiosity_redteam}。
> Large language models (LLMs) hold great potential for many natural language applications but risk generating incorrect or toxic content. To probe when an LLM generates unwanted content, the current paradigm is to recruit a \textit{red team} of human testers to design input prompts (i.e., test cases) that elicit undesirable responses from LLMs. However, relying solely on human testers is expensive and time-consuming. Recent works automate red teaming by training a separate red team LLM with reinforcement learning (RL) to generate test cases that maximize the chance of eliciting undesirable responses from the target LLM. However, current RL methods are only able to generate a small number of effective test cases resulting in a low coverage of the span of prompts that elicit undesirable responses from the target LLM. To overcome this limitation, we draw a connection between the problem of increasing the coverage of generated test cases and the well-studied approach of curiosity-driven exploration that optimizes for novelty. Our method of curiosity-driven red teaming (CRT) achieves greater coverage of test cases while mantaining or increasing their effectiveness compared to existing methods. Our method, CRT successfully provokes toxic responses from LLaMA2 model that has been heavily fine-tuned using human preferences to avoid toxic outputs. Code is available at \url{https://github.com/Improbable-AI/curiosity_redteam}
LLM应用
#### [在语言模型训练中，Adam 优化器相较于梯度下降法展现出更优性能，这一现象与重尾类别不平衡问题密切相关。本研究探讨了这一特性背后的原因，并揭示了 Adam 如何更好地应对重尾类别不平衡对语言模型训练的影响。](https://arxiv.org/abs/2402.19449)
#### Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models
发布时间：2024年02月29日
> 研究表明，Adam 在优化大型语言转换器时明显胜过梯度下降，尤其是在处理不均衡的词汇频率分布时优势更加突出，然而其中原因尚未明晰。实际上，语言建模任务中存在的严重类别不平衡问题对优化过程产生了挑战，梯度下降时，低频词的损失下降速度往往滞后于高频词。鉴于大部分样本来源于低频词，所以采用梯度下降时，整体平均损失的下降速率较慢。而 Adam 以及基于符号的方法则成功规避了这一难题，对所有类别都实现了预测性能的提升。为了确证类别不平衡是造成这一现象的关键因素，我们不仅在语言转换器领域，还涵盖了视觉CNNs和线性模型等多种模型结构与数据类型，验证了这一现象的普遍存在。此外，通过在交叉熵损失的线性分类问题上深入探究，我们揭示了重尾类别不平衡会引发病态条件，而 Adam 所采用的归一化手段能够有效抵消这一不利影响。
> Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models. We further study this phenomenon on a linear classification with cross-entropy loss, showing that heavy-tailed class imbalance leads to ill-conditioning, and that the normalization used by Adam can counteract it.
LLM理论
#### [ArCHer 是一种创新方法，通过运用分层多轮强化学习技术来训练语言模型智能体，使其在复杂对话场景中更具交互性和适应性。](https://arxiv.org/abs/2402.19446)
#### ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL
发布时间：2024年02月29日
> LLMs广泛应用于涉及多轮交互和智慧决策的“智能体”任务中，而强化学习（RL）为解决此类任务提供了通用方案。然而，目前针对LLMs的RL技术大多侧重于优化单次交互的奖励。实际上，大部分单次交互RL方法尚不能让LLMs具备在多轮交互中聪明地搜寻信息、合理分配功劳或反思过往行动的能力，而这对于完成智能体任务至关重要。那么，怎样才能设计出针对LLMs高效且有效的多轮RL算法呢？本文提出了一个专门面向LLMs微调的多轮RL算法构建框架，它不仅保持了现有单轮RL方法（如近端策略优化法）的灵活性，还能有效应对多轮交互、长远考虑及延迟奖励等问题。该框架采用分层RL策略，同时运行两个RL算法：一个是负责跨对话轮次累积奖励的高层离线价值型RL算法；另一个是基于高层价值函数，在每一轮对话或表述内训练令牌策略的低层RL算法。这一被称为ArCHer的分层Actor-Critic框架，还可启发其他的RL方法。实验表明，ArCHer在智能体任务上的表现显著优于现有方法，样本效率提高了大约100倍，并且随着模型容量增大至我们所测试的70亿级别，其性能也持续提升。
> A broad use case of large language models (LLMs) is in goal-directed decision-making tasks (or "agent" tasks), where an LLM needs to not just generate completions for a given prompt, but rather make intelligent decisions over a multi-turn interaction to accomplish a task (e.g., when interacting with the web, using tools, or providing customer support). Reinforcement learning (RL) provides a general paradigm to address such agent tasks, but current RL methods for LLMs largely focus on optimizing single-turn rewards. By construction, most single-turn RL methods cannot endow LLMs with the ability to intelligently seek information over multiple turns, perform credit assignment, or reason about their past actions -- all of which are critical in agent tasks. This raises the question: how can we design effective and efficient multi-turn RL algorithms for LLMs? In this paper, we develop a framework for building multi-turn RL algorithms for fine-tuning LLMs, that preserves the flexibility of existing single-turn RL methods for LLMs (e.g., proximal policy optimization), while accommodating multiple turns, long horizons, and delayed rewards effectively. To do this, our framework adopts a hierarchical RL approach and runs two RL algorithms in parallel: a high-level off-policy value-based RL algorithm to aggregate reward over utterances, and a low-level RL algorithm that utilizes this high-level value function to train a token policy within each utterance or turn. Our hierarchical framework, Actor-Critic Framework with a Hierarchical Structure (ArCHer), can also give rise to other RL methods. Empirically, we find that ArCHer significantly improves efficiency and performance on agent tasks, attaining a sample efficiency of about 100x over existing methods, while also improving with larger model capacity (upto the 7 billion scale that we tested on).
Agent
#### [为实现高效库导向的代码生成，我们提出了一种组合式API推荐方法。该方法旨在探索和推荐适用于此类任务的恰当API组合，以提升编程效率及代码质量。](https://arxiv.org/abs/2402.19431)
#### Compositional API Recommendation for Library-Oriented Code Generation
发布时间：2024年02月29日
> 尽管LLMs在代码生成领域表现出色，但面对未在训练数据中出现过的库时，生成面向库的代码能力仍有欠缺。过去的研究尝试借助API推荐技术引导LLMs使用库，即找出符合用户需求的API作为输入提示。然而，由于实际开发需求往往涉及多条细粒度API的综合应用，粒度匹配难题使API推荐成为一项棘手工作。因此，我们创新性地提出了CAPIR方案，采用“化整为零”的策略解决粗略需求下的API推荐问题。CAPIR首先利用基于LLM的分解器将大块任务细化为一系列小任务，再通过嵌入式检索器找到与各小任务相匹配的API。同时，CAPIR依靠LLM优化后的重排序机制筛选掉冗余API，确保最终推荐的精准性。为了更准确评估针对粗粒度需求的API推荐效果，我们构建了两个难度较高的基准测试——RAPID（基于文档推荐API）和LOCG（面向库的代码生成）。实验证明，在这两个基准上，CAPIR相比于现有基准方法表现出了显著优势。以RAPID中的Torchdata-AR数据集为例，CAPIR相对于当前最先进API推荐方法，成功将召回率@5提升了约24.5个百分点至43.2%，并将精确率@5提高了约21.6个百分点达到37.1%；而在LOCG的Torchdata-Code数据集中，相较于没有采用API推荐的代码生成方式，CAPIR将pass@100指标提高了大约12个百分点，达到了28.0%。
> Large language models (LLMs) have achieved exceptional performance in code generation. However, the performance remains unsatisfactory in generating library-oriented code, especially for the libraries not present in the training data of LLMs. Previous work utilizes API recommendation technology to help LLMs use libraries: it retrieves APIs related to the user requirements, then leverages them as context to prompt LLMs. However, developmental requirements can be coarse-grained, requiring a combination of multiple fine-grained APIs. This granularity inconsistency makes API recommendation a challenging task. To address this, we propose CAPIR (Compositional API Recommendation), which adopts a "divide-and-conquer" strategy to recommend APIs for coarse-grained requirements. Specifically, CAPIR employs an LLM-based Decomposer to break down a coarse-grained task description into several detailed subtasks. Then, CAPIR applies an embedding-based Retriever to identify relevant APIs corresponding to each subtask. Moreover, CAPIR leverages an LLM-based Reranker to filter out redundant APIs and provides the final recommendation. To facilitate the evaluation of API recommendation methods on coarse-grained requirements, we present two challenging benchmarks, RAPID (Recommend APIs based on Documentation) and LOCG (Library-Oriented Code Generation). Experimental results on these benchmarks, demonstrate the effectiveness of CAPIR in comparison to existing baselines. Specifically, on RAPID's Torchdata-AR dataset, compared to the state-of-the-art API recommendation approach, CAPIR improves recall@5 from 18.7% to 43.2% and precision@5 from 15.5% to 37.1%. On LOCG's Torchdata-Code dataset, compared to code generation without API recommendation, CAPIR improves pass@100 from 16.0% to 28.0%.
LLM应用
#### [精心打造知识：深入探索聊天式搜索引擎背后的创新运作机制](https://arxiv.org/abs/2402.19421)
#### Crafting Knowledge: Exploring the Creative Mechanisms of Chat-Based Search Engines
发布时间：2024年02月29日
> 搜索引擎作为数字信息传播的核心中介，将信息需求者与供给者紧密相连。以Bing Chat为代表的搭载大型语言模型（LLMs）及检索增强生成（RAG）技术的聊天型搜索引擎，则为搜索生态带来了革新性的跃进。这类引擎展现出类似人类的理解力与创造力，能解读网页信息并精巧回应。然而，LLMs内在的复杂性使得其“思考”过程如同黑箱，即使是设计者也难以完全洞察。本研究致力于深入探究LLM驱动的聊天式搜索引擎（以Bing Chat为例）如何选取信息源生成回答。为了实现这一目标，我们通过与新Bing的实际互动，积累了一个大规模数据集，其中包含它引用的网站及其与常规搜索引擎所列网站的对比情况。运用自然语言处理技术分析发现，Bing Chat更偏好那些既易读、结构规整且困惑度较低的网页内容，这意味着其有独特倾向去选用底层LLM容易预测的文本。我们进一步通过与基于GPT-4知识检索API的互动，收集更多数据，显示了RAG API与Bing Chat在文本偏好的一致性，暗示这类偏好其实源自于底层语言模型的固有特性，而非Bing Chat开发团队刻意编排的结果。此外，我们的研究还揭示了相比传统搜索引擎高排名的网站，RAG技术引用的网站间具有更高的相似度。
> In the domain of digital information dissemination, search engines act as pivotal conduits linking information seekers with providers. The advent of chat-based search engines utilizing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG), exemplified by Bing Chat, marks an evolutionary leap in the search ecosystem. They demonstrate metacognitive abilities in interpreting web information and crafting responses with human-like understanding and creativity. Nonetheless, the intricate nature of LLMs renders their "cognitive" processes opaque, challenging even their designers' understanding. This research aims to dissect the mechanisms through which an LLM-powered chat-based search engine, specifically Bing Chat, selects information sources for its responses. To this end, an extensive dataset has been compiled through engagements with New Bing, documenting the websites it cites alongside those listed by the conventional search engine. Employing natural language processing (NLP) techniques, the research reveals that Bing Chat exhibits a preference for content that is not only readable and formally structured, but also demonstrates lower perplexity levels, indicating a unique inclination towards text that is predictable by the underlying LLM. Further enriching our analysis, we procure an additional dataset through interactions with the GPT-4 based knowledge retrieval API, unveiling a congruent text preference between the RAG API and Bing Chat. This consensus suggests that these text preferences intrinsically emerge from the underlying language models, rather than being explicitly crafted by Bing Chat's developers. Moreover, our investigation documents a greater similarity among websites cited by RAG technologies compared to those ranked highest by conventional search engines.
RAG
#### [探究语言模型中地理表示随模型规模变化的规律](https://arxiv.org/abs/2402.19406)
#### On the Scaling Laws of Geographical Representation in Language Models
发布时间：2024年02月29日
> 研究表明，语言模型自始便在内部隐藏层捕捉地理信息，这一结论近期在LLMs领域得到了进一步验证。本篇论文致力于通过探索地理知识随语言模型扩大的演变过程，从而连接起经典理论与最新研究成果。我们揭示了即便是微小的语言模型也能体现地理知识，并且随着模型规模的增长，这种知识表现得愈发显著。然而，一个引人注意的现象是，尽管模型增大，却无法有效减轻训练数据内在的地理偏倚问题。
> Language models have long been shown to embed geographical information in their hidden representations. This line of work has recently been revisited by extending this result to Large Language Models (LLMs). In this paper, we propose to fill the gap between well-established and recent literature by observing how geographical knowledge evolves when scaling language models. We show that geographical knowledge is observable even for tiny models, and that it scales consistently as we increase the model size. Notably, we observe that larger language models cannot mitigate the geographical bias that is inherent to the training data.
LLM理论
#### [我们提出了一种针对新闻图片描述任务的“实体感知多模态对齐框架”，该框架旨在更好地整合和利用图文信息，以提升新闻图片自动描述的质量与准确性。](https://arxiv.org/abs/2402.19404)
#### Entity-Aware Multimodal Alignment Framework for News Image Captioning
发布时间：2024年02月29日
> 新闻图片captioning任务要求模型在新闻图片及相关新闻文本的基础上产出更丰富的描述，而多模态大型语言模型在此领域虽发展迅猛，但我们在实验中发现，常规MLLMs在零样本场景下生成实体信息的表现不佳。即使经过针对新闻图片captioning数据集的微调，其处理实体信息的能力仍较为有限。因此，为提升模型对多模态实体信息的处理能力，我们创新设计了两项多模态实体感知对齐任务，并构建了一套对齐框架，以优化模型并生成高质量的新闻图片标题。最终，我们的方法在GoodNews和NYTimes800k数据集上取得了显著突破，CIDEr得分分别从72.33提升至86.29、从70.83提升至85.61，超越了以往的最优水平。
> News image captioning task is a variant of image captioning task which requires model to generate a more informative caption with news image and the associated news article. Multimodal Large Language models have developed rapidly in recent years and is promising in news image captioning task. However, according to our experiments, common MLLMs are not good at generating the entities in zero-shot setting. Their abilities to deal with the entities information are still limited after simply fine-tuned on news image captioning dataset. To obtain a more powerful model to handle the multimodal entity information, we design two multimodal entity-aware alignment tasks and an alignment framework to align the model and generate the news image captions. Our method achieves better results than previous state-of-the-art models in CIDEr score (72.33 -> 86.29) on GoodNews dataset and (70.83 -> 85.61) on NYTimes800k dataset.
LLM应用
#### [在“硅智慧群体”中，大型语言模型（LLM）集成预测的准确性已达到与人类群体相当的水平，展示了强大的智能集成预测能力。](https://arxiv.org/abs/2402.19379)
#### Wisdom of the Silicon Crowd: LLM Ensemble Prediction Capabilities Match Human Crowd Accuracy
发布时间：2024年02月29日
> 实践中，人类预测准确性仰仗“众人智慧”效应，即汇聚众多个体预测者的观点能有效提升对未来事件的预见力。前人研究显示，即便最先进的LLMs作为独立预测者，其预测表现也逊色于多人预测比赛结果的平均水平。在第一项研究中，我们采用了包含12个LLMs的集合策略来深化这一领域研究，比较了该集合在31个二元问题上的预测结果与一项历时三个月、拥有925名人类预测者的比赛中的集体预测结果。结果显示，LLM集合不仅超越了基本无信息参照标准，而且在统计意义上与人类预测群体不相上下，同时还揭示出一种遵从性效应，即使正面和负面结果近乎均衡分布，模型平均预测值仍明显超过50%。在第二项研究中，我们探究了将人类的认知输出融入LLM（如GPT-4和Claude 2）预测过程中，能否提升其预测准确性。研究发现，当这两种模型接触到中位数人类预测作为辅助信息时，预测准确度都有所提升，提高幅度在17%至28%之间，尽管这种提升并未超越单纯将人类和机器预测结果平均的效果。最终，我们的研究成果表明，仅通过实施简便且实用的预测集合策略，LLMs便有望达到与人类群体预测比赛比肩的预测精确度，从而成功复制了“众人智慧”在LLMs领域的效应，并为此类技术在社会各个应用场景中的推广使用铺平了道路。
> Human forecasting accuracy in practice relies on the 'wisdom of the crowd' effect, in which predictions about future events are significantly improved by aggregating across a crowd of individual forecasters. Past work on the forecasting ability of large language models (LLMs) suggests that frontier LLMs, as individual forecasters, underperform compared to the gold standard of a human crowd forecasting tournament aggregate. In Study 1, we expand this research by using an LLM ensemble approach consisting of a crowd of twelve LLMs. We compare the aggregated LLM predictions on 31 binary questions to that of a crowd of 925 human forecasters from a three-month forecasting tournament. Our main analysis shows that the LLM crowd outperforms a simple no-information benchmark and is statistically equivalent to the human crowd. We also observe an acquiescence effect, with mean model predictions being significantly above 50%, despite an almost even split of positive and negative resolutions. Moreover, in Study 2, we test whether LLM predictions (of GPT-4 and Claude 2) can be improved by drawing on human cognitive output. We find that both models' forecasting accuracy benefits from exposure to the median human prediction as information, improving accuracy by between 17% and 28%: though this leads to less accurate predictions than simply averaging human and machine forecasts. Our results suggest that LLMs can achieve forecasting accuracy rivaling that of human crowd forecasting tournaments: via the simple, practically applicable method of forecast aggregation. This replicates the 'wisdom of the crowd' effect for LLMs, and opens up their use for a variety applications throughout society.
LLM应用
#### [OpenMedLM 显示，在使用开源大型语言模型处理医疗问答场景时，通过巧妙的提示工程技术，其表现甚至可以优于传统的微调方法。](https://arxiv.org/abs/2402.19371)
#### OpenMedLM: Prompt engineering can out-perform fine-tuning in medical question-answering with open-source large language models
发布时间：2024年02月29日
> 随着LLMs日渐擅长处理各类专业任务，并有助于拓宽医疗知识的公正获取途径，大部分医学专用LLMs均借助大量的专业医疗数据进行深度微调，消耗了巨大且昂贵的计算资源。尽管很多顶尖LLMs是封闭的专有模型，仅少数研究团队能接触，但开源（OS）模型凭借其性能的大幅提升及与生俱来的透明性和对医疗行业所需的合规性的支持，正逐渐成为医学LLMs发展的重要驱动力。为此，我们推出OpenMedLM这一创新的提示平台，它能在医学基准测试上展示OS LLMs的最新前沿成果。我们选取了一系列规模在70亿至700亿参数区间的OS基础LLMs，在四个权威医学基准测试（MedQA、MedMCQA、PubMedQA和MMLU医学子集）上进行了评测，并运用了多种提示策略，包括零样本、小样本学习、随机及kNN选择的链式思维方法，以及集成/自我一致性投票机制。结果显示，OpenMedLM在三个主流医学LLM基准测试上刷新了OS模型的最高纪录，超越了以往那些依赖耗资巨大的深度微调而取得最好成绩的OS模型。该模型在MedQA测试上获得了72.6%的精确度，比此前最佳成绩提高了2.4%，并在MMLU医学子集测试中达到81.7%的精确度，成为首个在这个基准上突破80%精确度大关的OS LLM。这一研究不仅揭示了至今为止在其他地方尚未被充分认识的OS LLMs所具备的医学特异性优势，还展现了通过深化提示工程技术，有效提升可获得的LLMs在医学应用场景下的性能潜力。
> LLMs have become increasingly capable at accomplishing a range of specialized-tasks and can be utilized to expand equitable access to medical knowledge. Most medical LLMs have involved extensive fine-tuning, leveraging specialized medical data and significant, thus costly, amounts of computational power. Many of the top performing LLMs are proprietary and their access is limited to very few research groups. However, open-source (OS) models represent a key area of growth for medical LLMs due to significant improvements in performance and an inherent ability to provide the transparency and compliance required in healthcare. We present OpenMedLM, a prompting platform which delivers state-of-the-art (SOTA) performance for OS LLMs on medical benchmarks. We evaluated a range of OS foundation LLMs (7B-70B) on four medical benchmarks (MedQA, MedMCQA, PubMedQA, MMLU medical-subset). We employed a series of prompting strategies, including zero-shot, few-shot, chain-of-thought (random selection and kNN selection), and ensemble/self-consistency voting. We found that OpenMedLM delivers OS SOTA results on three common medical LLM benchmarks, surpassing the previous best performing OS models that leveraged computationally costly extensive fine-tuning. The model delivers a 72.6% accuracy on the MedQA benchmark, outperforming the previous SOTA by 2.4%, and achieves 81.7% accuracy on the MMLU medical-subset, establishing itself as the first OS LLM to surpass 80% accuracy on this benchmark. Our results highlight medical-specific emergent properties in OS LLMs which have not yet been documented to date elsewhere, and showcase the benefits of further leveraging prompt engineering to improve the performance of accessible LLMs for medical applications.
LLM应用
#### [探究 SoK：大型语言模型如何助力提升数字取证调查效率](https://arxiv.org/abs/2402.19366)
#### SoK: Exploring the Potential of Large Language Models for Improving Digital Forensic Investigation Efficiency
发布时间：2024年02月29日
> 日益增多的数字取证案件对执法部门快速展开调查的能力提出了挑战。为解决这一问题，本研究细致梳理了将大型语言模型（LLMs）整合到数字取证过程中的潜力与效果。我们广泛回顾了相关文献，包括现行的数字取证模型、工具、LLMs技术、深度学习方法以及LLMs在侦查中的实际运用。通过深入研究，我们揭示了当前数字取证过程中存在的难题，并探讨了引入LLMs所面临的阻碍及其可能带来的机遇。总结而言，本文主张，在适宜的制约机制下，将LLMs应用于数字取证有望提升调查效能、增强证据追踪能力，并减轻执法机构遭遇的技术及司法壁垒。
> The growing number of cases requiring digital forensic analysis raises concerns about law enforcement's ability to conduct investigations promptly. Consequently, this systemisation of knowledge paper delves into the potential and effectiveness of integrating Large Language Models (LLMs) into digital forensic investigation to address these challenges. A thorough literature review is undertaken, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the utilisation of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and possibilities of incorporating LLMs. In conclusion, the study asserts that the adoption of LLMs in digital forensics, with appropriate constraints, holds the potential to enhance investigation efficiency, improve traceability, and alleviate technical and judicial barriers faced by law enforcement entities.
LLM应用
#### [在大型语言模型（LLM）中探讨水印窃取问题](https://arxiv.org/abs/2402.19361)
#### Watermark Stealing in Large Language Models
发布时间：2024年02月29日
> LLM 水印作为识别 AI 内容的有效手段备受瞩目，有人认为现有技术已接近实战阶段。但本研究对此提出异议，揭示了水印窃取（WS）是这类技术的一大安全隐患。研究证明，通过调用带水印 LLN 的 API 进行逆向解析，不仅能如先前研究所示实施可行的伪造攻击，还意外地大幅提升了擦除攻击的效果。我们首开先河，提出了自动化 WS 算法，并首次在真实场景下对欺骗与擦除攻击进行了全方位探究。实验显示，攻击者仅需不足50美元的成本，就能以超过80%的成功率轻松破解并擦除那些曾被认为安全可靠的尖端水印方案。这一系列发现在一定程度上颠覆了业界对 LLM 水印技术的传统认知，迫切要求研发更为坚固的水印保护机制。为了推动进一步研究，我们已在 https://watermark-stealing.org 上公开了所有代码及相关实例。
> LLM watermarking has attracted attention as a promising way to detect AI-generated content, with some works suggesting that current schemes may already be fit for deployment. In this work we dispute this claim, identifying watermark stealing (WS) as a fundamental vulnerability of these schemes. We show that querying the API of the watermarked LLM to approximately reverse-engineer a watermark enables practical spoofing attacks, as suggested in prior work, but also greatly boosts scrubbing attacks, which was previously unnoticed. We are the first to propose an automated WS algorithm and use it in the first comprehensive study of spoofing and scrubbing in realistic settings. We show that for under $50 an attacker can both spoof and scrub state-of-the-art schemes previously considered safe, with average success rate of over 80%. Our findings challenge common beliefs about LLM watermarking, stressing the need for more robust schemes. We make all our code and additional examples available at https://watermark-stealing.org.
LLM应用
#### [在城市计算领域，深度学习驱动的跨域数据融合技术正崭露头角。本文旨在梳理这一领域的分类体系，概述最新的技术进展，并展望未来的研究方向。](https://arxiv.org/abs/2402.19348)
#### Deep Learning for Cross-Domain Data Fusion in Urban Computing: Taxonomy, Advances, and Outlook
发布时间：2024年02月29日
> 面对城市的持续繁荣，Urban Computing 成为了借助各类源头（如地理、交通、社交媒体及环境数据）和形式（如时空、视觉、文本等多元信息）的跨领域数据融合之力，推动可持续发展的核心学科。如今，深度学习技术在智慧城市建设中的跨域数据融合应用正呈现出上升势头。因此，我们率先推出了首份系统综述，详尽梳理了针对城市计算设计的基于深度学习的数据融合方法的前沿进展。首先，我们从数据层面深入剖析各模态与数据源的独特作用；接着，我们将相关方法划分为四大类别——基于特征融合、基于对齐融合、基于对比融合和基于生成融合；然后，我们将多模态的城市应用场景进一步细分至七个维度，包括城市规划、交通、经济、公共安全、社会、环境和能源。相较于以往的同类综述，我们更加注重深度学习方法与城市计算实践的深度融合。同时，我们还探讨了大型语言模型（LLMs）与城市计算之间的互动关系，并预测了可能颠覆该领域的未来研究走向。我们深信，本次调查所勾勒的体系架构、进展概况和前瞻视野，将有力地充实研究社群的知识宝库。关于这份全面且与时俱进的论文清单概要，您可以在 https://github.com/yoshall/Awesome-Multimodal-Urban-Computing 获取。
> As cities continue to burgeon, Urban Computing emerges as a pivotal discipline for sustainable development by harnessing the power of cross-domain data fusion from diverse sources (e.g., geographical, traffic, social media, and environmental data) and modalities (e.g., spatio-temporal, visual, and textual modalities). Recently, we are witnessing a rising trend that utilizes various deep-learning methods to facilitate cross-domain data fusion in smart cities. To this end, we propose the first survey that systematically reviews the latest advancements in deep learning-based data fusion methods tailored for urban computing. Specifically, we first delve into data perspective to comprehend the role of each modality and data source. Secondly, we classify the methodology into four primary categories: feature-based, alignment-based, contrast-based, and generation-based fusion methods. Thirdly, we further categorize multi-modal urban applications into seven types: urban planning, transportation, economy, public safety, society, environment, and energy. Compared with previous surveys, we focus more on the synergy of deep learning methods with urban computing applications. Furthermore, we shed light on the interplay between Large Language Models (LLMs) and urban computing, postulating future research directions that could revolutionize the field. We firmly believe that the taxonomy, progress, and prospects delineated in our survey stand poised to significantly enrich the research community. The summary of the comprehensive and up-to-date paper list can be found at https://github.com/yoshall/Awesome-Multimodal-Urban-Computing.
LLM应用
#### [惊喜呈现：运用模型融合技术，轻松净化遭后门侵入的模型，实现安全“白吃午餐”](https://arxiv.org/abs/2402.19334)
#### Here's a Free Lunch: Sanitizing Backdoored Models with Model Merge
发布时间：2024年02月29日
> 开源运动使得预训练语言模型得以广泛应用，有力推进创新并让更多人接触到前沿技术。但同时也伴随着安全隐患，如后门攻击——利用特定输入激活隐匿的恶意行为，对NLP系统的完整性和可信度构成威胁。本文提出，即便模型并非绝对安全，也能通过将含后门模型与其他同类模型进行融合以缓解后门漏洞问题。实验中，我们研究了多种模型组合（如BERT-Base、RoBERTa-Large、Llama2-7B 以及 Mistral-7B）及数据集（例如 SST-2、OLID、AG News 和 QNLI）。相较于现有多种高级防御手段，我们的方法无需额外资源和专业知识，在推理阶段就提供了高效对抗后门攻击的有效防护，并且表现持续超越其他先进基准，平均降幅高达攻击成功率75%。由于模型融合本就是提升模型性能的常用策略，其所带来的防御层面的额外优势堪称无价之宝。
> The democratization of pre-trained language models through open-source initiatives has rapidly advanced innovation and expanded access to cutting-edge technologies. However, this openness also brings significant security risks, including backdoor attacks, where hidden malicious behaviors are triggered by specific inputs, compromising natural language processing (NLP) system integrity and reliability. This paper suggests that merging a backdoored model with other homogeneous models can remediate backdoor vulnerabilities even if such models are not entirely secure. In our experiments, we explore various models (BERT-Base, RoBERTa-Large, Llama2-7B, and Mistral-7B) and datasets (SST-2, OLID, AG News, and QNLI). Compared to multiple advanced defensive approaches, our method offers an effective and efficient inference-stage defense against backdoor attacks without additional resources or specific knowledge. Our approach consistently outperforms the other advanced baselines, leading to an average of 75% reduction in the attack success rate. Since model merging has been an established approach for improving model performance, the extra advantage it provides regarding defense can be seen as a cost-free bonus.
LLM应用
#### [我们提出了一种利用离散语音单元预训练技术打造紧凑型语音翻译模型的方法，该方法能够有效压缩模型体积的同时保持较高的翻译性能。](https://arxiv.org/abs/2402.19333)
#### Compact Speech Translation Models via Discrete Speech Units Pretraining
发布时间：2024年02月29日
> 现今，利用SSL预训练以实现强大的语音翻译（ST）性能已成为常态，但其较大的内存开销却限制了在设备端的部署。本文创新地在离散语音单元（DSU）上预训练小型模型，有效汲取SSL模型的优点。我们首先针对滤波器组至DSU和DSU至翻译数据，分别预训练编码器-解码器模型，随后取其编码器和解码器初始化一个新模型，并在少量语音翻译数据上进行微调。最终模型通过DSU预训练提炼SSL模型的知识，体积更为精巧。这种方法相较于直接将DSU作为模型输入，不仅拥有更简洁的推理过程和对DSU分词稳健性等优点，而且无需依赖转录文本，尤其适应于低资源环境。在CoVoST-2 X-En数据集上的评测显示，即使模型大小仅为原先一半，我们的方法仍能比直接微调SSL模型的ST系统高出0.5 BLEU以上，且性能堪比ASR预训练。
> Using Self-Supervised Learning (SSL) as model initialization is now common to obtain strong results in Speech Translation (ST). However, they also impose a large memory footprint, hindering on-device deployment. In this paper, we leverage the SSL models by pretraining smaller models on their Discrete Speech Units (DSU). We pretrain encoder-decoder models on 1) Filterbank-to-DSU and 2) DSU-to-Translation data, and take the encoder from 1) and the decoder from 2) to initialise a new model, finetuning this on limited speech-translation data. The final model becomes compact by using the DSU pretraining to distil the knowledge of the SSL model. Our method has several benefits over using DSU as model inputs, such as shorter inference pipeline and robustness over (DSU) tokenization. In contrast to ASR pretraining, it does not require transcripts, making it applicable to low-resource settings. Evaluation on CoVoST-2 X-En shows that our method is >$0.5$ BLEU better than a ST model that directly finetune the SSL model, given only half the model size, and on a par with ASR pretraining.
Agent
#### [通过细粒度视觉与语义互动实现全切片图像分类的泛化能力步骤1翻译：通用全视野图像分类借助于细粒度视觉-语义交互进行步骤2优化：本研究提出了一种利用细粒度视觉与语义相互作用实现全视野图像分类的泛化方法。](https://arxiv.org/abs/2402.19326)
#### Generalizable Whole Slide Image Classification with Fine-Grained Visual-Semantic Interaction
发布时间：2024年02月29日
> WSI分类常被视为MIL问题，而VLMs在这一领域崭露头角，表现出优异性能。不过现有技术仅依赖粗糙的病理性描述指导视觉特征学习，难以充分揭示病理性图像复杂多变的视觉特征，导致模型在各类下游任务上的泛化能力受限。同时，处理高分辨率WSI颇具计算挑战。为此，我们创新性地提出了FiVE框架，它聚焦于WSI分类中的“细粒度视觉-语义交互”，通过巧妙设计的查询方式，运用大型语言模型从各式非标准原始报告中提炼出精细的病理描述，并将其转化为训练所需的细粒度标签。借助TFS模块，我们引导模型精准捕捉WSI中的关键视觉信息，有效提升了表示学习效果及模型泛化能力。考虑到病理视觉模式在组织切片间存在冗余分布，我们在训练阶段只选取部分视觉实例进行处理。最终，本方法展现出极强的泛化性和优越的迁移性，在针对TCGA肺癌数据集的少量样本实验中，其准确率至少比其他方法高出9.19%，实现了显著超越。
> Whole Slide Image (WSI) classification is often formulated as a Multiple Instance Learning (MIL) problem. Recently, Vision-Language Models (VLMs) have demonstrated remarkable performance in WSI classification. However, existing methods leverage coarse-grained pathogenetic descriptions for visual representation supervision, which are insufficient to capture the complex visual appearance of pathogenetic images, hindering the generalizability of models on diverse downstream tasks. Additionally, processing high-resolution WSIs can be computationally expensive. In this paper, we propose a novel "Fine-grained Visual-Semantic Interaction" (FiVE) framework for WSI classification. It is designed to enhance the model's generalizability by leveraging the interplay between localized visual patterns and fine-grained pathological semantics. Specifically, with meticulously designed queries, we start by utilizing a large language model to extract fine-grained pathological descriptions from various non-standardized raw reports. The output descriptions are then reconstructed into fine-grained labels used for training. By introducing a Task-specific Fine-grained Semantics (TFS) module, we enable prompts to capture crucial visual information in WSIs, which enhances representation learning and augments generalization capabilities significantly. Furthermore, given that pathological visual patterns are redundantly distributed across tissue slices, we sample a subset of visual instances during training. Our method demonstrates robust generalizability and strong transferability, dominantly outperforming the counterparts on the TCGA Lung Cancer dataset with at least 9.19% higher accuracy in few-shot experiments.
LLM应用
#### [我们提供了一个简化开放量子系统模型的精确解决方案。这个结果为理解和操控此类复杂系统的动态行为提供了关键洞见。](https://arxiv.org/abs/2402.19307)
#### Solucion exacta para un modelo simplificado de un sistema cuantico abierto
发布时间：2024年02月29日
> 本工作构建了一个简化模型，模拟了初始激发的振荡器作为量子系统与大量基态、弱耦合的振荡器“reservoir”间的相互作用，如微腔中的振荡器与零温真空电磁场的情况。我们的首要任务是在这种环境下精确求解系统密度矩阵。采用的整体策略是运用演化算符一次性追踪所有振荡器的整体演变历程，以一个能分解成系统与reservoir部分的总初态为起点，在保证幺正演化的前提下，通过对环境各自由度的迹运算获得任何时刻系统的密度矩阵，这一步骤涉及对哈密顿量的对角化处理。我们选取了包含N=1000个振荡器的reservoir实例，确定的耦合强度值及ohmic类型的谱密度参数，并将所得结果与[2.3.1]节中提及的马尔科夫解决方案进行了比较验证。
> A simplified model of an initially excited oscillator as a quantum system interacting with a large number of oscillators acting as a reservoir has been developed in this work. All these oscillators are in their ground state uncoupled each other and at the limit of the weak coupling between the system and the reservoir. This system could be an oscillator excited in a microcavity that interacts with the vacuum's electromagnetic field at zero temperature. This work's primary goal is to obtain the system's density matrix's exact solution in these conditions. The general approach calculates all oscillators' evolution as a single isolated entity using the evolution operator. Starting from a total initial state that can be factored between the system and the reservoir, the evolution is unitary, and the partial trace is taken in all the degrees of freedom of the environment to obtain the density matrix of the system at any instant of time; this procedure requires diagonalizing Hamiltonian. The results are evaluated for a reservoir of N=1000 oscillators, particular values of the coupling force, and ohmic order of the spectral density, contrasted with the corresponding Markovian solution described in section [2.3.1].
Agent
#### [RL-GPT：融汇强化学习与“代码即策略”思想，实现两者深度整合。](https://arxiv.org/abs/2402.19299)
#### RL-GPT: Integrating Reinforcement Learning and Code-as-policy
发布时间：2024年02月29日
> LLMs擅长通过编码手段运用各类工具，但对于复杂逻辑及精准操控仍面临挑战。在实体交互任务中，高层规划易于直接编码实现，而底层动作往往需要针对具体任务进行细化调优，比如采用RL技术。为将两者完美融合，我们创新提出了一种双层递阶框架——RL-GPT，该框架包括一个负责深思熟虑的慢速代理与一个执行编码任务的快速代理。这样的拆解设计让两个代理各司其职，显著提升了整体流程的效率。相较于传统RL方法及现存GPT代理，我们的方案表现出更优的效能。实验表明，在Minecraft游戏中，仅用一天时间便能借助RTX3090显卡迅速挖到钻石；同时，它还在所有预设的MineDojo任务中都达到了顶尖水平。
> Large Language Models (LLMs) have demonstrated proficiency in utilizing various tools by coding, yet they face limitations in handling intricate logic and precise control. In embodied tasks, high-level planning is amenable to direct coding, while low-level actions often necessitate task-specific refinement, such as Reinforcement Learning (RL). To seamlessly integrate both modalities, we introduce a two-level hierarchical framework, RL-GPT, comprising a slow agent and a fast agent. The slow agent analyzes actions suitable for coding, while the fast agent executes coding tasks. This decomposition effectively focuses each agent on specific tasks, proving highly efficient within our pipeline. Our approach outperforms traditional RL methods and existing GPT agents, demonstrating superior efficiency. In the Minecraft game, it rapidly obtains diamonds within a single day on an RTX3090. Additionally, it achieves SOTA performance across all designated MineDojo tasks.
Agent
#### [WanJuan-CC 是一个公开发布的高品质英文网络文本数据集，注重安全性和高质量标准。](https://arxiv.org/abs/2402.19282)
#### WanJuan-CC: A Safe and High-Quality Open-sourced English Webtext Dataset
发布时间：2024年02月29日
> 本文推出了基于Common Crawl数据源打造的安全高品质开源英文网络文本数据集——万卷-CC。面对为语言模型构建大型预训练数据集所需海量优质数据的难题，我们精心设计了一整套处理流程，从约6800亿份英文原文档中萃取出2.22万亿个安全Token，并严选其中1万亿高质量Token构成了万卷-CC的核心部分，目前已对外开源3000亿Token。同时，文中详尽展示了与数据品质相关的统计数据，方便用户按需挑选适宜数据。为进一步验证万卷-CC的数据质量和实用价值，我们采用其与RefinedWeb数据集分别训练了10亿和30亿参数规模的模型。实验结果显示，在验证集及下游任务测试中，万卷-CC展现出了更为出色的性能表现。
> This paper presents WanJuan-CC, a safe and high-quality open-sourced English webtext dataset derived from Common Crawl data. The study addresses the challenges of constructing large-scale pre-training datasets for language models, which require vast amounts of high-quality data. A comprehensive process was designed to handle Common Crawl data, including extraction, heuristic rule filtering, fuzzy deduplication, content safety filtering, and data quality filtering. From approximately 68 billion original English documents, we obtained 2.22T Tokens of safe data and selected 1.0T Tokens of high-quality data as part of WanJuan-CC. We have open-sourced 300B Tokens from this dataset. The paper also provides statistical information related to data quality, enabling users to select appropriate data according to their needs. To evaluate the quality and utility of the dataset, we trained 1B-parameter and 3B-parameter models using WanJuan-CC and another dataset, RefinedWeb. Results show that WanJuan-CC performs better on validation datasets and downstream tasks.
LLM应用
#### [PlanGPT：针对城市规划领域打造的专属语言模型与高效信息检索技术，旨在显著优化城市规划实践。](https://arxiv.org/abs/2402.19273)
#### PlanGPT: Enhancing Urban Planning with Tailored Language Model and Efficient Retrieval
发布时间：2024年02月29日
> 面对城市规划的独特需求，通用大型语言模型往往显得力不从心。为此，我们携手中国城市规划研究院等专业机构，创新推出专为城市与空间规划打造的第一款大型语言模型——PlanGPT。它结合了定制本地数据库检索架构、针对性的基础模型微调及尖端工具功能。实际验证显示，PlanGPT 在应对生成规划文本、信息检索、文档评估等任务时表现出色，其输出精准契合城市规划的复杂特性，显著提升了城市规划专业人士的工作效能。
> In the field of urban planning, general-purpose large language models often struggle to meet the specific needs of planners. Tasks like generating urban planning texts, retrieving related information, and evaluating planning documents pose unique challenges. To enhance the efficiency of urban professionals and overcome these obstacles, we introduce PlanGPT, the first specialized Large Language Model tailored for urban and spatial planning. Developed through collaborative efforts with institutions like the Chinese Academy of Urban Planning, PlanGPT leverages a customized local database retrieval framework, domain-specific fine-tuning of base models, and advanced tooling capabilities. Empirical tests demonstrate that PlanGPT has achieved advanced performance, delivering responses of superior quality precisely tailored to the intricacies of urban planning.
Agent
#### [GSM-Plus 是一套全面的评测基准，旨在深入检验大型语言模型在解决数学问题时的鲁棒性表现。](https://arxiv.org/abs/2402.19255)
#### GSM-Plus: A Comprehensive Benchmark for Evaluating the Robustness of LLMs as Mathematical Problem Solvers
发布时间：2024年02月29日
> LLMs在各数学推理基准上屡创佳绩，但也引发了争议——它们究竟是真正理解和应用数学知识，还是仅仅依赖数学推理的“小聪明”。一个有力的例证是，对数学问题稍作调整，LLMs就可能做出错误判断。为此，我们设计了一系列数学问题变体，用以检验LLMs数学推理能力的稳健性，并推出了扩充版的对抗性小学数学(\datasetname)数据集，在GSM8K基础上增加了多样化的数学扰动。实验证明，尽管不同LLMs的数学推理能力层次不齐，但总体而言其表现并不稳健。即使是已在GSM8K中解答过的问题，只要添加新信息或变换问题焦点，LLMs仍可能出现差错。此外，我们还研究了如何通过融合现有提示技术提高LLMs的稳健性，尝试了一种创新的方法——基于推理目标与计算结果逐步生成和验证每一个中间思考过程。相关代码和数据可在\url{https://github.com/qtli/GSM-Plus}获取。
> Large language models (LLMs) have achieved impressive performance across various mathematical reasoning benchmarks. However, there are increasing debates regarding whether these models truly understand and apply mathematical knowledge or merely rely on shortcuts for mathematical reasoning. One essential and frequently occurring evidence is that when the math questions are slightly changed, LLMs can behave incorrectly. This motivates us to evaluate the robustness of LLMs' math reasoning capability by testing a wide range of question variations. We introduce the adversarial grade school math (\datasetname) dataset, an extension of GSM8K augmented with various mathematical perturbations. Our experiments on 25 LLMs and 4 prompting techniques show that while LLMs exhibit different levels of math reasoning abilities, their performances are far from robust. In particular, even for problems that have been solved in GSM8K, LLMs can make mistakes when new statements are added or the question targets are altered. We also explore whether more robust performance can be achieved by composing existing prompting methods, in which we try an iterative method that generates and verifies each intermediate thought based on its reasoning goal and calculation result. Code and data are available at \url{https://github.com/qtli/GSM-Plus}.
LLM应用
#### [面对最新挑战，让大型语言模型 (LLMs) 大显身手！本研究提出了一项针对中文动态问题回答的权威基准。](https://arxiv.org/abs/2402.19248)
#### Let LLMs Take on the Latest Challenges! A Chinese Dynamic Question Answering Benchmark
发布时间：2024年02月29日
> 目前，针对大型语言模型（LLMs）能力的评估方法成为研究焦点，其中关注的重点是如何应对LLMs在解答最新动态问题时表现欠佳的问题。为此，本文提出了CDQA——一个基于中文互联网最新新闻构建的中文动态问答评测基准，该基准包含了大量高质量的问答对。我们借助人机协作的方式筛选并整理数据，巧妙地依据答案变更频率对样本进行细分，以利于对LLMs能力进行精细化考察。同时，我们在CDQA上对一系列主流及尖端的中文LLMs进行了详尽的评估和分析，所得丰富实验结果和深刻见解揭示了CDQA颇具挑战性，亟待更多后续探究。我们坚信，这一基准将有望成为未来提升LLMs中文问答性能的关键数据宝库。
> How to better evaluate the capabilities of Large Language Models (LLMs) is the focal point and hot topic in current LLMs research. Previous work has noted that due to the extremely high cost of iterative updates of LLMs, they are often unable to answer the latest dynamic questions well. To promote the improvement of Chinese LLMs' ability to answer dynamic questions, in this paper, we introduce CDQA, a Chinese Dynamic QA benchmark containing question-answer pairs related to the latest news on the Chinese Internet. We obtain high-quality data through a pipeline that combines humans and models, and carefully classify the samples according to the frequency of answer changes to facilitate a more fine-grained observation of LLMs' capabilities. We have also evaluated and analyzed mainstream and advanced Chinese LLMs on CDQA. Extensive experiments and valuable insights suggest that our proposed CDQA is challenging and worthy of more further study. We believe that the benchmark we provide will become the key data resource for improving LLMs' Chinese question-answering ability in the future.
LLM应用
#### [记忆强化的生成对抗Transformer模型](https://arxiv.org/abs/2402.19218)
#### Memory-Augmented Generative Adversarial Transformers
发布时间：2024年02月29日
> 基于大型语言模型（如Transformer）的对话AI系统，在融合理论知识与生成语言时面临挑战，它们往往难以精准回答事实性问题。本研究提出了一种改进方案，即在标准Transformer结构基础上增加一个包含额外信息（如来自知识库的事实）的记忆库，以及一个用于检索该记忆的新注意力层，并将此扩展内存融入GAN启发的Transformer架构中。这一创新设计使我们可以灵活控制Transformer生成语言的得体性。实验首先展示了这套机制如何应用于解决目标导向对话中的事实查询难题，然后进一步验证了它在风格适应等场景中的有效性——可根据对话中人类参与者的社会属性等外部风格限制进行话语调整。
> Conversational AI systems that rely on Large Language Models, like Transformers, have difficulty interweaving external data (like facts) with the language they generate. Vanilla Transformer architectures are not designed for answering factual questions with high accuracy. This paper investigates a possible route for addressing this problem. We propose to extend the standard Transformer architecture with an additional memory bank holding extra information (such as facts drawn from a knowledge base), and an extra attention layer for addressing this memory. We add this augmented memory to a Generative Adversarial Network-inspired Transformer architecture. This setup allows for implementing arbitrary felicity conditions on the generated language of the Transformer. We first demonstrate how this machinery can be deployed for handling factual questions in goal-oriented dialogues. Secondly, we demonstrate that our approach can be useful for applications like {\it style adaptation} as well: the adaptation of utterances according to certain stylistic (external) constraints, like social properties of human interlocutors in dialogues.
Agent
#### [PeLLE 是一款以开放数据为基础、专为巴西葡萄牙语设计的编码器式语言模型。](https://arxiv.org/abs/2402.19204)
#### PeLLE: Encoder-based language models for Brazilian Portuguese based on open data
发布时间：2024年02月29日
> 本文推出了PeLLE——一款以RoBERTa架构为基础、专门面向巴西葡萄牙语的大规模语言模型系列，其训练素材来自精心编纂的Carolina语料库公开数据。为保证实验结果的可复现性，我们详尽阐述了模型预训练的细节。我们还对PeLLE模型和一众现有多语言以及针对PT-BR精炼优化的预训练Transformer-based大型LLM编码器展开了对比评测，在多项下游任务中考察了大型预训练模型与虽小却精心筛选预训练模型之间的性能差异。最终发现，尽管许多任务在大模型上表现出色，但在预训练阶段，部分任务确实能从使用小而精选的数据集中获益。
> In this paper we present PeLLE, a family of large language models based on the RoBERTa architecture, for Brazilian Portuguese, trained on curated, open data from the Carolina corpus. Aiming at reproducible results, we describe details of the pretraining of the models. We also evaluate PeLLE models against a set of existing multilingual and PT-BR refined pretrained Transformer-based LLM encoders, contrasting performance of large versus smaller-but-curated pretrained models in several downstream tasks. We conclude that several tasks perform better with larger models, but some tasks benefit from smaller-but-curated data in its pretraining.
LLM应用
#### [PRSA：一种针对大型语言模型的新型攻击手段——Prompt Reverse Stealing，通过逆向窃取提示信息对LLM发起挑战。](https://arxiv.org/abs/2402.19200)
#### PRSA: Prompt Reverse Stealing Attacks against Large Language Models
发布时间：2024年02月29日
> 提示作为一种关键的知识产权，赋予LLMs无需微调就能胜任特定任务的能力，凸显其价值日益提升。如今，诸如提示市场和各类LLM应用等基于提示的服务不断涌现，服务商常借助展示输入-输出实例的方式揭示提示的强大功能，吸引用户关注。然而，这种做法带来一个核心安全隐患：公开输入-输出示例是否可能增加泄露潜在提示的风险，进而侵犯开发者的知识产权呢？当前，这一问题尚缺乏系统性研究。为此，本文首开先河，深度探究并构建了一套针对商业LLMs的创新逆向窃取提示攻击框架——PRSA。该框架的核心在于通过解析输入-输出对的关键特征，模拟并逐渐揭秘目标提示。PRSA包含两大关键步骤：提示变异与提示剪枝。在变异环节，我们设计了一种基于差异化反馈的提示注意力算法，精准捕获关键特征，助力高效推测目标提示。而在剪枝环节，则甄别并遮蔽那些依赖特定输入的词语，从而使提示能灵活应对多样化的输入，实现更好的泛化能力。经过大规模的实验验证，我们证实PRSA在现实场景下确实构成了重大威胁。目前，我们已将这些研究成果通报给相关提示服务提供商，并正积极与其协作，共同寻求实施保护措施以捍卫提示的版权权益。
> Prompt, recognized as crucial intellectual property, enables large language models (LLMs) to perform specific tasks without the need of fine-tuning, underscoring their escalating importance. With the rise of prompt-based services, such as prompt marketplaces and LLM applications, providers often display prompts' capabilities through input-output examples to attract users. However, this paradigm raises a pivotal security concern: does the exposure of input-output pairs pose the risk of potential prompt leakage, infringing on the intellectual property rights of the developers? To our knowledge, this problem still has not been comprehensively explored yet. To remedy this gap, in this paper, we perform the first in depth exploration and propose a novel attack framework for reverse-stealing prompts against commercial LLMs, namely PRSA. The main idea of PRSA is that by analyzing the critical features of the input-output pairs, we mimic and gradually infer (steal) the target prompts. In detail, PRSA mainly consists of two key phases: prompt mutation and prompt pruning. In the mutation phase, we propose a prompt attention algorithm based on differential feedback to capture these critical features for effectively inferring the target prompts. In the prompt pruning phase, we identify and mask the words dependent on specific inputs, enabling the prompts to accommodate diverse inputs for generalization. Through extensive evaluation, we verify that PRSA poses a severe threat in real world scenarios. We have reported these findings to prompt service providers and actively collaborate with them to take protective measures for prompt copyright.
LLM应用
#### [StarCoder 2 与 The Stack v2：引领下一代创新潮流](https://arxiv.org/abs/2402.19173)
#### StarCoder 2 and The Stack v2: The Next Generation
发布时间：2024年02月29日
> BigCode项目致力于负责任地开发大型代码语言模型（Code LLMs），并携手Software Heritage（SWH）推出StarCoder2。基于SWH丰富的源代码档案，我们打造了一个名为The Stack v2的强大基础。在囊括619种编程语言的SWH仓库基础上，我们精选了GitHub PR、Kaggle笔记本和代码文档等优质数据源，构建出比首版StarCoder大四倍的训练集。我们在此基础上训练了拥有3B、7B和15B参数的StarCoder2系列模型，它们在3.3万亿至4.3万亿个令牌上进行训练，并在广泛的Code LLM基准测试中接受了深度评测。其中，小巧的StarCoder2-3B在多数基准测试中击败了同级规模的其他Code LLM，并超越了StarCoderBase-15B。而大体量的StarCoder2-15B则在同等尺寸模型中一骑绝尘，甚至能与体积超过自身两倍的CodeLlama-34B平分秋色，甚至在某些数学、代码推理及低资源语言任务上胜出。尽管DeepSeekCoder-33B在高资源语言的代码补全任务上表现出色，但在数学和代码推理基准测试以及若干低资源语言场景下，StarCoder2-15B的表现更为优秀。我们已将模型权重以OpenRAIL许可开放，并通过公开源代码数据的SoftWare Heritage持久标识符（SWHIDs），保证了训练数据的完全透明。
> The BigCode project, an open-scientific collaboration focused on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder2. In partnership with Software Heritage (SWH), we build The Stack v2 on top of the digital commons of their source code archive. Alongside the SWH repositories spanning 619 programming languages, we carefully select other high-quality data sources, such as GitHub pull requests, Kaggle notebooks, and code documentation. This results in a training set that is 4x larger than the first StarCoder dataset. We train StarCoder2 models with 3B, 7B, and 15B parameters on 3.3 to 4.3 trillion tokens and thoroughly evaluate them on a comprehensive set of Code LLM benchmarks. We find that our small model, StarCoder2-3B, outperforms other Code LLMs of similar size on most benchmarks, and also outperforms StarCoderBase-15B. Our large model, StarCoder2- 15B, significantly outperforms other models of comparable size. In addition, it matches or outperforms CodeLlama-34B, a model more than twice its size. Although DeepSeekCoder- 33B is the best-performing model at code completion for high-resource languages, we find that StarCoder2-15B outperforms it on math and code reasoning benchmarks, as well as several low-resource languages. We make the model weights available under an OpenRAIL license and ensure full transparency regarding the training data by releasing the SoftWare Heritage persistent IDentifiers (SWHIDs) of the source code data.
Agent
#### [实时教授大型语言模型掌握新语言](https://arxiv.org/abs/2402.19167)
#### Teaching Large Language Models an Unseen Language on the Fly
发布时间：2024年02月29日
> 面对大量低资源乃至极低资源语言（尤其是训练数据极其有限）的支持难题，现有大型语言模型显得力不从心。为此，我们研究LLMs能否通过提示即刻习得新语言。为深入探讨此问题，我们精心构建了一套专门针对当前尚未被任何LLM支持的壮语的研究集，并创新提出了\textsc{DiPMT++}框架，利用上下文学习技术令LLMs适应未曾遇见的语言。仅使用一本词典和5千句平行语料，\textsc{DiPMT++}就显著提高了GPT-4对中壮互译任务的表现，使得中译壮的BLEU得分从零跃升至16分，而壮译中的成绩更是高达32分。不仅如此，我们进一步证实了这一框架在实际应用中能够帮助人们翻译完全陌生的语言，从而有力地推动了语言多样性的保护工作。
> Existing large language models struggle to support numerous low-resource languages, particularly the extremely low-resource ones where there is minimal training data available for effective parameter updating. We thus investigate whether LLMs can learn a new language on the fly solely through prompting. To study this question, we collect a research suite for Zhuang, a language supported by no LLMs currently. We introduce \textsc{DiPMT++}, a framework for adapting LLMs to unseen languages by in-context learning. Using a dictionary and only 5K parallel sentences, \textsc{DiPMT++} significantly enhances the performance of GPT-4 from 0 to 16 BLEU for Chinese-to-Zhuang translation and achieves 32 BLEU for Zhuang-to-Chinese translation. Furthermore, we demonstrate the practical utility of this framework in aiding humans to translate completely unseen languages, which could contribute to the preservation of linguistic diversity.
LLM应用