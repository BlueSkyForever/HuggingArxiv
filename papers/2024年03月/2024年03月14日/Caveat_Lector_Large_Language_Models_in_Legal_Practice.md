# [敬请留意：大型语言模型在法律领域的运用，需审慎对待](https://arxiv.org/abs/2403.09163)

发布时间：2024年03月14日

`LLM应用`

``

``

> Caveat Lector: Large Language Models in Legal Practice

> 如今人们对LLMs的关注源自多数用户难以评估生成文本的质量，这使得LLMs看似能力超群。然而，其流畅易懂的特点可能误导人们对生成文本过分信赖，从而潜藏过度依赖的风险。试问谁能抗拒那些完美无瑕的法律表述呢？本文结合最新技术和法学研究成果，对LLMs在法律实践中作用的盲目乐观论断进行了理性平衡。若在未深入理解LLMs局限性的情况下将其融入法律工作流程，非但可能导致效率降低，甚至可能带来实实在在的风险。尽管LLMs在生成文本方面展现出了空前实力，却仍不具备理解文本深层含义的能力。没有理解力，LLMs就无法真正运用语言、获取知识或进行复杂推理。它们通过随机词预测训练建模语言，无法辨别真实与虚构之间的界限。LLMs掌握的法律知识仅局限于其参数记忆下的词串，且这些知识往往残缺不全且存在大量谬误。LLMs处理的是词频分布而非经验证据，这就导致它们容易臆想出看似有帮助、相关，实则错误的信息。在像法律服务这类高风险领域，这一缺陷尤其令人警醒。现阶段，律师们应当谨慎对待由LLMs生成的文本内容。

> The current fascination with large language models, or LLMs, derives from the fact that many users lack the expertise to evaluate the quality of the generated text. LLMs may therefore appear more capable than they actually are. The dangerous combination of fluency and superficial plausibility leads to the temptation to trust the generated text and creates the risk of overreliance. Who would not trust perfect legalese? Relying recent findings in both technical and legal scholarship, this Article counterbalances the overly optimistic predictions as to the role of LLMs in legal practice. Integrating LLMs into legal workstreams without a better comprehension of their limitations, will create inefficiencies if not outright risks. Notwithstanding their unprecedented ability to generate text, LLMs do not understand text. Without the ability to understand meaning, LLMs will remain unable to use language, to acquire knowledge and to perform complex reasoning tasks. Trained to model language on the basis of stochastic word predictions, LLMs cannot distinguish fact from fiction. Their knowledge of the law is limited to word strings memorized in their parameters. It is also incomplete and largely incorrect. LLMs operate at the level of word distributions, not at the level of verified facts. The resulting propensity to hallucinate, to produce statements that are incorrect but appear helpful and relevant, is alarming in high-risk areas like legal services. At present, lawyers should beware of relying on text generated by LLMs.