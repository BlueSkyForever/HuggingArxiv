# 2024年03月

- [Hierarchical Indexing for Retrieval-Augmented Opinion Summarization](2024年03月01日/Hierarchical_Indexing_for_Retrieval-Augmented_Opinion_Summarization.md)

    - [翻译: 为提升检索增强型观点摘要的效果，我们引入了层次化索引技术。该方法旨在通过构建多层次的索引结构，有效组织和检索相关文本信息，从而优化观点总结的质量与效率。](2024年03月01日/Hierarchical_Indexing_for_Retrieval-Augmented_Opinion_Summarization.md)

- [HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding](2024年03月01日/HALC_Object_Hallucination_Reduction_via_Adaptive_Focal-Contrast_Decoding.md)

    - [翻译: HALC 方法提出了一种新颖的自适应焦点对比解码技术，旨在有效减少对象幻觉现象。该方法针对图像识别中的错误预测问题，通过优化解码过程来提升模型对真实目标的区分能力和鲁棒性。](2024年03月01日/HALC_Object_Hallucination_Reduction_via_Adaptive_Focal-Contrast_Decoding.md)

- [Rethinking Tokenization: Crafting Better Tokenizers for Large Language Models](2024年03月01日/Rethinking_Tokenization_Crafting_Better_Tokenizers_for_Large_Language_Models.md)

    - [翻译: 面对大型语言模型，我们有必要重新审视和改进分词方法，以创造出更能满足其需求的高性能分词器。](2024年03月01日/Rethinking_Tokenization_Crafting_Better_Tokenizers_for_Large_Language_Models.md)

- [Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with Fact-Checking in Turkish](2024年03月01日/Cross-Lingual_Learning_vs._Low-Resource_Fine-Tuning_A_Case_Study_with_Fact-Checking_in_Turkish.md)

    - [翻译: 本研究通过土耳其语的事实查证案例，探讨了跨语言学习与低资源微调两种方法的优劣。](2024年03月01日/Cross-Lingual_Learning_vs._Low-Resource_Fine-Tuning_A_Case_Study_with_Fact-Checking_in_Turkish.md)

- [Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview](2024年03月01日/Post-decoder_Biasing_for_End-to-End_Speech_Recognition_of_Multi-turn_Medical_Interview.md)

    - [翻译: 在多轮医疗访谈端到端语音识别技术中，我们采用了解码器后置偏置策略以优化识别效果。](2024年03月01日/Post-decoder_Biasing_for_End-to-End_Speech_Recognition_of_Multi-turn_Medical_Interview.md)

- [Semi-Instruct: Bridging Natural-Instruct and Self-Instruct for Code Large Language Models](2024年03月01日/Semi-Instruct_Bridging_Natural-Instruct_and_Self-Instruct_for_Code_Large_Language_Models.md)

    - [翻译: Semi-Instruct 方法旨在弥合自然指令与自我指令之间的鸿沟，以提升代码大型语言模型的表现。它通过结合两种教学模式的优势，探索在代码理解和生成任务中更高效地引导大型语言模型的新途径。](2024年03月01日/Semi-Instruct_Bridging_Natural-Instruct_and_Self-Instruct_for_Code_Large_Language_Models.md)

- [Never-Ending Embodied Robot Learning](2024年03月01日/Never-Ending_Embodied_Robot_Learning.md)

    - [翻译: 无尽的实体化机器人学习](2024年03月01日/Never-Ending_Embodied_Robot_Learning.md)

- [Self-Consistent Decoding for More Factual Open Responses](2024年03月01日/Self-Consistent_Decoding_for_More_Factual_Open_Responses.md)

    - [翻译: 为了生成更为事实准确的开放式回答，我们采用“自我一致性解码”方法。](2024年03月01日/Self-Consistent_Decoding_for_More_Factual_Open_Responses.md)

- [Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents](2024年03月01日/Playing_NetHack_with_LLMs_Potential_&_Limitations_as_Zero-Shot_Agents.md)

    - [翻译: 在运用 LLMs 探索 NetHack 游戏中，我们发掘其作为零样本代理的潜力与局限。这项研究聚焦于 LLMS 在未经专门训练情况下，即“零样本”状态下应对复杂游戏环境的能力及其限制。](2024年03月01日/Playing_NetHack_with_LLMs_Potential_&_Limitations_as_Zero-Shot_Agents.md)

- [Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks](2024年03月01日/Diff-Plugin_Revitalizing_Details_for_Diffusion-based_Low-level_Tasks.md)

    - [翻译: Diff-Plugin：激活扩散式底层任务中的精细细节，赋予其新的生命力](2024年03月01日/Diff-Plugin_Revitalizing_Details_for_Diffusion-based_Low-level_Tasks.md)

- [NeuPIMs: A NPU-PIM Heterogeneous Acceleration for Batched Inference of Large Language Model](2024年03月01日/NeuPIMs_A_NPU-PIM_Heterogeneous_Acceleration_for_Batched_Inference_of_Large_Language_Model.md)

    - [翻译: NeuPIMs，为解决大型语言模型批量推理问题而生，是一种融合了NPU与PIM技术的高效异构加速方案。](2024年03月01日/NeuPIMs_A_NPU-PIM_Heterogeneous_Acceleration_for_Batched_Inference_of_Large_Language_Model.md)

- [Standardizing the Measurement of Text Diversity: A Tool and a Comparative Analysis of Scores](2024年03月01日/Standardizing_the_Measurement_of_Text_Diversity_A_Tool_and_a_Comparative_Analysis_of_Scores.md)

    - [翻译: 为了更准确、直观地评估文本多样性，本研究提出了一种标准化测量工具，并对不同方法所得分数进行了深入对比分析。](2024年03月01日/Standardizing_the_Measurement_of_Text_Diversity_A_Tool_and_a_Comparative_Analysis_of_Scores.md)

- [DyPyBench: A Benchmark of Executable Python Software](2024年03月01日/DyPyBench_A_Benchmark_of_Executable_Python_Software.md)

    - [翻译: DyPyBench 是一款专注于可执行 Python 软件性能评估的基准测试工具，用于衡量各类 Python 应用程序的实际运行效果。](2024年03月01日/DyPyBench_A_Benchmark_of_Executable_Python_Software.md)

- [Large Language Models for Simultaneous Named Entity Extraction and Spelling Correction](2024年03月01日/Large_Language_Models_for_Simultaneous_Named_Entity_Extraction_and_Spelling_Correction.md)

    - [翻译: 针对同时执行命名实体提取与拼写修正任务，本研究探讨了大型语言模型的应用潜力。通过利用大型语言模型的力量，我们旨在提升模型在面对实体抽取与拼写错误修正双重挑战时的表现。](2024年03月01日/Large_Language_Models_for_Simultaneous_Named_Entity_Extraction_and_Spelling_Correction.md)

- [VisionLLaMA: A Unified LLaMA Interface for Vision Tasks](2024年03月01日/VisionLLaMA_A_Unified_LLaMA_Interface_for_Vision_Tasks.md)

    - [翻译: VisionLLaMA 是一个为各类视觉任务打造的统一 LLaMA（大规模预训练语言模型）接口，旨在整合并发挥 LLama 在视觉领域的强大功能。](2024年03月01日/VisionLLaMA_A_Unified_LLaMA_Interface_for_Vision_Tasks.md)

- [ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models](2024年03月01日/ROME_Memorization_Insights_from_Text,_Probability_and_Hidden_State_in_Large_Language_Models.md)

    - [翻译: ROME 研究深入探索大型语言模型中，通过分析文本、概率分布以及隐藏状态揭示其内在的记忆机制。](2024年03月01日/ROME_Memorization_Insights_from_Text,_Probability_and_Hidden_State_in_Large_Language_Models.md)

- [TempCompass: Do Video LLMs Really Understand Videos?](2024年03月01日/TempCompass_Do_Video_LLMs_Really_Understand_Videos.md)

    - [翻译: TempCompass——探究视频 LLM 是否真正具备理解视频内容的能力。](2024年03月01日/TempCompass_Do_Video_LLMs_Really_Understand_Videos.md)

- [LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues](2024年03月01日/LUCID_LLM-Generated_Utterances_for_Complex_and_Interesting_Dialogues.md)

    - [翻译: LUCID：针对复杂且引人入胜的对话，利用LLM技术生成高质量话语](2024年03月01日/LUCID_LLM-Generated_Utterances_for_Complex_and_Interesting_Dialogues.md)

- [When Large Language Models Confront Repository-Level Automatic Program Repair: How Well They Done?](2024年03月01日/When_Large_Language_Models_Confront_Repository-Level_Automatic_Program_Repair_How_Well_They_Done.md)

    - [翻译: 面对仓库级自动程序修复任务，大型语言模型的表现究竟如何呢？](2024年03月01日/When_Large_Language_Models_Confront_Repository-Level_Automatic_Program_Repair_How_Well_They_Done.md)

- [Mitigating Reversal Curse via Semantic-aware Permutation Training](2024年03月01日/Mitigating_Reversal_Curse_via_Semantic-aware_Permutation_Training.md)

    - [翻译: 为了解决反转诅咒问题，我们提出了一种基于语义感知排列训练的方法。该方法通过精心设计的训练策略，能够有效抑制模型在处理特定任务时出现的反转诅咒效应，从而提升模型性能和鲁棒性。](2024年03月01日/Mitigating_Reversal_Curse_via_Semantic-aware_Permutation_Training.md)

- [AtP*: An efficient and scalable method for localizing LLM behaviour to components](2024年03月01日/AtP_An_efficient_and_scalable_method_for_localizing_LLM_behaviour_to_components.md)

    - [翻译: AtP*：一项创新技术，高效且易于规模化应用，旨在对大型语言模型（LLM）的行为进行精细化组件定位。](2024年03月01日/AtP_An_efficient_and_scalable_method_for_localizing_LLM_behaviour_to_components.md)

- [LAB: Large-Scale Alignment for ChatBots](2024年03月01日/LAB_Large-Scale_Alignment_for_ChatBots.md)

    - [翻译: LAB项目致力于为聊天机器人开发大规模的对齐技术，旨在提升其对话理解和生成能力。](2024年03月01日/LAB_Large-Scale_Alignment_for_ChatBots.md)

- [LLMCRIT: Teaching Large Language Models to Use Criteria](2024年03月01日/LLMCRIT_Teaching_Large_Language_Models_to_Use_Criteria.md)

    - [翻译: LLMCRIT 计划旨在教授大型语言模型如何运用评判标准。](2024年03月01日/LLMCRIT_Teaching_Large_Language_Models_to_Use_Criteria.md)

- [FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based Sentiment Analysis](2024年03月01日/FaiMA_Feature-aware_In-context_Learning_for_Multi-domain_Aspect-based_Sentiment_Analysis.md)

    - [翻译: FaiMA 是一项创新技术，专注于在多领域情境下进行特征感知的上下文学习，以提升基于方面的观点分析效果。](2024年03月01日/FaiMA_Feature-aware_In-context_Learning_for_Multi-domain_Aspect-based_Sentiment_Analysis.md)

- [Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers](2024年03月01日/Reading_Subtext_Evaluating_Large_Language_Models_on_Short_Story_Summarization_with_Writers.md)

    - [翻译: 在“解读言外之意”的研究中，我们通过让大型语言模型处理由作家编写的短篇小说摘要，来评估其在该任务上的表现能力。](2024年03月01日/Reading_Subtext_Evaluating_Large_Language_Models_on_Short_Story_Summarization_with_Writers.md)

- [Towards Full Authorship with AI: Supporting Revision with AI-Generated Views](2024年03月01日/Towards_Full_Authorship_with_AI_Supporting_Revision_with_AI-Generated_Views.md)

    - [翻译: 向着以AI驱动的完全创作迈进，我们探讨如何借助AI生成的视角来有效支持文章修订过程。](2024年03月01日/Towards_Full_Authorship_with_AI_Supporting_Revision_with_AI-Generated_Views.md)

- [AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks](2024年03月01日/AutoAttacker_A_Large_Language_Model_Guided_System_to_Implement_Automatic_Cyber-attacks.md)

    - [翻译: AutoAttacker 是一套在大型语言模型指导下运作的智能系统，致力于执行自动化网络攻击任务。](2024年03月01日/AutoAttacker_A_Large_Language_Model_Guided_System_to_Implement_Automatic_Cyber-attacks.md)

- [Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks](2024年03月01日/Peacock_A_Family_of_Arabic_Multimodal_Large_Language_Models_and_Benchmarks.md)

    - [翻译: 孔雀系列：展现了一族专为阿拉伯语设计的多模态大型语言模型及其对应的基准测试标准](2024年03月01日/Peacock_A_Family_of_Arabic_Multimodal_Large_Language_Models_and_Benchmarks.md)

- [BasedAI: A decentralized P2P network for Zero Knowledge Large Language Models (ZK-LLMs)](2024年03月01日/BasedAI_A_decentralized_P2P_network_for_Zero_Knowledge_Large_Language_Models_(ZK-LLMs).md)

    - [翻译: BasedAI 是一个专为零知识大型语言模型打造的去中心化P2P网络，旨在为ZK-LLMs提供高效、安全的分布式运行环境。](2024年03月01日/BasedAI_A_decentralized_P2P_network_for_Zero_Knowledge_Large_Language_Models_(ZK-LLMs).md)

- [Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries](2024年03月01日/Attribute_Structuring_Improves_LLM-Based_Evaluation_of_Clinical_Text_Summaries.md)

    - [翻译: 通过属性结构化优化，我们能够提升LLM在评估临床文本摘要时的表现。](2024年03月01日/Attribute_Structuring_Improves_LLM-Based_Evaluation_of_Clinical_Text_Summaries.md)

- [Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language](2024年03月01日/Leveraging_Prompt-Based_Large_Language_Models_Predicting_Pandemic_Health_Decisions_and_Outcomes_Through_Social_Media_Language.md)

    - [翻译: 利用 prompt 优化的大型语言模型，我们可以从社交媒体的语言中洞悉并预测疫情期间人们的健康决策与相应结果。](2024年03月01日/Leveraging_Prompt-Based_Large_Language_Models_Predicting_Pandemic_Health_Decisions_and_Outcomes_Through_Social_Media_Language.md)

- [LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems](2024年03月01日/LocalRQA_From_Generating_Data_to_Locally_Training,_Testing,_and_Deploying_Retrieval-Augmented_QA_Systems.md)

    - [翻译: LocalRQA：一站式方案，从构建数据集到本地完成增强检索型问答系统的训练、测试与部署。](2024年03月01日/LocalRQA_From_Generating_Data_to_Locally_Training,_Testing,_and_Deploying_Retrieval-Augmented_QA_Systems.md)

- [MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection](2024年03月01日/MALTO_at_SemEval-2024_Task_6_Leveraging_Synthetic_Data_for_LLM_Hallucination_Detection.md)

    - [翻译: SemEval-2024第六项任务中，MALTO团队采用创新策略，借助合成数据增强大型语言模型对幻觉内容的识别能力。](2024年03月01日/MALTO_at_SemEval-2024_Task_6_Leveraging_Synthetic_Data_for_LLM_Hallucination_Detection.md)

- [AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models](2024年03月01日/AutoRD_An_Automatic_and_End-to-End_System_for_Rare_Disease_Knowledge_Graph_Construction_Based_on_Ontologies-enhanced_Large_Language_Models.md)

    - [翻译: AutoRD 是一款创新的全自动端到端系统，它利用了本体增强的大型语言模型技术，专注于高效构建罕见病知识图谱。](2024年03月01日/AutoRD_An_Automatic_and_End-to-End_System_for_Rare_Disease_Knowledge_Graph_Construction_Based_on_Ontologies-enhanced_Large_Language_Models.md)

- [MediSwift: Efficient Sparse Pre-trained Biomedical Language Models](2024年03月01日/MediSwift_Efficient_Sparse_Pre-trained_Biomedical_Language_Models.md)

    - [翻译: MediSwift 是一种高效、预先训练的稀疏型生物医学语言模型，专为提升处理领域内大规模数据的效率而设计。](2024年03月01日/MediSwift_Efficient_Sparse_Pre-trained_Biomedical_Language_Models.md)

- [Differentially Private Knowledge Distillation via Synthetic Text Generation](2024年03月01日/Differentially_Private_Knowledge_Distillation_via_Synthetic_Text_Generation.md)

    - [翻译: 我们提出了一种新颖的方法，利用合成文本生成技术来实现差异隐私保护下的知识蒸馏，这种方法能够在保护数据隐私的同时提取和传递模型知识。](2024年03月01日/Differentially_Private_Knowledge_Distillation_via_Synthetic_Text_Generation.md)

- [DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models](2024年03月01日/DiaHalu_A_Dialogue-level_Hallucination_Evaluation_Benchmark_for_Large_Language_Models.md)

    - [翻译: DiaHalu：一款针对大型语言模型设计的对话级 hallucination 评估基准工具，旨在精准衡量其在对话生成中的幻觉现象表现。](2024年03月01日/DiaHalu_A_Dialogue-level_Hallucination_Evaluation_Benchmark_for_Large_Language_Models.md)

- [A systematic evaluation of large language models for generating programming code](2024年03月01日/A_systematic_evaluation_of_large_language_models_for_generating_programming_code.md)

    - [翻译: 本研究对大型语言模型在生成编程代码任务上的表现进行了全面而系统的评估。](2024年03月01日/A_systematic_evaluation_of_large_language_models_for_generating_programming_code.md)

- [Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment](2024年03月01日/Text_classification_of_column_headers_with_a_controlled_vocabulary_leveraging_LLMs_for_metadata_enrichment.md)

    - [翻译: 借助LLMs，本研究探讨如何运用受控词汇对列标题进行文本分类，以实现元数据的有效丰富。](2024年03月01日/Text_classification_of_column_headers_with_a_controlled_vocabulary_leveraging_LLMs_for_metadata_enrichment.md)

- [Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models](2024年03月01日/Crimson_Empowering_Strategic_Reasoning_in_Cybersecurity_through_Large_Language_Models.md)

    - [翻译: Crimson项目致力于运用大型语言模型来增强网络安全领域中的战略推理，以期在应对网络威胁时提供更为精准且深思熟虑的解决方案。](2024年03月01日/Crimson_Empowering_Strategic_Reasoning_in_Cybersecurity_through_Large_Language_Models.md)

- [DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases](2024年03月01日/DFIN-SQL_Integrating_Focused_Schema_with_DIN-SQL_for_Superior_Accuracy_in_Large-Scale_Databases.md)

    - [翻译: DFIN-SQL 是一项创新技术，它将聚焦模式与 DIN-SQL 整合，旨在提升在处理大型数据库时的查询精确度。](2024年03月01日/DFIN-SQL_Integrating_Focused_Schema_with_DIN-SQL_for_Superior_Accuracy_in_Large-Scale_Databases.md)

- [Teach LLMs to Phish: Stealing Private Information from Language Models](2024年03月01日/Teach_LLMs_to_Phish_Stealing_Private_Information_from_Language_Models.md)

    - [翻译: 让 LLM 学会“垂钓”隐私：探究如何从语言模型中获取敏感信息](2024年03月01日/Teach_LLMs_to_Phish_Stealing_Private_Information_from_Language_Models.md)

- [Open Assistant Toolkit -- version 2](2024年03月01日/Open_Assistant_Toolkit_--_version_2.md)

    - [翻译: Open Assistant Toolkit 第二版](2024年03月01日/Open_Assistant_Toolkit_--_version_2.md)

- [Accelerating Greedy Coordinate Gradient via Probe Sampling](2024年03月02日/Accelerating_Greedy_Coordinate_Gradient_via_Probe_Sampling.md)

    - [翻译: 我们提出了一种利用探针采样技术来提升贪婪坐标梯度法的效率，即“加速贪婪坐标梯度探针采样方法”，尤其在处理大规模优化问题时，有效提高了算法的运行速度与性能。](2024年03月02日/Accelerating_Greedy_Coordinate_Gradient_via_Probe_Sampling.md)

- [SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code](2024年03月02日/SceneCraft_An_LLM_Agent_for_Synthesizing_3D_Scene_as_Blender_Code.md)

    - [翻译: SceneCraft——专为生成Blender代码而设计的3D场景构建LLM智能体](2024年03月02日/SceneCraft_An_LLM_Agent_for_Synthesizing_3D_Scene_as_Blender_Code.md)

- [Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal](2024年03月02日/Mitigating_Catastrophic_Forgetting_in_Large_Language_Models_with_Self-Synthesized_Rehearsal.md)

    - [翻译: 在大型语言模型中，采用自合成复习方法有效减轻灾难性遗忘问题。](2024年03月02日/Mitigating_Catastrophic_Forgetting_in_Large_Language_Models_with_Self-Synthesized_Rehearsal.md)

- [IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact](2024年03月02日/IntactKV_Improving_Large_Language_Model_Quantization_by_Keeping_Pivot_Tokens_Intact.md)

    - [翻译: IntactKV 方法旨在提升大型语言模型量化性能，其核心在于保留枢轴令牌的完整性。](2024年03月02日/IntactKV_Improving_Large_Language_Model_Quantization_by_Keeping_Pivot_Tokens_Intact.md)

- [Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy](2024年03月02日/Inexact_Unlearning_Needs_More_Careful_Evaluations_to_Avoid_a_False_Sense_of_Privacy.md)

    - [翻译: 针对 Inexact Unlearning，为了防止对隐私安全产生误解，我们必须对其进行更为细致的评估。](2024年03月02日/Inexact_Unlearning_Needs_More_Careful_Evaluations_to_Avoid_a_False_Sense_of_Privacy.md)

- [API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access](2024年03月02日/API_Is_Enough_Conformal_Prediction_for_Large_Language_Models_Without_Logit-Access.md)

    - [翻译: 仅使用 API 即可实现：无需访问 logits，也能为大型语言模型应用相符预测技术。](2024年03月02日/API_Is_Enough_Conformal_Prediction_for_Large_Language_Models_Without_Logit-Access.md)

- [Data-free Multi-label Image Recognition via LLM-powered Prompt Tuning](2024年03月02日/Data-free_Multi-label_Image_Recognition_via_LLM-powered_Prompt_Tuning.md)

    - [翻译: 借助 LLM 强大的提示调优技术，我们能够实现无需原始数据的多标签图像识别。这项研究探讨了如何在没有数据的情况下，利用 LLM 的能力进行多标签图像识别任务的优化和提升。](2024年03月02日/Data-free_Multi-label_Image_Recognition_via_LLM-powered_Prompt_Tuning.md)

- [The Case for Animal-Friendly AI](2024年03月02日/The_Case_for_Animal-Friendly_AI.md)

    - [翻译: 倡导动物友好型 AI：为何我们需要关注并研发对动物友好的人工智能技术？](2024年03月02日/The_Case_for_Animal-Friendly_AI.md)

- [DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling](2024年03月02日/DMoERM_Recipes_of_Mixture-of-Experts_for_Effective_Reward_Modeling.md)

    - [翻译: DMoERM：揭秘混合专家模型在高效奖励建模中的秘籍](2024年03月02日/DMoERM_Recipes_of_Mixture-of-Experts_for_Effective_Reward_Modeling.md)

- [RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots](2024年03月02日/RAGged_Edges_The_Double-Edged_Sword_of_Retrieval-Augmented_Chatbots.md)

    - [翻译: 标题：“RAGged Edges”揭示了检索增强型聊天机器人这一把双刃剑的复杂性。该研究探讨了在提升聊天机器人性能的同时，检索增强技术所带来的挑战与局限性。](2024年03月02日/RAGged_Edges_The_Double-Edged_Sword_of_Retrieval-Augmented_Chatbots.md)

- [STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models](2024年03月02日/STAR_Constraint_LoRA_with_Dynamic_Active_Learning_for_Data-Efficient_Fine-Tuning_of_Large_Language_Models.md)

    - [翻译: STAR 方法将动态主动学习与约束版的 LoRA 结合，旨在提升大型语言模型在数据有限条件下的微调效率。](2024年03月02日/STAR_Constraint_LoRA_with_Dynamic_Active_Learning_for_Data-Efficient_Fine-Tuning_of_Large_Language_Models.md)

- [HeteGen: Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices](2024年03月02日/HeteGen_Heterogeneous_Parallel_Inference_for_Large_Language_Models_on_Resource-Constrained_Devices.md)

    - [翻译: HeteGen 是专为资源有限的设备设计的，能够实现大型语言模型的异构并行推理技术。这项技术针对大模型在资源受限环境下的高效运行，提供了一种创新的并行处理方案。](2024年03月02日/HeteGen_Heterogeneous_Parallel_Inference_for_Large_Language_Models_on_Resource-Constrained_Devices.md)

- [A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization](2024年03月02日/A_Survey_of_AI-generated_Text_Forensic_Systems_Detection,_Attribution,_and_Characterization.md)

    - [翻译: 本篇综述聚焦于人工智能生成文本的取证系统，涵盖了检测、归属及其特性分析三大核心领域。](2024年03月02日/A_Survey_of_AI-generated_Text_Forensic_Systems_Detection,_Attribution,_and_Characterization.md)

- [ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies](2024年03月02日/ParallelPARC_A_Scalable_Pipeline_for_Generating_Natural-Language_Analogies.md)

    - [翻译: ParallelPARC，一款专为高效生成自然语言类比而设计的可扩展式处理流程](2024年03月02日/ParallelPARC_A_Scalable_Pipeline_for_Generating_Natural-Language_Analogies.md)

- [LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization](2024年03月02日/LLM-PQ_Serving_LLM_on_Heterogeneous_Clusters_with_Phase-Aware_Partition_and_Adaptive_Quantization.md)

    - [翻译: LLM-PQ方案，针对异构集群环境，采用阶段感知分区与自适应量化技术，有效服务于大型语言模型，提升其在各类集群上的运行效率。](2024年03月02日/LLM-PQ_Serving_LLM_on_Heterogeneous_Clusters_with_Phase-Aware_Partition_and_Adaptive_Quantization.md)

- [Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data](2024年03月02日/Evaluating_Large_Language_Models_as_Virtual_Annotators_for_Time-series_Physical_Sensing_Data.md)

    - [翻译: 本研究探讨将大型语言模型应用于时间序列物理传感数据的虚拟标注任务，以评估其作为有效标注工具的能力。](2024年03月02日/Evaluating_Large_Language_Models_as_Virtual_Annotators_for_Time-series_Physical_Sensing_Data.md)

- [LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation](2024年03月02日/LLaMoCo_Instruction_Tuning_of_Large_Language_Models_for_Optimization_Code_Generation.md)

    - [翻译: LLaMoCo 是一项研究，专注于通过指令微调大规模语言模型，以提升其生成优化代码的能力。](2024年03月02日/LLaMoCo_Instruction_Tuning_of_Large_Language_Models_for_Optimization_Code_Generation.md)

- [Text-guided Explorable Image Super-resolution](2024年03月02日/Text-guided_Explorable_Image_Super-resolution.md)

    - [翻译: Text-guided Explorable Image Super-resolution，即借助文本引导实现可交互式探索的图像超分辨率技术。](2024年03月02日/Text-guided_Explorable_Image_Super-resolution.md)

- [Distilling Text Style Transfer With Self-Explanation From LLMs](2024年03月02日/Distilling_Text_Style_Transfer_With_Self-Explanation_From_LLMs.md)

    - [翻译: 本研究致力于从大型语言模型（LLM）中提炼出带有自我解释功能的文本风格转换技术，旨在探索如何有效利用LLM进行文本风格迁移，并通过自我解释机制提升其可解释性和应用效果。](2024年03月02日/Distilling_Text_Style_Transfer_With_Self-Explanation_From_LLMs.md)

- [CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring Commonsense Reasoning and Long-Tail Knowledge](2024年03月02日/CR-LT-KGQA_A_Knowledge_Graph_Question_Answering_Dataset_Requiring_Commonsense_Reasoning_and_Long-Tail_Knowledge.md)

    - [翻译: CR-LT-KGQA 是一个专注于常识推理与长尾知识需求的知识图谱问答数据集，旨在提升模型在解决复杂问题时兼顾广泛而稀疏知识的能力。](2024年03月02日/CR-LT-KGQA_A_Knowledge_Graph_Question_Answering_Dataset_Requiring_Commonsense_Reasoning_and_Long-Tail_Knowledge.md)

- [Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering](2024年03月02日/Right_for_Right_Reasons_Large_Language_Models_for_Verifiable_Commonsense_Knowledge_Graph_Question_Answering.md)

    - [翻译: 追求“因为对所以对”——大型语言模型助力可靠解答常识知识图谱问题](2024年03月02日/Right_for_Right_Reasons_Large_Language_Models_for_Verifiable_Commonsense_Knowledge_Graph_Question_Answering.md)

- [On the Compressibility of Quantized Large Language Models](2024年03月02日/On_the_Compressibility_of_Quantized_Large_Language_Models.md)

    - [翻译: 本研究探讨了量化后的大型语言模型（LLM）的压缩潜力，深入分析其在降低存储需求和计算开销方面的可能性。](2024年03月02日/On_the_Compressibility_of_Quantized_Large_Language_Models.md)

- [Automatic Question-Answer Generation for Long-Tail Knowledge](2024年03月02日/Automatic_Question-Answer_Generation_for_Long-Tail_Knowledge.md)

    - [翻译: 为解决长尾知识难题，本研究致力于探索自动问题与答案生成技术，旨在高效精准地生成针对海量且分布稀疏的长尾知识的问题与答案对。](2024年03月02日/Automatic_Question-Answer_Generation_for_Long-Tail_Knowledge.md)

- [Evaluating and Mitigating Number Hallucinations in Large Vision-Language Models: A Consistency Perspective](2024年03月02日/Evaluating_and_Mitigating_Number_Hallucinations_in_Large_Vision-Language_Models_A_Consistency_Perspective.md)

    - [翻译: 本研究从一致性视角出发，探讨并解决大型视觉-语言模型在处理过程中出现的数字幻觉现象。](2024年03月02日/Evaluating_and_Mitigating_Number_Hallucinations_in_Large_Vision-Language_Models_A_Consistency_Perspective.md)

- [LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems](2024年03月02日/LM4OPT_Unveiling_the_Potential_of_Large_Language_Models_in_Formulating_Mathematical_Optimization_Problems.md)

    - [翻译: LM4OPT项目揭示了大型语言模型在解决数学优化问题时所蕴含的巨大潜能，探索其如何有效用于构建这类问题的解决方案。](2024年03月02日/LM4OPT_Unveiling_the_Potential_of_Large_Language_Models_in_Formulating_Mathematical_Optimization_Problems.md)

- [Chaining thoughts and LLMs to learn DNA structural biophysics](2024年03月02日/Chaining_thoughts_and_LLMs_to_learn_DNA_structural_biophysics.md)

    - [翻译: 通过联动思维与大型语言模型（LLM），我们致力于探索和学习DNA结构生物物理学的奥秘。](2024年03月02日/Chaining_thoughts_and_LLMs_to_learn_DNA_structural_biophysics.md)

- [VBART: The Turkish LLM](2024年03月02日/VBART_The_Turkish_LLM.md)

    - [翻译: VBART——探究土耳其的大型语言模型](2024年03月02日/VBART_The_Turkish_LLM.md)

- [Improving the Validity of Automatically Generated Feedback via Reinforcement Learning](2024年03月02日/Improving_the_Validity_of_Automatically_Generated_Feedback_via_Reinforcement_Learning.md)

    - [翻译: 本研究运用强化学习技术，致力于提升自动化生成反馈的可靠性和准确性。](2024年03月02日/Improving_the_Validity_of_Automatically_Generated_Feedback_via_Reinforcement_Learning.md)

- [NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention](2024年03月02日/NoMAD-Attention_Efficient_LLM_Inference_on_CPUs_Through_Multiply-add-free_Attention.md)

    - [翻译: NoMAD-Attention技术致力于提升CPU环境下LLM推理效率，它采用无需乘加操作的注意力机制，实现大型语言模型在CPU上的高效推理。](2024年03月02日/NoMAD-Attention_Efficient_LLM_Inference_on_CPUs_Through_Multiply-add-free_Attention.md)

- [Employing LLMs for Incident Response Planning and Review](2024年03月02日/Employing_LLMs_for_Incident_Response_Planning_and_Review.md)

    - [翻译: 在事件响应规划与复盘中运用 LLMs 技术，以提升效率和精准度。](2024年03月02日/Employing_LLMs_for_Incident_Response_Planning_and_Review.md)

- [Dissecting Language Models: Machine Unlearning via Selective Pruning](2024年03月02日/Dissecting_Language_Models_Machine_Unlearning_via_Selective_Pruning.md)

    - [翻译: 本文探讨通过选择性剪枝技术深入剖析并“卸载”语言模型中的特定知识，实现机器的“忘却”过程。](2024年03月02日/Dissecting_Language_Models_Machine_Unlearning_via_Selective_Pruning.md)

- [GuardT2I: Defending Text-to-Image Models from Adversarial Prompts](2024年03月03日/GuardT2I_Defending_Text-to-Image_Models_from_Adversarial_Prompts.md)

    - [翻译: GuardT2I：针对对抗性文本提示对文本到图像模型的防御机制](2024年03月03日/GuardT2I_Defending_Text-to-Image_Models_from_Adversarial_Prompts.md)

- [GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features](2024年03月03日/GPTSee_Enhancing_Moment_Retrieval_and_Highlight_Detection_via_Description-Based_Similarity_Features.md)

    - [翻译: GPTSee 利用描述性相似性特征提升关键时刻检索与精彩片段检测能力](2024年03月03日/GPTSee_Enhancing_Moment_Retrieval_and_Highlight_Detection_via_Description-Based_Similarity_Features.md)

- [Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge](2024年03月03日/Fine_Tuning_vs._Retrieval_Augmented_Generation_for_Less_Popular_Knowledge.md)

    - [翻译: 面对较少为人所知的知识领域，我们探究微调和检索增强生成两种方法的优劣。](2024年03月03日/Fine_Tuning_vs._Retrieval_Augmented_Generation_for_Less_Popular_Knowledge.md)

- [Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval](2024年03月03日/Image2Sentence_based_Asymmetrical_Zero-shot_Composed_Image_Retrieval.md)

    - [翻译: Image2Sentence 技术驱动的非对称零样本图像组合检索方法，旨在实现仅通过文本描述即可检索未见过的组合图像。](2024年03月03日/Image2Sentence_based_Asymmetrical_Zero-shot_Composed_Image_Retrieval.md)

- [The Implicit Bias of Heterogeneity towards Invariance and Causality](2024年03月03日/The_Implicit_Bias_of_Heterogeneity_towards_Invariance_and_Causality.md)

    - [翻译: 异质性中蕴含着对不变性和因果性的内在倾向，本文探讨这一隐含偏置的实质及其影响。](2024年03月03日/The_Implicit_Bias_of_Heterogeneity_towards_Invariance_and_Causality.md)

- [OVEL: Large Language Model as Memory Manager for Online Video Entity Linking](2024年03月03日/OVEL_Large_Language_Model_as_Memory_Manager_for_Online_Video_Entity_Linking.md)

    - [翻译: OVEL 利用大型语言模型充当在线视频实体链接的记忆管家，提升链接效能。](2024年03月03日/OVEL_Large_Language_Model_as_Memory_Manager_for_Online_Video_Entity_Linking.md)

- [In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation](2024年03月03日/In-Context_Sharpness_as_Alerts_An_Inner_Representation_Perspective_for_Hallucination_Mitigation.md)

    - [翻译: 将“情境尖锐度”视为预警信号，我们从内在表征的视角探讨其在缓解大型语言模型生成幻觉问题上的作用。](2024年03月03日/In-Context_Sharpness_as_Alerts_An_Inner_Representation_Perspective_for_Hallucination_Mitigation.md)

- [Revisiting Dynamic Evaluation: Online Adaptation for Large Language Models](2024年03月03日/Revisiting_Dynamic_Evaluation_Online_Adaptation_for_Large_Language_Models.md)

    - [翻译: 我们重新审视“动态评估”这一概念，探讨其在大型语言模型中的应用——即在线适应策略，以实现模型性能的即时优化与更新。](2024年03月03日/Revisiting_Dynamic_Evaluation_Online_Adaptation_for_Large_Language_Models.md)

- [Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics](2024年03月03日/Fantastic_Semantics_and_Where_to_Find_Them_Investigating_Which_Layers_of_Generative_LLMs_Reflect_Lexical_Semantics.md)

    - [翻译: 《寻找奇幻的语义世界：研究生成型LLM中各层对词汇语义的体现》](2024年03月03日/Fantastic_Semantics_and_Where_to_Find_Them_Investigating_Which_Layers_of_Generative_LLMs_Reflect_Lexical_Semantics.md)

- [InfiMM-HD: A Leap Forward in High-Resolution Multimodal Understanding](2024年03月03日/InfiMM-HD_A_Leap_Forward_in_High-Resolution_Multimodal_Understanding.md)

    - [翻译: InfiMM-HD——在高清多模态理解领域实现了一次显著的跃进](2024年03月03日/InfiMM-HD_A_Leap_Forward_in_High-Resolution_Multimodal_Understanding.md)

- [Infusing Knowledge into Large Language Models with Contextual Prompts](2024年03月03日/Infusing_Knowledge_into_Large_Language_Models_with_Contextual_Prompts.md)

    - [翻译: 本研究探讨如何巧妙利用上下文提示，将知识有效地融入大型语言模型中。](2024年03月03日/Infusing_Knowledge_into_Large_Language_Models_with_Contextual_Prompts.md)

- [Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation](2024年03月03日/Align-to-Distill_Trainable_Attention_Alignment_for_Knowledge_Distillation_in_Neural_Machine_Translation.md)

    - [翻译: 在神经机器翻译中，我们提出了一种名为“Align-to-Distill”的方法，它通过可训练的注意力对齐机制实现知识的有效蒸馏。这一创新技术旨在提升模型在知识转移过程中的性能和效率，特别是在神经机器翻译任务上。](2024年03月03日/Align-to-Distill_Trainable_Attention_Alignment_for_Knowledge_Distillation_in_Neural_Machine_Translation.md)

- [KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean Healthcare Professional Licensing Examinations](2024年03月03日/KorMedMCQA_Multi-Choice_Question_Answering_Benchmark_for_Korean_Healthcare_Professional_Licensing_Examinations.md)

    - [翻译: KorMedMCQA 是专为韩国医疗专业执照考试打造的多选题答题基准测试，旨在衡量和评估考生在该领域内的专业知识水平。](2024年03月03日/KorMedMCQA_Multi-Choice_Question_Answering_Benchmark_for_Korean_Healthcare_Professional_Licensing_Examinations.md)

- [Logic Rules as Explanations for Legal Case Retrieval](2024年03月03日/Logic_Rules_as_Explanations_for_Legal_Case_Retrieval.md)

    - [翻译: 在法律案例检索领域，逻辑规则被用作一种解释手段。进一步优化，逻辑规则在挖掘和理解相关判例中扮演着解释性工具的角色，助力提升案例检索效率与准确性。](2024年03月03日/Logic_Rules_as_Explanations_for_Legal_Case_Retrieval.md)

- [Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study](2024年03月03日/Can_LLMs_Generate_Architectural_Design_Decisions_-An_Exploratory_Empirical_study.md)

    - [翻译: 探究 LLMS 是否具备生成建筑设计决策的能力：一项实证研究之旅](2024年03月03日/Can_LLMs_Generate_Architectural_Design_Decisions_-An_Exploratory_Empirical_study.md)

- [Improving LLM Code Generation with Grammar Augmentation](2024年03月03日/Improving_LLM_Code_Generation_with_Grammar_Augmentation.md)

    - [翻译: LLMM代码生成能力的提升，我们借助了语法增强技术。本研究致力于探究如何通过针对性地增加和调整语法结构，优化大型语言模型在代码生成任务上的表现。](2024年03月03日/Improving_LLM_Code_Generation_with_Grammar_Augmentation.md)

- [Relational to RDF Data Migration by Query Co-Evaluation](2024年03月03日/Relational_to_RDF_Data_Migration_by_Query_Co-Evaluation.md)

    - [翻译: 借助查询协同求值技术，实现从关系型数据向 RDF 数据的迁移步骤 1 直译：关系型数据到 RDF 数据迁移通过查询协同求值实现步骤 2 简洁优雅翻译：本研究探讨了一种基于查询协同求值的方法，用于实现关系型数据库与 RDF 数据间的高效迁移。](2024年03月03日/Relational_to_RDF_Data_Migration_by_Query_Co-Evaluation.md)

- [Using LLMs for Tabletop Exercises within the Security Domain](2024年03月03日/Using_LLMs_for_Tabletop_Exercises_within_the_Security_Domain.md)

    - [翻译: 针对安全领域，本研究探讨运用LLMs进行桌面模拟训练的可能性与效果。](2024年03月03日/Using_LLMs_for_Tabletop_Exercises_within_the_Security_Domain.md)

- [Towards Comprehensive Vietnamese Retrieval-Augmented Generation and Large Language Models](2024年03月03日/Towards_Comprehensive_Vietnamese_Retrieval-Augmented_Generation_and_Large_Language_Models.md)

    - [翻译: 致力于打造全方位的越南语检索增强生成方案，并探索大型语言模型在此领域的应用潜力。](2024年03月03日/Towards_Comprehensive_Vietnamese_Retrieval-Augmented_Generation_and_Large_Language_Models.md)

- [SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos](2024年03月03日/SCHEMA_State_CHangEs_MAtter_for_Procedure_Planning_in_Instructional_Videos.md)

    - [翻译: SCHEMA 研究表明，在解析教学视频中的程序规划时，状态变化起到关键作用。](2024年03月03日/SCHEMA_State_CHangEs_MAtter_for_Procedure_Planning_in_Instructional_Videos.md)

- [IoT Device Labeling Using Large Language Models](2024年03月03日/IoT_Device_Labeling_Using_Large_Language_Models.md)

    - [翻译: 借助大型语言模型实现物联网设备智能标注](2024年03月03日/IoT_Device_Labeling_Using_Large_Language_Models.md)

- [SARD: A Human-AI Collaborative Story Generation](2024年03月03日/SARD_A_Human-AI_Collaborative_Story_Generation.md)

    - [翻译: SARD：携手人类与AI共创故事新篇章](2024年03月03日/SARD_A_Human-AI_Collaborative_Story_Generation.md)

- [SERVAL: Synergy Learning between Vertical Models and LLMs towards Oracle-Level Zero-shot Medical Prediction](2024年03月03日/SERVAL_Synergy_Learning_between_Vertical_Models_and_LLMs_towards_Oracle-Level_Zero-shot_Medical_Prediction.md)

    - [翻译: SERVAL 研究通过构建垂直模型与大型语言模型（LLMs）间的协同效应，致力于在零样本条件下达到“Oracle级别”的医疗预测精度。](2024年03月03日/SERVAL_Synergy_Learning_between_Vertical_Models_and_LLMs_towards_Oracle-Level_Zero-shot_Medical_Prediction.md)

- [ReMatch: Retrieval Enhanced Schema Matching with LLMs](2024年03月03日/ReMatch_Retrieval_Enhanced_Schema_Matching_with_LLMs.md)

    - [翻译: ReMatch技术利用LLMs的力量，实现了检索增强型模式匹配，让数据结构间的对应关系更加精准高效。](2024年03月03日/ReMatch_Retrieval_Enhanced_Schema_Matching_with_LLMs.md)

- [Transformers for Supervised Online Continual Learning](2024年03月03日/Transformers_for_Supervised_Online_Continual_Learning.md)

    - [翻译: 面向监督在线连续学习的 Transformer 模型研究](2024年03月03日/Transformers_for_Supervised_Online_Continual_Learning.md)

- [Citation-Enhanced Generation for LLM-based Chatbots](2024年03月03日/Citation-Enhanced_Generation_for_LLM-based_Chatbots.md)

    - [翻译: 为基于大型语言模型（LLM）的聊天机器人引入引文增强生成技术，旨在提升其对话内容的准确性和可信度。](2024年03月03日/Citation-Enhanced_Generation_for_LLM-based_Chatbots.md)

- [Query Augmentation by Decoding Semantics from Brain Signals](2024年03月03日/Query_Augmentation_by_Decoding_Semantics_from_Brain_Signals.md)

    - [翻译: 本研究探讨了一种创新方法，通过解读大脑信号中的语义信息来丰富和增强查询，实现与用户思维更深层次的交互。](2024年03月03日/Query_Augmentation_by_Decoding_Semantics_from_Brain_Signals.md)

- [Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5](2024年03月04日/Automated_Generation_of_Multiple-Choice_Cloze_Questions_for_Assessing_English_Vocabulary_Using_GPT-turbo_3.5.md)

    - [翻译: 本研究运用 GPT-turbo 3.5 技术，自动创建适合评估英语词汇掌握程度的多选填空题。](2024年03月04日/Automated_Generation_of_Multiple-Choice_Cloze_Questions_for_Assessing_English_Vocabulary_Using_GPT-turbo_3.5.md)

- [Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism](2024年03月04日/Large_Language_Model-Based_Evolutionary_Optimizer_Reasoning_with_elitism.md)

    - [翻译: 这款基于大型语言模型的进化优化器，通过精英主义原理进行智能推理。它巧妙地运用了大型语言模型的优势，在不断优化过程中甄选并借鉴最优解决方案进行迭代升级。](2024年03月04日/Large_Language_Model-Based_Evolutionary_Optimizer_Reasoning_with_elitism.md)

- [Unveiling Hidden Links Between Unseen Security Entities](2024年03月04日/Unveiling_Hidden_Links_Between_Unseen_Security_Entities.md)

    - [翻译: 本研究致力于揭开未知安全实体间的潜在关联，探寻那些未曾显现的隐性联系。](2024年03月04日/Unveiling_Hidden_Links_Between_Unseen_Security_Entities.md)

- [LLM-Oriented Retrieval Tuner](2024年03月04日/LLM-Oriented_Retrieval_Tuner.md)

    - [翻译: 针对 LLM 的检索优化器，旨在对大型语言模型进行精准高效的检索调优。](2024年03月04日/LLM-Oriented_Retrieval_Tuner.md)

- [FakeNewsGPT4: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs](2024年03月04日/FakeNewsGPT4_Advancing_Multimodal_Fake_News_Detection_through_Knowledge-Augmented_LVLMs.md)

    - [翻译: FakeNewsGPT4 是一项创新研究，利用了知识增强的多模态大型语言模型，旨在提升假新闻检测能力。](2024年03月04日/FakeNewsGPT4_Advancing_Multimodal_Fake_News_Detection_through_Knowledge-Augmented_LVLMs.md)

- [Evaluating the Explainability of Neural Rankers](2024年03月04日/Evaluating_the_Explainability_of_Neural_Rankers.md)

    - [翻译: 本研究旨在深入探讨和评估神经网络排序模型的可解释性，以揭示其内部决策机制及优化依据。](2024年03月04日/Evaluating_the_Explainability_of_Neural_Rankers.md)

- [SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis](2024年03月04日/SciAssess_Benchmarking_LLM_Proficiency_in_Scientific_Literature_Analysis.md)

    - [翻译: SciAssess 是一个针对大型语言模型（LLM）在科学文献分析能力上的基准测试工具，旨在衡量和评估 LLM 在理解和解析科学文献方面的专业水准。](2024年03月04日/SciAssess_Benchmarking_LLM_Proficiency_in_Scientific_Literature_Analysis.md)

- [Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models](2024年03月04日/Multi-perspective_Improvement_of_Knowledge_Graph_Completion_with_Large_Language_Models.md)

    - [翻译: 本研究探讨如何借助大型语言模型从多个视角提升知识图谱补全任务的效果。](2024年03月04日/Multi-perspective_Improvement_of_Knowledge_Graph_Completion_with_Large_Language_Models.md)

- [ContrastRepair: Enhancing Conversation-Based Automated Program Repair via Contrastive Test Case Pairs](2024年03月04日/ContrastRepair_Enhancing_Conversation-Based_Automated_Program_Repair_via_Contrastive_Test_Case_Pairs.md)

    - [翻译: ContrastRepair 是一种创新方法，通过构建并利用对比测试用例对，有效提升基于对话模式的自动化程序修复能力。](2024年03月04日/ContrastRepair_Enhancing_Conversation-Based_Automated_Program_Repair_via_Contrastive_Test_Case_Pairs.md)

- [AS-ES Learning: Towards Efficient CoT Learning in Small Models](2024年03月04日/AS-ES_Learning_Towards_Efficient_CoT_Learning_in_Small_Models.md)

    - [翻译: AS-ES 学习致力于在小型模型中实现高效的概念到文本（CoT）学习，旨在提升模型理解和应用复杂概念的能力。](2024年03月04日/AS-ES_Learning_Towards_Efficient_CoT_Learning_in_Small_Models.md)

- [Analyzing and Adapting Large Language Models for Few-Shot Multilingual NLU: Are We There Yet?](2024年03月04日/Analyzing_and_Adapting_Large_Language_Models_for_Few-Shot_Multilingual_NLU_Are_We_There_Yet.md)

    - [翻译: 针对少量样本多语言 NLU 任务，对大型语言模型进行分析与适应的研究：我们是否已达成目标？](2024年03月04日/Analyzing_and_Adapting_Large_Language_Models_for_Few-Shot_Multilingual_NLU_Are_We_There_Yet.md)

- [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](2024年03月04日/To_Generate_or_to_Retrieve_On_the_Effectiveness_of_Artificial_Contexts_for_Medical_Open-Domain_Question_Answering.md)

    - [翻译: 探究“生成”与“检索”的抉择——人工构建的上下文对医学开放领域问答效果的影响](2024年03月04日/To_Generate_or_to_Retrieve_On_the_Effectiveness_of_Artificial_Contexts_for_Medical_Open-Domain_Question_Answering.md)

- [Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with Wider Topic Analysis](2024年03月04日/Arabic_Text_Sentiment_Analysis_Reinforcing_Human-Performed_Surveys_with_Wider_Topic_Analysis.md)

    - [翻译: 本研究聚焦于阿拉伯语文本情感分析，通过融合更广泛的主题分析以增强基于人类调查的结果，旨在提升对调查数据的洞察力和准确性。](2024年03月04日/Arabic_Text_Sentiment_Analysis_Reinforcing_Human-Performed_Surveys_with_Wider_Topic_Analysis.md)

- [xT: Nested Tokenization for Larger Context in Large Images](2024年03月04日/xT_Nested_Tokenization_for_Larger_Context_in_Large_Images.md)

    - [翻译: xT 技术提出了一种针对大型图像的嵌套分词方法，旨在捕获并处理更大范围的上下文信息。](2024年03月04日/xT_Nested_Tokenization_for_Larger_Context_in_Large_Images.md)

- [Fostering the Ecosystem of Open Neural Encoders for Portuguese with Albertina PT* Family](2024年03月04日/Fostering_the_Ecosystem_of_Open_Neural_Encoders_for_Portuguese_with_Albertina_PT_Family.md)

    - [翻译: Albertina PT* 系列旨在促进葡萄牙语开放神经编码器生态系统的构建与发展](2024年03月04日/Fostering_the_Ecosystem_of_Open_Neural_Encoders_for_Portuguese_with_Albertina_PT_Family.md)

- [An Improved Traditional Chinese Evaluation Suite for Foundation Model](2024年03月04日/An_Improved_Traditional_Chinese_Evaluation_Suite_for_Foundation_Model.md)

    - [翻译: 为了更好地评测基础模型在处理汉字任务时的性能，我们推出了一个优化的传统中文评估套件。这个改进版套件旨在深入考察和精确衡量各类基础模型在处理汉字文本及理解传统中国文化情境中的表现。](2024年03月04日/An_Improved_Traditional_Chinese_Evaluation_Suite_for_Foundation_Model.md)

- [Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral](2024年03月04日/Rethinking_LLM_Language_Adaptation_A_Case_Study_on_Chinese_Mixtral.md)

    - [翻译: 对LLM的语言适应性进行再思考——以“Chinese Mixtral”为例的深度探究](2024年03月04日/Rethinking_LLM_Language_Adaptation_A_Case_Study_on_Chinese_Mixtral.md)

- [One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models](2024年03月04日/One_Prompt_Word_is_Enough_to_Boost_Adversarial_Robustness_for_Pre-trained_Vision-Language_Models.md)

    - [翻译: 惊人发现，只需单个提示词即可显著增强预训练视觉-语言模型在对抗性环境中的稳健性。](2024年03月04日/One_Prompt_Word_is_Enough_to_Boost_Adversarial_Robustness_for_Pre-trained_Vision-Language_Models.md)

- [CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text](2024年03月04日/CatCode_A_Comprehensive_Evaluation_Framework_for_LLMs_On_the_Mixture_of_Code_and_Text.md)

    - [翻译: CatCode 是一个综合性的评估框架，专为在混合代码与文本环境中的大型语言模型（LLMs）设计，旨在全方位测评其性能表现。](2024年03月04日/CatCode_A_Comprehensive_Evaluation_Framework_for_LLMs_On_the_Mixture_of_Code_and_Text.md)

- [NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models](2024年03月04日/NPHardEval4V_A_Dynamic_Reasoning_Benchmark_of_Multimodal_Large_Language_Models.md)

    - [翻译: NPHardEval4V 是针对多模态大型语言模型设计的一套动态推理性能评估基准，旨在全面检验此类模型在复杂场景下的理解与推理能力。](2024年03月04日/NPHardEval4V_A_Dynamic_Reasoning_Benchmark_of_Multimodal_Large_Language_Models.md)

- [WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations](2024年03月04日/WebCiteS_Attributed_Query-Focused_Summarization_on_Chinese_Web_Search_Results_with_Citations.md)

    - [翻译: WebCiteS 是一种创新技术，专注于对中文网页搜索结果进行带引文的查询焦点摘要。该技术旨在通过考虑引用信息，提升搜索结果摘要的质量和针对性。](2024年03月04日/WebCiteS_Attributed_Query-Focused_Summarization_on_Chinese_Web_Search_Results_with_Citations.md)

- [How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems](2024年03月04日/How_Multimodal_Integration_Boost_the_Performance_of_LLM_for_Optimization_Case_Study_on_Capacitated_Vehicle_Routing_Problems.md)

    - [翻译: 通过研究载量受限车辆路径问题，本文探讨了多模态集成如何显著增强大型语言模型（LLM）在优化任务中的表现。](2024年03月04日/How_Multimodal_Integration_Boost_the_Performance_of_LLM_for_Optimization_Case_Study_on_Capacitated_Vehicle_Routing_Problems.md)

- [AI Language Models Could Both Help and Harm Equity in Marine Policymaking: The Case Study of the BBNJ Question-Answering Bot](2024年03月04日/AI_Language_Models_Could_Both_Help_and_Harm_Equity_in_Marine_Policymaking_The_Case_Study_of_the_BBNJ_Question-Answering_Bot.md)

    - [翻译: AI语言模型在海洋政策制定领域的应用，如BBNJ问答机器人案例所示，既能促进公平性也可能带来潜在的不平等问题。本研究通过该案例探讨了这一双刃剑效应。](2024年03月04日/AI_Language_Models_Could_Both_Help_and_Harm_Equity_in_Marine_Policymaking_The_Case_Study_of_the_BBNJ_Question-Answering_Bot.md)

- [Derivative-Free Optimization for Low-Rank Adaptation in Large Language Models](2024年03月04日/Derivative-Free_Optimization_for_Low-Rank_Adaptation_in_Large_Language_Models.md)

    - [翻译: 针对大型语言模型中的低秩适应问题，本研究探讨了无需依赖梯度信息的优化方法。](2024年03月04日/Derivative-Free_Optimization_for_Low-Rank_Adaptation_in_Large_Language_Models.md)

- [Differentially Private Synthetic Data via Foundation Model APIs 2: Text](2024年03月04日/Differentially_Private_Synthetic_Data_via_Foundation_Model_APIs_2_Text.md)

    - [翻译: 借助基础模型API，我们推出了针对文本的第二版差分隐私合成数据技术。这项技术利用基础模型能力，在保证数据隐私性的同时生成高质量的合成文本数据。](2024年03月04日/Differentially_Private_Synthetic_Data_via_Foundation_Model_APIs_2_Text.md)

- [Decode Neural signal as Speech](2024年03月04日/Decode_Neural_signal_as_Speech.md)

    - [翻译: 本研究致力于将神经信号转化为可识别的语音，探索从大脑活动直接解读言语信息的可能性。](2024年03月04日/Decode_Neural_signal_as_Speech.md)

- [NoteLLM: A Retrievable Large Language Model for Note Recommendation](2024年03月04日/NoteLLM_A_Retrievable_Large_Language_Model_for_Note_Recommendation.md)

    - [翻译: NoteLLM，一款专为笔记推荐打造的可检索型大型语言模型。](2024年03月04日/NoteLLM_A_Retrievable_Large_Language_Model_for_Note_Recommendation.md)

- [Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning](2024年03月04日/Key-Point-Driven_Data_Synthesis_with_its_Enhancement_on_Mathematical_Reasoning.md)

    - [翻译: 通过关键点驱动的数据合成技术，并对其进行优化，以提升数学推理性能。这项研究聚焦于利用关键点引导的数据合成方法，有效增强模型在数学推理任务上的表现。](2024年03月04日/Key-Point-Driven_Data_Synthesis_with_its_Enhancement_on_Mathematical_Reasoning.md)

- [RegionGPT: Towards Region Understanding Vision Language Model](2024年03月04日/RegionGPT_Towards_Region_Understanding_Vision_Language_Model.md)

    - [翻译: RegionGPT——迈向理解视觉区域的新型语言模型，旨在提升视觉与语言融合模型在区域理解层面的表现。](2024年03月04日/RegionGPT_Towards_Region_Understanding_Vision_Language_Model.md)

- [Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures](2024年03月04日/Vision-RWKV_Efficient_and_Scalable_Visual_Perception_with_RWKV-Like_Architectures.md)

    - [翻译: Vision-RWKV 是一种采用类RWKV架构设计，有效实现了视觉感知的高效性和可扩展性的方法。](2024年03月04日/Vision-RWKV_Efficient_and_Scalable_Visual_Perception_with_RWKV-Like_Architectures.md)

- [Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation](2024年03月04日/Beyond_Specialization_Assessing_the_Capabilities_of_MLLMs_in_Age_and_Gender_Estimation.md)

    - [翻译: 本研究超越了单一领域的专业性，致力于评估多语言大型模型（MLLMs）在年龄与性别估算任务中的能力。](2024年03月04日/Beyond_Specialization_Assessing_the_Capabilities_of_MLLMs_in_Age_and_Gender_Estimation.md)

- [FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction](2024年03月04日/FENICE_Factuality_Evaluation_of_summarization_based_on_Natural_language_Inference_and_Claim_Extraction.md)

    - [翻译: FENICE 是一种利用自然语言推理和论断抽取技术对摘要进行事实性评估的方法。](2024年03月04日/FENICE_Factuality_Evaluation_of_summarization_based_on_Natural_language_Inference_and_Claim_Extraction.md)

- [KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection](2024年03月04日/KnowPhish_Large_Language_Models_Meet_Multimodal_Knowledge_Graphs_for_Enhancing_Reference-Based_Phishing_Detection.md)

    - [翻译: KnowPhish项目将大型语言模型与多模态知识图谱相结合，旨在强化基于参照的钓鱼检测技术，实现更高效的网络欺诈识别。](2024年03月04日/KnowPhish_Large_Language_Models_Meet_Multimodal_Knowledge_Graphs_for_Enhancing_Reference-Based_Phishing_Detection.md)

- [PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models](2024年03月04日/PHAnToM_Personality_Has_An_Effect_on_Theory-of-Mind_Reasoning_in_Large_Language_Models.md)

    - [翻译: PHAnToM研究表明，大型语言模型的心智理论推理会受到模型所具备的个性特征的影响。](2024年03月04日/PHAnToM_Personality_Has_An_Effect_on_Theory-of-Mind_Reasoning_in_Large_Language_Models.md)

- [Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks](2024年03月04日/Towards_Intent-Based_Network_Management_Large_Language_Models_for_Intent_Extraction_in_5G_Core_Networks.md)

    - [翻译: 致力于打造基于意图的网络管理模式，我们探索了在5G核心网络环境下运用大型语言模型抽取用户意图的可能性。](2024年03月04日/Towards_Intent-Based_Network_Management_Large_Language_Models_for_Intent_Extraction_in_5G_Core_Networks.md)

- [3DTopia: Large Text-to-3D Generation Model with Hybrid Diffusion Priors](2024年03月04日/3DTopia_Large_Text-to-3D_Generation_Model_with_Hybrid_Diffusion_Priors.md)

    - [翻译: 3DTopia是一款创新的大型文本转三维生成模型，巧妙融合了混合扩散先验技术，实现从文本信息高效构建高质量三维模型。](2024年03月04日/3DTopia_Large_Text-to-3D_Generation_Model_with_Hybrid_Diffusion_Priors.md)

- [TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language Models](2024年03月04日/TPLLM_A_Traffic_Prediction_Framework_Based_on_Pretrained_Large_Language_Models.md)

    - [翻译: TPLLM 是一种基于预训练大型语言模型的交通预测方案，该框架利用大规模语言模型的强大泛化和学习能力，对交通流量进行精准预测。](2024年03月04日/TPLLM_A_Traffic_Prediction_Framework_Based_on_Pretrained_Large_Language_Models.md)

- [Not all Layers of LLMs are Necessary during Inference](2024年03月04日/Not_all_Layers_of_LLMs_are_Necessary_during_Inference.md)

    - [翻译: 对于LLM的推理阶段，并非所有层级都不可或缺。](2024年03月04日/Not_all_Layers_of_LLMs_are_Necessary_during_Inference.md)

- [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](2024年03月04日/Masked_Thought_Simply_Masking_Partial_Reasoning_Steps_Can_Improve_Mathematical_Reasoning_Learning_of_Language_Models.md)

    - [翻译: Masked Thought 研究表明，简单地对部分推理步骤进行遮蔽处理，就能有效增强语言模型在数学推理学习上的表现。](2024年03月04日/Masked_Thought_Simply_Masking_Partial_Reasoning_Steps_Can_Improve_Mathematical_Reasoning_Learning_of_Language_Models.md)

- [Cognition is All You Need - The Next Layer of AI Above Large Language Models](2024年03月04日/Cognition_is_All_You_Need_-_The_Next_Layer_of_AI_Above_Large_Language_Models.md)

    - [翻译: 在大型语言模型基础上，认知力量被视为推动AI发展的下一关键层次 ——“认知即一切”。](2024年03月04日/Cognition_is_All_You_Need_-_The_Next_Layer_of_AI_Above_Large_Language_Models.md)

- [Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation](2024年03月04日/Memoro_Using_Large_Language_Models_to_Realize_a_Concise_Interface_for_Real-Time_Memory_Augmentation.md)

    - [翻译: Memoro项目通过运用大型语言模型，打造出一个能够实现实时记忆增强的精炼界面。](2024年03月04日/Memoro_Using_Large_Language_Models_to_Realize_a_Concise_Interface_for_Real-Time_Memory_Augmentation.md)

- [Using LLMs for the Extraction and Normalization of Product Attribute Values](2024年03月04日/Using_LLMs_for_the_Extraction_and_Normalization_of_Product_Attribute_Values.md)

    - [翻译: 运用 LLM 技术抽取并规范产品属性值，本研究旨在探索这一方法在处理产品信息时的高效性和准确性。](2024年03月04日/Using_LLMs_for_the_Extraction_and_Normalization_of_Product_Attribute_Values.md)

- [Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models](2024年03月04日/Leveraging_Weakly_Annotated_Data_for_Hate_Speech_Detection_in_Code-Mixed_Hinglish_A_Feasibility-Driven_Transfer_Learning_Approach_with_Large_Language_Models.md)

    - [翻译: 针对混合语种 Hinglish 中的仇恨言论检测问题，我们提出了一种以可行性为导向的迁移学习策略，充分利用弱标注数据，并结合大型语言模型的力量。](2024年03月04日/Leveraging_Weakly_Annotated_Data_for_Hate_Speech_Detection_in_Code-Mixed_Hinglish_A_Feasibility-Driven_Transfer_Learning_Approach_with_Large_Language_Models.md)

- [Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding](2024年03月04日/Found_in_the_Middle_How_Language_Models_Use_Long_Contexts_Better_via_Plug-and-Play_Positional_Encoding.md)

    - [翻译: 标题翻译：“巧用位置编码，解锁语言模型对长距离上下文的理解”正文翻译：研究表明，语言模型可通过创新的“即插即用”位置编码技术，显著提升其理解和利用长上下文信息的能力。](2024年03月04日/Found_in_the_Middle_How_Language_Models_Use_Long_Contexts_Better_via_Plug-and-Play_Positional_Encoding.md)

- [Large Language Models in Fire Engineering: An Examination of Technical Questions Against Domain Knowledge](2024年03月04日/Large_Language_Models_in_Fire_Engineering_An_Examination_of_Technical_Questions_Against_Domain_Knowledge.md)

    - [翻译: 本研究探讨了大型语言模型在消防工程领域的应用，通过对照领域专业知识来检验其解答技术问题的能力。](2024年03月04日/Large_Language_Models_in_Fire_Engineering_An_Examination_of_Technical_Questions_Against_Domain_Knowledge.md)

- [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](2024年03月05日/The_WMDP_Benchmark_Measuring_and_Reducing_Malicious_Use_With_Unlearning.md)

    - [翻译: WMDP基准计划旨在衡量并有效减少恶意使用，其方法是采用“消除学习”技术。这个测试标准聚焦于评估及降低利用机器学习模型进行恶意行为的可能性，并探索通过“遗忘学习”机制来达成这一目标的途径。](2024年03月05日/The_WMDP_Benchmark_Measuring_and_Reducing_Malicious_Use_With_Unlearning.md)

- [CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments](2024年03月05日/CLEVR-POC_Reasoning-Intensive_Visual_Question_Answering_in_Partially_Observable_Environments.md)

    - [翻译: CLEVR-POC 是一个专注于在局部可观察环境下的高强度视觉推理问答研究，旨在探究在不完全信息条件下进行复杂视觉推理的能力。](2024年03月05日/CLEVR-POC_Reasoning-Intensive_Visual_Question_Answering_in_Partially_Observable_Environments.md)

- [MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets](2024年03月05日/MAGID_An_Automated_Pipeline_for_Generating_Synthetic_Multi-modal_Datasets.md)

    - [翻译: MAGID 是一款自动化的流水线工具，专注于创建合成型多模态数据集。](2024年03月05日/MAGID_An_Automated_Pipeline_for_Generating_Synthetic_Multi-modal_Datasets.md)

- [Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement](2024年03月05日/Towards_Democratized_Flood_Risk_Management_An_Advanced_AI_Assistant_Enabled_by_GPT-4_for_Enhanced_Interpretability_and_Public_Engagement.md)

    - [翻译: 为实现洪水风险管理的大众化，我们引入了一款基于 GPT-4 技术的先进 AI 助手。这款智能助手致力于增强模型解释力和促进公众积极参与洪水风险管理工作。](2024年03月05日/Towards_Democratized_Flood_Risk_Management_An_Advanced_AI_Assistant_Enabled_by_GPT-4_for_Enhanced_Interpretability_and_Public_Engagement.md)

- [Reliable, Adaptable, and Attributable Language Models with Retrieval](2024年03月05日/Reliable,_Adaptable,_and_Attributable_Language_Models_with_Retrieval.md)

    - [翻译: 致力于构建可靠、灵活且具有明确来源的检索型语言模型，以提升其性能和可信度。](2024年03月05日/Reliable,_Adaptable,_and_Attributable_Language_Models_with_Retrieval.md)

- [SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection](2024年03月05日/SNIFFER_Multimodal_Large_Language_Model_for_Explainable_Out-of-Context_Misinformation_Detection.md)

    - [翻译: SNIFFER是一款专注于可解释性离群信息检测的多模态大型语言模型，能够有效识别和解析上下文缺失情况下的错误信息。](2024年03月05日/SNIFFER_Multimodal_Large_Language_Model_for_Explainable_Out-of-Context_Misinformation_Detection.md)

- [PARADISE: Evaluating Implicit Planning Skills of Language Models with Procedural Warnings and Tips Dataset](2024年03月05日/PARADISE_Evaluating_Implicit_Planning_Skills_of_Language_Models_with_Procedural_Warnings_and_Tips_Dataset.md)

    - [翻译: PARADISE 是一项研究，它借助程序性警告和提示数据集来评估语言模型在隐式规划任务上的表现能力。](2024年03月05日/PARADISE_Evaluating_Implicit_Planning_Skills_of_Language_Models_with_Procedural_Warnings_and_Tips_Dataset.md)

- [Quantum Many-Body Physics Calculations with Large Language Models](2024年03月05日/Quantum_Many-Body_Physics_Calculations_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型探索量子多体物理问题的计算解决之道](2024年03月05日/Quantum_Many-Body_Physics_Calculations_with_Large_Language_Models.md)

- [Language Guided Exploration for RL Agents in Text Environments](2024年03月05日/Language_Guided_Exploration_for_RL_Agents_in_Text_Environments.md)

    - [翻译: 针对文本环境中的强化学习（RL）智能体，我们提出语言指导的探索策略，利用自然语言引导智能体在复杂环境中高效探索和学习。](2024年03月05日/Language_Guided_Exploration_for_RL_Agents_in_Text_Environments.md)

- [CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following](2024年03月05日/CoGenesis_A_Framework_Collaborating_Large_and_Small_Language_Models_for_Secure_Context-Aware_Instruction_Following.md)

    - [翻译: CoGenesis 是一种创新框架，它巧妙地整合了大型和小型语言模型的力量，旨在实现安全且具备情境感知能力的指令执行。](2024年03月05日/CoGenesis_A_Framework_Collaborating_Large_and_Small_Language_Models_for_Secure_Context-Aware_Instruction_Following.md)

- [Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution](2024年03月05日/Angry_Men,_Sad_Women_Large_Language_Models_Reflect_Gendered_Stereotypes_in_Emotion_Attribution.md)

    - [翻译: 大型语言模型揭示了在情绪认知上存在的性别刻板印象，即“愤怒的男人”与“悲伤的女人”。本研究针对这一现象，深入探讨了大型语言模型如何在情感属性分配中体现性别偏见。](2024年03月05日/Angry_Men,_Sad_Women_Large_Language_Models_Reflect_Gendered_Stereotypes_in_Emotion_Attribution.md)

- ["In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning](2024年03月05日/In_Dialogues_We_Learn_Towards_Personalized_Dialogue_Without_Pre-defined_Profiles_through_In-Dialogue_Learning.md)

    - [翻译: “对话即学习”：探索无预设用户画像的个性化对话，借助于对话过程中的实时学习技术](2024年03月05日/In_Dialogues_We_Learn_Towards_Personalized_Dialogue_Without_Pre-defined_Profiles_through_In-Dialogue_Learning.md)

- [KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](2024年03月05日/KnowAgent_Knowledge-Augmented_Planning_for_LLM-Based_Agents.md)

    - [翻译: KnowAgent是一种为基于大型语言模型（LLM）的智能体设计的知识增强规划方案，旨在通过融合知识与LLM能力来提升其决策与规划效能。](2024年03月05日/KnowAgent_Knowledge-Augmented_Planning_for_LLM-Based_Agents.md)

- [MiKASA: Multi-Key-Anchor & Scene-Aware Transformer for 3D Visual Grounding](2024年03月05日/MiKASA_Multi-Key-Anchor_&_Scene-Aware_Transformer_for_3D_Visual_Grounding.md)

    - [翻译: MiKASA——这款创新的三维视觉定位模型，巧妙融合了多键锚点与场景感知技术，以Transformer架构为核心，旨在提升三维空间中的目标定位精准度。](2024年03月05日/MiKASA_Multi-Key-Anchor_&_Scene-Aware_Transformer_for_3D_Visual_Grounding.md)

- [Learning to Use Tools via Cooperative and Interactive Agents](2024年03月05日/Learning_to_Use_Tools_via_Cooperative_and_Interactive_Agents.md)

    - [翻译: 在合作与互动智能体的引导下掌握工具使用技能](2024年03月05日/Learning_to_Use_Tools_via_Cooperative_and_Interactive_Agents.md)

- [Socratic Reasoning Improves Positive Text Rewriting](2024年03月05日/Socratic_Reasoning_Improves_Positive_Text_Rewriting.md)

    - [翻译: 运用苏格拉底式推理能够显著优化正面文本的重写过程，使其更具说服力和深度。](2024年03月05日/Socratic_Reasoning_Improves_Positive_Text_Rewriting.md)

- [Word Importance Explains How Prompts Affect Language Model Outputs](2024年03月05日/Word_Importance_Explains_How_Prompts_Affect_Language_Model_Outputs.md)

    - [翻译: 探究词语权重：揭示提示如何驱动语言模型的输出变化](2024年03月05日/Word_Importance_Explains_How_Prompts_Affect_Language_Model_Outputs.md)

- [OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following](2024年03月05日/OPEx_A_Component-Wise_Analysis_of_LLM-Centric_Agents_in_Embodied_Instruction_Following.md)

    - [翻译: OPEx研究针对具身指令跟随任务中以大型语言模型（LLM）为核心的智能体，对其进行深入的组件级分析。](2024年03月05日/OPEx_A_Component-Wise_Analysis_of_LLM-Centric_Agents_in_Embodied_Instruction_Following.md)

- [Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations](2024年03月05日/Knowledge_Graphs_as_Context_Sources_for_LLM-Based_Explanations_of_Learning_Recommendations.md)

    - [翻译: 在基于LLM的学习推荐解释中，知识图谱可作为重要的上下文信息源。](2024年03月05日/Knowledge_Graphs_as_Context_Sources_for_LLM-Based_Explanations_of_Learning_Recommendations.md)

- [Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large Language Models](2024年03月05日/Feast_Your_Eyes_Mixture-of-Resolution_Adaptation_for_Multimodal_Large_Language_Models.md)

    - [翻译: 标题生动翻译：“饱览盛宴”：探究多模态大型语言模型中的混合分辨率自适应技术](2024年03月05日/Feast_Your_Eyes_Mixture-of-Resolution_Adaptation_for_Multimodal_Large_Language_Models.md)

- [Localized Zeroth-Order Prompt Optimization](2024年03月05日/Localized_Zeroth-Order_Prompt_Optimization.md)

    - [翻译: 针对局部化的零阶提示优化技术，该方法利用零阶优化策略对模型的提示进行微调，特别是在特定任务或领域中，以提升模型的表现和适应性。](2024年03月05日/Localized_Zeroth-Order_Prompt_Optimization.md)

- [MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer](2024年03月05日/MADTP_Multimodal_Alignment-Guided_Dynamic_Token_Pruning_for_Accelerating_Vision-Language_Transformer.md)

    - [翻译: MADTP是一种创新方法，通过多模态对齐指导下的动态令牌剪枝策略，有效提升视觉-语言Transformer模型的运算效率。](2024年03月05日/MADTP_Multimodal_Alignment-Guided_Dynamic_Token_Pruning_for_Accelerating_Vision-Language_Transformer.md)

- [Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges](2024年03月05日/Data_Augmentation_using_LLMs_Data_Perspectives,_Learning_Paradigms_and_Challenges.md)

    - [翻译: LLM 数据增强技术探究：从数据角度出发，探讨其背后的新型学习范式及其面临的挑战](2024年03月05日/Data_Augmentation_using_LLMs_Data_Perspectives,_Learning_Paradigms_and_Challenges.md)

- [Multi-modal Instruction Tuned LLMs with Fine-grained Visual Perception](2024年03月05日/Multi-modal_Instruction_Tuned_LLMs_with_Fine-grained_Visual_Perception.md)

    - [翻译: 通过细粒度视觉感知优化的多模态指令训练LLM技术，使模型能够更好地理解并融合多种模态信息，特别是在处理包含丰富视觉元素的任务时。](2024年03月05日/Multi-modal_Instruction_Tuned_LLMs_with_Fine-grained_Visual_Perception.md)

- [Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering](2024年03月05日/Evidence-Focused_Fact_Summarization_for_Knowledge-Augmented_Zero-Shot_Question_Answering.md)

    - [翻译: 为了解决知识增强型零样本问题回答的挑战，我们提出了一种聚焦于证据的事实摘要方法，旨在提炼关键事实信息以辅助解答未曾见过的问题。](2024年03月05日/Evidence-Focused_Fact_Summarization_for_Knowledge-Augmented_Zero-Shot_Question_Answering.md)

- [ChatGPT and biometrics: an assessment of face recognition, gender detection, and age estimation capabilities](2024年03月05日/ChatGPT_and_biometrics_an_assessment_of_face_recognition,_gender_detection,_and_age_estimation_capabilities.md)

    - [翻译: ChatGPT 结合生物识别技术实测：针对人脸识别、性别辨别及年龄估算功能进行综合评估](2024年03月05日/ChatGPT_and_biometrics_an_assessment_of_face_recognition,_gender_detection,_and_age_estimation_capabilities.md)

- [WikiTableEdit: A Benchmark for Table Editing by Natural Language Instruction](2024年03月05日/WikiTableEdit_A_Benchmark_for_Table_Editing_by_Natural_Language_Instruction.md)

    - [翻译: WikiTableEdit 是一个专门针对通过自然语言指令进行表格编辑任务的基准测试工具，旨在评估和衡量模型在理解并执行基于文本的表格修改指令方面的性能。](2024年03月05日/WikiTableEdit_A_Benchmark_for_Table_Editing_by_Natural_Language_Instruction.md)

- [SimuCourt: Building Judicial Decision-Making Agents with Real-world Judgement Documents](2024年03月05日/SimuCourt_Building_Judicial_Decision-Making_Agents_with_Real-world_Judgement_Documents.md)

    - [翻译: SimuCourt项目致力于通过真实世界司法判决文档，打造能够进行司法决策制定的智能代理。](2024年03月05日/SimuCourt_Building_Judicial_Decision-Making_Agents_with_Real-world_Judgement_Documents.md)

- [Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation](2024年03月05日/Benchmarking_the_Text-to-SQL_Capability_of_Large_Language_Models_A_Comprehensive_Evaluation.md)

    - [翻译: 针对大型语言模型（LLM）的Text-to-SQL转换能力，本研究进行了深入且全面的基准评测。](2024年03月05日/Benchmarking_the_Text-to-SQL_Capability_of_Large_Language_Models_A_Comprehensive_Evaluation.md)

- [PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers](2024年03月05日/PaperWeaver_Enriching_Topical_Paper_Alerts_by_Contextualizing_Recommended_Papers_with_User-collected_Papers.md)

    - [翻译: PaperWeaver，一款智能工具，能够将用户自行收藏的论文作为上下文，以此强化推荐论文的相关性，从而提升主题论文提醒的质量。](2024年03月05日/PaperWeaver_Enriching_Topical_Paper_Alerts_by_Contextualizing_Recommended_Papers_with_User-collected_Papers.md)

- [ImgTrojan: Jailbreaking Vision-Language Models with ONE Image](2024年03月05日/ImgTrojan_Jailbreaking_Vision-Language_Models_with_ONE_Image.md)

    - [翻译: ImgTrojan：仅凭一张图像即可实现对视觉-语言模型的“越狱”攻击](2024年03月05日/ImgTrojan_Jailbreaking_Vision-Language_Models_with_ONE_Image.md)

- [A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods](2024年03月05日/A_Comprehensive_Survey_on_Process-Oriented_Automatic_Text_Summarization_with_Exploration_of_LLM-Based_Methods.md)

    - [翻译: 本研究对过程导向自动文本摘要进行全面综述，并深度探索基于大型语言模型（LLM）的方法在该领域中的应用。](2024年03月05日/A_Comprehensive_Survey_on_Process-Oriented_Automatic_Text_Summarization_with_Exploration_of_LLM-Based_Methods.md)

- [Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation](2024年03月05日/Domain-Agnostic_Mutual_Prompting_for_Unsupervised_Domain_Adaptation.md)

    - [翻译: 为解决无监督领域适应问题，我们提出“领域无关的相互提示”方法，该方法能够在不同领域间进行有效知识迁移，无需任何领域标注数据。](2024年03月05日/Domain-Agnostic_Mutual_Prompting_for_Unsupervised_Domain_Adaptation.md)

- [In Search of Truth: An Interrogation Approach to Hallucination Detection](2024年03月05日/In_Search_of_Truth_An_Interrogation_Approach_to_Hallucination_Detection.md)

    - [翻译: 为揭示真相，我们提出了一种通过质询法来探测幻觉的新途径。](2024年03月05日/In_Search_of_Truth_An_Interrogation_Approach_to_Hallucination_Detection.md)

- [MathScale: Scaling Instruction Tuning for Mathematical Reasoning](2024年03月05日/MathScale_Scaling_Instruction_Tuning_for_Mathematical_Reasoning.md)

    - [翻译: MathScale 是一种专门针对数学推理能力提升而设计的指令调优扩展方案。](2024年03月05日/MathScale_Scaling_Instruction_Tuning_for_Mathematical_Reasoning.md)

- [An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Models are Task-specific Classifiers](2024年03月05日/An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation_Fine-tuned_Judge_Models_are_Task-specific_Classifiers.md)

    - [翻译: 本研究通过实证方法探究了将大型语言模型（LLM）作为评价工具的应用，其中经过微调的Judge模型实质上成为了针对特定任务的分类器。](2024年03月05日/An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation_Fine-tuned_Judge_Models_are_Task-specific_Classifiers.md)

- [DPPA: Pruning Method for Large Language Model to Model Merging](2024年03月05日/DPPA_Pruning_Method_for_Large_Language_Model_to_Model_Merging.md)

    - [翻译: DPPA：一种针对大型语言模型整合的高效剪枝技术，旨在优化模型合并过程。](2024年03月05日/DPPA_Pruning_Method_for_Large_Language_Model_to_Model_Merging.md)

- [Evaluating and Optimizing Educational Content with Large Language Model Judgments](2024年03月05日/Evaluating_and_Optimizing_Educational_Content_with_Large_Language_Model_Judgments.md)

    - [翻译: 利用大型语言模型评判来评估与优化教育内容，以提升教学质量及效果。](2024年03月05日/Evaluating_and_Optimizing_Educational_Content_with_Large_Language_Model_Judgments.md)

- [PromptKD: Unsupervised Prompt Distillation for Vision-Language Models](2024年03月05日/PromptKD_Unsupervised_Prompt_Distillation_for_Vision-Language_Models.md)

    - [翻译: PromptKD 是一种针对视觉-语言模型的创新方法，通过无监督的方式进行提示蒸馏，以提升此类模型的表现和泛化能力。](2024年03月05日/PromptKD_Unsupervised_Prompt_Distillation_for_Vision-Language_Models.md)

- [EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs](2024年03月05日/EasyQuant_An_Efficient_Data-free_Quantization_Algorithm_for_LLMs.md)

    - [翻译: EasyQuant：针对LLMs设计的高效无数据量化方案](2024年03月05日/EasyQuant_An_Efficient_Data-free_Quantization_Algorithm_for_LLMs.md)

- [Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations](2024年03月05日/Emerging_Synergies_Between_Large_Language_Models_and_Machine_Learning_in_Ecommerce_Recommendations.md)

    - [翻译: 在电商推荐领域，大型语言模型与机器学习技术正展现出日益增强的协同潜力。](2024年03月05日/Emerging_Synergies_Between_Large_Language_Models_and_Machine_Learning_in_Ecommerce_Recommendations.md)

- [In-Memory Learning: A Declarative Learning Framework for Large Language Models](2024年03月05日/In-Memory_Learning_A_Declarative_Learning_Framework_for_Large_Language_Models.md)

    - [翻译: 内存学习：一种针对大型语言模型设计的声明式学习方案，它提供了一种新颖高效的方法来训练和优化大规模模型。](2024年03月05日/In-Memory_Learning_A_Declarative_Learning_Framework_for_Large_Language_Models.md)

- [Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models](2024年03月05日/Role_Prompting_Guided_Domain_Adaptation_with_General_Capability_Preserve_for_Large_Language_Models.md)

    - [翻译: 在保持LLM广泛能力的前提下，我们提出了一种通过角色提示驱动的领域适应技术。](2024年03月05日/Role_Prompting_Guided_Domain_Adaptation_with_General_Capability_Preserve_for_Large_Language_Models.md)

- [HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents](2024年03月05日/HINTs_Sensemaking_on_large_collections_of_documents_with_Hypergraph_visualization_and_INTelligent_agents.md)

    - [翻译: HINTs 技术利用超图可视化和智能代理，在大规模文档集合中实现高效的意义挖掘和理解。](2024年03月05日/HINTs_Sensemaking_on_large_collections_of_documents_with_Hypergraph_visualization_and_INTelligent_agents.md)

- [CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models](2024年03月05日/CURATRON_Complete_Robust_Preference_Data_for_Robust_Alignment_of_Large_Language_Models.md)

    - [翻译: CURATRON 提供了一套完整的、针对大型语言模型进行稳健对齐所必需的高质量偏好数据，以实现其在各类任务中的可靠和稳健表现。](2024年03月05日/CURATRON_Complete_Robust_Preference_Data_for_Robust_Alignment_of_Large_Language_Models.md)

- [Towards Training A Chinese Large Language Model for Anesthesiology](2024年03月05日/Towards_Training_A_Chinese_Large_Language_Model_for_Anesthesiology.md)

    - [翻译: 致力于训练适用于麻醉学领域的大型中文语言模型](2024年03月05日/Towards_Training_A_Chinese_Large_Language_Model_for_Anesthesiology.md)

- [Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment](2024年03月05日/Causal_Prompting_Debiasing_Large_Language_Model_Prompting_based_on_Front-Door_Adjustment.md)

    - [翻译: 因果提示法：运用前门调整策略校正大型语言模型的提示偏差](2024年03月05日/Causal_Prompting_Debiasing_Large_Language_Model_Prompting_based_on_Front-Door_Adjustment.md)

- [HARGPT: Are LLMs Zero-Shot Human Activity Recognizers?](2024年03月05日/HARGPT_Are_LLMs_Zero-Shot_Human_Activity_Recognizers.md)

    - [翻译: HARGPT 探究：LLMs 在零样本情况下能否胜任人类活动识别任务？](2024年03月05日/HARGPT_Are_LLMs_Zero-Shot_Human_Activity_Recognizers.md)

- [Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models](2024年03月05日/Crossing_Linguistic_Horizons_Finetuning_and_Comprehensive_Evaluation_of_Vietnamese_Large_Language_Models.md)

    - [翻译: 跨语言界限探索，对越南大型语言模型进行细致调整与综合评测](2024年03月05日/Crossing_Linguistic_Horizons_Finetuning_and_Comprehensive_Evaluation_of_Vietnamese_Large_Language_Models.md)

- [Android in the Zoo: Chain-of-Action-Thought for GUI Agents](2024年03月05日/Android_in_the_Zoo_Chain-of-Action-Thought_for_GUI_Agents.md)

    - [翻译: 在“Android in the Zoo”研究中，我们提出了 GUI 代理的“行动思维链”概念，旨在通过模拟人类在面对界面操作时的逻辑思考过程，提升 Android 系统中 GUI 代理的智能决策与执行能力。](2024年03月05日/Android_in_the_Zoo_Chain-of-Action-Thought_for_GUI_Agents.md)

- [Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models](2024年03月05日/Mixture-of-LoRAs_An_Efficient_Multitask_Tuning_for_Large_Language_Models.md)

    - [翻译: Mixture-of-LoRAs 是一项创新技术，专为大型语言模型设计的高效多任务调优方案。](2024年03月05日/Mixture-of-LoRAs_An_Efficient_Multitask_Tuning_for_Large_Language_Models.md)

- [Generative Explanations for Program Synthesizers](2024年03月05日/Generative_Explanations_for_Program_Synthesizers.md)

    - [翻译: 面向程序合成器的生成性解释技术](2024年03月05日/Generative_Explanations_for_Program_Synthesizers.md)

- [Generative News Recommendation](2024年03月05日/Generative_News_Recommendation.md)

    - [翻译: 创新性生成新闻推荐技术步骤 1 翻译：Generative News Recommendation 直译为“生成式新闻推荐”。步骤 2 翻译：为了更生动活泼、简洁优雅地表达，可以将“生成式新闻推荐”进一步诠释为“创新性生成新闻推荐技术”，既体现了该技术的前沿性和智能性，也突出了其在新闻推荐领域的独特应用。](2024年03月05日/Generative_News_Recommendation.md)

- [Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization](2024年03月05日/Negating_Negatives_Alignment_without_Human_Positive_Samples_via_Distributional_Dispreference_Optimization.md)

    - [翻译: 本研究提出了一种新颖方法，利用分布性逆偏优化技术，在没有人工标注的正样本情况下也能实现对齐效果。这种方法巧妙地“消除负例”，突破了以往依赖正样本的局限。](2024年03月05日/Negating_Negatives_Alignment_without_Human_Positive_Samples_via_Distributional_Dispreference_Optimization.md)

- [Human vs. Machine: Language Models and Wargames](2024年03月05日/Human_vs._Machine_Language_Models_and_Wargames.md)

    - [翻译: 人类与机器的较量：探究语言模型在战争模拟游戏中的表现与应用](2024年03月05日/Human_vs._Machine_Language_Models_and_Wargames.md)

- [Explaining Genetic Programming Trees using Large Language Models](2024年03月05日/Explaining_Genetic_Programming_Trees_using_Large_Language_Models.md)

    - [翻译: 本研究探讨如何运用大型语言模型来解析遗传编程树的内在逻辑，以实现对复杂模型结构的深入理解与解读。](2024年03月05日/Explaining_Genetic_Programming_Trees_using_Large_Language_Models.md)

- [Japanese-English Sentence Translation Exercises Dataset for Automatic Grading](2024年03月05日/Japanese-English_Sentence_Translation_Exercises_Dataset_for_Automatic_Grading.md)

    - [翻译: 该数据集包含日语-英语句子翻译练习题目，专为实现自动化评分而设计。](2024年03月05日/Japanese-English_Sentence_Translation_Exercises_Dataset_for_Automatic_Grading.md)

- [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](2024年03月05日/Learning_to_Maximize_Mutual_Information_for_Chain-of-Thought_Distillation.md)

    - [翻译: 本研究致力于学习如何优化互信息，以应用于链式思考蒸馏技术中，旨在提升模型对复杂问题的推理能力。](2024年03月05日/Learning_to_Maximize_Mutual_Information_for_Chain-of-Thought_Distillation.md)

- [Enhancing Vision-Language Pre-training with Rich Supervisions](2024年03月05日/Enhancing_Vision-Language_Pre-training_with_Rich_Supervisions.md)

    - [翻译: 在视觉-语言预训练中，我们致力于借助丰富的监督信息以增强模型性能。](2024年03月05日/Enhancing_Vision-Language_Pre-training_with_Rich_Supervisions.md)

- [Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation](2024年03月05日/Learn_to_Code_Sustainably_An_Empirical_Study_on_LLM-based_Green_Code_Generation.md)

    - [翻译: 探究如何实现可持续编程，本研究通过实证方法考察了基于大型语言模型（LLM）的绿色代码生成技术。](2024年03月05日/Learn_to_Code_Sustainably_An_Empirical_Study_on_LLM-based_Green_Code_Generation.md)

- [Scope of Large Language Models for Mining Emerging Opinions in Online Health Discourse](2024年03月05日/Scope_of_Large_Language_Models_for_Mining_Emerging_Opinions_in_Online_Health_Discourse.md)

    - [翻译: 探究大型语言模型在揭示在线健康讨论中新兴观点方面的潜力及应用范围](2024年03月05日/Scope_of_Large_Language_Models_for_Mining_Emerging_Opinions_in_Online_Health_Discourse.md)

- [DIVERSE: Deciphering Internet Views on the U.S. Military Through Video Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification](2024年03月05日/DIVERSE_Deciphering_Internet_Views_on_the_U.S._Military_Through_Video_Comment_Stance_Analysis,_A_Novel_Benchmark_Dataset_for_Stance_Classification.md)

    - [翻译: DIVERSE 是一个创新的基准数据集，它专注于通过分析视频评论中的立场来解读网络舆论中关于美国军事的不同观点，为 stance 分类任务提供了有力支持。](2024年03月05日/DIVERSE_Deciphering_Internet_Views_on_the_U.S._Military_Through_Video_Comment_Stance_Analysis,_A_Novel_Benchmark_Dataset_for_Stance_Classification.md)

- [Guardrail Baselines for Unlearning in LLMs](2024年03月05日/Guardrail_Baselines_for_Unlearning_in_LLMs.md)

    - [翻译: 针对LLMs的遗忘问题，我们提出“防护栏基线”，旨在为模型提供一种有效去除有害信息或实现数据遗忘的基准方法。](2024年03月05日/Guardrail_Baselines_for_Unlearning_in_LLMs.md)

- [Book2Dial: Generating Teacher-Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots](2024年03月05日/Book2Dial_Generating_Teacher-Student_Interactions_from_Textbooks_for_Cost-Effective_Development_of_Educational_Chatbots.md)

    - [翻译: Book2Dial 是一项创新方法，通过将教科书内容转化为教师与学生的互动对话，为高效开发教育聊天机器人降低成本。这项技术能够自动生成源于教科书的对话场景，助力构建更具教学价值的教育聊天机器人。](2024年03月05日/Book2Dial_Generating_Teacher-Student_Interactions_from_Textbooks_for_Cost-Effective_Development_of_Educational_Chatbots.md)

- ["It's the only thing I can trust": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance](2024年03月05日/It's_the_only_thing_I_can_trust_Envisioning_Large_Language_Model_Use_by_Autistic_Workers_for_Communication_Assistance.md)

    - [翻译: 在协助沟通方面，大型语言模型成为自闭症工作者表达与交流的可靠工具。“这是我唯一信赖之物”，让我们展望这一技术如何助力自闭症群体实现有效沟通。](2024年03月05日/It's_the_only_thing_I_can_trust_Envisioning_Large_Language_Model_Use_by_Autistic_Workers_for_Communication_Assistance.md)

- [Bridging Language and Items for Retrieval and Recommendation](2024年03月06日/Bridging_Language_and_Items_for_Retrieval_and_Recommendation.md)

    - [翻译: 为实现检索与推荐，构建语言与物品之间的桥梁](2024年03月06日/Bridging_Language_and_Items_for_Retrieval_and_Recommendation.md)

- [Did Translation Models Get More Robust Without Anyone Even Noticing?](2024年03月06日/Did_Translation_Models_Get_More_Robust_Without_Anyone_Even_Noticing.md)

    - [翻译: 翻译模型是否悄无声息地增强了稳健性？](2024年03月06日/Did_Translation_Models_Get_More_Robust_Without_Anyone_Even_Noticing.md)

- [Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing](2024年03月06日/Fuzzing_BusyBox_Leveraging_LLM_and_Crash_Reuse_for_Embedded_Bug_Unearthing.md)

    - [翻译: 通过结合 LLM 技术与崩溃重用策略，我们致力于对 BusyBox 进行高效模糊测试，以揭示隐藏的嵌入式软件漏洞。](2024年03月06日/Fuzzing_BusyBox_Leveraging_LLM_and_Crash_Reuse_for_Embedded_Bug_Unearthing.md)

- [SaulLM-7B: A pioneering Large Language Model for Law](2024年03月06日/SaulLM-7B_A_pioneering_Large_Language_Model_for_Law.md)

    - [翻译: SaulLM-7B，作为一款开路先锋般的大型语言模型，专为法律应用场景打造。](2024年03月06日/SaulLM-7B_A_pioneering_Large_Language_Model_for_Law.md)

- [Learning to Decode Collaboratively with Multiple Language Models](2024年03月06日/Learning_to_Decode_Collaboratively_with_Multiple_Language_Models.md)

    - [翻译: 本研究探讨如何训练多个语言模型协同解码，以提升整体的解码效果和性能。](2024年03月06日/Learning_to_Decode_Collaboratively_with_Multiple_Language_Models.md)

- [On the Origins of Linear Representations in Large Language Models](2024年03月06日/On_the_Origins_of_Linear_Representations_in_Large_Language_Models.md)

    - [翻译: 本文深入探讨大型语言模型内部线性表示的起源，揭示其内在机理与构建过程。](2024年03月06日/On_the_Origins_of_Linear_Representations_in_Large_Language_Models.md)

- [KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions](2024年03月06日/KIWI_A_Dataset_of_Knowledge-Intensive_Writing_Instructions_for_Answering_Research_Questions.md)

    - [翻译: KIWI 数据集，专为解答研究问题而设计，提供了丰富的知识密集型写作指导。](2024年03月06日/KIWI_A_Dataset_of_Knowledge-Intensive_Writing_Instructions_for_Answering_Research_Questions.md)

- [Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning](2024年03月06日/Are_Language_Models_Puzzle_Prodigies_Algorithmic_Puzzles_Unveil_Serious_Challenges_in_Multimodal_Reasoning.md)

    - [翻译: 语言模型堪称解谜高手吗？通过算法谜题，我们发现它们在解决多模态推理问题时面临重大挑战。](2024年03月06日/Are_Language_Models_Puzzle_Prodigies_Algorithmic_Puzzles_Unveil_Serious_Challenges_in_Multimodal_Reasoning.md)

- [X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification](2024年03月06日/X-Shot_A_Unified_System_to_Handle_Frequent,_Few-shot_and_Zero-shot_Learning_Simultaneously_in_Classification.md)

    - [翻译: X-Shot 系统集大成，一举囊括了分类任务中频繁出现、少量样本及零样本的学习场景，实现了一体化解决方案。](2024年03月06日/X-Shot_A_Unified_System_to_Handle_Frequent,_Few-shot_and_Zero-shot_Learning_Simultaneously_in_Classification.md)

- [Designing Informative Metrics for Few-Shot Example Selection](2024年03月06日/Designing_Informative_Metrics_for_Few-Shot_Example_Selection.md)

    - [翻译: 本研究致力于设计针对少量示例选择的有效度量标准，以期提升模型在有限数据下的学习与泛化能力。](2024年03月06日/Designing_Informative_Metrics_for_Few-Shot_Example_Selection.md)

- [Emojinize : Enriching Any Text with Emoji Translations](2024年03月06日/Emojinize__Enriching_Any_Text_with_Emoji_Translations.md)

    - [翻译: Emojinize项目致力于为任意文本增添生动有趣的Emoji表达，实现文本内容的emoji化增强。](2024年03月06日/Emojinize__Enriching_Any_Text_with_Emoji_Translations.md)

- [ShortGPT: Layers in Large Language Models are More Redundant Than You Expect](2024年03月06日/ShortGPT_Layers_in_Large_Language_Models_are_More_Redundant_Than_You_Expect.md)

    - [翻译: ShortGPT 揭示，大型语言模型内部的层级存在超乎预期的冗余现象。](2024年03月06日/ShortGPT_Layers_in_Large_Language_Models_are_More_Redundant_Than_You_Expect.md)

- [Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ](2024年03月06日/Evaluating_the_Elementary_Multilingual_Capabilities_of_Large_Language_Models_with_MultiQ.md)

    - [翻译: 我们运用 MultiQ 工具，对大型语言模型在处理基础多语言任务时的能力进行深入评估。](2024年03月06日/Evaluating_the_Elementary_Multilingual_Capabilities_of_Large_Language_Models_with_MultiQ.md)

- [Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection from Remote Sensing Imagery](2024年03月06日/Popeye_A_Unified_Visual-Language_Model_for_Multi-Source_Ship_Detection_from_Remote_Sensing_Imagery.md)

    - [翻译: Popeye 是一款集成了视觉与语言处理能力的统一模型，专为在遥感图像中实现多源船舶检测而设计。](2024年03月06日/Popeye_A_Unified_Visual-Language_Model_for_Multi-Source_Ship_Detection_from_Remote_Sensing_Imagery.md)

- [PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion](2024年03月06日/PPTC-R_benchmark_Towards_Evaluating_the_Robustness_of_Large_Language_Models_for_PowerPoint_Task_Completion.md)

    - [翻译: PPTC-R基准测试旨在深入探究大型语言模型在应对PowerPoint任务挑战时的稳健性表现。](2024年03月06日/PPTC-R_benchmark_Towards_Evaluating_the_Robustness_of_Large_Language_Models_for_PowerPoint_Task_Completion.md)

- [German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset](2024年03月06日/German_also_Hallucinates!_Inconsistency_Detection_in_News_Summaries_with_the_Absinth_Dataset.md)

    - [翻译: 德语文本亦会“幻想”！利用Absinth数据集揭示新闻摘要中的不一致性问题](2024年03月06日/German_also_Hallucinates!_Inconsistency_Detection_in_News_Summaries_with_the_Absinth_Dataset.md)

- [Towards Safe and Aligned Large Language Models for Medicine](2024年03月06日/Towards_Safe_and_Aligned_Large_Language_Models_for_Medicine.md)

    - [翻译: 本研究致力于研发适用于医学领域的安全且高度兼容的大型语言模型，旨在提升其在医疗场景下的表现和可靠性。](2024年03月06日/Towards_Safe_and_Aligned_Large_Language_Models_for_Medicine.md)

- [Multimodal Transformer for Comics Text-Cloze](2024年03月06日/Multimodal_Transformer_for_Comics_Text-Cloze.md)

    - [翻译: 针对漫画文本完形填空任务，我们采用多模态 Transformer 技术，旨在整合图像与文本信息，以提升模型在理解漫画情境并准确完成文本完形填空方面的性能。](2024年03月06日/Multimodal_Transformer_for_Comics_Text-Cloze.md)

- [Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese](2024年03月06日/Rapidly_Developing_High-quality_Instruction_Data_and_Evaluation_Benchmark_for_Large_Language_Models_with_Minimal_Human_Effort_A_Case_Study_on_Japanese.md)

    - [翻译: 针对大型语言模型，本研究案例展示了如何高效地以最小化人工投入的方式快速构建高质量的指令数据集及评估基准，此方法特别适用于日语场景。](2024年03月06日/Rapidly_Developing_High-quality_Instruction_Data_and_Evaluation_Benchmark_for_Large_Language_Models_with_Minimal_Human_Effort_A_Case_Study_on_Japanese.md)

- [General2Specialized LLMs Translation for E-commerce](2024年03月06日/General2Specialized_LLMs_Translation_for_E-commerce.md)

    - [翻译: 面向电商领域的 General2Specialized LLMs 翻译技术](2024年03月06日/General2Specialized_LLMs_Translation_for_E-commerce.md)

- [Automatic Bi-modal Question Title Generation for Stack Overflow with Prompt Learning](2024年03月06日/Automatic_Bi-modal_Question_Title_Generation_for_Stack_Overflow_with_Prompt_Learning.md)

    - [翻译: 本研究借助提示学习技术，针对 Stack Overflow 平台开发了一种自动为编程问题生成融合两种模态信息的标题方法。](2024年03月06日/Automatic_Bi-modal_Question_Title_Generation_for_Stack_Overflow_with_Prompt_Learning.md)

- [K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data](2024年03月06日/K-Link_Knowledge-Link_Graph_from_LLMs_for_Enhanced_Representation_Learning_in_Multivariate_Time-Series_Data.md)

    - [翻译: K-Link 方法通过从大型语言模型（LLMs）中提炼出知识链接图，旨在提升多元时间序列数据的表征学习效果。](2024年03月06日/K-Link_Knowledge-Link_Graph_from_LLMs_for_Enhanced_Representation_Learning_in_Multivariate_Time-Series_Data.md)

- [SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models](2024年03月06日/SheetAgent_A_Generalist_Agent_for_Spreadsheet_Reasoning_and_Manipulation_via_Large_Language_Models.md)

    - [翻译: SheetAgent 是一款借助大型语言模型，实现对电子表格进行高效推理与灵活操控的全能型智能助手。](2024年03月06日/SheetAgent_A_Generalist_Agent_for_Spreadsheet_Reasoning_and_Manipulation_via_Large_Language_Models.md)

- [GPTopic: Dynamic and Interactive Topic Representations](2024年03月06日/GPTopic_Dynamic_and_Interactive_Topic_Representations.md)

    - [翻译: GPTopic：探索动态且互动的主题表达方式](2024年03月06日/GPTopic_Dynamic_and_Interactive_Topic_Representations.md)

- [Multimodal Large Language Models to Support Real-World Fact-Checking](2024年03月06日/Multimodal_Large_Language_Models_to_Support_Real-World_Fact-Checking.md)

    - [翻译: 为助力现实世界中的事实核查，我们引入了多模态大型语言模型。这类模型能够整合多种信息源，以提升对复杂情境中事实信息的精准判断能力。](2024年03月06日/Multimodal_Large_Language_Models_to_Support_Real-World_Fact-Checking.md)

- [Assessing the Aesthetic Evaluation Capabilities of GPT-4 with Vision: Insights from Group and Individual Assessments](2024年03月06日/Assessing_the_Aesthetic_Evaluation_Capabilities_of_GPT-4_with_Vision_Insights_from_Group_and_Individual_Assessments.md)

    - [翻译: 通过对 GPT-4 进行群体及个体评估，本研究探索其结合视觉进行审美评价的能力，并揭示相关深刻见解。](2024年03月06日/Assessing_the_Aesthetic_Evaluation_Capabilities_of_GPT-4_with_Vision_Insights_from_Group_and_Individual_Assessments.md)

- [RouteExplainer: An Explanation Framework for Vehicle Routing Problem](2024年03月06日/RouteExplainer_An_Explanation_Framework_for_Vehicle_Routing_Problem.md)

    - [翻译: RouteExplainer 是一个专为解决车辆路径规划问题而设计的解释性框架，旨在深入解析并清晰展现路径决策背后的逻辑与依据。](2024年03月06日/RouteExplainer_An_Explanation_Framework_for_Vehicle_Routing_Problem.md)

- [Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem](2024年03月06日/Benchmarking_Hallucination_in_Large_Language_Models_based_on_Unanswerable_Math_Word_Problem.md)

    - [翻译: 本研究通过利用无解数学题，对大型语言模型中出现的“幻想”现象进行基准评估，旨在深入理解并量化其在面对这类问题时的错误生成表现。](2024年03月06日/Benchmarking_Hallucination_in_Large_Language_Models_based_on_Unanswerable_Math_Word_Problem.md)

- [Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models](2024年03月06日/Emotional_Manipulation_Through_Prompt_Engineering_Amplifies_Disinformation_Generation_in_AI_Large_Language_Models.md)

    - [翻译: 运用提示工程技术进行情感操纵，能够加剧 AI 大型语言模型制造虚假信息的问题。](2024年03月06日/Emotional_Manipulation_Through_Prompt_Engineering_Amplifies_Disinformation_Generation_in_AI_Large_Language_Models.md)

- [Prompt Mining for Language-based Human Mobility Forecasting](2024年03月06日/Prompt_Mining_for_Language-based_Human_Mobility_Forecasting.md)

    - [翻译: 在语言驱动的人类行动轨迹预测中，我们探索了提示挖掘技术的应用，旨在通过有效提取和利用提示信息来提升预测准确性与模型效能。](2024年03月06日/Prompt_Mining_for_Language-based_Human_Mobility_Forecasting.md)

- [Towards Efficient and Effective Unlearning of Large Language Models for Recommendation](2024年03月06日/Towards_Efficient_and_Effective_Unlearning_of_Large_Language_Models_for_Recommendation.md)

    - [翻译: 本研究致力于探索如何让大型语言模型在推荐场景中实现高效且有效的遗忘学习，即针对已学习内容进行有效“反学习”。（注：此处将“unlearning”翻译为“遗忘学习”或“反学习”，是因为在AI领域中，“unlearning”通常指的是对模型已经学到的内容进行去除或更新的过程。）](2024年03月06日/Towards_Efficient_and_Effective_Unlearning_of_Large_Language_Models_for_Recommendation.md)

- [Non-verbal information in spontaneous speech - towards a new framework of analysis](2024年03月06日/Non-verbal_information_in_spontaneous_speech_-_towards_a_new_framework_of_analysis.md)

    - [翻译: 在探索自发性言语的奥秘时，我们正迈向一个全新的分析框架，聚焦于其中蕴含的非言语信息。](2024年03月06日/Non-verbal_information_in_spontaneous_speech_-_towards_a_new_framework_of_analysis.md)

- [CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models](2024年03月06日/CLongEval_A_Chinese_Benchmark_for_Evaluating_Long-Context_Large_Language_Models.md)

    - [翻译: CLongEval —— 专为评估大型语言模型在处理长文本情境能力而设的中文评测基准](2024年03月06日/CLongEval_A_Chinese_Benchmark_for_Evaluating_Long-Context_Large_Language_Models.md)

- [GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection](2024年03月06日/GaLore_Memory-Efficient_LLM_Training_by_Gradient_Low-Rank_Projection.md)

    - [翻译: GaLore——一种通过梯度低秩投影技术提升大语言模型（LLM）训练内存效率的新方案。](2024年03月06日/GaLore_Memory-Efficient_LLM_Training_by_Gradient_Low-Rank_Projection.md)

- [A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation](2024年03月06日/A_Knowledge_Plug-and-Play_Test_Bed_for_Open-domain_Dialogue_Generation.md)

    - [翻译: 我们构建了一个针对开放领域对话生成的“知识即插即用”测试平台，旨在便捷地探究和验证各类知识在对话生成任务中的应用效果。](2024年03月06日/A_Knowledge_Plug-and-Play_Test_Bed_for_Open-domain_Dialogue_Generation.md)

- [Aligners: Decoupling LLMs and Alignment](2024年03月06日/Aligners_Decoupling_LLMs_and_Alignment.md)

    - [翻译: 本文探讨“对齐器”，旨在将大型语言模型（LLM）与其对齐机制分离。通过这种方法，我们深入研究如何独立优化LLM的性能与对其行为和输出的可控性，以实现更好的对齐效果。](2024年03月06日/Aligners_Decoupling_LLMs_and_Alignment.md)

- [Self-Evaluation of Large Language Model based on Glass-box Features](2024年03月06日/Self-Evaluation_of_Large_Language_Model_based_on_Glass-box_Features.md)

    - [翻译: 针对大型语言模型，本研究采用 Glass-box 特征进行自我评估，旨在通过解析模型内部透明可见的特征来评价其性能表现。](2024年03月06日/Self-Evaluation_of_Large_Language_Model_based_on_Glass-box_Features.md)

- [Large Language Models are In-Context Molecule Learners](2024年03月06日/Large_Language_Models_are_In-Context_Molecule_Learners.md)

    - [翻译: 大型语言模型擅长于在上下文中学习分子知识（注：由于原文标题简洁且具有一定的专业性，从准确性和生动性角度考虑，在翻译时保留了“上下文”这一术语，并将“learner”译为更符合中文表达习惯的“学习者”，同时也强调了其在分子领域的学习能力。）](2024年03月06日/Large_Language_Models_are_In-Context_Molecule_Learners.md)

- [Generative AI for Synthetic Data Generation: Methods, Challenges and the Future](2024年03月06日/Generative_AI_for_Synthetic_Data_Generation_Methods,_Challenges_and_the_Future.md)

    - [翻译: 探究生成式AI在合成数据创造中的方法论、面临的挑战及其未来趋势](2024年03月06日/Generative_AI_for_Synthetic_Data_Generation_Methods,_Challenges_and_the_Future.md)

- [Metric-aware LLM inference](2024年03月06日/Metric-aware_LLM_inference.md)

    - [翻译: 面向指标的 LLM 推理技术](2024年03月06日/Metric-aware_LLM_inference.md)

- [Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy](2024年03月06日/Improving_Retrieval_in_Theme-specific_Applications_using_a_Corpus_Topical_Taxonomy.md)

    - [翻译: 通过构建和运用基于语料库的主题分类体系，本研究致力于提升各类特定主题应用中的检索效果。](2024年03月06日/Improving_Retrieval_in_Theme-specific_Applications_using_a_Corpus_Topical_Taxonomy.md)

- [Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference](2024年03月06日/Chatbot_Arena_An_Open_Platform_for_Evaluating_LLMs_by_Human_Preference.md)

    - [翻译: Chatbot Arena——一个通过人类偏好评判LLMs表现的公开平台，旨在为各类大型语言模型提供公正、直观的人性化评估环境。](2024年03月06日/Chatbot_Arena_An_Open_Platform_for_Evaluating_LLMs_by_Human_Preference.md)

- [Privacy-preserving Fine-tuning of Large Language Models through Flatness](2024年03月06日/Privacy-preserving_Fine-tuning_of_Large_Language_Models_through_Flatness.md)

    - [翻译: 针对大型语言模型，我们提出了一种基于“平坦性”的隐私保护微调方法。该方法旨在在保持模型性能的同时，有效保障用户数据隐私，特别是在对大型语言模型进行针对性优化时。](2024年03月06日/Privacy-preserving_Fine-tuning_of_Large_Language_Models_through_Flatness.md)

- [Exploring LLM-based Agents for Root Cause Analysis](2024年03月06日/Exploring_LLM-based_Agents_for_Root_Cause_Analysis.md)

    - [翻译: 本研究致力于探究基于大型语言模型（LLM）的智能体在根因分析任务中的应用与潜力。](2024年03月06日/Exploring_LLM-based_Agents_for_Root_Cause_Analysis.md)

- [Can Large Language Models Reason and Plan?](2024年03月06日/Can_Large_Language_Models_Reason_and_Plan.md)

    - [翻译: 探究大型语言模型能否进行推理与规划步骤解释：](2024年03月06日/Can_Large_Language_Models_Reason_and_Plan.md)

- [Artificial Intelligence Exploring the Patent Field](2024年03月06日/Artificial_Intelligence_Exploring_the_Patent_Field.md)

    - [翻译: 人工智能涉足专利界，正不断探寻其中的创新疆域。](2024年03月06日/Artificial_Intelligence_Exploring_the_Patent_Field.md)

- [Can Large Language Models do Analytical Reasoning?](2024年03月06日/Can_Large_Language_Models_do_Analytical_Reasoning.md)

    - [翻译: 大型语言模型是否具备进行分析推理的能力呢？](2024年03月06日/Can_Large_Language_Models_do_Analytical_Reasoning.md)

- [Enhancing chest X-ray datasets with privacy-preserving large language models and multi-type annotations: a data-driven approach for improved classification](2024年03月06日/Enhancing_chest_X-ray_datasets_with_privacy-preserving_large_language_models_and_multi-type_annotations_a_data-driven_approach_for_improved_classification.md)

    - [翻译: 我们提出了一种数据驱动的方案，利用隐私保护的大规模语言模型及多元注解技术来提升胸部X射线数据集的质量，从而实现更精确的分类效果。](2024年03月06日/Enhancing_chest_X-ray_datasets_with_privacy-preserving_large_language_models_and_multi-type_annotations_a_data-driven_approach_for_improved_classification.md)

- [FaaF: Facts as a Function for the evaluation of RAG systems](2024年03月06日/FaaF_Facts_as_a_Function_for_the_evaluation_of_RAG_systems.md)

    - [翻译: FaaF：提出“事实即函数”方法，用于评估 RAG 系统的表现。](2024年03月06日/FaaF_Facts_as_a_Function_for_the_evaluation_of_RAG_systems.md)

- [Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks](2024年03月06日/Neural_Exec_Learning_(and_Learning_from)_Execution_Triggers_for_Prompt_Injection_Attacks.md)

    - [翻译: Neural Exec：针对提示注入攻击，研究并借鉴执行触发器的学习机制](2024年03月06日/Neural_Exec_Learning_(and_Learning_from)_Execution_Triggers_for_Prompt_Injection_Attacks.md)

- [MeaCap: Memory-Augmented Zero-shot Image Captioning](2024年03月06日/MeaCap_Memory-Augmented_Zero-shot_Image_Captioning.md)

    - [翻译: MeaCap 是一种“记忆增强型零样本图像描述”技术，它利用记忆机制提升在未见过的图像上进行自动描述的能力。](2024年03月06日/MeaCap_Memory-Augmented_Zero-shot_Image_Captioning.md)

- [Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models](2024年03月06日/Quantifying_Contamination_in_Evaluating_Code_Generation_Capabilities_of_Language_Models.md)

    - [翻译: 在衡量语言模型进行代码生成的能力时，本研究专注于量化其中的“污染”因素，以准确评估其真实性能。](2024年03月06日/Quantifying_Contamination_in_Evaluating_Code_Generation_Capabilities_of_Language_Models.md)

- [WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](2024年03月06日/WaterMax_breaking_the_LLM_watermark_detectability-robustness-quality_trade-off.md)

    - [翻译: WaterMax 技术突破了 LLM 水印在可检测性、鲁棒性和质量间的传统折衷困境。](2024年03月06日/WaterMax_breaking_the_LLM_watermark_detectability-robustness-quality_trade-off.md)

- [KnowledgeVIS: Interpreting Language Models by Comparing Fill-in-the-Blank Prompts](2024年03月07日/KnowledgeVIS_Interpreting_Language_Models_by_Comparing_Fill-in-the-Blank_Prompts.md)

    - [翻译: 知识可视化（KnowledgeVIS）：一种通过对比填空式提示，深入解读语言模型的新方法。](2024年03月07日/KnowledgeVIS_Interpreting_Language_Models_by_Comparing_Fill-in-the-Blank_Prompts.md)

- [LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error](2024年03月07日/LLMs_in_the_Imaginarium_Tool_Learning_through_Simulated_Trial_and_Error.md)

    - [翻译: 在“想象工坊”场景下，LLMs 通过模拟试验与错误的方式习得工具使用技巧。](2024年03月07日/LLMs_in_the_Imaginarium_Tool_Learning_through_Simulated_Trial_and_Error.md)

- [Common 7B Language Models Already Possess Strong Math Capabilities](2024年03月07日/Common_7B_Language_Models_Already_Possess_Strong_Math_Capabilities.md)

    - [翻译: 现今的主流70亿参数语言模型普遍展现出强劲的数学处理能力。](2024年03月07日/Common_7B_Language_Models_Already_Possess_Strong_Math_Capabilities.md)

- [ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes](2024年03月07日/ObjectCompose_Evaluating_Resilience_of_Vision-Based_Models_on_Object-to-Background_Compositional_Changes.md)

    - [翻译: ObjectCompose 项目旨在评测视觉模型在面临对象与背景组合变化时的抗干扰能力。](2024年03月07日/ObjectCompose_Evaluating_Resilience_of_Vision-Based_Models_on_Object-to-Background_Compositional_Changes.md)

- [Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification](2024年03月07日/Fact-Checking_the_Output_of_Large_Language_Models_via_Token-Level_Uncertainty_Quantification.md)

    - [翻译: 针对大型语言模型的输出，我们采用Token级别不确定性量化方法进行深度事实核查。](2024年03月07日/Fact-Checking_the_Output_of_Large_Language_Models_via_Token-Level_Uncertainty_Quantification.md)

- [Telecom Language Models: Must They Be Large?](2024年03月07日/Telecom_Language_Models_Must_They_Be_Large.md)

    - [翻译: 电信领域的语言模型是否必须具备大模型特性？](2024年03月07日/Telecom_Language_Models_Must_They_Be_Large.md)

- [Teaching Large Language Models to Reason with Reinforcement Learning](2024年03月07日/Teaching_Large_Language_Models_to_Reason_with_Reinforcement_Learning.md)

    - [翻译: 运用强化学习策略，训练大型语言模型掌握推理技能](2024年03月07日/Teaching_Large_Language_Models_to_Reason_with_Reinforcement_Learning.md)

- [CAT: Enhancing Multimodal Large Language Model to Answer Questions in Dynamic Audio-Visual Scenarios](2024年03月07日/CAT_Enhancing_Multimodal_Large_Language_Model_to_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios.md)

    - [翻译: CAT研究致力于提升大型多模态语言模型，在充满变化的音视频场景下解答问题的能力。](2024年03月07日/CAT_Enhancing_Multimodal_Large_Language_Model_to_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios.md)

- [Strong Priority and Determinacy in Timed CCS](2024年03月07日/Strong_Priority_and_Determinacy_in_Timed_CCS.md)

    - [翻译: 针对定时进程演算（Timed CCS）中体现的强优先级与确定性进行深入探讨，揭示其内在机制与影响。步骤 1 翻译：Strong Priority and Determinacy in Timed Calculus of Communicating Systems (CCS)步骤 2 翻译：在通信系统计时演算（Timed CCS）中，强优先级与确定性的概念具有重要价值。本研究致力于阐述并剖析这两个特性在处理实时交互过程中的作用及其对系统行为的深刻影响。](2024年03月07日/Strong_Priority_and_Determinacy_in_Timed_CCS.md)

- [A Detailed Audio-Text Data Simulation Pipeline using Single-Event Sounds](2024年03月07日/A_Detailed_Audio-Text_Data_Simulation_Pipeline_using_Single-Event_Sounds.md)

    - [翻译: 我们构建了一种基于单个事件声音的精细音频文本数据仿真流程，旨在高效生成高质量的模拟数据。](2024年03月07日/A_Detailed_Audio-Text_Data_Simulation_Pipeline_using_Single-Event_Sounds.md)

- [Embodied Understanding of Driving Scenarios](2024年03月07日/Embodied_Understanding_of_Driving_Scenarios.md)

    - [翻译: 深入探究驾驶场景中的具身认知](2024年03月07日/Embodied_Understanding_of_Driving_Scenarios.md)

- [Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition](2024年03月07日/Wiki-TabNERAdvancing_Table_Interpretation_Through_Named_Entity_Recognition.md)

    - [翻译: Wiki-TabNER项目致力于借助命名实体识别技术提升表格理解能力，从而推动表格信息的有效解读。](2024年03月07日/Wiki-TabNERAdvancing_Table_Interpretation_Through_Named_Entity_Recognition.md)

- [Where does In-context Translation Happen in Large Language Models](2024年03月07日/Where_does_In-context_Translation_Happen_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型内部，上下文翻译究竟如何运作呢？](2024年03月07日/Where_does_In-context_Translation_Happen_in_Large_Language_Models.md)

- [GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability](2024年03月07日/GraphInstruct_Empowering_Large_Language_Models_with_Graph_Understanding_and_Reasoning_Capability.md)

    - [翻译: GraphInstruct 是一项技术，它赋予大型语言模型强大的图理解和推理能力。](2024年03月07日/GraphInstruct_Empowering_Large_Language_Models_with_Graph_Understanding_and_Reasoning_Capability.md)

- [Do Large Language Model Understand Multi-Intent Spoken Language ?](2024年03月07日/Do_Large_Language_Model_Understand_Multi-Intent_Spoken_Language_.md)

    - [翻译: 大型语言模型是否能洞悉多意图口语？](2024年03月07日/Do_Large_Language_Model_Understand_Multi-Intent_Spoken_Language_.md)

- [Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset](2024年03月07日/Pearl_A_Review-driven_Persona-Knowledge_Grounded_Conversational_Recommendation_Dataset.md)

    - [翻译: Pearl 是一个独特的对话式推荐数据集，它以评论为驱动，并紧密结合了人格知识。该数据集致力于提供更加情境化和个性化的对话推荐服务。](2024年03月07日/Pearl_A_Review-driven_Persona-Knowledge_Grounded_Conversational_Recommendation_Dataset.md)

- [Low-Resource Court Judgment Summarization for Common Law Systems](2024年03月07日/Low-Resource_Court_Judgment_Summarization_for_Common_Law_Systems.md)

    - [翻译: 致力于普通法系环境下的低资源法院判决摘要生成，本研究关注在有限数据条件下，如何高效地为法院判决文档创建精炼、准确的摘要。](2024年03月07日/Low-Resource_Court_Judgment_Summarization_for_Common_Law_Systems.md)

- [Membership Inference Attacks and Privacy in Topic Modeling](2024年03月07日/Membership_Inference_Attacks_and_Privacy_in_Topic_Modeling.md)

    - [翻译: 针对主题模型的成员身份推断攻击及其对隐私保护的影响](2024年03月07日/Membership_Inference_Attacks_and_Privacy_in_Topic_Modeling.md)

- [Feedback-Generation for Programming Exercises With GPT-4](2024年03月07日/Feedback-Generation_for_Programming_Exercises_With_GPT-4.md)

    - [翻译: GPT-4 在编程练习中助力生成针对性反馈](2024年03月07日/Feedback-Generation_for_Programming_Exercises_With_GPT-4.md)

- [Sentiment-driven prediction of financial returns: a Bayesian-enhanced FinBERT approach](2024年03月07日/Sentiment-driven_prediction_of_financial_returns_a_Bayesian-enhanced_FinBERT_approach.md)

    - [翻译: 运用贝叶斯增强技术优化的FinBERT模型，针对情感驱动的金融收益预测展开研究。](2024年03月07日/Sentiment-driven_prediction_of_financial_returns_a_Bayesian-enhanced_FinBERT_approach.md)

- [SGNet: Folding Symmetrical Protein Complex with Deep Learning](2024年03月07日/SGNet_Folding_Symmetrical_Protein_Complex_with_Deep_Learning.md)

    - [翻译: SGNet 是一个运用深度学习技术来高效折叠对称蛋白质复合体的方法。](2024年03月07日/SGNet_Folding_Symmetrical_Protein_Complex_with_Deep_Learning.md)

- [Acceleron: A Tool to Accelerate Research Ideation](2024年03月07日/Acceleron_A_Tool_to_Accelerate_Research_Ideation.md)

    - [翻译: Acceleron，一款致力于提升研究构思速度的有效工具](2024年03月07日/Acceleron_A_Tool_to_Accelerate_Research_Ideation.md)

- [ProMoAI: Process Modeling with Generative AI](2024年03月07日/ProMoAI_Process_Modeling_with_Generative_AI.md)

    - [翻译: ProMoAI——利用生成式人工智能技术进行流程模型构建](2024年03月07日/ProMoAI_Process_Modeling_with_Generative_AI.md)

- [Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models](2024年03月07日/Measuring_Meaning_Composition_in_the_Human_Brain_with_Composition_Scores_from_Large_Language_Models.md)

    - [翻译: 本研究借助大型语言模型计算出的意义组合得分，探索人类大脑中意义组合的量化衡量方法。](2024年03月07日/Measuring_Meaning_Composition_in_the_Human_Brain_with_Composition_Scores_from_Large_Language_Models.md)

- [Discriminative Probing and Tuning for Text-to-Image Generation](2024年03月07日/Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation.md)

    - [翻译: 针对文本到图像生成任务，我们采用鉴别性探查和调整技术，以深入探究模型内部机制，并优化其生成效果。](2024年03月07日/Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation.md)

- [Online Adaptation of Language Models with a Memory of Amortized Contexts](2024年03月07日/Online_Adaptation_of_Language_Models_with_a_Memory_of_Amortized_Contexts.md)

    - [翻译: 通过运用对上下文进行平均化的记忆技术，在线优化语言模型以适应不同场景。](2024年03月07日/Online_Adaptation_of_Language_Models_with_a_Memory_of_Amortized_Contexts.md)

- [Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders](2024年03月07日/Can_Your_Model_Tell_a_Negation_from_an_Implicature_Unravelling_Challenges_With_Intent_Encoders.md)

    - [翻译: 探究模型是否能够有效区分否定表达与蕴含含义，同时揭示在构建意图编码器过程中所遇到的难题。](2024年03月07日/Can_Your_Model_Tell_a_Negation_from_an_Implicature_Unravelling_Challenges_With_Intent_Encoders.md)

- [HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild](2024年03月07日/HaluEval-Wild_Evaluating_Hallucinations_of_Language_Models_in_the_Wild.md)

    - [翻译: HaluEval-Wild 是一项针对真实环境中的语言模型所生成的幻觉内容进行评估的研究项目。](2024年03月07日/HaluEval-Wild_Evaluating_Hallucinations_of_Language_Models_in_the_Wild.md)

- [Effectiveness Assessment of Recent Large Vision-Language Models](2024年03月07日/Effectiveness_Assessment_of_Recent_Large_Vision-Language_Models.md)

    - [翻译: 本研究致力于评估最新大型视觉-语言模型的实际效果，探究其在各类跨模态任务中的表现与价值。](2024年03月07日/Effectiveness_Assessment_of_Recent_Large_Vision-Language_Models.md)

- [Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model with Proxy](2024年03月07日/Proxy-RLHF_Decoupling_Generation_and_Alignment_in_Large_Language_Model_with_Proxy.md)

    - [翻译: Proxy-RLHF 是一种创新方法，它在大型语言模型中巧妙地运用“代理”手段，成功实现了生成能力与对齐目标的解耦合，尤其适用于提升语言模型在保持高质量文本生成的同时，更好地满足预设规范和要求。](2024年03月07日/Proxy-RLHF_Decoupling_Generation_and_Alignment_in_Large_Language_Model_with_Proxy.md)

- [Advancing Biomedical Text Mining with Community Challenges](2024年03月07日/Advancing_Biomedical_Text_Mining_with_Community_Challenges.md)

    - [翻译: 社区挑战驱动生物医学文本挖掘的进步与突破](2024年03月07日/Advancing_Biomedical_Text_Mining_with_Community_Challenges.md)

- [Can Small Language Models be Good Reasoners for Sequential Recommendation?](2024年03月07日/Can_Small_Language_Models_be_Good_Reasoners_for_Sequential_Recommendation.md)

    - [翻译: 小型语言模型能否在序列推荐任务上展现出色的推理能力呢？](2024年03月07日/Can_Small_Language_Models_be_Good_Reasoners_for_Sequential_Recommendation.md)

- [Towards Robustness Analysis of E-Commerce Ranking System](2024年03月07日/Towards_Robustness_Analysis_of_E-Commerce_Ranking_System.md)

    - [翻译: 本研究致力于深入探究电子商务排名系统的鲁棒性，旨在全面分析和提升该系统在复杂环境下的稳定性和可靠性。](2024年03月07日/Towards_Robustness_Analysis_of_E-Commerce_Ranking_System.md)

- [Federated Recommendation via Hybrid Retrieval Augmented Generation](2024年03月07日/Federated_Recommendation_via_Hybrid_Retrieval_Augmented_Generation.md)

    - [翻译: 我们提出了一种混合检索增强生成方法，以实现联邦推荐系统。该方法巧妙结合了检索和生成技术，在保护用户数据隐私的同时，有效提升了推荐系统的性能和准确性。步骤 1：联邦推荐是通过混合检索增强生成技术实现的。步骤 2：在保证用户数据隐私的前提下，一种名为“混合检索增强生成”的创新技术被应用于联邦推荐场景中，旨在融合检索与生成策略，以优化推荐效果并保障数据安全性。](2024年03月07日/Federated_Recommendation_via_Hybrid_Retrieval_Augmented_Generation.md)

- [UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed Entities](2024年03月07日/UltraWiki_Ultra-fine-grained_Entity_Set_Expansion_with_Negative_Seed_Entities.md)

    - [翻译: UltraWiki项目致力于通过引入负向种子实体，实现对实体集进行超精细的扩展探索。](2024年03月07日/UltraWiki_Ultra-fine-grained_Entity_Set_Expansion_with_Negative_Seed_Entities.md)

- [DEEP-ICL: Definition-Enriched Experts for Language Model In-Context Learning](2024年03月07日/DEEP-ICL_Definition-Enriched_Experts_for_Language_Model_In-Context_Learning.md)

    - [翻译: DEEP-ICL：致力于为语言模型的上下文学习注入更多定义性知识的专家系统](2024年03月07日/DEEP-ICL_Definition-Enriched_Experts_for_Language_Model_In-Context_Learning.md)

- [iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries](2024年03月07日/iScore_Visual_Analytics_for_Interpreting_How_Language_Models_Automatically_Score_Summaries.md)

    - [翻译: iScore 是一款可视化分析工具，它帮助我们理解语言模型如何自动评估和打分摘要内容。](2024年03月07日/iScore_Visual_Analytics_for_Interpreting_How_Language_Models_Automatically_Score_Summaries.md)

- [XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution](2024年03月07日/XPSR_Cross-modal_Priors_for_Diffusion-based_Image_Super-Resolution.md)

    - [翻译: XPSR：探索扩散式图像超分辨率技术中的跨模态先验知识，旨在提升图像处理性能和质量。](2024年03月07日/XPSR_Cross-modal_Priors_for_Diffusion-based_Image_Super-Resolution.md)

- [Are Human Conversations Special? A Large Language Model Perspective](2024年03月07日/Are_Human_Conversations_Special_A_Large_Language_Model_Perspective.md)

    - [翻译: 从大型语言模型的角度出发，我们是否能断言人类对话具有某种特殊性呢？](2024年03月07日/Are_Human_Conversations_Special_A_Large_Language_Model_Perspective.md)

- [Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs](2024年03月07日/Is_this_the_real_life_Is_this_just_fantasy_The_Misleading_Success_of_Simulating_Social_Interactions_With_LLMs.md)

    - [翻译: 现实抑或幻象？LLMs在模拟社交互动中取得的成功，其真实性是否存在误导性呢？](2024年03月07日/Is_this_the_real_life_Is_this_just_fantasy_The_Misleading_Success_of_Simulating_Social_Interactions_With_LLMs.md)

- [Can't Remember Details in Long Documents? You Need Some R&R](2024年03月07日/Can't_Remember_Details_in_Long_Documents_You_Need_Some_R&R.md)

    - [翻译: 面对长篇文档，细节总记不住？或许你需要来点“R&R”魔法。 （注：这里的“R&R”在原文中未明确指出含义，可能是“Rest and Relaxation（休息与放松）”或某种解决方法的缩写，在翻译时可根据上下文进行适当推测和解释。）](2024年03月07日/Can't_Remember_Details_in_Long_Documents_You_Need_Some_R&R.md)

- [DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation](2024年03月07日/DiffChat_Learning_to_Chat_with_Text-to-Image_Synthesis_Models_for_Interactive_Image_Creation.md)

    - [翻译: DiffChat 让我们能够通过学习与文本转图像合成模型进行对话，从而实现图像的互动式创作。](2024年03月07日/DiffChat_Learning_to_Chat_with_Text-to-Image_Synthesis_Models_for_Interactive_Image_Creation.md)

- [Embracing Large Language and Multimodal Models for Prosthetic Technologies](2024年03月07日/Embracing_Large_Language_and_Multimodal_Models_for_Prosthetic_Technologies.md)

    - [翻译: 积极采用大型语言及多模态模型赋能假体技术发展](2024年03月07日/Embracing_Large_Language_and_Multimodal_Models_for_Prosthetic_Technologies.md)

- [Tell me the truth: A system to measure the trustworthiness of Large Language Models](2024年03月07日/Tell_me_the_truth_A_system_to_measure_the_trustworthiness_of_Large_Language_Models.md)

    - [翻译: 揭示真相：该系统旨在评测大型语言模型的信任度，以准确衡量其可靠程度。](2024年03月07日/Tell_me_the_truth_A_system_to_measure_the_trustworthiness_of_Large_Language_Models.md)

- [An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment](2024年03月07日/An_In-depth_Evaluation_of_GPT-4_in_Sentence_Simplification_with_Error-based_Human_Assessment.md)

    - [翻译: 通过细致的错误导向人工评估，我们对GPT-4在句子简化任务中的表现进行了深度剖析。](2024年03月07日/An_In-depth_Evaluation_of_GPT-4_in_Sentence_Simplification_with_Error-based_Human_Assessment.md)

- [SecGPT: An Execution Isolation Architecture for LLM-Based Systems](2024年03月07日/SecGPT_An_Execution_Isolation_Architecture_for_LLM-Based_Systems.md)

    - [翻译: SecGPT是一种专为基于大型语言模型（LLM）的系统设计的执行隔离架构，旨在确保其安全性和稳定性。](2024年03月07日/SecGPT_An_Execution_Isolation_Architecture_for_LLM-Based_Systems.md)

- [Automatic and Universal Prompt Injection Attacks against Large Language Models](2024年03月07日/Automatic_and_Universal_Prompt_Injection_Attacks_against_Large_Language_Models.md)

    - [翻译: 自动且普遍性的提示注入攻击，对大型语言模型构成了威胁。这项研究探讨了如何针对大型语言模型实施自动化、普适性的提示注入攻击，揭示其潜在安全风险。](2024年03月07日/Automatic_and_Universal_Prompt_Injection_Attacks_against_Large_Language_Models.md)

- [A Survey on Human-AI Teaming with Large Pre-Trained Models](2024年03月07日/A_Survey_on_Human-AI_Teaming_with_Large_Pre-Trained_Models.md)

    - [翻译: 本篇调研聚焦于大型预训练模型在人机协作中的应用，详尽探讨了这一领域的最新进展与实践。](2024年03月07日/A_Survey_on_Human-AI_Teaming_with_Large_Pre-Trained_Models.md)

- [Self-Adapting Large Visual-Language Models to Edge Devices across Visual Modalities](2024年03月07日/Self-Adapting_Large_Visual-Language_Models_to_Edge_Devices_across_Visual_Modalities.md)

    - [翻译: 该研究致力于将自适应的大型视觉-语言模型推广至不同视觉模态下的边缘设备，实现模型在各类终端上的高效运行。](2024年03月07日/Self-Adapting_Large_Visual-Language_Models_to_Edge_Devices_across_Visual_Modalities.md)

- [ConstitutionalExperts: Training a Mixture of Principle-based Prompts](2024年03月07日/ConstitutionalExperts_Training_a_Mixture_of_Principle-based_Prompts.md)

    - [翻译: 「宪法专家」模型：通过融合原则性提示进行训练，旨在提升模型在处理宪法相关问题时的专业性和准确性。](2024年03月07日/ConstitutionalExperts_Training_a_Mixture_of_Principle-based_Prompts.md)

- [Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question answering](2024年03月07日/Few_shot_chain-of-thought_driven_reasoning_to_prompt_LLMs_for_open_ended_medical_question_answering.md)

    - [翻译: 针对开放式医疗问题解答，我们采用少量示例的链式思考驱动方式来激活LLM的强大推理能力。](2024年03月07日/Few_shot_chain-of-thought_driven_reasoning_to_prompt_LLMs_for_open_ended_medical_question_answering.md)

- [Evaluating Biases in Context-Dependent Health Questions](2024年03月07日/Evaluating_Biases_in_Context-Dependent_Health_Questions.md)

    - [翻译: 本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](2024年03月07日/Evaluating_Biases_in_Context-Dependent_Health_Questions.md)

- [Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks](2024年03月07日/Evaluation_of_LLMs_on_Syntax-Aware_Code_Fill-in-the-Middle_Tasks.md)

    - [翻译: 我们对LLMs在处理具有语法敏感性的代码中间填充任务时的表现进行评估，以深入探究其理解和生成代码结构的能力。](2024年03月07日/Evaluation_of_LLMs_on_Syntax-Aware_Code_Fill-in-the-Middle_Tasks.md)

- [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](2024年03月08日/Gemini_1.5_Unlocking_multimodal_understanding_across_millions_of_tokens_of_context.md)

    - [翻译: Gemini 1.5 开启新篇章，跨过数百万个上下文标记，释放强大的多模态理解潜力](2024年03月08日/Gemini_1.5_Unlocking_multimodal_understanding_across_millions_of_tokens_of_context.md)

- [GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM](2024年03月08日/GEAR_An_Efficient_KV_Cache_Compression_Recipefor_Near-Lossless_Generative_Inference_of_LLM.md)

    - [翻译: GEAR是专为LLM设计的一种有效KV缓存压缩策略，旨在实现近无损的生成推理性能。这款新颖的压缩方案助力LLM在进行生成推理时，既能保持高效性又能实现近乎无损的质量保证。](2024年03月08日/GEAR_An_Efficient_KV_Cache_Compression_Recipefor_Near-Lossless_Generative_Inference_of_LLM.md)

- [Beyond Finite Data: Towards Data-free Out-of-distribution Generalization via Extrapola](2024年03月08日/Beyond_Finite_Data_Towards_Data-free_Out-of-distribution_Generalization_via_Extrapola.md)

    - [翻译: 迈向无限可能：利用外推法突破数据局限，实现对未见过数据分布的泛化能力](2024年03月08日/Beyond_Finite_Data_Towards_Data-free_Out-of-distribution_Generalization_via_Extrapola.md)

- [To Err Is Human, but Llamas Can Learn It Too](2024年03月08日/To_Err_Is_Human,_but_Llamas_Can_Learn_It_Too.md)

    - [翻译: 犯错误是人类的天性，然而羊驼也同样具有学习犯错的能力。](2024年03月08日/To_Err_Is_Human,_but_Llamas_Can_Learn_It_Too.md)

- [Will GPT-4 Run DOOM?](2024年03月08日/Will_GPT-4_Run_DOOM.md)

    - [翻译: GPT-4 是否具备运行经典游戏 DOOM 的能力？](2024年03月08日/Will_GPT-4_Run_DOOM.md)

- [Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs](2024年03月08日/Cost-Performance_Optimization_for_Processing_Low-Resource_Language_Tasks_Using_Commercial_LLMs.md)

    - [翻译: 针对低资源语言任务，本研究探讨如何运用商业大型语言模型进行成本与性能的优化，以期在保证任务完成质量的同时，有效控制处理此类任务的成本。](2024年03月08日/Cost-Performance_Optimization_for_Processing_Low-Resource_Language_Tasks_Using_Commercial_LLMs.md)

- [HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction](2024年03月08日/HistGen_Histopathology_Report_Generation_via_Local-Global_Feature_Encoding_and_Cross-modal_Context_Interaction.md)

    - [翻译: HistGen 是一种创新方法，利用局部-全局特征编码及跨模态上下文互动技术，专为自动生成组织病理学报告而设计。](2024年03月08日/HistGen_Histopathology_Report_Generation_via_Local-Global_Feature_Encoding_and_Cross-modal_Context_Interaction.md)

- [Exploring Robust Features for Few-Shot Object Detection in Satellite Imagery](2024年03月08日/Exploring_Robust_Features_for_Few-Shot_Object_Detection_in_Satellite_Imagery.md)

    - [翻译: 本研究致力于挖掘卫星图像中能够有效应用于少量样本目标检测任务的稳健特征，旨在提升该领域的检测性能和泛化能力。](2024年03月08日/Exploring_Robust_Features_for_Few-Shot_Object_Detection_in_Satellite_Imagery.md)

- [Explaining Pre-Trained Language Models with Attribution Scores: An Analysis in Low-Resource Settings](2024年03月08日/Explaining_Pre-Trained_Language_Models_with_Attribution_Scores_An_Analysis_in_Low-Resource_Settings.md)

    - [翻译: 针对低资源场景，本研究通过归因分数深入剖析预训练语言模型的工作原理。](2024年03月08日/Explaining_Pre-Trained_Language_Models_with_Attribution_Scores_An_Analysis_in_Low-Resource_Settings.md)

- [ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues](2024年03月08日/ChatASU_Evoking_LLM's_Reflexion_to_Truly_Understand_Aspect_Sentiment_in_Dialogues.md)

    - [翻译: ChatASU 研究通过触发 LLM 在对话情境中的深度反思，旨在真实捕捉和理解方面的具体情感倾向。](2024年03月08日/ChatASU_Evoking_LLM's_Reflexion_to_Truly_Understand_Aspect_Sentiment_in_Dialogues.md)

- [RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation](2024年03月08日/RAT_Retrieval_Augmented_Thoughts_Elicit_Context-Aware_Reasoning_in_Long-Horizon_Generation.md)

    - [翻译: RAT技术通过引入检索增强思维，在长时段生成任务中有效激发了情境感知的推理能力。](2024年03月08日/RAT_Retrieval_Augmented_Thoughts_Elicit_Context-Aware_Reasoning_in_Long-Horizon_Generation.md)

- [Tapilot-Crossing: Benchmarking and Evolving LLMs Towards Interactive Data Analysis Agents](2024年03月08日/Tapilot-Crossing_Benchmarking_and_Evolving_LLMs_Towards_Interactive_Data_Analysis_Agents.md)

    - [翻译: Tapilot-Crossing 是一个专注于推动大型语言模型（LLMs）向交互式数据分析代理演进的基准测试项目，旨在评测并提升 LLMS 在此领域的能力。](2024年03月08日/Tapilot-Crossing_Benchmarking_and_Evolving_LLMs_Towards_Interactive_Data_Analysis_Agents.md)

- [ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications](2024年03月08日/ACLSum_A_New_Dataset_for_Aspect-based_Summarization_of_Scientific_Publications.md)

    - [翻译: ACLSum —— 专为科研论文打造的全新方面式摘要数据集](2024年03月08日/ACLSum_A_New_Dataset_for_Aspect-based_Summarization_of_Scientific_Publications.md)

- [LLM4Decompile: Decompiling Binary Code with Large Language Models](2024年03月08日/LLM4Decompile_Decompiling_Binary_Code_with_Large_Language_Models.md)

    - [翻译: LLM4Decompile 是一项利用大型语言模型来实现二进制代码反编译的技术。](2024年03月08日/LLM4Decompile_Decompiling_Binary_Code_with_Large_Language_Models.md)

- [ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models](2024年03月08日/ERBench_An_Entity-Relationship_based_Automatically_Verifiable_Hallucination_Benchmark_for_Large_Language_Models.md)

    - [翻译: ERBench 是专为大型语言模型设计的、基于实体关系的自动化验证幻觉基准测试，旨在精确衡量和评估模型在处理复杂实体关系时出现的幻觉现象。](2024年03月08日/ERBench_An_Entity-Relationship_based_Automatically_Verifiable_Hallucination_Benchmark_for_Large_Language_Models.md)

- [Debiasing Large Visual Language Models](2024年03月08日/Debiasing_Large_Visual_Language_Models.md)

    - [翻译: 本研究致力于探讨如何有效去偏大型视觉语言模型，以提升其准确性和公正性。](2024年03月08日/Debiasing_Large_Visual_Language_Models.md)

- [Cross-lingual Transfer or Machine Translation? On Data Augmentation for Monolingual Semantic Textual Similarity](2024年03月08日/Cross-lingual_Transfer_or_Machine_Translation_On_Data_Augmentation_for_Monolingual_Semantic_Textual_Similarity.md)

    - [翻译: 在探讨单语种语义文本相似度的数据增强方法时，究竟是采用跨语言迁移技术还是机器翻译策略呢？本研究旨在深入探究这一问题。](2024年03月08日/Cross-lingual_Transfer_or_Machine_Translation_On_Data_Augmentation_for_Monolingual_Semantic_Textual_Similarity.md)

- [Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance](2024年03月08日/Tracking_Meets_LoRA_Faster_Training,_Larger_Model,_Stronger_Performance.md)

    - [翻译: 在本次研究中，我们将追踪技术与LoRA相结合，带来更快的训练速度、支持更大规模的模型，并实现了更出色的整体性能。](2024年03月08日/Tracking_Meets_LoRA_Faster_Training,_Larger_Model,_Stronger_Performance.md)

- [Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering](2024年03月08日/Harnessing_Multi-Role_Capabilities_of_Large_Language_Models_for_Open-Domain_Question_Answering.md)

    - [翻译: 为解决开放领域问题回答任务，本研究探讨如何有效地利用大型语言模型所具备的多元角色功能。](2024年03月08日/Harnessing_Multi-Role_Capabilities_of_Large_Language_Models_for_Open-Domain_Question_Answering.md)

- [Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation](2024年03月08日/Overcoming_Reward_Overoptimization_via_Adversarial_Policy_Optimization_with_Lightweight_Uncertainty_Estimation.md)

    - [翻译: 借助轻量级不确定性估计的对抗性策略优化方法，有效解决奖励函数过度优化难题。](2024年03月08日/Overcoming_Reward_Overoptimization_via_Adversarial_Policy_Optimization_with_Lightweight_Uncertainty_Estimation.md)

- [On Protecting the Data Privacy of Large Language Models (LLMs): A Survey](2024年03月08日/On_Protecting_the_Data_Privacy_of_Large_Language_Models_(LLMs)_A_Survey.md)

    - [翻译: 本文对保护LLMs数据隐私的策略进行了一次全面的调查，旨在深入探讨和总结当前针对大型语言模型的数据安全防护措施。](2024年03月08日/On_Protecting_the_Data_Privacy_of_Large_Language_Models_(LLMs)_A_Survey.md)

- [Towards a Psychology of Machines: Large Language Models Predict Human Memory](2024年03月08日/Towards_a_Psychology_of_Machines_Large_Language_Models_Predict_Human_Memory.md)

    - [翻译: 致力于探索机器的心理学层面，大型语言模型已展现出预测人类记忆的能力。](2024年03月08日/Towards_a_Psychology_of_Machines_Large_Language_Models_Predict_Human_Memory.md)

- [Inverse Design of Photonic Crystal Surface Emitting Lasers is a Sequence Modeling Problem](2024年03月08日/Inverse_Design_of_Photonic_Crystal_Surface_Emitting_Lasers_is_a_Sequence_Modeling_Problem.md)

    - [翻译: 设计光子晶体表面发射激光器的逆向工程实质上可视为一个序列模型构建问题。](2024年03月08日/Inverse_Design_of_Photonic_Crystal_Surface_Emitting_Lasers_is_a_Sequence_Modeling_Problem.md)

- [Med3DInsight: Enhancing 3D Medical Image Understanding with 2D Multi-Modal Large Language Models](2024年03月08日/Med3DInsight_Enhancing_3D_Medical_Image_Understanding_with_2D_Multi-Modal_Large_Language_Models.md)

    - [翻译: Med3DInsight项目利用2D多模态大型语言模型的力量，提升三维医学图像的深入理解和分析能力。](2024年03月08日/Med3DInsight_Enhancing_3D_Medical_Image_Understanding_with_2D_Multi-Modal_Large_Language_Models.md)

- [ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment](2024年03月08日/ELLA_Equip_Diffusion_Models_with_LLM_for_Enhanced_Semantic_Alignment.md)

    - [翻译: ELLA项目通过将LLM与扩散模型相结合，旨在提升模型的语义对齐性能。](2024年03月08日/ELLA_Equip_Diffusion_Models_with_LLM_for_Enhanced_Semantic_Alignment.md)

- [ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models](2024年03月08日/ChatUIE_Exploring_Chat-based_Unified_Information_Extraction_using_Large_Language_Models.md)

    - [翻译: ChatUIE 是一项研究，借助大型语言模型的力量，致力于探究和实现基于聊天模式的统一信息抽取技术。](2024年03月08日/ChatUIE_Exploring_Chat-based_Unified_Information_Extraction_using_Large_Language_Models.md)

- [Benchmarking Large Language Models for Molecule Prediction Tasks](2024年03月08日/Benchmarking_Large_Language_Models_for_Molecule_Prediction_Tasks.md)

    - [翻译: 本研究致力于为分子预测任务设定基准，对大型语言模型的表现进行全面评估和对比。](2024年03月08日/Benchmarking_Large_Language_Models_for_Molecule_Prediction_Tasks.md)

- [Can we obtain significant success in RST discourse parsing by using Large Language Models?](2024年03月08日/Can_we_obtain_significant_success_in_RST_discourse_parsing_by_using_Large_Language_Models.md)

    - [翻译: 在 RST 对话解析任务上，大型语言模型能否助力我们实现显著突破？](2024年03月08日/Can_we_obtain_significant_success_in_RST_discourse_parsing_by_using_Large_Language_Models.md)

- [Aligning Large Language Models for Controllable Recommendations](2024年03月08日/Aligning_Large_Language_Models_for_Controllable_Recommendations.md)

    - [翻译: 本研究致力于将大型语言模型与可控推荐相结合，通过调整和优化模型以实现更为精准且可控的推荐效果。](2024年03月08日/Aligning_Large_Language_Models_for_Controllable_Recommendations.md)

- [Multimodal Infusion Tuning for Large Models](2024年03月08日/Multimodal_Infusion_Tuning_for_Large_Models.md)

    - [翻译: 针对大型模型的多模态融合优化技术，旨在通过深度融合不同模态的信息来提升模型性能。](2024年03月08日/Multimodal_Infusion_Tuning_for_Large_Models.md)