# 2024年03月

- [Hierarchical Indexing for Retrieval-Augmented Opinion Summarization](2024年03月01日/Hierarchical_Indexing_for_Retrieval-Augmented_Opinion_Summarization.md)

    - [翻译: 为提升检索增强型观点摘要的效果，我们引入了层次化索引技术。该方法旨在通过构建多层次的索引结构，有效组织和检索相关文本信息，从而优化观点总结的质量与效率。](2024年03月01日/Hierarchical_Indexing_for_Retrieval-Augmented_Opinion_Summarization.md)

- [HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding](2024年03月01日/HALC_Object_Hallucination_Reduction_via_Adaptive_Focal-Contrast_Decoding.md)

    - [翻译: HALC 方法提出了一种新颖的自适应焦点对比解码技术，旨在有效减少对象幻觉现象。该方法针对图像识别中的错误预测问题，通过优化解码过程来提升模型对真实目标的区分能力和鲁棒性。](2024年03月01日/HALC_Object_Hallucination_Reduction_via_Adaptive_Focal-Contrast_Decoding.md)

- [Rethinking Tokenization: Crafting Better Tokenizers for Large Language Models](2024年03月01日/Rethinking_Tokenization_Crafting_Better_Tokenizers_for_Large_Language_Models.md)

    - [翻译: 面对大型语言模型，我们有必要重新审视和改进分词方法，以创造出更能满足其需求的高性能分词器。](2024年03月01日/Rethinking_Tokenization_Crafting_Better_Tokenizers_for_Large_Language_Models.md)

- [Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with Fact-Checking in Turkish](2024年03月01日/Cross-Lingual_Learning_vs._Low-Resource_Fine-Tuning_A_Case_Study_with_Fact-Checking_in_Turkish.md)

    - [翻译: 本研究通过土耳其语的事实查证案例，探讨了跨语言学习与低资源微调两种方法的优劣。](2024年03月01日/Cross-Lingual_Learning_vs._Low-Resource_Fine-Tuning_A_Case_Study_with_Fact-Checking_in_Turkish.md)

- [Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview](2024年03月01日/Post-decoder_Biasing_for_End-to-End_Speech_Recognition_of_Multi-turn_Medical_Interview.md)

    - [翻译: 在多轮医疗访谈端到端语音识别技术中，我们采用了解码器后置偏置策略以优化识别效果。](2024年03月01日/Post-decoder_Biasing_for_End-to-End_Speech_Recognition_of_Multi-turn_Medical_Interview.md)

- [Semi-Instruct: Bridging Natural-Instruct and Self-Instruct for Code Large Language Models](2024年03月01日/Semi-Instruct_Bridging_Natural-Instruct_and_Self-Instruct_for_Code_Large_Language_Models.md)

    - [翻译: Semi-Instruct 方法旨在弥合自然指令与自我指令之间的鸿沟，以提升代码大型语言模型的表现。它通过结合两种教学模式的优势，探索在代码理解和生成任务中更高效地引导大型语言模型的新途径。](2024年03月01日/Semi-Instruct_Bridging_Natural-Instruct_and_Self-Instruct_for_Code_Large_Language_Models.md)

- [Never-Ending Embodied Robot Learning](2024年03月01日/Never-Ending_Embodied_Robot_Learning.md)

    - [翻译: 无尽的实体化机器人学习](2024年03月01日/Never-Ending_Embodied_Robot_Learning.md)

- [Self-Consistent Decoding for More Factual Open Responses](2024年03月01日/Self-Consistent_Decoding_for_More_Factual_Open_Responses.md)

    - [翻译: 为了生成更为事实准确的开放式回答，我们采用“自我一致性解码”方法。](2024年03月01日/Self-Consistent_Decoding_for_More_Factual_Open_Responses.md)

- [Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents](2024年03月01日/Playing_NetHack_with_LLMs_Potential_&_Limitations_as_Zero-Shot_Agents.md)

    - [翻译: 在运用 LLMs 探索 NetHack 游戏中，我们发掘其作为零样本代理的潜力与局限。这项研究聚焦于 LLMS 在未经专门训练情况下，即“零样本”状态下应对复杂游戏环境的能力及其限制。](2024年03月01日/Playing_NetHack_with_LLMs_Potential_&_Limitations_as_Zero-Shot_Agents.md)

- [Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks](2024年03月01日/Diff-Plugin_Revitalizing_Details_for_Diffusion-based_Low-level_Tasks.md)

    - [翻译: Diff-Plugin：激活扩散式底层任务中的精细细节，赋予其新的生命力](2024年03月01日/Diff-Plugin_Revitalizing_Details_for_Diffusion-based_Low-level_Tasks.md)

- [NeuPIMs: A NPU-PIM Heterogeneous Acceleration for Batched Inference of Large Language Model](2024年03月01日/NeuPIMs_A_NPU-PIM_Heterogeneous_Acceleration_for_Batched_Inference_of_Large_Language_Model.md)

    - [翻译: NeuPIMs，为解决大型语言模型批量推理问题而生，是一种融合了NPU与PIM技术的高效异构加速方案。](2024年03月01日/NeuPIMs_A_NPU-PIM_Heterogeneous_Acceleration_for_Batched_Inference_of_Large_Language_Model.md)

- [Standardizing the Measurement of Text Diversity: A Tool and a Comparative Analysis of Scores](2024年03月01日/Standardizing_the_Measurement_of_Text_Diversity_A_Tool_and_a_Comparative_Analysis_of_Scores.md)

    - [翻译: 为了更准确、直观地评估文本多样性，本研究提出了一种标准化测量工具，并对不同方法所得分数进行了深入对比分析。](2024年03月01日/Standardizing_the_Measurement_of_Text_Diversity_A_Tool_and_a_Comparative_Analysis_of_Scores.md)

- [DyPyBench: A Benchmark of Executable Python Software](2024年03月01日/DyPyBench_A_Benchmark_of_Executable_Python_Software.md)

    - [翻译: DyPyBench 是一款专注于可执行 Python 软件性能评估的基准测试工具，用于衡量各类 Python 应用程序的实际运行效果。](2024年03月01日/DyPyBench_A_Benchmark_of_Executable_Python_Software.md)

- [Large Language Models for Simultaneous Named Entity Extraction and Spelling Correction](2024年03月01日/Large_Language_Models_for_Simultaneous_Named_Entity_Extraction_and_Spelling_Correction.md)

    - [翻译: 针对同时执行命名实体提取与拼写修正任务，本研究探讨了大型语言模型的应用潜力。通过利用大型语言模型的力量，我们旨在提升模型在面对实体抽取与拼写错误修正双重挑战时的表现。](2024年03月01日/Large_Language_Models_for_Simultaneous_Named_Entity_Extraction_and_Spelling_Correction.md)

- [VisionLLaMA: A Unified LLaMA Interface for Vision Tasks](2024年03月01日/VisionLLaMA_A_Unified_LLaMA_Interface_for_Vision_Tasks.md)

    - [翻译: VisionLLaMA 是一个为各类视觉任务打造的统一 LLaMA（大规模预训练语言模型）接口，旨在整合并发挥 LLama 在视觉领域的强大功能。](2024年03月01日/VisionLLaMA_A_Unified_LLaMA_Interface_for_Vision_Tasks.md)

- [ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models](2024年03月01日/ROME_Memorization_Insights_from_Text,_Probability_and_Hidden_State_in_Large_Language_Models.md)

    - [翻译: ROME 研究深入探索大型语言模型中，通过分析文本、概率分布以及隐藏状态揭示其内在的记忆机制。](2024年03月01日/ROME_Memorization_Insights_from_Text,_Probability_and_Hidden_State_in_Large_Language_Models.md)

- [TempCompass: Do Video LLMs Really Understand Videos?](2024年03月01日/TempCompass_Do_Video_LLMs_Really_Understand_Videos.md)

    - [翻译: TempCompass——探究视频 LLM 是否真正具备理解视频内容的能力。](2024年03月01日/TempCompass_Do_Video_LLMs_Really_Understand_Videos.md)

- [LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues](2024年03月01日/LUCID_LLM-Generated_Utterances_for_Complex_and_Interesting_Dialogues.md)

    - [翻译: LUCID：针对复杂且引人入胜的对话，利用LLM技术生成高质量话语](2024年03月01日/LUCID_LLM-Generated_Utterances_for_Complex_and_Interesting_Dialogues.md)

- [When Large Language Models Confront Repository-Level Automatic Program Repair: How Well They Done?](2024年03月01日/When_Large_Language_Models_Confront_Repository-Level_Automatic_Program_Repair_How_Well_They_Done.md)

    - [翻译: 面对仓库级自动程序修复任务，大型语言模型的表现究竟如何呢？](2024年03月01日/When_Large_Language_Models_Confront_Repository-Level_Automatic_Program_Repair_How_Well_They_Done.md)

- [Mitigating Reversal Curse via Semantic-aware Permutation Training](2024年03月01日/Mitigating_Reversal_Curse_via_Semantic-aware_Permutation_Training.md)

    - [翻译: 为了解决反转诅咒问题，我们提出了一种基于语义感知排列训练的方法。该方法通过精心设计的训练策略，能够有效抑制模型在处理特定任务时出现的反转诅咒效应，从而提升模型性能和鲁棒性。](2024年03月01日/Mitigating_Reversal_Curse_via_Semantic-aware_Permutation_Training.md)

- [AtP*: An efficient and scalable method for localizing LLM behaviour to components](2024年03月01日/AtP_An_efficient_and_scalable_method_for_localizing_LLM_behaviour_to_components.md)

    - [翻译: AtP*：一项创新技术，高效且易于规模化应用，旨在对大型语言模型（LLM）的行为进行精细化组件定位。](2024年03月01日/AtP_An_efficient_and_scalable_method_for_localizing_LLM_behaviour_to_components.md)

- [LAB: Large-Scale Alignment for ChatBots](2024年03月01日/LAB_Large-Scale_Alignment_for_ChatBots.md)

    - [翻译: LAB项目致力于为聊天机器人开发大规模的对齐技术，旨在提升其对话理解和生成能力。](2024年03月01日/LAB_Large-Scale_Alignment_for_ChatBots.md)

- [LLMCRIT: Teaching Large Language Models to Use Criteria](2024年03月01日/LLMCRIT_Teaching_Large_Language_Models_to_Use_Criteria.md)

    - [翻译: LLMCRIT 计划旨在教授大型语言模型如何运用评判标准。](2024年03月01日/LLMCRIT_Teaching_Large_Language_Models_to_Use_Criteria.md)

- [FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based Sentiment Analysis](2024年03月01日/FaiMA_Feature-aware_In-context_Learning_for_Multi-domain_Aspect-based_Sentiment_Analysis.md)

    - [翻译: FaiMA 是一项创新技术，专注于在多领域情境下进行特征感知的上下文学习，以提升基于方面的观点分析效果。](2024年03月01日/FaiMA_Feature-aware_In-context_Learning_for_Multi-domain_Aspect-based_Sentiment_Analysis.md)

- [Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers](2024年03月01日/Reading_Subtext_Evaluating_Large_Language_Models_on_Short_Story_Summarization_with_Writers.md)

    - [翻译: 在“解读言外之意”的研究中，我们通过让大型语言模型处理由作家编写的短篇小说摘要，来评估其在该任务上的表现能力。](2024年03月01日/Reading_Subtext_Evaluating_Large_Language_Models_on_Short_Story_Summarization_with_Writers.md)

- [Towards Full Authorship with AI: Supporting Revision with AI-Generated Views](2024年03月01日/Towards_Full_Authorship_with_AI_Supporting_Revision_with_AI-Generated_Views.md)

    - [翻译: 向着以AI驱动的完全创作迈进，我们探讨如何借助AI生成的视角来有效支持文章修订过程。](2024年03月01日/Towards_Full_Authorship_with_AI_Supporting_Revision_with_AI-Generated_Views.md)

- [AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks](2024年03月01日/AutoAttacker_A_Large_Language_Model_Guided_System_to_Implement_Automatic_Cyber-attacks.md)

    - [翻译: AutoAttacker 是一套在大型语言模型指导下运作的智能系统，致力于执行自动化网络攻击任务。](2024年03月01日/AutoAttacker_A_Large_Language_Model_Guided_System_to_Implement_Automatic_Cyber-attacks.md)

- [Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks](2024年03月01日/Peacock_A_Family_of_Arabic_Multimodal_Large_Language_Models_and_Benchmarks.md)

    - [翻译: 孔雀系列：展现了一族专为阿拉伯语设计的多模态大型语言模型及其对应的基准测试标准](2024年03月01日/Peacock_A_Family_of_Arabic_Multimodal_Large_Language_Models_and_Benchmarks.md)

- [BasedAI: A decentralized P2P network for Zero Knowledge Large Language Models (ZK-LLMs)](2024年03月01日/BasedAI_A_decentralized_P2P_network_for_Zero_Knowledge_Large_Language_Models_(ZK-LLMs).md)

    - [翻译: BasedAI 是一个专为零知识大型语言模型打造的去中心化P2P网络，旨在为ZK-LLMs提供高效、安全的分布式运行环境。](2024年03月01日/BasedAI_A_decentralized_P2P_network_for_Zero_Knowledge_Large_Language_Models_(ZK-LLMs).md)

- [Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries](2024年03月01日/Attribute_Structuring_Improves_LLM-Based_Evaluation_of_Clinical_Text_Summaries.md)

    - [翻译: 通过属性结构化优化，我们能够提升LLM在评估临床文本摘要时的表现。](2024年03月01日/Attribute_Structuring_Improves_LLM-Based_Evaluation_of_Clinical_Text_Summaries.md)

- [Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language](2024年03月01日/Leveraging_Prompt-Based_Large_Language_Models_Predicting_Pandemic_Health_Decisions_and_Outcomes_Through_Social_Media_Language.md)

    - [翻译: 利用 prompt 优化的大型语言模型，我们可以从社交媒体的语言中洞悉并预测疫情期间人们的健康决策与相应结果。](2024年03月01日/Leveraging_Prompt-Based_Large_Language_Models_Predicting_Pandemic_Health_Decisions_and_Outcomes_Through_Social_Media_Language.md)

- [LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems](2024年03月01日/LocalRQA_From_Generating_Data_to_Locally_Training,_Testing,_and_Deploying_Retrieval-Augmented_QA_Systems.md)

    - [翻译: LocalRQA：一站式方案，从构建数据集到本地完成增强检索型问答系统的训练、测试与部署。](2024年03月01日/LocalRQA_From_Generating_Data_to_Locally_Training,_Testing,_and_Deploying_Retrieval-Augmented_QA_Systems.md)

- [MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection](2024年03月01日/MALTO_at_SemEval-2024_Task_6_Leveraging_Synthetic_Data_for_LLM_Hallucination_Detection.md)

    - [翻译: SemEval-2024第六项任务中，MALTO团队采用创新策略，借助合成数据增强大型语言模型对幻觉内容的识别能力。](2024年03月01日/MALTO_at_SemEval-2024_Task_6_Leveraging_Synthetic_Data_for_LLM_Hallucination_Detection.md)

- [AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models](2024年03月01日/AutoRD_An_Automatic_and_End-to-End_System_for_Rare_Disease_Knowledge_Graph_Construction_Based_on_Ontologies-enhanced_Large_Language_Models.md)

    - [翻译: AutoRD 是一款创新的全自动端到端系统，它利用了本体增强的大型语言模型技术，专注于高效构建罕见病知识图谱。](2024年03月01日/AutoRD_An_Automatic_and_End-to-End_System_for_Rare_Disease_Knowledge_Graph_Construction_Based_on_Ontologies-enhanced_Large_Language_Models.md)

- [MediSwift: Efficient Sparse Pre-trained Biomedical Language Models](2024年03月01日/MediSwift_Efficient_Sparse_Pre-trained_Biomedical_Language_Models.md)

    - [翻译: MediSwift 是一种高效、预先训练的稀疏型生物医学语言模型，专为提升处理领域内大规模数据的效率而设计。](2024年03月01日/MediSwift_Efficient_Sparse_Pre-trained_Biomedical_Language_Models.md)

- [Differentially Private Knowledge Distillation via Synthetic Text Generation](2024年03月01日/Differentially_Private_Knowledge_Distillation_via_Synthetic_Text_Generation.md)

    - [翻译: 我们提出了一种新颖的方法，利用合成文本生成技术来实现差异隐私保护下的知识蒸馏，这种方法能够在保护数据隐私的同时提取和传递模型知识。](2024年03月01日/Differentially_Private_Knowledge_Distillation_via_Synthetic_Text_Generation.md)

- [DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models](2024年03月01日/DiaHalu_A_Dialogue-level_Hallucination_Evaluation_Benchmark_for_Large_Language_Models.md)

    - [翻译: DiaHalu：一款针对大型语言模型设计的对话级 hallucination 评估基准工具，旨在精准衡量其在对话生成中的幻觉现象表现。](2024年03月01日/DiaHalu_A_Dialogue-level_Hallucination_Evaluation_Benchmark_for_Large_Language_Models.md)

- [A systematic evaluation of large language models for generating programming code](2024年03月01日/A_systematic_evaluation_of_large_language_models_for_generating_programming_code.md)

    - [翻译: 本研究对大型语言模型在生成编程代码任务上的表现进行了全面而系统的评估。](2024年03月01日/A_systematic_evaluation_of_large_language_models_for_generating_programming_code.md)

- [Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment](2024年03月01日/Text_classification_of_column_headers_with_a_controlled_vocabulary_leveraging_LLMs_for_metadata_enrichment.md)

    - [翻译: 借助LLMs，本研究探讨如何运用受控词汇对列标题进行文本分类，以实现元数据的有效丰富。](2024年03月01日/Text_classification_of_column_headers_with_a_controlled_vocabulary_leveraging_LLMs_for_metadata_enrichment.md)

- [Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models](2024年03月01日/Crimson_Empowering_Strategic_Reasoning_in_Cybersecurity_through_Large_Language_Models.md)

    - [翻译: Crimson项目致力于运用大型语言模型来增强网络安全领域中的战略推理，以期在应对网络威胁时提供更为精准且深思熟虑的解决方案。](2024年03月01日/Crimson_Empowering_Strategic_Reasoning_in_Cybersecurity_through_Large_Language_Models.md)

- [DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases](2024年03月01日/DFIN-SQL_Integrating_Focused_Schema_with_DIN-SQL_for_Superior_Accuracy_in_Large-Scale_Databases.md)

    - [翻译: DFIN-SQL 是一项创新技术，它将聚焦模式与 DIN-SQL 整合，旨在提升在处理大型数据库时的查询精确度。](2024年03月01日/DFIN-SQL_Integrating_Focused_Schema_with_DIN-SQL_for_Superior_Accuracy_in_Large-Scale_Databases.md)

- [Teach LLMs to Phish: Stealing Private Information from Language Models](2024年03月01日/Teach_LLMs_to_Phish_Stealing_Private_Information_from_Language_Models.md)

    - [翻译: 让 LLM 学会“垂钓”隐私：探究如何从语言模型中获取敏感信息](2024年03月01日/Teach_LLMs_to_Phish_Stealing_Private_Information_from_Language_Models.md)

- [Open Assistant Toolkit -- version 2](2024年03月01日/Open_Assistant_Toolkit_--_version_2.md)

    - [翻译: Open Assistant Toolkit 第二版](2024年03月01日/Open_Assistant_Toolkit_--_version_2.md)

- [Accelerating Greedy Coordinate Gradient via Probe Sampling](2024年03月02日/Accelerating_Greedy_Coordinate_Gradient_via_Probe_Sampling.md)

    - [翻译: 我们提出了一种利用探针采样技术来提升贪婪坐标梯度法的效率，即“加速贪婪坐标梯度探针采样方法”，尤其在处理大规模优化问题时，有效提高了算法的运行速度与性能。](2024年03月02日/Accelerating_Greedy_Coordinate_Gradient_via_Probe_Sampling.md)

- [SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code](2024年03月02日/SceneCraft_An_LLM_Agent_for_Synthesizing_3D_Scene_as_Blender_Code.md)

    - [翻译: SceneCraft——专为生成Blender代码而设计的3D场景构建LLM智能体](2024年03月02日/SceneCraft_An_LLM_Agent_for_Synthesizing_3D_Scene_as_Blender_Code.md)

- [Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal](2024年03月02日/Mitigating_Catastrophic_Forgetting_in_Large_Language_Models_with_Self-Synthesized_Rehearsal.md)

    - [翻译: 在大型语言模型中，采用自合成复习方法有效减轻灾难性遗忘问题。](2024年03月02日/Mitigating_Catastrophic_Forgetting_in_Large_Language_Models_with_Self-Synthesized_Rehearsal.md)

- [IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact](2024年03月02日/IntactKV_Improving_Large_Language_Model_Quantization_by_Keeping_Pivot_Tokens_Intact.md)

    - [翻译: IntactKV 方法旨在提升大型语言模型量化性能，其核心在于保留枢轴令牌的完整性。](2024年03月02日/IntactKV_Improving_Large_Language_Model_Quantization_by_Keeping_Pivot_Tokens_Intact.md)

- [Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy](2024年03月02日/Inexact_Unlearning_Needs_More_Careful_Evaluations_to_Avoid_a_False_Sense_of_Privacy.md)

    - [翻译: 针对 Inexact Unlearning，为了防止对隐私安全产生误解，我们必须对其进行更为细致的评估。](2024年03月02日/Inexact_Unlearning_Needs_More_Careful_Evaluations_to_Avoid_a_False_Sense_of_Privacy.md)

- [API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access](2024年03月02日/API_Is_Enough_Conformal_Prediction_for_Large_Language_Models_Without_Logit-Access.md)

    - [翻译: 仅使用 API 即可实现：无需访问 logits，也能为大型语言模型应用相符预测技术。](2024年03月02日/API_Is_Enough_Conformal_Prediction_for_Large_Language_Models_Without_Logit-Access.md)

- [Data-free Multi-label Image Recognition via LLM-powered Prompt Tuning](2024年03月02日/Data-free_Multi-label_Image_Recognition_via_LLM-powered_Prompt_Tuning.md)

    - [翻译: 借助 LLM 强大的提示调优技术，我们能够实现无需原始数据的多标签图像识别。这项研究探讨了如何在没有数据的情况下，利用 LLM 的能力进行多标签图像识别任务的优化和提升。](2024年03月02日/Data-free_Multi-label_Image_Recognition_via_LLM-powered_Prompt_Tuning.md)

- [The Case for Animal-Friendly AI](2024年03月02日/The_Case_for_Animal-Friendly_AI.md)

    - [翻译: 倡导动物友好型 AI：为何我们需要关注并研发对动物友好的人工智能技术？](2024年03月02日/The_Case_for_Animal-Friendly_AI.md)

- [DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling](2024年03月02日/DMoERM_Recipes_of_Mixture-of-Experts_for_Effective_Reward_Modeling.md)

    - [翻译: DMoERM：揭秘混合专家模型在高效奖励建模中的秘籍](2024年03月02日/DMoERM_Recipes_of_Mixture-of-Experts_for_Effective_Reward_Modeling.md)

- [RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots](2024年03月02日/RAGged_Edges_The_Double-Edged_Sword_of_Retrieval-Augmented_Chatbots.md)

    - [翻译: 标题：“RAGged Edges”揭示了检索增强型聊天机器人这一把双刃剑的复杂性。该研究探讨了在提升聊天机器人性能的同时，检索增强技术所带来的挑战与局限性。](2024年03月02日/RAGged_Edges_The_Double-Edged_Sword_of_Retrieval-Augmented_Chatbots.md)

- [STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models](2024年03月02日/STAR_Constraint_LoRA_with_Dynamic_Active_Learning_for_Data-Efficient_Fine-Tuning_of_Large_Language_Models.md)

    - [翻译: STAR 方法将动态主动学习与约束版的 LoRA 结合，旨在提升大型语言模型在数据有限条件下的微调效率。](2024年03月02日/STAR_Constraint_LoRA_with_Dynamic_Active_Learning_for_Data-Efficient_Fine-Tuning_of_Large_Language_Models.md)

- [HeteGen: Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices](2024年03月02日/HeteGen_Heterogeneous_Parallel_Inference_for_Large_Language_Models_on_Resource-Constrained_Devices.md)

    - [翻译: HeteGen 是专为资源有限的设备设计的，能够实现大型语言模型的异构并行推理技术。这项技术针对大模型在资源受限环境下的高效运行，提供了一种创新的并行处理方案。](2024年03月02日/HeteGen_Heterogeneous_Parallel_Inference_for_Large_Language_Models_on_Resource-Constrained_Devices.md)

- [A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization](2024年03月02日/A_Survey_of_AI-generated_Text_Forensic_Systems_Detection,_Attribution,_and_Characterization.md)

    - [翻译: 本篇综述聚焦于人工智能生成文本的取证系统，涵盖了检测、归属及其特性分析三大核心领域。](2024年03月02日/A_Survey_of_AI-generated_Text_Forensic_Systems_Detection,_Attribution,_and_Characterization.md)

- [ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies](2024年03月02日/ParallelPARC_A_Scalable_Pipeline_for_Generating_Natural-Language_Analogies.md)

    - [翻译: ParallelPARC，一款专为高效生成自然语言类比而设计的可扩展式处理流程](2024年03月02日/ParallelPARC_A_Scalable_Pipeline_for_Generating_Natural-Language_Analogies.md)

- [LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization](2024年03月02日/LLM-PQ_Serving_LLM_on_Heterogeneous_Clusters_with_Phase-Aware_Partition_and_Adaptive_Quantization.md)

    - [翻译: LLM-PQ方案，针对异构集群环境，采用阶段感知分区与自适应量化技术，有效服务于大型语言模型，提升其在各类集群上的运行效率。](2024年03月02日/LLM-PQ_Serving_LLM_on_Heterogeneous_Clusters_with_Phase-Aware_Partition_and_Adaptive_Quantization.md)

- [Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data](2024年03月02日/Evaluating_Large_Language_Models_as_Virtual_Annotators_for_Time-series_Physical_Sensing_Data.md)

    - [翻译: 本研究探讨将大型语言模型应用于时间序列物理传感数据的虚拟标注任务，以评估其作为有效标注工具的能力。](2024年03月02日/Evaluating_Large_Language_Models_as_Virtual_Annotators_for_Time-series_Physical_Sensing_Data.md)

- [LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation](2024年03月02日/LLaMoCo_Instruction_Tuning_of_Large_Language_Models_for_Optimization_Code_Generation.md)

    - [翻译: LLaMoCo 是一项研究，专注于通过指令微调大规模语言模型，以提升其生成优化代码的能力。](2024年03月02日/LLaMoCo_Instruction_Tuning_of_Large_Language_Models_for_Optimization_Code_Generation.md)

- [Text-guided Explorable Image Super-resolution](2024年03月02日/Text-guided_Explorable_Image_Super-resolution.md)

    - [翻译: Text-guided Explorable Image Super-resolution，即借助文本引导实现可交互式探索的图像超分辨率技术。](2024年03月02日/Text-guided_Explorable_Image_Super-resolution.md)

- [Distilling Text Style Transfer With Self-Explanation From LLMs](2024年03月02日/Distilling_Text_Style_Transfer_With_Self-Explanation_From_LLMs.md)

    - [翻译: 本研究致力于从大型语言模型（LLM）中提炼出带有自我解释功能的文本风格转换技术，旨在探索如何有效利用LLM进行文本风格迁移，并通过自我解释机制提升其可解释性和应用效果。](2024年03月02日/Distilling_Text_Style_Transfer_With_Self-Explanation_From_LLMs.md)

- [CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring Commonsense Reasoning and Long-Tail Knowledge](2024年03月02日/CR-LT-KGQA_A_Knowledge_Graph_Question_Answering_Dataset_Requiring_Commonsense_Reasoning_and_Long-Tail_Knowledge.md)

    - [翻译: CR-LT-KGQA 是一个专注于常识推理与长尾知识需求的知识图谱问答数据集，旨在提升模型在解决复杂问题时兼顾广泛而稀疏知识的能力。](2024年03月02日/CR-LT-KGQA_A_Knowledge_Graph_Question_Answering_Dataset_Requiring_Commonsense_Reasoning_and_Long-Tail_Knowledge.md)

- [Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering](2024年03月02日/Right_for_Right_Reasons_Large_Language_Models_for_Verifiable_Commonsense_Knowledge_Graph_Question_Answering.md)

    - [翻译: 追求“因为对所以对”——大型语言模型助力可靠解答常识知识图谱问题](2024年03月02日/Right_for_Right_Reasons_Large_Language_Models_for_Verifiable_Commonsense_Knowledge_Graph_Question_Answering.md)

- [On the Compressibility of Quantized Large Language Models](2024年03月02日/On_the_Compressibility_of_Quantized_Large_Language_Models.md)

    - [翻译: 本研究探讨了量化后的大型语言模型（LLM）的压缩潜力，深入分析其在降低存储需求和计算开销方面的可能性。](2024年03月02日/On_the_Compressibility_of_Quantized_Large_Language_Models.md)

- [Automatic Question-Answer Generation for Long-Tail Knowledge](2024年03月02日/Automatic_Question-Answer_Generation_for_Long-Tail_Knowledge.md)

    - [翻译: 为解决长尾知识难题，本研究致力于探索自动问题与答案生成技术，旨在高效精准地生成针对海量且分布稀疏的长尾知识的问题与答案对。](2024年03月02日/Automatic_Question-Answer_Generation_for_Long-Tail_Knowledge.md)

- [Evaluating and Mitigating Number Hallucinations in Large Vision-Language Models: A Consistency Perspective](2024年03月02日/Evaluating_and_Mitigating_Number_Hallucinations_in_Large_Vision-Language_Models_A_Consistency_Perspective.md)

    - [翻译: 本研究从一致性视角出发，探讨并解决大型视觉-语言模型在处理过程中出现的数字幻觉现象。](2024年03月02日/Evaluating_and_Mitigating_Number_Hallucinations_in_Large_Vision-Language_Models_A_Consistency_Perspective.md)

- [LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems](2024年03月02日/LM4OPT_Unveiling_the_Potential_of_Large_Language_Models_in_Formulating_Mathematical_Optimization_Problems.md)

    - [翻译: LM4OPT项目揭示了大型语言模型在解决数学优化问题时所蕴含的巨大潜能，探索其如何有效用于构建这类问题的解决方案。](2024年03月02日/LM4OPT_Unveiling_the_Potential_of_Large_Language_Models_in_Formulating_Mathematical_Optimization_Problems.md)

- [Chaining thoughts and LLMs to learn DNA structural biophysics](2024年03月02日/Chaining_thoughts_and_LLMs_to_learn_DNA_structural_biophysics.md)

    - [翻译: 通过联动思维与大型语言模型（LLM），我们致力于探索和学习DNA结构生物物理学的奥秘。](2024年03月02日/Chaining_thoughts_and_LLMs_to_learn_DNA_structural_biophysics.md)

- [VBART: The Turkish LLM](2024年03月02日/VBART_The_Turkish_LLM.md)

    - [翻译: VBART——探究土耳其的大型语言模型](2024年03月02日/VBART_The_Turkish_LLM.md)

- [Improving the Validity of Automatically Generated Feedback via Reinforcement Learning](2024年03月02日/Improving_the_Validity_of_Automatically_Generated_Feedback_via_Reinforcement_Learning.md)

    - [翻译: 本研究运用强化学习技术，致力于提升自动化生成反馈的可靠性和准确性。](2024年03月02日/Improving_the_Validity_of_Automatically_Generated_Feedback_via_Reinforcement_Learning.md)

- [NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention](2024年03月02日/NoMAD-Attention_Efficient_LLM_Inference_on_CPUs_Through_Multiply-add-free_Attention.md)

    - [翻译: NoMAD-Attention技术致力于提升CPU环境下LLM推理效率，它采用无需乘加操作的注意力机制，实现大型语言模型在CPU上的高效推理。](2024年03月02日/NoMAD-Attention_Efficient_LLM_Inference_on_CPUs_Through_Multiply-add-free_Attention.md)

- [Employing LLMs for Incident Response Planning and Review](2024年03月02日/Employing_LLMs_for_Incident_Response_Planning_and_Review.md)

    - [翻译: 在事件响应规划与复盘中运用 LLMs 技术，以提升效率和精准度。](2024年03月02日/Employing_LLMs_for_Incident_Response_Planning_and_Review.md)

- [Dissecting Language Models: Machine Unlearning via Selective Pruning](2024年03月02日/Dissecting_Language_Models_Machine_Unlearning_via_Selective_Pruning.md)

    - [翻译: 本文探讨通过选择性剪枝技术深入剖析并“卸载”语言模型中的特定知识，实现机器的“忘却”过程。](2024年03月02日/Dissecting_Language_Models_Machine_Unlearning_via_Selective_Pruning.md)

- [AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks](2024年03月02日/AutoDefense_Multi-Agent_LLM_Defense_against_Jailbreak_Attacks.md)

    - [翻译: AutoDefense：一款针对越狱攻击设计的多智能体防御方案，专门用于保护大型语言模型（LLM）的安全。](2024年03月02日/AutoDefense_Multi-Agent_LLM_Defense_against_Jailbreak_Attacks.md)

- [A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition](2024年03月02日/A_Cross-Modal_Approach_to_Silent_Speech_with_LLM-Enhanced_Recognition.md)

    - [翻译: 我们提出了一种创新的跨模态方法，借助 LLM 强化技术来提升无声语音的识别能力。](2024年03月02日/A_Cross-Modal_Approach_to_Silent_Speech_with_LLM-Enhanced_Recognition.md)

- [Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction Using EHR Data](2024年03月02日/Large_Language_Multimodal_Models_for_5-Year_Chronic_Disease_Cohort_Prediction_Using_EHR_Data.md)

    - [翻译: 本研究采用大规模多模态语言模型，利用电子健康记录数据来预测五年内慢性疾病队列的发展趋势。](2024年03月02日/Large_Language_Multimodal_Models_for_5-Year_Chronic_Disease_Cohort_Prediction_Using_EHR_Data.md)

- [SyllabusQA: A Course Logistics Question Answering Dataset](2024年03月02日/SyllabusQA_A_Course_Logistics_Question_Answering_Dataset.md)

    - [翻译: SyllabusQA——一个专注于课程运行事务问答的数据集](2024年03月02日/SyllabusQA_A_Course_Logistics_Question_Answering_Dataset.md)

- [GuardT2I: Defending Text-to-Image Models from Adversarial Prompts](2024年03月03日/GuardT2I_Defending_Text-to-Image_Models_from_Adversarial_Prompts.md)

    - [翻译: GuardT2I：针对对抗性文本提示对文本到图像模型的防御机制](2024年03月03日/GuardT2I_Defending_Text-to-Image_Models_from_Adversarial_Prompts.md)

- [GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features](2024年03月03日/GPTSee_Enhancing_Moment_Retrieval_and_Highlight_Detection_via_Description-Based_Similarity_Features.md)

    - [翻译: GPTSee 利用描述性相似性特征提升关键时刻检索与精彩片段检测能力](2024年03月03日/GPTSee_Enhancing_Moment_Retrieval_and_Highlight_Detection_via_Description-Based_Similarity_Features.md)

- [Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge](2024年03月03日/Fine_Tuning_vs._Retrieval_Augmented_Generation_for_Less_Popular_Knowledge.md)

    - [翻译: 面对较少为人所知的知识领域，我们探究微调和检索增强生成两种方法的优劣。](2024年03月03日/Fine_Tuning_vs._Retrieval_Augmented_Generation_for_Less_Popular_Knowledge.md)

- [Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval](2024年03月03日/Image2Sentence_based_Asymmetrical_Zero-shot_Composed_Image_Retrieval.md)

    - [翻译: Image2Sentence 技术驱动的非对称零样本图像组合检索方法，旨在实现仅通过文本描述即可检索未见过的组合图像。](2024年03月03日/Image2Sentence_based_Asymmetrical_Zero-shot_Composed_Image_Retrieval.md)

- [The Implicit Bias of Heterogeneity towards Invariance and Causality](2024年03月03日/The_Implicit_Bias_of_Heterogeneity_towards_Invariance_and_Causality.md)

    - [翻译: 异质性中蕴含着对不变性和因果性的内在倾向，本文探讨这一隐含偏置的实质及其影响。](2024年03月03日/The_Implicit_Bias_of_Heterogeneity_towards_Invariance_and_Causality.md)

- [OVEL: Large Language Model as Memory Manager for Online Video Entity Linking](2024年03月03日/OVEL_Large_Language_Model_as_Memory_Manager_for_Online_Video_Entity_Linking.md)

    - [翻译: OVEL 利用大型语言模型充当在线视频实体链接的记忆管家，提升链接效能。](2024年03月03日/OVEL_Large_Language_Model_as_Memory_Manager_for_Online_Video_Entity_Linking.md)

- [In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation](2024年03月03日/In-Context_Sharpness_as_Alerts_An_Inner_Representation_Perspective_for_Hallucination_Mitigation.md)

    - [翻译: 将“情境尖锐度”视为预警信号，我们从内在表征的视角探讨其在缓解大型语言模型生成幻觉问题上的作用。](2024年03月03日/In-Context_Sharpness_as_Alerts_An_Inner_Representation_Perspective_for_Hallucination_Mitigation.md)

- [Revisiting Dynamic Evaluation: Online Adaptation for Large Language Models](2024年03月03日/Revisiting_Dynamic_Evaluation_Online_Adaptation_for_Large_Language_Models.md)

    - [翻译: 我们重新审视“动态评估”这一概念，探讨其在大型语言模型中的应用——即在线适应策略，以实现模型性能的即时优化与更新。](2024年03月03日/Revisiting_Dynamic_Evaluation_Online_Adaptation_for_Large_Language_Models.md)

- [Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics](2024年03月03日/Fantastic_Semantics_and_Where_to_Find_Them_Investigating_Which_Layers_of_Generative_LLMs_Reflect_Lexical_Semantics.md)

    - [翻译: 《寻找奇幻的语义世界：研究生成型LLM中各层对词汇语义的体现》](2024年03月03日/Fantastic_Semantics_and_Where_to_Find_Them_Investigating_Which_Layers_of_Generative_LLMs_Reflect_Lexical_Semantics.md)

- [InfiMM-HD: A Leap Forward in High-Resolution Multimodal Understanding](2024年03月03日/InfiMM-HD_A_Leap_Forward_in_High-Resolution_Multimodal_Understanding.md)

    - [翻译: InfiMM-HD——在高清多模态理解领域实现了一次显著的跃进](2024年03月03日/InfiMM-HD_A_Leap_Forward_in_High-Resolution_Multimodal_Understanding.md)

- [Infusing Knowledge into Large Language Models with Contextual Prompts](2024年03月03日/Infusing_Knowledge_into_Large_Language_Models_with_Contextual_Prompts.md)

    - [翻译: 本研究探讨如何巧妙利用上下文提示，将知识有效地融入大型语言模型中。](2024年03月03日/Infusing_Knowledge_into_Large_Language_Models_with_Contextual_Prompts.md)

- [Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation](2024年03月03日/Align-to-Distill_Trainable_Attention_Alignment_for_Knowledge_Distillation_in_Neural_Machine_Translation.md)

    - [翻译: 在神经机器翻译中，我们提出了一种名为“Align-to-Distill”的方法，它通过可训练的注意力对齐机制实现知识的有效蒸馏。这一创新技术旨在提升模型在知识转移过程中的性能和效率，特别是在神经机器翻译任务上。](2024年03月03日/Align-to-Distill_Trainable_Attention_Alignment_for_Knowledge_Distillation_in_Neural_Machine_Translation.md)

- [KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean Healthcare Professional Licensing Examinations](2024年03月03日/KorMedMCQA_Multi-Choice_Question_Answering_Benchmark_for_Korean_Healthcare_Professional_Licensing_Examinations.md)

    - [翻译: KorMedMCQA 是专为韩国医疗专业执照考试打造的多选题答题基准测试，旨在衡量和评估考生在该领域内的专业知识水平。](2024年03月03日/KorMedMCQA_Multi-Choice_Question_Answering_Benchmark_for_Korean_Healthcare_Professional_Licensing_Examinations.md)

- [Logic Rules as Explanations for Legal Case Retrieval](2024年03月03日/Logic_Rules_as_Explanations_for_Legal_Case_Retrieval.md)

    - [翻译: 在法律案例检索领域，逻辑规则被用作一种解释手段。进一步优化，逻辑规则在挖掘和理解相关判例中扮演着解释性工具的角色，助力提升案例检索效率与准确性。](2024年03月03日/Logic_Rules_as_Explanations_for_Legal_Case_Retrieval.md)

- [Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study](2024年03月03日/Can_LLMs_Generate_Architectural_Design_Decisions_-An_Exploratory_Empirical_study.md)

    - [翻译: 探究 LLMS 是否具备生成建筑设计决策的能力：一项实证研究之旅](2024年03月03日/Can_LLMs_Generate_Architectural_Design_Decisions_-An_Exploratory_Empirical_study.md)

- [Improving LLM Code Generation with Grammar Augmentation](2024年03月03日/Improving_LLM_Code_Generation_with_Grammar_Augmentation.md)

    - [翻译: LLMM代码生成能力的提升，我们借助了语法增强技术。本研究致力于探究如何通过针对性地增加和调整语法结构，优化大型语言模型在代码生成任务上的表现。](2024年03月03日/Improving_LLM_Code_Generation_with_Grammar_Augmentation.md)

- [Relational to RDF Data Migration by Query Co-Evaluation](2024年03月03日/Relational_to_RDF_Data_Migration_by_Query_Co-Evaluation.md)

    - [翻译: 借助查询协同求值技术，实现从关系型数据向 RDF 数据的迁移步骤 1 直译：关系型数据到 RDF 数据迁移通过查询协同求值实现步骤 2 简洁优雅翻译：本研究探讨了一种基于查询协同求值的方法，用于实现关系型数据库与 RDF 数据间的高效迁移。](2024年03月03日/Relational_to_RDF_Data_Migration_by_Query_Co-Evaluation.md)

- [Using LLMs for Tabletop Exercises within the Security Domain](2024年03月03日/Using_LLMs_for_Tabletop_Exercises_within_the_Security_Domain.md)

    - [翻译: 针对安全领域，本研究探讨运用LLMs进行桌面模拟训练的可能性与效果。](2024年03月03日/Using_LLMs_for_Tabletop_Exercises_within_the_Security_Domain.md)

- [Towards Comprehensive Vietnamese Retrieval-Augmented Generation and Large Language Models](2024年03月03日/Towards_Comprehensive_Vietnamese_Retrieval-Augmented_Generation_and_Large_Language_Models.md)

    - [翻译: 致力于打造全方位的越南语检索增强生成方案，并探索大型语言模型在此领域的应用潜力。](2024年03月03日/Towards_Comprehensive_Vietnamese_Retrieval-Augmented_Generation_and_Large_Language_Models.md)

- [SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos](2024年03月03日/SCHEMA_State_CHangEs_MAtter_for_Procedure_Planning_in_Instructional_Videos.md)

    - [翻译: SCHEMA 研究表明，在解析教学视频中的程序规划时，状态变化起到关键作用。](2024年03月03日/SCHEMA_State_CHangEs_MAtter_for_Procedure_Planning_in_Instructional_Videos.md)

- [IoT Device Labeling Using Large Language Models](2024年03月03日/IoT_Device_Labeling_Using_Large_Language_Models.md)

    - [翻译: 借助大型语言模型实现物联网设备智能标注](2024年03月03日/IoT_Device_Labeling_Using_Large_Language_Models.md)

- [SARD: A Human-AI Collaborative Story Generation](2024年03月03日/SARD_A_Human-AI_Collaborative_Story_Generation.md)

    - [翻译: SARD：携手人类与AI共创故事新篇章](2024年03月03日/SARD_A_Human-AI_Collaborative_Story_Generation.md)

- [SERVAL: Synergy Learning between Vertical Models and LLMs towards Oracle-Level Zero-shot Medical Prediction](2024年03月03日/SERVAL_Synergy_Learning_between_Vertical_Models_and_LLMs_towards_Oracle-Level_Zero-shot_Medical_Prediction.md)

    - [翻译: SERVAL 研究通过构建垂直模型与大型语言模型（LLMs）间的协同效应，致力于在零样本条件下达到“Oracle级别”的医疗预测精度。](2024年03月03日/SERVAL_Synergy_Learning_between_Vertical_Models_and_LLMs_towards_Oracle-Level_Zero-shot_Medical_Prediction.md)

- [ReMatch: Retrieval Enhanced Schema Matching with LLMs](2024年03月03日/ReMatch_Retrieval_Enhanced_Schema_Matching_with_LLMs.md)

    - [翻译: ReMatch技术利用LLMs的力量，实现了检索增强型模式匹配，让数据结构间的对应关系更加精准高效。](2024年03月03日/ReMatch_Retrieval_Enhanced_Schema_Matching_with_LLMs.md)

- [Transformers for Supervised Online Continual Learning](2024年03月03日/Transformers_for_Supervised_Online_Continual_Learning.md)

    - [翻译: 面向监督在线连续学习的 Transformer 模型研究](2024年03月03日/Transformers_for_Supervised_Online_Continual_Learning.md)

- [Citation-Enhanced Generation for LLM-based Chatbots](2024年03月03日/Citation-Enhanced_Generation_for_LLM-based_Chatbots.md)

    - [翻译: 为基于大型语言模型（LLM）的聊天机器人引入引文增强生成技术，旨在提升其对话内容的准确性和可信度。](2024年03月03日/Citation-Enhanced_Generation_for_LLM-based_Chatbots.md)

- [Query Augmentation by Decoding Semantics from Brain Signals](2024年03月03日/Query_Augmentation_by_Decoding_Semantics_from_Brain_Signals.md)

    - [翻译: 本研究探讨了一种创新方法，通过解读大脑信号中的语义信息来丰富和增强查询，实现与用户思维更深层次的交互。](2024年03月03日/Query_Augmentation_by_Decoding_Semantics_from_Brain_Signals.md)

- [Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5](2024年03月04日/Automated_Generation_of_Multiple-Choice_Cloze_Questions_for_Assessing_English_Vocabulary_Using_GPT-turbo_3.5.md)

    - [翻译: 本研究运用 GPT-turbo 3.5 技术，自动创建适合评估英语词汇掌握程度的多选填空题。](2024年03月04日/Automated_Generation_of_Multiple-Choice_Cloze_Questions_for_Assessing_English_Vocabulary_Using_GPT-turbo_3.5.md)

- [Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism](2024年03月04日/Large_Language_Model-Based_Evolutionary_Optimizer_Reasoning_with_elitism.md)

    - [翻译: 这款基于大型语言模型的进化优化器，通过精英主义原理进行智能推理。它巧妙地运用了大型语言模型的优势，在不断优化过程中甄选并借鉴最优解决方案进行迭代升级。](2024年03月04日/Large_Language_Model-Based_Evolutionary_Optimizer_Reasoning_with_elitism.md)

- [Unveiling Hidden Links Between Unseen Security Entities](2024年03月04日/Unveiling_Hidden_Links_Between_Unseen_Security_Entities.md)

    - [翻译: 本研究致力于揭开未知安全实体间的潜在关联，探寻那些未曾显现的隐性联系。](2024年03月04日/Unveiling_Hidden_Links_Between_Unseen_Security_Entities.md)

- [LLM-Oriented Retrieval Tuner](2024年03月04日/LLM-Oriented_Retrieval_Tuner.md)

    - [翻译: 针对 LLM 的检索优化器，旨在对大型语言模型进行精准高效的检索调优。](2024年03月04日/LLM-Oriented_Retrieval_Tuner.md)

- [FakeNewsGPT4: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs](2024年03月04日/FakeNewsGPT4_Advancing_Multimodal_Fake_News_Detection_through_Knowledge-Augmented_LVLMs.md)

    - [翻译: FakeNewsGPT4 是一项创新研究，利用了知识增强的多模态大型语言模型，旨在提升假新闻检测能力。](2024年03月04日/FakeNewsGPT4_Advancing_Multimodal_Fake_News_Detection_through_Knowledge-Augmented_LVLMs.md)

- [Evaluating the Explainability of Neural Rankers](2024年03月04日/Evaluating_the_Explainability_of_Neural_Rankers.md)

    - [翻译: 本研究旨在深入探讨和评估神经网络排序模型的可解释性，以揭示其内部决策机制及优化依据。](2024年03月04日/Evaluating_the_Explainability_of_Neural_Rankers.md)

- [SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis](2024年03月04日/SciAssess_Benchmarking_LLM_Proficiency_in_Scientific_Literature_Analysis.md)

    - [翻译: SciAssess 是一个针对大型语言模型（LLM）在科学文献分析能力上的基准测试工具，旨在衡量和评估 LLM 在理解和解析科学文献方面的专业水准。](2024年03月04日/SciAssess_Benchmarking_LLM_Proficiency_in_Scientific_Literature_Analysis.md)

- [Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models](2024年03月04日/Multi-perspective_Improvement_of_Knowledge_Graph_Completion_with_Large_Language_Models.md)

    - [翻译: 本研究探讨如何借助大型语言模型从多个视角提升知识图谱补全任务的效果。](2024年03月04日/Multi-perspective_Improvement_of_Knowledge_Graph_Completion_with_Large_Language_Models.md)

- [ContrastRepair: Enhancing Conversation-Based Automated Program Repair via Contrastive Test Case Pairs](2024年03月04日/ContrastRepair_Enhancing_Conversation-Based_Automated_Program_Repair_via_Contrastive_Test_Case_Pairs.md)

    - [翻译: ContrastRepair 是一种创新方法，通过构建并利用对比测试用例对，有效提升基于对话模式的自动化程序修复能力。](2024年03月04日/ContrastRepair_Enhancing_Conversation-Based_Automated_Program_Repair_via_Contrastive_Test_Case_Pairs.md)

- [AS-ES Learning: Towards Efficient CoT Learning in Small Models](2024年03月04日/AS-ES_Learning_Towards_Efficient_CoT_Learning_in_Small_Models.md)

    - [翻译: AS-ES 学习致力于在小型模型中实现高效的概念到文本（CoT）学习，旨在提升模型理解和应用复杂概念的能力。](2024年03月04日/AS-ES_Learning_Towards_Efficient_CoT_Learning_in_Small_Models.md)

- [Analyzing and Adapting Large Language Models for Few-Shot Multilingual NLU: Are We There Yet?](2024年03月04日/Analyzing_and_Adapting_Large_Language_Models_for_Few-Shot_Multilingual_NLU_Are_We_There_Yet.md)

    - [翻译: 针对少量样本多语言 NLU 任务，对大型语言模型进行分析与适应的研究：我们是否已达成目标？](2024年03月04日/Analyzing_and_Adapting_Large_Language_Models_for_Few-Shot_Multilingual_NLU_Are_We_There_Yet.md)

- [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](2024年03月04日/To_Generate_or_to_Retrieve_On_the_Effectiveness_of_Artificial_Contexts_for_Medical_Open-Domain_Question_Answering.md)

    - [翻译: 探究“生成”与“检索”的抉择——人工构建的上下文对医学开放领域问答效果的影响](2024年03月04日/To_Generate_or_to_Retrieve_On_the_Effectiveness_of_Artificial_Contexts_for_Medical_Open-Domain_Question_Answering.md)

- [Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with Wider Topic Analysis](2024年03月04日/Arabic_Text_Sentiment_Analysis_Reinforcing_Human-Performed_Surveys_with_Wider_Topic_Analysis.md)

    - [翻译: 本研究聚焦于阿拉伯语文本情感分析，通过融合更广泛的主题分析以增强基于人类调查的结果，旨在提升对调查数据的洞察力和准确性。](2024年03月04日/Arabic_Text_Sentiment_Analysis_Reinforcing_Human-Performed_Surveys_with_Wider_Topic_Analysis.md)

- [xT: Nested Tokenization for Larger Context in Large Images](2024年03月04日/xT_Nested_Tokenization_for_Larger_Context_in_Large_Images.md)

    - [翻译: xT 技术提出了一种针对大型图像的嵌套分词方法，旨在捕获并处理更大范围的上下文信息。](2024年03月04日/xT_Nested_Tokenization_for_Larger_Context_in_Large_Images.md)

- [Fostering the Ecosystem of Open Neural Encoders for Portuguese with Albertina PT* Family](2024年03月04日/Fostering_the_Ecosystem_of_Open_Neural_Encoders_for_Portuguese_with_Albertina_PT_Family.md)

    - [翻译: Albertina PT* 系列旨在促进葡萄牙语开放神经编码器生态系统的构建与发展](2024年03月04日/Fostering_the_Ecosystem_of_Open_Neural_Encoders_for_Portuguese_with_Albertina_PT_Family.md)

- [An Improved Traditional Chinese Evaluation Suite for Foundation Model](2024年03月04日/An_Improved_Traditional_Chinese_Evaluation_Suite_for_Foundation_Model.md)

    - [翻译: 为了更好地评测基础模型在处理汉字任务时的性能，我们推出了一个优化的传统中文评估套件。这个改进版套件旨在深入考察和精确衡量各类基础模型在处理汉字文本及理解传统中国文化情境中的表现。](2024年03月04日/An_Improved_Traditional_Chinese_Evaluation_Suite_for_Foundation_Model.md)

- [Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral](2024年03月04日/Rethinking_LLM_Language_Adaptation_A_Case_Study_on_Chinese_Mixtral.md)

    - [翻译: 对LLM的语言适应性进行再思考——以“Chinese Mixtral”为例的深度探究](2024年03月04日/Rethinking_LLM_Language_Adaptation_A_Case_Study_on_Chinese_Mixtral.md)

- [One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models](2024年03月04日/One_Prompt_Word_is_Enough_to_Boost_Adversarial_Robustness_for_Pre-trained_Vision-Language_Models.md)

    - [翻译: 惊人发现，只需单个提示词即可显著增强预训练视觉-语言模型在对抗性环境中的稳健性。](2024年03月04日/One_Prompt_Word_is_Enough_to_Boost_Adversarial_Robustness_for_Pre-trained_Vision-Language_Models.md)

- [CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text](2024年03月04日/CatCode_A_Comprehensive_Evaluation_Framework_for_LLMs_On_the_Mixture_of_Code_and_Text.md)

    - [翻译: CatCode 是一个综合性的评估框架，专为在混合代码与文本环境中的大型语言模型（LLMs）设计，旨在全方位测评其性能表现。](2024年03月04日/CatCode_A_Comprehensive_Evaluation_Framework_for_LLMs_On_the_Mixture_of_Code_and_Text.md)

- [NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models](2024年03月04日/NPHardEval4V_A_Dynamic_Reasoning_Benchmark_of_Multimodal_Large_Language_Models.md)

    - [翻译: NPHardEval4V 是针对多模态大型语言模型设计的一套动态推理性能评估基准，旨在全面检验此类模型在复杂场景下的理解与推理能力。](2024年03月04日/NPHardEval4V_A_Dynamic_Reasoning_Benchmark_of_Multimodal_Large_Language_Models.md)

- [WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations](2024年03月04日/WebCiteS_Attributed_Query-Focused_Summarization_on_Chinese_Web_Search_Results_with_Citations.md)

    - [翻译: WebCiteS 是一种创新技术，专注于对中文网页搜索结果进行带引文的查询焦点摘要。该技术旨在通过考虑引用信息，提升搜索结果摘要的质量和针对性。](2024年03月04日/WebCiteS_Attributed_Query-Focused_Summarization_on_Chinese_Web_Search_Results_with_Citations.md)

- [How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems](2024年03月04日/How_Multimodal_Integration_Boost_the_Performance_of_LLM_for_Optimization_Case_Study_on_Capacitated_Vehicle_Routing_Problems.md)

    - [翻译: 通过研究载量受限车辆路径问题，本文探讨了多模态集成如何显著增强大型语言模型（LLM）在优化任务中的表现。](2024年03月04日/How_Multimodal_Integration_Boost_the_Performance_of_LLM_for_Optimization_Case_Study_on_Capacitated_Vehicle_Routing_Problems.md)

- [AI Language Models Could Both Help and Harm Equity in Marine Policymaking: The Case Study of the BBNJ Question-Answering Bot](2024年03月04日/AI_Language_Models_Could_Both_Help_and_Harm_Equity_in_Marine_Policymaking_The_Case_Study_of_the_BBNJ_Question-Answering_Bot.md)

    - [翻译: AI语言模型在海洋政策制定领域的应用，如BBNJ问答机器人案例所示，既能促进公平性也可能带来潜在的不平等问题。本研究通过该案例探讨了这一双刃剑效应。](2024年03月04日/AI_Language_Models_Could_Both_Help_and_Harm_Equity_in_Marine_Policymaking_The_Case_Study_of_the_BBNJ_Question-Answering_Bot.md)

- [Derivative-Free Optimization for Low-Rank Adaptation in Large Language Models](2024年03月04日/Derivative-Free_Optimization_for_Low-Rank_Adaptation_in_Large_Language_Models.md)

    - [翻译: 针对大型语言模型中的低秩适应问题，本研究探讨了无需依赖梯度信息的优化方法。](2024年03月04日/Derivative-Free_Optimization_for_Low-Rank_Adaptation_in_Large_Language_Models.md)

- [Differentially Private Synthetic Data via Foundation Model APIs 2: Text](2024年03月04日/Differentially_Private_Synthetic_Data_via_Foundation_Model_APIs_2_Text.md)

    - [翻译: 借助基础模型API，我们推出了针对文本的第二版差分隐私合成数据技术。这项技术利用基础模型能力，在保证数据隐私性的同时生成高质量的合成文本数据。](2024年03月04日/Differentially_Private_Synthetic_Data_via_Foundation_Model_APIs_2_Text.md)

- [Decode Neural signal as Speech](2024年03月04日/Decode_Neural_signal_as_Speech.md)

    - [翻译: 本研究致力于将神经信号转化为可识别的语音，探索从大脑活动直接解读言语信息的可能性。](2024年03月04日/Decode_Neural_signal_as_Speech.md)

- [NoteLLM: A Retrievable Large Language Model for Note Recommendation](2024年03月04日/NoteLLM_A_Retrievable_Large_Language_Model_for_Note_Recommendation.md)

    - [翻译: NoteLLM，一款专为笔记推荐打造的可检索型大型语言模型。](2024年03月04日/NoteLLM_A_Retrievable_Large_Language_Model_for_Note_Recommendation.md)

- [Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning](2024年03月04日/Key-Point-Driven_Data_Synthesis_with_its_Enhancement_on_Mathematical_Reasoning.md)

    - [翻译: 通过关键点驱动的数据合成技术，并对其进行优化，以提升数学推理性能。这项研究聚焦于利用关键点引导的数据合成方法，有效增强模型在数学推理任务上的表现。](2024年03月04日/Key-Point-Driven_Data_Synthesis_with_its_Enhancement_on_Mathematical_Reasoning.md)

- [RegionGPT: Towards Region Understanding Vision Language Model](2024年03月04日/RegionGPT_Towards_Region_Understanding_Vision_Language_Model.md)

    - [翻译: RegionGPT——迈向理解视觉区域的新型语言模型，旨在提升视觉与语言融合模型在区域理解层面的表现。](2024年03月04日/RegionGPT_Towards_Region_Understanding_Vision_Language_Model.md)

- [Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures](2024年03月04日/Vision-RWKV_Efficient_and_Scalable_Visual_Perception_with_RWKV-Like_Architectures.md)

    - [翻译: Vision-RWKV 是一种采用类RWKV架构设计，有效实现了视觉感知的高效性和可扩展性的方法。](2024年03月04日/Vision-RWKV_Efficient_and_Scalable_Visual_Perception_with_RWKV-Like_Architectures.md)

- [Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation](2024年03月04日/Beyond_Specialization_Assessing_the_Capabilities_of_MLLMs_in_Age_and_Gender_Estimation.md)

    - [翻译: 本研究超越了单一领域的专业性，致力于评估多语言大型模型（MLLMs）在年龄与性别估算任务中的能力。](2024年03月04日/Beyond_Specialization_Assessing_the_Capabilities_of_MLLMs_in_Age_and_Gender_Estimation.md)

- [FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction](2024年03月04日/FENICE_Factuality_Evaluation_of_summarization_based_on_Natural_language_Inference_and_Claim_Extraction.md)

    - [翻译: FENICE 是一种利用自然语言推理和论断抽取技术对摘要进行事实性评估的方法。](2024年03月04日/FENICE_Factuality_Evaluation_of_summarization_based_on_Natural_language_Inference_and_Claim_Extraction.md)

- [KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection](2024年03月04日/KnowPhish_Large_Language_Models_Meet_Multimodal_Knowledge_Graphs_for_Enhancing_Reference-Based_Phishing_Detection.md)

    - [翻译: KnowPhish项目将大型语言模型与多模态知识图谱相结合，旨在强化基于参照的钓鱼检测技术，实现更高效的网络欺诈识别。](2024年03月04日/KnowPhish_Large_Language_Models_Meet_Multimodal_Knowledge_Graphs_for_Enhancing_Reference-Based_Phishing_Detection.md)

- [PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models](2024年03月04日/PHAnToM_Personality_Has_An_Effect_on_Theory-of-Mind_Reasoning_in_Large_Language_Models.md)

    - [翻译: PHAnToM研究表明，大型语言模型的心智理论推理会受到模型所具备的个性特征的影响。](2024年03月04日/PHAnToM_Personality_Has_An_Effect_on_Theory-of-Mind_Reasoning_in_Large_Language_Models.md)

- [Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks](2024年03月04日/Towards_Intent-Based_Network_Management_Large_Language_Models_for_Intent_Extraction_in_5G_Core_Networks.md)

    - [翻译: 致力于打造基于意图的网络管理模式，我们探索了在5G核心网络环境下运用大型语言模型抽取用户意图的可能性。](2024年03月04日/Towards_Intent-Based_Network_Management_Large_Language_Models_for_Intent_Extraction_in_5G_Core_Networks.md)

- [3DTopia: Large Text-to-3D Generation Model with Hybrid Diffusion Priors](2024年03月04日/3DTopia_Large_Text-to-3D_Generation_Model_with_Hybrid_Diffusion_Priors.md)

    - [翻译: 3DTopia是一款创新的大型文本转三维生成模型，巧妙融合了混合扩散先验技术，实现从文本信息高效构建高质量三维模型。](2024年03月04日/3DTopia_Large_Text-to-3D_Generation_Model_with_Hybrid_Diffusion_Priors.md)

- [TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language Models](2024年03月04日/TPLLM_A_Traffic_Prediction_Framework_Based_on_Pretrained_Large_Language_Models.md)

    - [翻译: TPLLM 是一种基于预训练大型语言模型的交通预测方案，该框架利用大规模语言模型的强大泛化和学习能力，对交通流量进行精准预测。](2024年03月04日/TPLLM_A_Traffic_Prediction_Framework_Based_on_Pretrained_Large_Language_Models.md)

- [Not all Layers of LLMs are Necessary during Inference](2024年03月04日/Not_all_Layers_of_LLMs_are_Necessary_during_Inference.md)

    - [翻译: 对于LLM的推理阶段，并非所有层级都不可或缺。](2024年03月04日/Not_all_Layers_of_LLMs_are_Necessary_during_Inference.md)

- [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](2024年03月04日/Masked_Thought_Simply_Masking_Partial_Reasoning_Steps_Can_Improve_Mathematical_Reasoning_Learning_of_Language_Models.md)

    - [翻译: Masked Thought 研究表明，简单地对部分推理步骤进行遮蔽处理，就能有效增强语言模型在数学推理学习上的表现。](2024年03月04日/Masked_Thought_Simply_Masking_Partial_Reasoning_Steps_Can_Improve_Mathematical_Reasoning_Learning_of_Language_Models.md)

- [Cognition is All You Need - The Next Layer of AI Above Large Language Models](2024年03月04日/Cognition_is_All_You_Need_-_The_Next_Layer_of_AI_Above_Large_Language_Models.md)

    - [翻译: 在大型语言模型基础上，认知力量被视为推动AI发展的下一关键层次 ——“认知即一切”。](2024年03月04日/Cognition_is_All_You_Need_-_The_Next_Layer_of_AI_Above_Large_Language_Models.md)

- [Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation](2024年03月04日/Memoro_Using_Large_Language_Models_to_Realize_a_Concise_Interface_for_Real-Time_Memory_Augmentation.md)

    - [翻译: Memoro项目通过运用大型语言模型，打造出一个能够实现实时记忆增强的精炼界面。](2024年03月04日/Memoro_Using_Large_Language_Models_to_Realize_a_Concise_Interface_for_Real-Time_Memory_Augmentation.md)

- [Using LLMs for the Extraction and Normalization of Product Attribute Values](2024年03月04日/Using_LLMs_for_the_Extraction_and_Normalization_of_Product_Attribute_Values.md)

    - [翻译: 运用 LLM 技术抽取并规范产品属性值，本研究旨在探索这一方法在处理产品信息时的高效性和准确性。](2024年03月04日/Using_LLMs_for_the_Extraction_and_Normalization_of_Product_Attribute_Values.md)

- [Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models](2024年03月04日/Leveraging_Weakly_Annotated_Data_for_Hate_Speech_Detection_in_Code-Mixed_Hinglish_A_Feasibility-Driven_Transfer_Learning_Approach_with_Large_Language_Models.md)

    - [翻译: 针对混合语种 Hinglish 中的仇恨言论检测问题，我们提出了一种以可行性为导向的迁移学习策略，充分利用弱标注数据，并结合大型语言模型的力量。](2024年03月04日/Leveraging_Weakly_Annotated_Data_for_Hate_Speech_Detection_in_Code-Mixed_Hinglish_A_Feasibility-Driven_Transfer_Learning_Approach_with_Large_Language_Models.md)

- [Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding](2024年03月04日/Found_in_the_Middle_How_Language_Models_Use_Long_Contexts_Better_via_Plug-and-Play_Positional_Encoding.md)

    - [翻译: 研究揭示，借助“即插即用”位置编码，语言模型能够更有效地利用长篇幅的上下文信息。](2024年03月04日/Found_in_the_Middle_How_Language_Models_Use_Long_Contexts_Better_via_Plug-and-Play_Positional_Encoding.md)

- [Large Language Models in Fire Engineering: An Examination of Technical Questions Against Domain Knowledge](2024年03月04日/Large_Language_Models_in_Fire_Engineering_An_Examination_of_Technical_Questions_Against_Domain_Knowledge.md)

    - [翻译: 探究大型语言模型如何应用于火灾工程领域，通过对比领域专业知识来审视其解决技术问题的能力。](2024年03月04日/Large_Language_Models_in_Fire_Engineering_An_Examination_of_Technical_Questions_Against_Domain_Knowledge.md)

- [Online Training of Large Language Models: Learn while chatting](2024年03月04日/Online_Training_of_Large_Language_Models_Learn_while_chatting.md)

    - [翻译: 大型语言模型的在线训练技术，让模型在互动聊天中实时学习与成长。](2024年03月04日/Online_Training_of_Large_Language_Models_Learn_while_chatting.md)

- [Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents](2024年03月04日/Trial_and_Error_Exploration-Based_Trajectory_Optimization_for_LLM_Agents.md)

    - [翻译: 通过“试错”方式，研究针对LLM智能体的探索式轨迹优化策略。](2024年03月04日/Trial_and_Error_Exploration-Based_Trajectory_Optimization_for_LLM_Agents.md)

- [Predicting Learning Performance with Large Language Models: A Study in Adult Literacy](2024年03月04日/Predicting_Learning_Performance_with_Large_Language_Models_A_Study_in_Adult_Literacy.md)

    - [翻译: 本研究利用大型语言模型探索预测成人识字学习表现的可能性，深入探究其在识字教育领域的应用潜力。](2024年03月04日/Predicting_Learning_Performance_with_Large_Language_Models_A_Study_in_Adult_Literacy.md)

- [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](2024年03月05日/The_WMDP_Benchmark_Measuring_and_Reducing_Malicious_Use_With_Unlearning.md)

    - [翻译: WMDP基准计划旨在衡量并有效减少恶意使用，其方法是采用“消除学习”技术。这个测试标准聚焦于评估及降低利用机器学习模型进行恶意行为的可能性，并探索通过“遗忘学习”机制来达成这一目标的途径。](2024年03月05日/The_WMDP_Benchmark_Measuring_and_Reducing_Malicious_Use_With_Unlearning.md)

- [CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments](2024年03月05日/CLEVR-POC_Reasoning-Intensive_Visual_Question_Answering_in_Partially_Observable_Environments.md)

    - [翻译: CLEVR-POC 是一个专注于在局部可观察环境下的高强度视觉推理问答研究，旨在探究在不完全信息条件下进行复杂视觉推理的能力。](2024年03月05日/CLEVR-POC_Reasoning-Intensive_Visual_Question_Answering_in_Partially_Observable_Environments.md)

- [MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets](2024年03月05日/MAGID_An_Automated_Pipeline_for_Generating_Synthetic_Multi-modal_Datasets.md)

    - [翻译: MAGID 是一款自动化的流水线工具，专注于创建合成型多模态数据集。](2024年03月05日/MAGID_An_Automated_Pipeline_for_Generating_Synthetic_Multi-modal_Datasets.md)

- [Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement](2024年03月05日/Towards_Democratized_Flood_Risk_Management_An_Advanced_AI_Assistant_Enabled_by_GPT-4_for_Enhanced_Interpretability_and_Public_Engagement.md)

    - [翻译: 为实现洪水风险管理的大众化，我们引入了一款基于 GPT-4 技术的先进 AI 助手。这款智能助手致力于增强模型解释力和促进公众积极参与洪水风险管理工作。](2024年03月05日/Towards_Democratized_Flood_Risk_Management_An_Advanced_AI_Assistant_Enabled_by_GPT-4_for_Enhanced_Interpretability_and_Public_Engagement.md)

- [Reliable, Adaptable, and Attributable Language Models with Retrieval](2024年03月05日/Reliable,_Adaptable,_and_Attributable_Language_Models_with_Retrieval.md)

    - [翻译: 致力于构建可靠、灵活且具有明确来源的检索型语言模型，以提升其性能和可信度。](2024年03月05日/Reliable,_Adaptable,_and_Attributable_Language_Models_with_Retrieval.md)

- [SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection](2024年03月05日/SNIFFER_Multimodal_Large_Language_Model_for_Explainable_Out-of-Context_Misinformation_Detection.md)

    - [翻译: SNIFFER是一款专注于可解释性离群信息检测的多模态大型语言模型，能够有效识别和解析上下文缺失情况下的错误信息。](2024年03月05日/SNIFFER_Multimodal_Large_Language_Model_for_Explainable_Out-of-Context_Misinformation_Detection.md)

- [PARADISE: Evaluating Implicit Planning Skills of Language Models with Procedural Warnings and Tips Dataset](2024年03月05日/PARADISE_Evaluating_Implicit_Planning_Skills_of_Language_Models_with_Procedural_Warnings_and_Tips_Dataset.md)

    - [翻译: PARADISE 是一项研究，它借助程序性警告和提示数据集来评估语言模型在隐式规划任务上的表现能力。](2024年03月05日/PARADISE_Evaluating_Implicit_Planning_Skills_of_Language_Models_with_Procedural_Warnings_and_Tips_Dataset.md)

- [Quantum Many-Body Physics Calculations with Large Language Models](2024年03月05日/Quantum_Many-Body_Physics_Calculations_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型探索量子多体物理问题的计算解决之道](2024年03月05日/Quantum_Many-Body_Physics_Calculations_with_Large_Language_Models.md)

- [Language Guided Exploration for RL Agents in Text Environments](2024年03月05日/Language_Guided_Exploration_for_RL_Agents_in_Text_Environments.md)

    - [翻译: 针对文本环境中的强化学习（RL）智能体，我们提出语言指导的探索策略，利用自然语言引导智能体在复杂环境中高效探索和学习。](2024年03月05日/Language_Guided_Exploration_for_RL_Agents_in_Text_Environments.md)

- [CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following](2024年03月05日/CoGenesis_A_Framework_Collaborating_Large_and_Small_Language_Models_for_Secure_Context-Aware_Instruction_Following.md)

    - [翻译: CoGenesis 是一种创新框架，它巧妙地整合了大型和小型语言模型的力量，旨在实现安全且具备情境感知能力的指令执行。](2024年03月05日/CoGenesis_A_Framework_Collaborating_Large_and_Small_Language_Models_for_Secure_Context-Aware_Instruction_Following.md)

- [Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution](2024年03月05日/Angry_Men,_Sad_Women_Large_Language_Models_Reflect_Gendered_Stereotypes_in_Emotion_Attribution.md)

    - [翻译: 大型语言模型揭示了在情绪认知上存在的性别刻板印象，即“愤怒的男人”与“悲伤的女人”。本研究针对这一现象，深入探讨了大型语言模型如何在情感属性分配中体现性别偏见。](2024年03月05日/Angry_Men,_Sad_Women_Large_Language_Models_Reflect_Gendered_Stereotypes_in_Emotion_Attribution.md)

- ["In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning](2024年03月05日/In_Dialogues_We_Learn_Towards_Personalized_Dialogue_Without_Pre-defined_Profiles_through_In-Dialogue_Learning.md)

    - [翻译: “对话即学习”：探索无预设用户画像的个性化对话，借助于对话过程中的实时学习技术](2024年03月05日/In_Dialogues_We_Learn_Towards_Personalized_Dialogue_Without_Pre-defined_Profiles_through_In-Dialogue_Learning.md)

- [KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](2024年03月05日/KnowAgent_Knowledge-Augmented_Planning_for_LLM-Based_Agents.md)

    - [翻译: KnowAgent是一种为基于大型语言模型（LLM）的智能体设计的知识增强规划方案，旨在通过融合知识与LLM能力来提升其决策与规划效能。](2024年03月05日/KnowAgent_Knowledge-Augmented_Planning_for_LLM-Based_Agents.md)

- [MiKASA: Multi-Key-Anchor & Scene-Aware Transformer for 3D Visual Grounding](2024年03月05日/MiKASA_Multi-Key-Anchor_&_Scene-Aware_Transformer_for_3D_Visual_Grounding.md)

    - [翻译: MiKASA——这款创新的三维视觉定位模型，巧妙融合了多键锚点与场景感知技术，以Transformer架构为核心，旨在提升三维空间中的目标定位精准度。](2024年03月05日/MiKASA_Multi-Key-Anchor_&_Scene-Aware_Transformer_for_3D_Visual_Grounding.md)

- [Learning to Use Tools via Cooperative and Interactive Agents](2024年03月05日/Learning_to_Use_Tools_via_Cooperative_and_Interactive_Agents.md)

    - [翻译: 在合作与互动智能体的引导下掌握工具使用技能](2024年03月05日/Learning_to_Use_Tools_via_Cooperative_and_Interactive_Agents.md)

- [Socratic Reasoning Improves Positive Text Rewriting](2024年03月05日/Socratic_Reasoning_Improves_Positive_Text_Rewriting.md)

    - [翻译: 运用苏格拉底式推理能够显著优化正面文本的重写过程，使其更具说服力和深度。](2024年03月05日/Socratic_Reasoning_Improves_Positive_Text_Rewriting.md)

- [Word Importance Explains How Prompts Affect Language Model Outputs](2024年03月05日/Word_Importance_Explains_How_Prompts_Affect_Language_Model_Outputs.md)

    - [翻译: 探究词语权重：揭示提示如何驱动语言模型的输出变化](2024年03月05日/Word_Importance_Explains_How_Prompts_Affect_Language_Model_Outputs.md)

- [OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following](2024年03月05日/OPEx_A_Component-Wise_Analysis_of_LLM-Centric_Agents_in_Embodied_Instruction_Following.md)

    - [翻译: OPEx研究针对具身指令跟随任务中以大型语言模型（LLM）为核心的智能体，对其进行深入的组件级分析。](2024年03月05日/OPEx_A_Component-Wise_Analysis_of_LLM-Centric_Agents_in_Embodied_Instruction_Following.md)

- [Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations](2024年03月05日/Knowledge_Graphs_as_Context_Sources_for_LLM-Based_Explanations_of_Learning_Recommendations.md)

    - [翻译: 在基于LLM的学习推荐解释中，知识图谱可作为重要的上下文信息源。](2024年03月05日/Knowledge_Graphs_as_Context_Sources_for_LLM-Based_Explanations_of_Learning_Recommendations.md)

- [Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large Language Models](2024年03月05日/Feast_Your_Eyes_Mixture-of-Resolution_Adaptation_for_Multimodal_Large_Language_Models.md)

    - [翻译: 标题生动翻译：“饱览盛宴”：探究多模态大型语言模型中的混合分辨率自适应技术](2024年03月05日/Feast_Your_Eyes_Mixture-of-Resolution_Adaptation_for_Multimodal_Large_Language_Models.md)

- [Localized Zeroth-Order Prompt Optimization](2024年03月05日/Localized_Zeroth-Order_Prompt_Optimization.md)

    - [翻译: 针对局部化的零阶提示优化技术，该方法利用零阶优化策略对模型的提示进行微调，特别是在特定任务或领域中，以提升模型的表现和适应性。](2024年03月05日/Localized_Zeroth-Order_Prompt_Optimization.md)

- [MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer](2024年03月05日/MADTP_Multimodal_Alignment-Guided_Dynamic_Token_Pruning_for_Accelerating_Vision-Language_Transformer.md)

    - [翻译: MADTP是一种创新方法，通过多模态对齐指导下的动态令牌剪枝策略，有效提升视觉-语言Transformer模型的运算效率。](2024年03月05日/MADTP_Multimodal_Alignment-Guided_Dynamic_Token_Pruning_for_Accelerating_Vision-Language_Transformer.md)

- [Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges](2024年03月05日/Data_Augmentation_using_LLMs_Data_Perspectives,_Learning_Paradigms_and_Challenges.md)

    - [翻译: LLM 数据增强技术探究：从数据角度出发，探讨其背后的新型学习范式及其面临的挑战](2024年03月05日/Data_Augmentation_using_LLMs_Data_Perspectives,_Learning_Paradigms_and_Challenges.md)

- [Multi-modal Instruction Tuned LLMs with Fine-grained Visual Perception](2024年03月05日/Multi-modal_Instruction_Tuned_LLMs_with_Fine-grained_Visual_Perception.md)

    - [翻译: 通过细粒度视觉感知优化的多模态指令训练LLM技术，使模型能够更好地理解并融合多种模态信息，特别是在处理包含丰富视觉元素的任务时。](2024年03月05日/Multi-modal_Instruction_Tuned_LLMs_with_Fine-grained_Visual_Perception.md)

- [Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering](2024年03月05日/Evidence-Focused_Fact_Summarization_for_Knowledge-Augmented_Zero-Shot_Question_Answering.md)

    - [翻译: 为了解决知识增强型零样本问题回答的挑战，我们提出了一种聚焦于证据的事实摘要方法，旨在提炼关键事实信息以辅助解答未曾见过的问题。](2024年03月05日/Evidence-Focused_Fact_Summarization_for_Knowledge-Augmented_Zero-Shot_Question_Answering.md)

- [ChatGPT and biometrics: an assessment of face recognition, gender detection, and age estimation capabilities](2024年03月05日/ChatGPT_and_biometrics_an_assessment_of_face_recognition,_gender_detection,_and_age_estimation_capabilities.md)

    - [翻译: ChatGPT 结合生物识别技术实测：针对人脸识别、性别辨别及年龄估算功能进行综合评估](2024年03月05日/ChatGPT_and_biometrics_an_assessment_of_face_recognition,_gender_detection,_and_age_estimation_capabilities.md)

- [WikiTableEdit: A Benchmark for Table Editing by Natural Language Instruction](2024年03月05日/WikiTableEdit_A_Benchmark_for_Table_Editing_by_Natural_Language_Instruction.md)

    - [翻译: WikiTableEdit 是一个专门针对通过自然语言指令进行表格编辑任务的基准测试工具，旨在评估和衡量模型在理解并执行基于文本的表格修改指令方面的性能。](2024年03月05日/WikiTableEdit_A_Benchmark_for_Table_Editing_by_Natural_Language_Instruction.md)

- [SimuCourt: Building Judicial Decision-Making Agents with Real-world Judgement Documents](2024年03月05日/SimuCourt_Building_Judicial_Decision-Making_Agents_with_Real-world_Judgement_Documents.md)

    - [翻译: SimuCourt项目致力于通过真实世界司法判决文档，打造能够进行司法决策制定的智能代理。](2024年03月05日/SimuCourt_Building_Judicial_Decision-Making_Agents_with_Real-world_Judgement_Documents.md)

- [Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation](2024年03月05日/Benchmarking_the_Text-to-SQL_Capability_of_Large_Language_Models_A_Comprehensive_Evaluation.md)

    - [翻译: 针对大型语言模型（LLM）的Text-to-SQL转换能力，本研究进行了深入且全面的基准评测。](2024年03月05日/Benchmarking_the_Text-to-SQL_Capability_of_Large_Language_Models_A_Comprehensive_Evaluation.md)

- [PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers](2024年03月05日/PaperWeaver_Enriching_Topical_Paper_Alerts_by_Contextualizing_Recommended_Papers_with_User-collected_Papers.md)

    - [翻译: PaperWeaver，一款智能工具，能够将用户自行收藏的论文作为上下文，以此强化推荐论文的相关性，从而提升主题论文提醒的质量。](2024年03月05日/PaperWeaver_Enriching_Topical_Paper_Alerts_by_Contextualizing_Recommended_Papers_with_User-collected_Papers.md)

- [ImgTrojan: Jailbreaking Vision-Language Models with ONE Image](2024年03月05日/ImgTrojan_Jailbreaking_Vision-Language_Models_with_ONE_Image.md)

    - [翻译: ImgTrojan：仅凭一张图像即可实现对视觉-语言模型的“越狱”攻击](2024年03月05日/ImgTrojan_Jailbreaking_Vision-Language_Models_with_ONE_Image.md)

- [A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods](2024年03月05日/A_Comprehensive_Survey_on_Process-Oriented_Automatic_Text_Summarization_with_Exploration_of_LLM-Based_Methods.md)

    - [翻译: 本研究对过程导向自动文本摘要进行全面综述，并深度探索基于大型语言模型（LLM）的方法在该领域中的应用。](2024年03月05日/A_Comprehensive_Survey_on_Process-Oriented_Automatic_Text_Summarization_with_Exploration_of_LLM-Based_Methods.md)

- [Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation](2024年03月05日/Domain-Agnostic_Mutual_Prompting_for_Unsupervised_Domain_Adaptation.md)

    - [翻译: 为解决无监督领域适应问题，我们提出“领域无关的相互提示”方法，该方法能够在不同领域间进行有效知识迁移，无需任何领域标注数据。](2024年03月05日/Domain-Agnostic_Mutual_Prompting_for_Unsupervised_Domain_Adaptation.md)

- [In Search of Truth: An Interrogation Approach to Hallucination Detection](2024年03月05日/In_Search_of_Truth_An_Interrogation_Approach_to_Hallucination_Detection.md)

    - [翻译: 为揭示真相，我们提出了一种通过质询法来探测幻觉的新途径。](2024年03月05日/In_Search_of_Truth_An_Interrogation_Approach_to_Hallucination_Detection.md)

- [MathScale: Scaling Instruction Tuning for Mathematical Reasoning](2024年03月05日/MathScale_Scaling_Instruction_Tuning_for_Mathematical_Reasoning.md)

    - [翻译: MathScale 是一种专门针对数学推理能力提升而设计的指令调优扩展方案。](2024年03月05日/MathScale_Scaling_Instruction_Tuning_for_Mathematical_Reasoning.md)

- [An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Models are Task-specific Classifiers](2024年03月05日/An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation_Fine-tuned_Judge_Models_are_Task-specific_Classifiers.md)

    - [翻译: 本研究通过实证方法探究了将大型语言模型（LLM）作为评价工具的应用，其中经过微调的Judge模型实质上成为了针对特定任务的分类器。](2024年03月05日/An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation_Fine-tuned_Judge_Models_are_Task-specific_Classifiers.md)

- [DPPA: Pruning Method for Large Language Model to Model Merging](2024年03月05日/DPPA_Pruning_Method_for_Large_Language_Model_to_Model_Merging.md)

    - [翻译: DPPA：一种针对大型语言模型整合的高效剪枝技术，旨在优化模型合并过程。](2024年03月05日/DPPA_Pruning_Method_for_Large_Language_Model_to_Model_Merging.md)

- [Evaluating and Optimizing Educational Content with Large Language Model Judgments](2024年03月05日/Evaluating_and_Optimizing_Educational_Content_with_Large_Language_Model_Judgments.md)

    - [翻译: 利用大型语言模型评判来评估与优化教育内容，以提升教学质量及效果。](2024年03月05日/Evaluating_and_Optimizing_Educational_Content_with_Large_Language_Model_Judgments.md)

- [PromptKD: Unsupervised Prompt Distillation for Vision-Language Models](2024年03月05日/PromptKD_Unsupervised_Prompt_Distillation_for_Vision-Language_Models.md)

    - [翻译: PromptKD 是一种针对视觉-语言模型的创新方法，通过无监督的方式进行提示蒸馏，以提升此类模型的表现和泛化能力。](2024年03月05日/PromptKD_Unsupervised_Prompt_Distillation_for_Vision-Language_Models.md)

- [EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs](2024年03月05日/EasyQuant_An_Efficient_Data-free_Quantization_Algorithm_for_LLMs.md)

    - [翻译: EasyQuant：针对LLMs设计的高效无数据量化方案](2024年03月05日/EasyQuant_An_Efficient_Data-free_Quantization_Algorithm_for_LLMs.md)

- [Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations](2024年03月05日/Emerging_Synergies_Between_Large_Language_Models_and_Machine_Learning_in_Ecommerce_Recommendations.md)

    - [翻译: 在电商推荐领域，大型语言模型与机器学习技术正展现出日益增强的协同潜力。](2024年03月05日/Emerging_Synergies_Between_Large_Language_Models_and_Machine_Learning_in_Ecommerce_Recommendations.md)

- [In-Memory Learning: A Declarative Learning Framework for Large Language Models](2024年03月05日/In-Memory_Learning_A_Declarative_Learning_Framework_for_Large_Language_Models.md)

    - [翻译: 内存学习：一种针对大型语言模型设计的声明式学习方案，它提供了一种新颖高效的方法来训练和优化大规模模型。](2024年03月05日/In-Memory_Learning_A_Declarative_Learning_Framework_for_Large_Language_Models.md)

- [Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models](2024年03月05日/Role_Prompting_Guided_Domain_Adaptation_with_General_Capability_Preserve_for_Large_Language_Models.md)

    - [翻译: 在保持LLM广泛能力的前提下，我们提出了一种通过角色提示驱动的领域适应技术。](2024年03月05日/Role_Prompting_Guided_Domain_Adaptation_with_General_Capability_Preserve_for_Large_Language_Models.md)

- [HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents](2024年03月05日/HINTs_Sensemaking_on_large_collections_of_documents_with_Hypergraph_visualization_and_INTelligent_agents.md)

    - [翻译: HINTs 技术利用超图可视化和智能代理，在大规模文档集合中实现高效的意义挖掘和理解。](2024年03月05日/HINTs_Sensemaking_on_large_collections_of_documents_with_Hypergraph_visualization_and_INTelligent_agents.md)

- [CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models](2024年03月05日/CURATRON_Complete_Robust_Preference_Data_for_Robust_Alignment_of_Large_Language_Models.md)

    - [翻译: CURATRON 提供了一套完整的、针对大型语言模型进行稳健对齐所必需的高质量偏好数据，以实现其在各类任务中的可靠和稳健表现。](2024年03月05日/CURATRON_Complete_Robust_Preference_Data_for_Robust_Alignment_of_Large_Language_Models.md)

- [Towards Training A Chinese Large Language Model for Anesthesiology](2024年03月05日/Towards_Training_A_Chinese_Large_Language_Model_for_Anesthesiology.md)

    - [翻译: 致力于训练适用于麻醉学领域的大型中文语言模型](2024年03月05日/Towards_Training_A_Chinese_Large_Language_Model_for_Anesthesiology.md)

- [Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment](2024年03月05日/Causal_Prompting_Debiasing_Large_Language_Model_Prompting_based_on_Front-Door_Adjustment.md)

    - [翻译: 因果提示法：运用前门调整策略校正大型语言模型的提示偏差](2024年03月05日/Causal_Prompting_Debiasing_Large_Language_Model_Prompting_based_on_Front-Door_Adjustment.md)

- [HARGPT: Are LLMs Zero-Shot Human Activity Recognizers?](2024年03月05日/HARGPT_Are_LLMs_Zero-Shot_Human_Activity_Recognizers.md)

    - [翻译: HARGPT 探究：LLMs 在零样本情况下能否胜任人类活动识别任务？](2024年03月05日/HARGPT_Are_LLMs_Zero-Shot_Human_Activity_Recognizers.md)

- [Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models](2024年03月05日/Crossing_Linguistic_Horizons_Finetuning_and_Comprehensive_Evaluation_of_Vietnamese_Large_Language_Models.md)

    - [翻译: 跨语言界限探索，对越南大型语言模型进行细致调整与综合评测](2024年03月05日/Crossing_Linguistic_Horizons_Finetuning_and_Comprehensive_Evaluation_of_Vietnamese_Large_Language_Models.md)

- [Android in the Zoo: Chain-of-Action-Thought for GUI Agents](2024年03月05日/Android_in_the_Zoo_Chain-of-Action-Thought_for_GUI_Agents.md)

    - [翻译: 在“Android in the Zoo”研究中，我们提出了 GUI 代理的“行动思维链”概念，旨在通过模拟人类在面对界面操作时的逻辑思考过程，提升 Android 系统中 GUI 代理的智能决策与执行能力。](2024年03月05日/Android_in_the_Zoo_Chain-of-Action-Thought_for_GUI_Agents.md)

- [Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models](2024年03月05日/Mixture-of-LoRAs_An_Efficient_Multitask_Tuning_for_Large_Language_Models.md)

    - [翻译: Mixture-of-LoRAs 是一项创新技术，专为大型语言模型设计的高效多任务调优方案。](2024年03月05日/Mixture-of-LoRAs_An_Efficient_Multitask_Tuning_for_Large_Language_Models.md)

- [Generative Explanations for Program Synthesizers](2024年03月05日/Generative_Explanations_for_Program_Synthesizers.md)

    - [翻译: 面向程序合成器的生成性解释技术](2024年03月05日/Generative_Explanations_for_Program_Synthesizers.md)

- [Generative News Recommendation](2024年03月05日/Generative_News_Recommendation.md)

    - [翻译: 创新性生成新闻推荐技术步骤 1 翻译：Generative News Recommendation 直译为“生成式新闻推荐”。步骤 2 翻译：为了更生动活泼、简洁优雅地表达，可以将“生成式新闻推荐”进一步诠释为“创新性生成新闻推荐技术”，既体现了该技术的前沿性和智能性，也突出了其在新闻推荐领域的独特应用。](2024年03月05日/Generative_News_Recommendation.md)

- [Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization](2024年03月05日/Negating_Negatives_Alignment_without_Human_Positive_Samples_via_Distributional_Dispreference_Optimization.md)

    - [翻译: 本研究提出了一种新颖方法，利用分布性逆偏优化技术，在没有人工标注的正样本情况下也能实现对齐效果。这种方法巧妙地“消除负例”，突破了以往依赖正样本的局限。](2024年03月05日/Negating_Negatives_Alignment_without_Human_Positive_Samples_via_Distributional_Dispreference_Optimization.md)

- [Human vs. Machine: Language Models and Wargames](2024年03月05日/Human_vs._Machine_Language_Models_and_Wargames.md)

    - [翻译: 人类与机器的较量：探究语言模型在战争模拟游戏中的表现与应用](2024年03月05日/Human_vs._Machine_Language_Models_and_Wargames.md)

- [Explaining Genetic Programming Trees using Large Language Models](2024年03月05日/Explaining_Genetic_Programming_Trees_using_Large_Language_Models.md)

    - [翻译: 本研究探讨如何运用大型语言模型来解析遗传编程树的内在逻辑，以实现对复杂模型结构的深入理解与解读。](2024年03月05日/Explaining_Genetic_Programming_Trees_using_Large_Language_Models.md)

- [Japanese-English Sentence Translation Exercises Dataset for Automatic Grading](2024年03月05日/Japanese-English_Sentence_Translation_Exercises_Dataset_for_Automatic_Grading.md)

    - [翻译: 该数据集包含日语-英语句子翻译练习题目，专为实现自动化评分而设计。](2024年03月05日/Japanese-English_Sentence_Translation_Exercises_Dataset_for_Automatic_Grading.md)

- [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](2024年03月05日/Learning_to_Maximize_Mutual_Information_for_Chain-of-Thought_Distillation.md)

    - [翻译: 本研究致力于学习如何优化互信息，以应用于链式思考蒸馏技术中，旨在提升模型对复杂问题的推理能力。](2024年03月05日/Learning_to_Maximize_Mutual_Information_for_Chain-of-Thought_Distillation.md)

- [Enhancing Vision-Language Pre-training with Rich Supervisions](2024年03月05日/Enhancing_Vision-Language_Pre-training_with_Rich_Supervisions.md)

    - [翻译: 在视觉-语言预训练中，我们致力于借助丰富的监督信息以增强模型性能。](2024年03月05日/Enhancing_Vision-Language_Pre-training_with_Rich_Supervisions.md)

- [Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation](2024年03月05日/Learn_to_Code_Sustainably_An_Empirical_Study_on_LLM-based_Green_Code_Generation.md)

    - [翻译: 探究如何实现可持续编程，本研究通过实证方法考察了基于大型语言模型（LLM）的绿色代码生成技术。](2024年03月05日/Learn_to_Code_Sustainably_An_Empirical_Study_on_LLM-based_Green_Code_Generation.md)

- [Scope of Large Language Models for Mining Emerging Opinions in Online Health Discourse](2024年03月05日/Scope_of_Large_Language_Models_for_Mining_Emerging_Opinions_in_Online_Health_Discourse.md)

    - [翻译: 探究大型语言模型在揭示在线健康讨论中新兴观点方面的潜力及应用范围](2024年03月05日/Scope_of_Large_Language_Models_for_Mining_Emerging_Opinions_in_Online_Health_Discourse.md)

- [DIVERSE: Deciphering Internet Views on the U.S. Military Through Video Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification](2024年03月05日/DIVERSE_Deciphering_Internet_Views_on_the_U.S._Military_Through_Video_Comment_Stance_Analysis,_A_Novel_Benchmark_Dataset_for_Stance_Classification.md)

    - [翻译: DIVERSE 是一个创新的基准数据集，它专注于通过分析视频评论中的立场来解读网络舆论中关于美国军事的不同观点，为 stance 分类任务提供了有力支持。](2024年03月05日/DIVERSE_Deciphering_Internet_Views_on_the_U.S._Military_Through_Video_Comment_Stance_Analysis,_A_Novel_Benchmark_Dataset_for_Stance_Classification.md)

- [Guardrail Baselines for Unlearning in LLMs](2024年03月05日/Guardrail_Baselines_for_Unlearning_in_LLMs.md)

    - [翻译: 针对LLMs的遗忘问题，我们提出“防护栏基线”，旨在为模型提供一种有效去除有害信息或实现数据遗忘的基准方法。](2024年03月05日/Guardrail_Baselines_for_Unlearning_in_LLMs.md)

- [Book2Dial: Generating Teacher-Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots](2024年03月05日/Book2Dial_Generating_Teacher-Student_Interactions_from_Textbooks_for_Cost-Effective_Development_of_Educational_Chatbots.md)

    - [翻译: Book2Dial 是一项创新方法，通过将教科书内容转化为教师与学生的互动对话，为高效开发教育聊天机器人降低成本。这项技术能够自动生成源于教科书的对话场景，助力构建更具教学价值的教育聊天机器人。](2024年03月05日/Book2Dial_Generating_Teacher-Student_Interactions_from_Textbooks_for_Cost-Effective_Development_of_Educational_Chatbots.md)

- ["It's the only thing I can trust": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance](2024年03月05日/It's_the_only_thing_I_can_trust_Envisioning_Large_Language_Model_Use_by_Autistic_Workers_for_Communication_Assistance.md)

    - [翻译: 在协助沟通方面，大型语言模型成为自闭症工作者表达与交流的可靠工具。“这是我唯一信赖之物”，让我们展望这一技术如何助力自闭症群体实现有效沟通。](2024年03月05日/It's_the_only_thing_I_can_trust_Envisioning_Large_Language_Model_Use_by_Autistic_Workers_for_Communication_Assistance.md)

- [InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents](2024年03月05日/InjecAgent_Benchmarking_Indirect_Prompt_Injections_in_Tool-Integrated_Large_Language_Model_Agents.md)

    - [翻译: InjecAgent 是一个针对工具整合型大型语言模型代理的基准测试项目，专注于探究间接提示注入技术的效果。](2024年03月05日/InjecAgent_Benchmarking_Indirect_Prompt_Injections_in_Tool-Integrated_Large_Language_Model_Agents.md)

- [Prospect Personalized Recommendation on Large Language Model-based Agent Platform](2024年03月05日/Prospect_Personalized_Recommendation_on_Large_Language_Model-based_Agent_Platform.md)

    - [翻译: 面向未来，我们探讨在大型语言模型驱动的智能代理平台上实现个性化推荐的可能性与前景。](2024年03月05日/Prospect_Personalized_Recommendation_on_Large_Language_Model-based_Agent_Platform.md)

- [Human Simulacra: A Step toward the Personification of Large Language Models](2024年03月05日/Human_Simulacra_A_Step_toward_the_Personification_of_Large_Language_Models.md)

    - [翻译: 探索“人类模拟”，我们正朝着赋予大型语言模型更多人格特征的方向迈进，使其更接近真实人类的交互体验。](2024年03月05日/Human_Simulacra_A_Step_toward_the_Personification_of_Large_Language_Models.md)

- [Measuring Diversity in Co-creative Image Generation](2024年03月05日/Measuring_Diversity_in_Co-creative_Image_Generation.md)

    - [翻译: 探究协同式图像生成中的多样性度量](2024年03月05日/Measuring_Diversity_in_Co-creative_Image_Generation.md)

- [Bridging Language and Items for Retrieval and Recommendation](2024年03月06日/Bridging_Language_and_Items_for_Retrieval_and_Recommendation.md)

    - [翻译: 为实现检索与推荐，构建语言与物品之间的桥梁](2024年03月06日/Bridging_Language_and_Items_for_Retrieval_and_Recommendation.md)

- [Did Translation Models Get More Robust Without Anyone Even Noticing?](2024年03月06日/Did_Translation_Models_Get_More_Robust_Without_Anyone_Even_Noticing.md)

    - [翻译: 翻译模型是否悄无声息地增强了稳健性？](2024年03月06日/Did_Translation_Models_Get_More_Robust_Without_Anyone_Even_Noticing.md)

- [Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing](2024年03月06日/Fuzzing_BusyBox_Leveraging_LLM_and_Crash_Reuse_for_Embedded_Bug_Unearthing.md)

    - [翻译: 通过结合 LLM 技术与崩溃重用策略，我们致力于对 BusyBox 进行高效模糊测试，以揭示隐藏的嵌入式软件漏洞。](2024年03月06日/Fuzzing_BusyBox_Leveraging_LLM_and_Crash_Reuse_for_Embedded_Bug_Unearthing.md)

- [SaulLM-7B: A pioneering Large Language Model for Law](2024年03月06日/SaulLM-7B_A_pioneering_Large_Language_Model_for_Law.md)

    - [翻译: SaulLM-7B，作为一款开路先锋般的大型语言模型，专为法律应用场景打造。](2024年03月06日/SaulLM-7B_A_pioneering_Large_Language_Model_for_Law.md)

- [Learning to Decode Collaboratively with Multiple Language Models](2024年03月06日/Learning_to_Decode_Collaboratively_with_Multiple_Language_Models.md)

    - [翻译: 本研究探讨如何训练多个语言模型协同解码，以提升整体的解码效果和性能。](2024年03月06日/Learning_to_Decode_Collaboratively_with_Multiple_Language_Models.md)

- [On the Origins of Linear Representations in Large Language Models](2024年03月06日/On_the_Origins_of_Linear_Representations_in_Large_Language_Models.md)

    - [翻译: 本文深入探讨大型语言模型内部线性表示的起源，揭示其内在机理与构建过程。](2024年03月06日/On_the_Origins_of_Linear_Representations_in_Large_Language_Models.md)

- [KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions](2024年03月06日/KIWI_A_Dataset_of_Knowledge-Intensive_Writing_Instructions_for_Answering_Research_Questions.md)

    - [翻译: KIWI 数据集，专为解答研究问题而设计，提供了丰富的知识密集型写作指导。](2024年03月06日/KIWI_A_Dataset_of_Knowledge-Intensive_Writing_Instructions_for_Answering_Research_Questions.md)

- [Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning](2024年03月06日/Are_Language_Models_Puzzle_Prodigies_Algorithmic_Puzzles_Unveil_Serious_Challenges_in_Multimodal_Reasoning.md)

    - [翻译: 语言模型堪称解谜高手吗？通过算法谜题，我们发现它们在解决多模态推理问题时面临重大挑战。](2024年03月06日/Are_Language_Models_Puzzle_Prodigies_Algorithmic_Puzzles_Unveil_Serious_Challenges_in_Multimodal_Reasoning.md)

- [X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification](2024年03月06日/X-Shot_A_Unified_System_to_Handle_Frequent,_Few-shot_and_Zero-shot_Learning_Simultaneously_in_Classification.md)

    - [翻译: X-Shot 系统集大成，一举囊括了分类任务中频繁出现、少量样本及零样本的学习场景，实现了一体化解决方案。](2024年03月06日/X-Shot_A_Unified_System_to_Handle_Frequent,_Few-shot_and_Zero-shot_Learning_Simultaneously_in_Classification.md)

- [Designing Informative Metrics for Few-Shot Example Selection](2024年03月06日/Designing_Informative_Metrics_for_Few-Shot_Example_Selection.md)

    - [翻译: 本研究致力于设计针对少量示例选择的有效度量标准，以期提升模型在有限数据下的学习与泛化能力。](2024年03月06日/Designing_Informative_Metrics_for_Few-Shot_Example_Selection.md)

- [Emojinize : Enriching Any Text with Emoji Translations](2024年03月06日/Emojinize__Enriching_Any_Text_with_Emoji_Translations.md)

    - [翻译: Emojinize项目致力于为任意文本增添生动有趣的Emoji表达，实现文本内容的emoji化增强。](2024年03月06日/Emojinize__Enriching_Any_Text_with_Emoji_Translations.md)

- [ShortGPT: Layers in Large Language Models are More Redundant Than You Expect](2024年03月06日/ShortGPT_Layers_in_Large_Language_Models_are_More_Redundant_Than_You_Expect.md)

    - [翻译: ShortGPT 揭示，大型语言模型内部的层级存在超乎预期的冗余现象。](2024年03月06日/ShortGPT_Layers_in_Large_Language_Models_are_More_Redundant_Than_You_Expect.md)

- [Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ](2024年03月06日/Evaluating_the_Elementary_Multilingual_Capabilities_of_Large_Language_Models_with_MultiQ.md)

    - [翻译: 我们运用 MultiQ 工具，对大型语言模型在处理基础多语言任务时的能力进行深入评估。](2024年03月06日/Evaluating_the_Elementary_Multilingual_Capabilities_of_Large_Language_Models_with_MultiQ.md)

- [Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection from Remote Sensing Imagery](2024年03月06日/Popeye_A_Unified_Visual-Language_Model_for_Multi-Source_Ship_Detection_from_Remote_Sensing_Imagery.md)

    - [翻译: Popeye 是一款集成了视觉与语言处理能力的统一模型，专为在遥感图像中实现多源船舶检测而设计。](2024年03月06日/Popeye_A_Unified_Visual-Language_Model_for_Multi-Source_Ship_Detection_from_Remote_Sensing_Imagery.md)

- [PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion](2024年03月06日/PPTC-R_benchmark_Towards_Evaluating_the_Robustness_of_Large_Language_Models_for_PowerPoint_Task_Completion.md)

    - [翻译: PPTC-R基准测试旨在深入探究大型语言模型在应对PowerPoint任务挑战时的稳健性表现。](2024年03月06日/PPTC-R_benchmark_Towards_Evaluating_the_Robustness_of_Large_Language_Models_for_PowerPoint_Task_Completion.md)

- [German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset](2024年03月06日/German_also_Hallucinates!_Inconsistency_Detection_in_News_Summaries_with_the_Absinth_Dataset.md)

    - [翻译: 德语文本亦会“幻想”！利用Absinth数据集揭示新闻摘要中的不一致性问题](2024年03月06日/German_also_Hallucinates!_Inconsistency_Detection_in_News_Summaries_with_the_Absinth_Dataset.md)

- [Towards Safe and Aligned Large Language Models for Medicine](2024年03月06日/Towards_Safe_and_Aligned_Large_Language_Models_for_Medicine.md)

    - [翻译: 本研究致力于研发适用于医学领域的安全且高度兼容的大型语言模型，旨在提升其在医疗场景下的表现和可靠性。](2024年03月06日/Towards_Safe_and_Aligned_Large_Language_Models_for_Medicine.md)

- [Multimodal Transformer for Comics Text-Cloze](2024年03月06日/Multimodal_Transformer_for_Comics_Text-Cloze.md)

    - [翻译: 针对漫画文本完形填空任务，我们采用多模态 Transformer 技术，旨在整合图像与文本信息，以提升模型在理解漫画情境并准确完成文本完形填空方面的性能。](2024年03月06日/Multimodal_Transformer_for_Comics_Text-Cloze.md)

- [Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese](2024年03月06日/Rapidly_Developing_High-quality_Instruction_Data_and_Evaluation_Benchmark_for_Large_Language_Models_with_Minimal_Human_Effort_A_Case_Study_on_Japanese.md)

    - [翻译: 针对大型语言模型，本研究案例展示了如何高效地以最小化人工投入的方式快速构建高质量的指令数据集及评估基准，此方法特别适用于日语场景。](2024年03月06日/Rapidly_Developing_High-quality_Instruction_Data_and_Evaluation_Benchmark_for_Large_Language_Models_with_Minimal_Human_Effort_A_Case_Study_on_Japanese.md)

- [General2Specialized LLMs Translation for E-commerce](2024年03月06日/General2Specialized_LLMs_Translation_for_E-commerce.md)

    - [翻译: 面向电商领域的 General2Specialized LLMs 翻译技术](2024年03月06日/General2Specialized_LLMs_Translation_for_E-commerce.md)

- [Automatic Bi-modal Question Title Generation for Stack Overflow with Prompt Learning](2024年03月06日/Automatic_Bi-modal_Question_Title_Generation_for_Stack_Overflow_with_Prompt_Learning.md)

    - [翻译: 本研究借助提示学习技术，针对 Stack Overflow 平台开发了一种自动为编程问题生成融合两种模态信息的标题方法。](2024年03月06日/Automatic_Bi-modal_Question_Title_Generation_for_Stack_Overflow_with_Prompt_Learning.md)

- [K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data](2024年03月06日/K-Link_Knowledge-Link_Graph_from_LLMs_for_Enhanced_Representation_Learning_in_Multivariate_Time-Series_Data.md)

    - [翻译: K-Link 方法通过从大型语言模型（LLMs）中提炼出知识链接图，旨在提升多元时间序列数据的表征学习效果。](2024年03月06日/K-Link_Knowledge-Link_Graph_from_LLMs_for_Enhanced_Representation_Learning_in_Multivariate_Time-Series_Data.md)

- [SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models](2024年03月06日/SheetAgent_A_Generalist_Agent_for_Spreadsheet_Reasoning_and_Manipulation_via_Large_Language_Models.md)

    - [翻译: SheetAgent 是一款借助大型语言模型，实现对电子表格进行高效推理与灵活操控的全能型智能助手。](2024年03月06日/SheetAgent_A_Generalist_Agent_for_Spreadsheet_Reasoning_and_Manipulation_via_Large_Language_Models.md)

- [GPTopic: Dynamic and Interactive Topic Representations](2024年03月06日/GPTopic_Dynamic_and_Interactive_Topic_Representations.md)

    - [翻译: GPTopic：探索动态且互动的主题表达方式](2024年03月06日/GPTopic_Dynamic_and_Interactive_Topic_Representations.md)

- [Multimodal Large Language Models to Support Real-World Fact-Checking](2024年03月06日/Multimodal_Large_Language_Models_to_Support_Real-World_Fact-Checking.md)

    - [翻译: 为助力现实世界中的事实核查，我们引入了多模态大型语言模型。这类模型能够整合多种信息源，以提升对复杂情境中事实信息的精准判断能力。](2024年03月06日/Multimodal_Large_Language_Models_to_Support_Real-World_Fact-Checking.md)

- [Assessing the Aesthetic Evaluation Capabilities of GPT-4 with Vision: Insights from Group and Individual Assessments](2024年03月06日/Assessing_the_Aesthetic_Evaluation_Capabilities_of_GPT-4_with_Vision_Insights_from_Group_and_Individual_Assessments.md)

    - [翻译: 通过对 GPT-4 进行群体及个体评估，本研究探索其结合视觉进行审美评价的能力，并揭示相关深刻见解。](2024年03月06日/Assessing_the_Aesthetic_Evaluation_Capabilities_of_GPT-4_with_Vision_Insights_from_Group_and_Individual_Assessments.md)

- [RouteExplainer: An Explanation Framework for Vehicle Routing Problem](2024年03月06日/RouteExplainer_An_Explanation_Framework_for_Vehicle_Routing_Problem.md)

    - [翻译: RouteExplainer 是一个专为解决车辆路径规划问题而设计的解释性框架，旨在深入解析并清晰展现路径决策背后的逻辑与依据。](2024年03月06日/RouteExplainer_An_Explanation_Framework_for_Vehicle_Routing_Problem.md)

- [Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem](2024年03月06日/Benchmarking_Hallucination_in_Large_Language_Models_based_on_Unanswerable_Math_Word_Problem.md)

    - [翻译: 本研究通过利用无解数学题，对大型语言模型中出现的“幻想”现象进行基准评估，旨在深入理解并量化其在面对这类问题时的错误生成表现。](2024年03月06日/Benchmarking_Hallucination_in_Large_Language_Models_based_on_Unanswerable_Math_Word_Problem.md)

- [Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models](2024年03月06日/Emotional_Manipulation_Through_Prompt_Engineering_Amplifies_Disinformation_Generation_in_AI_Large_Language_Models.md)

    - [翻译: 运用提示工程技术进行情感操纵，能够加剧 AI 大型语言模型制造虚假信息的问题。](2024年03月06日/Emotional_Manipulation_Through_Prompt_Engineering_Amplifies_Disinformation_Generation_in_AI_Large_Language_Models.md)

- [Prompt Mining for Language-based Human Mobility Forecasting](2024年03月06日/Prompt_Mining_for_Language-based_Human_Mobility_Forecasting.md)

    - [翻译: 在语言驱动的人类行动轨迹预测中，我们探索了提示挖掘技术的应用，旨在通过有效提取和利用提示信息来提升预测准确性与模型效能。](2024年03月06日/Prompt_Mining_for_Language-based_Human_Mobility_Forecasting.md)

- [Towards Efficient and Effective Unlearning of Large Language Models for Recommendation](2024年03月06日/Towards_Efficient_and_Effective_Unlearning_of_Large_Language_Models_for_Recommendation.md)

    - [翻译: 本研究致力于探索如何让大型语言模型在推荐场景中实现高效且有效的遗忘学习，即针对已学习内容进行有效“反学习”。（注：此处将“unlearning”翻译为“遗忘学习”或“反学习”，是因为在AI领域中，“unlearning”通常指的是对模型已经学到的内容进行去除或更新的过程。）](2024年03月06日/Towards_Efficient_and_Effective_Unlearning_of_Large_Language_Models_for_Recommendation.md)

- [Non-verbal information in spontaneous speech - towards a new framework of analysis](2024年03月06日/Non-verbal_information_in_spontaneous_speech_-_towards_a_new_framework_of_analysis.md)

    - [翻译: 在探索自发性言语的奥秘时，我们正迈向一个全新的分析框架，聚焦于其中蕴含的非言语信息。](2024年03月06日/Non-verbal_information_in_spontaneous_speech_-_towards_a_new_framework_of_analysis.md)

- [CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models](2024年03月06日/CLongEval_A_Chinese_Benchmark_for_Evaluating_Long-Context_Large_Language_Models.md)

    - [翻译: CLongEval —— 专为评估大型语言模型在处理长文本情境能力而设的中文评测基准](2024年03月06日/CLongEval_A_Chinese_Benchmark_for_Evaluating_Long-Context_Large_Language_Models.md)

- [GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection](2024年03月06日/GaLore_Memory-Efficient_LLM_Training_by_Gradient_Low-Rank_Projection.md)

    - [翻译: GaLore——一种通过梯度低秩投影技术提升大语言模型（LLM）训练内存效率的新方案。](2024年03月06日/GaLore_Memory-Efficient_LLM_Training_by_Gradient_Low-Rank_Projection.md)

- [A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation](2024年03月06日/A_Knowledge_Plug-and-Play_Test_Bed_for_Open-domain_Dialogue_Generation.md)

    - [翻译: 我们构建了一个针对开放领域对话生成的“知识即插即用”测试平台，旨在便捷地探究和验证各类知识在对话生成任务中的应用效果。](2024年03月06日/A_Knowledge_Plug-and-Play_Test_Bed_for_Open-domain_Dialogue_Generation.md)

- [Aligners: Decoupling LLMs and Alignment](2024年03月06日/Aligners_Decoupling_LLMs_and_Alignment.md)

    - [翻译: 本文探讨“对齐器”，旨在将大型语言模型（LLM）与其对齐机制分离。通过这种方法，我们深入研究如何独立优化LLM的性能与对其行为和输出的可控性，以实现更好的对齐效果。](2024年03月06日/Aligners_Decoupling_LLMs_and_Alignment.md)

- [Self-Evaluation of Large Language Model based on Glass-box Features](2024年03月06日/Self-Evaluation_of_Large_Language_Model_based_on_Glass-box_Features.md)

    - [翻译: 针对大型语言模型，本研究采用 Glass-box 特征进行自我评估，旨在通过解析模型内部透明可见的特征来评价其性能表现。](2024年03月06日/Self-Evaluation_of_Large_Language_Model_based_on_Glass-box_Features.md)

- [Large Language Models are In-Context Molecule Learners](2024年03月06日/Large_Language_Models_are_In-Context_Molecule_Learners.md)

    - [翻译: 大型语言模型擅长于在上下文中学习分子知识（注：由于原文标题简洁且具有一定的专业性，从准确性和生动性角度考虑，在翻译时保留了“上下文”这一术语，并将“learner”译为更符合中文表达习惯的“学习者”，同时也强调了其在分子领域的学习能力。）](2024年03月06日/Large_Language_Models_are_In-Context_Molecule_Learners.md)

- [Generative AI for Synthetic Data Generation: Methods, Challenges and the Future](2024年03月06日/Generative_AI_for_Synthetic_Data_Generation_Methods,_Challenges_and_the_Future.md)

    - [翻译: 探究生成式AI在合成数据创造中的方法论、面临的挑战及其未来趋势](2024年03月06日/Generative_AI_for_Synthetic_Data_Generation_Methods,_Challenges_and_the_Future.md)

- [Metric-aware LLM inference](2024年03月06日/Metric-aware_LLM_inference.md)

    - [翻译: 面向指标的 LLM 推理技术](2024年03月06日/Metric-aware_LLM_inference.md)

- [Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy](2024年03月06日/Improving_Retrieval_in_Theme-specific_Applications_using_a_Corpus_Topical_Taxonomy.md)

    - [翻译: 通过构建和运用基于语料库的主题分类体系，本研究致力于提升各类特定主题应用中的检索效果。](2024年03月06日/Improving_Retrieval_in_Theme-specific_Applications_using_a_Corpus_Topical_Taxonomy.md)

- [Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference](2024年03月06日/Chatbot_Arena_An_Open_Platform_for_Evaluating_LLMs_by_Human_Preference.md)

    - [翻译: Chatbot Arena——一个通过人类偏好评判LLMs表现的公开平台，旨在为各类大型语言模型提供公正、直观的人性化评估环境。](2024年03月06日/Chatbot_Arena_An_Open_Platform_for_Evaluating_LLMs_by_Human_Preference.md)

- [Privacy-preserving Fine-tuning of Large Language Models through Flatness](2024年03月06日/Privacy-preserving_Fine-tuning_of_Large_Language_Models_through_Flatness.md)

    - [翻译: 针对大型语言模型，我们提出了一种基于“平坦性”的隐私保护微调方法。该方法旨在在保持模型性能的同时，有效保障用户数据隐私，特别是在对大型语言模型进行针对性优化时。](2024年03月06日/Privacy-preserving_Fine-tuning_of_Large_Language_Models_through_Flatness.md)

- [Exploring LLM-based Agents for Root Cause Analysis](2024年03月06日/Exploring_LLM-based_Agents_for_Root_Cause_Analysis.md)

    - [翻译: 本研究致力于探究基于大型语言模型（LLM）的智能体在根因分析任务中的应用与潜力。](2024年03月06日/Exploring_LLM-based_Agents_for_Root_Cause_Analysis.md)

- [Can Large Language Models Reason and Plan?](2024年03月06日/Can_Large_Language_Models_Reason_and_Plan.md)

    - [翻译: 探究大型语言模型能否进行推理与规划步骤解释：](2024年03月06日/Can_Large_Language_Models_Reason_and_Plan.md)

- [Artificial Intelligence Exploring the Patent Field](2024年03月06日/Artificial_Intelligence_Exploring_the_Patent_Field.md)

    - [翻译: 人工智能涉足专利界，正不断探寻其中的创新疆域。](2024年03月06日/Artificial_Intelligence_Exploring_the_Patent_Field.md)

- [Can Large Language Models do Analytical Reasoning?](2024年03月06日/Can_Large_Language_Models_do_Analytical_Reasoning.md)

    - [翻译: 大型语言模型是否具备进行分析推理的能力呢？](2024年03月06日/Can_Large_Language_Models_do_Analytical_Reasoning.md)

- [Enhancing chest X-ray datasets with privacy-preserving large language models and multi-type annotations: a data-driven approach for improved classification](2024年03月06日/Enhancing_chest_X-ray_datasets_with_privacy-preserving_large_language_models_and_multi-type_annotations_a_data-driven_approach_for_improved_classification.md)

    - [翻译: 我们提出了一种数据驱动的方案，利用隐私保护的大规模语言模型及多元注解技术来提升胸部X射线数据集的质量，从而实现更精确的分类效果。](2024年03月06日/Enhancing_chest_X-ray_datasets_with_privacy-preserving_large_language_models_and_multi-type_annotations_a_data-driven_approach_for_improved_classification.md)

- [FaaF: Facts as a Function for the evaluation of RAG systems](2024年03月06日/FaaF_Facts_as_a_Function_for_the_evaluation_of_RAG_systems.md)

    - [翻译: FaaF：提出“事实即函数”方法，用于评估 RAG 系统的表现。](2024年03月06日/FaaF_Facts_as_a_Function_for_the_evaluation_of_RAG_systems.md)

- [Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks](2024年03月06日/Neural_Exec_Learning_(and_Learning_from)_Execution_Triggers_for_Prompt_Injection_Attacks.md)

    - [翻译: Neural Exec：针对提示注入攻击，研究并借鉴执行触发器的学习机制](2024年03月06日/Neural_Exec_Learning_(and_Learning_from)_Execution_Triggers_for_Prompt_Injection_Attacks.md)

- [MeaCap: Memory-Augmented Zero-shot Image Captioning](2024年03月06日/MeaCap_Memory-Augmented_Zero-shot_Image_Captioning.md)

    - [翻译: MeaCap 是一种“记忆增强型零样本图像描述”技术，它利用记忆机制提升在未见过的图像上进行自动描述的能力。](2024年03月06日/MeaCap_Memory-Augmented_Zero-shot_Image_Captioning.md)

- [Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models](2024年03月06日/Quantifying_Contamination_in_Evaluating_Code_Generation_Capabilities_of_Language_Models.md)

    - [翻译: 在衡量语言模型代码生成能力的过程中，本研究致力于量化评估中的“污染”问题，以更准确地了解模型的真实效能。](2024年03月06日/Quantifying_Contamination_in_Evaluating_Code_Generation_Capabilities_of_Language_Models.md)

- [WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](2024年03月06日/WaterMax_breaking_the_LLM_watermark_detectability-robustness-quality_trade-off.md)

    - [翻译: WaterMax 技术突破了 LLM 水印在可检测性、鲁棒性和生成文本质量间的固有折衷，实现了三者的兼顾优化。](2024年03月06日/WaterMax_breaking_the_LLM_watermark_detectability-robustness-quality_trade-off.md)

- [Human I/O: Towards a Unified Approach to Detecting Situational Impairments](2024年03月06日/Human_IO_Towards_a_Unified_Approach_to_Detecting_Situational_Impairments.md)

    - [翻译: Human I/O：致力于构建一种用于识别情境性功能障碍的综合方法](2024年03月06日/Human_IO_Towards_a_Unified_Approach_to_Detecting_Situational_Impairments.md)

- [Bridging Text and Molecule: A Survey on Multimodal Frameworks for Molecule](2024年03月06日/Bridging_Text_and_Molecule_A_Survey_on_Multimodal_Frameworks_for_Molecule.md)

    - [翻译: 此篇综述致力于探索连结文本与分子世界的桥梁——多模态框架在分子领域的应用与发展。](2024年03月06日/Bridging_Text_and_Molecule_A_Survey_on_Multimodal_Frameworks_for_Molecule.md)

- [KnowledgeVIS: Interpreting Language Models by Comparing Fill-in-the-Blank Prompts](2024年03月07日/KnowledgeVIS_Interpreting_Language_Models_by_Comparing_Fill-in-the-Blank_Prompts.md)

    - [翻译: 知识可视化（KnowledgeVIS）：一种通过对比填空式提示，深入解读语言模型的新方法。](2024年03月07日/KnowledgeVIS_Interpreting_Language_Models_by_Comparing_Fill-in-the-Blank_Prompts.md)

- [LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error](2024年03月07日/LLMs_in_the_Imaginarium_Tool_Learning_through_Simulated_Trial_and_Error.md)

    - [翻译: 在“想象工坊”场景下，LLMs 通过模拟试验与错误的方式习得工具使用技巧。](2024年03月07日/LLMs_in_the_Imaginarium_Tool_Learning_through_Simulated_Trial_and_Error.md)

- [Common 7B Language Models Already Possess Strong Math Capabilities](2024年03月07日/Common_7B_Language_Models_Already_Possess_Strong_Math_Capabilities.md)

    - [翻译: 现今的主流70亿参数语言模型普遍展现出强劲的数学处理能力。](2024年03月07日/Common_7B_Language_Models_Already_Possess_Strong_Math_Capabilities.md)

- [ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes](2024年03月07日/ObjectCompose_Evaluating_Resilience_of_Vision-Based_Models_on_Object-to-Background_Compositional_Changes.md)

    - [翻译: ObjectCompose 项目旨在评测视觉模型在面临对象与背景组合变化时的抗干扰能力。](2024年03月07日/ObjectCompose_Evaluating_Resilience_of_Vision-Based_Models_on_Object-to-Background_Compositional_Changes.md)

- [Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification](2024年03月07日/Fact-Checking_the_Output_of_Large_Language_Models_via_Token-Level_Uncertainty_Quantification.md)

    - [翻译: 针对大型语言模型的输出，我们采用Token级别不确定性量化方法进行深度事实核查。](2024年03月07日/Fact-Checking_the_Output_of_Large_Language_Models_via_Token-Level_Uncertainty_Quantification.md)

- [Telecom Language Models: Must They Be Large?](2024年03月07日/Telecom_Language_Models_Must_They_Be_Large.md)

    - [翻译: 电信领域的语言模型是否必须具备大模型特性？](2024年03月07日/Telecom_Language_Models_Must_They_Be_Large.md)

- [Teaching Large Language Models to Reason with Reinforcement Learning](2024年03月07日/Teaching_Large_Language_Models_to_Reason_with_Reinforcement_Learning.md)

    - [翻译: 运用强化学习策略，训练大型语言模型掌握推理技能](2024年03月07日/Teaching_Large_Language_Models_to_Reason_with_Reinforcement_Learning.md)

- [CAT: Enhancing Multimodal Large Language Model to Answer Questions in Dynamic Audio-Visual Scenarios](2024年03月07日/CAT_Enhancing_Multimodal_Large_Language_Model_to_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios.md)

    - [翻译: CAT研究致力于提升大型多模态语言模型，在充满变化的音视频场景下解答问题的能力。](2024年03月07日/CAT_Enhancing_Multimodal_Large_Language_Model_to_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios.md)

- [Strong Priority and Determinacy in Timed CCS](2024年03月07日/Strong_Priority_and_Determinacy_in_Timed_CCS.md)

    - [翻译: 针对定时进程演算（Timed CCS）中体现的强优先级与确定性进行深入探讨，揭示其内在机制与影响。步骤 1 翻译：Strong Priority and Determinacy in Timed Calculus of Communicating Systems (CCS)步骤 2 翻译：在通信系统计时演算（Timed CCS）中，强优先级与确定性的概念具有重要价值。本研究致力于阐述并剖析这两个特性在处理实时交互过程中的作用及其对系统行为的深刻影响。](2024年03月07日/Strong_Priority_and_Determinacy_in_Timed_CCS.md)

- [A Detailed Audio-Text Data Simulation Pipeline using Single-Event Sounds](2024年03月07日/A_Detailed_Audio-Text_Data_Simulation_Pipeline_using_Single-Event_Sounds.md)

    - [翻译: 我们构建了一种基于单个事件声音的精细音频文本数据仿真流程，旨在高效生成高质量的模拟数据。](2024年03月07日/A_Detailed_Audio-Text_Data_Simulation_Pipeline_using_Single-Event_Sounds.md)

- [Embodied Understanding of Driving Scenarios](2024年03月07日/Embodied_Understanding_of_Driving_Scenarios.md)

    - [翻译: 深入探究驾驶场景中的具身认知](2024年03月07日/Embodied_Understanding_of_Driving_Scenarios.md)

- [Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition](2024年03月07日/Wiki-TabNERAdvancing_Table_Interpretation_Through_Named_Entity_Recognition.md)

    - [翻译: Wiki-TabNER项目致力于借助命名实体识别技术提升表格理解能力，从而推动表格信息的有效解读。](2024年03月07日/Wiki-TabNERAdvancing_Table_Interpretation_Through_Named_Entity_Recognition.md)

- [Where does In-context Translation Happen in Large Language Models](2024年03月07日/Where_does_In-context_Translation_Happen_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型内部，上下文翻译究竟如何运作呢？](2024年03月07日/Where_does_In-context_Translation_Happen_in_Large_Language_Models.md)

- [GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability](2024年03月07日/GraphInstruct_Empowering_Large_Language_Models_with_Graph_Understanding_and_Reasoning_Capability.md)

    - [翻译: GraphInstruct 是一项技术，它赋予大型语言模型强大的图理解和推理能力。](2024年03月07日/GraphInstruct_Empowering_Large_Language_Models_with_Graph_Understanding_and_Reasoning_Capability.md)

- [Do Large Language Model Understand Multi-Intent Spoken Language ?](2024年03月07日/Do_Large_Language_Model_Understand_Multi-Intent_Spoken_Language_.md)

    - [翻译: 大型语言模型是否能洞悉多意图口语？](2024年03月07日/Do_Large_Language_Model_Understand_Multi-Intent_Spoken_Language_.md)

- [Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset](2024年03月07日/Pearl_A_Review-driven_Persona-Knowledge_Grounded_Conversational_Recommendation_Dataset.md)

    - [翻译: Pearl 是一个独特的对话式推荐数据集，它以评论为驱动，并紧密结合了人格知识。该数据集致力于提供更加情境化和个性化的对话推荐服务。](2024年03月07日/Pearl_A_Review-driven_Persona-Knowledge_Grounded_Conversational_Recommendation_Dataset.md)

- [Low-Resource Court Judgment Summarization for Common Law Systems](2024年03月07日/Low-Resource_Court_Judgment_Summarization_for_Common_Law_Systems.md)

    - [翻译: 致力于普通法系环境下的低资源法院判决摘要生成，本研究关注在有限数据条件下，如何高效地为法院判决文档创建精炼、准确的摘要。](2024年03月07日/Low-Resource_Court_Judgment_Summarization_for_Common_Law_Systems.md)

- [Membership Inference Attacks and Privacy in Topic Modeling](2024年03月07日/Membership_Inference_Attacks_and_Privacy_in_Topic_Modeling.md)

    - [翻译: 针对主题模型的成员身份推断攻击及其对隐私保护的影响](2024年03月07日/Membership_Inference_Attacks_and_Privacy_in_Topic_Modeling.md)

- [Feedback-Generation for Programming Exercises With GPT-4](2024年03月07日/Feedback-Generation_for_Programming_Exercises_With_GPT-4.md)

    - [翻译: GPT-4 在编程练习中助力生成针对性反馈](2024年03月07日/Feedback-Generation_for_Programming_Exercises_With_GPT-4.md)

- [Sentiment-driven prediction of financial returns: a Bayesian-enhanced FinBERT approach](2024年03月07日/Sentiment-driven_prediction_of_financial_returns_a_Bayesian-enhanced_FinBERT_approach.md)

    - [翻译: 运用贝叶斯增强技术优化的FinBERT模型，针对情感驱动的金融收益预测展开研究。](2024年03月07日/Sentiment-driven_prediction_of_financial_returns_a_Bayesian-enhanced_FinBERT_approach.md)

- [SGNet: Folding Symmetrical Protein Complex with Deep Learning](2024年03月07日/SGNet_Folding_Symmetrical_Protein_Complex_with_Deep_Learning.md)

    - [翻译: SGNet 是一个运用深度学习技术来高效折叠对称蛋白质复合体的方法。](2024年03月07日/SGNet_Folding_Symmetrical_Protein_Complex_with_Deep_Learning.md)

- [Acceleron: A Tool to Accelerate Research Ideation](2024年03月07日/Acceleron_A_Tool_to_Accelerate_Research_Ideation.md)

    - [翻译: Acceleron，一款致力于提升研究构思速度的有效工具](2024年03月07日/Acceleron_A_Tool_to_Accelerate_Research_Ideation.md)

- [ProMoAI: Process Modeling with Generative AI](2024年03月07日/ProMoAI_Process_Modeling_with_Generative_AI.md)

    - [翻译: ProMoAI——利用生成式人工智能技术进行流程模型构建](2024年03月07日/ProMoAI_Process_Modeling_with_Generative_AI.md)

- [Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models](2024年03月07日/Measuring_Meaning_Composition_in_the_Human_Brain_with_Composition_Scores_from_Large_Language_Models.md)

    - [翻译: 本研究借助大型语言模型计算出的意义组合得分，探索人类大脑中意义组合的量化衡量方法。](2024年03月07日/Measuring_Meaning_Composition_in_the_Human_Brain_with_Composition_Scores_from_Large_Language_Models.md)

- [Discriminative Probing and Tuning for Text-to-Image Generation](2024年03月07日/Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation.md)

    - [翻译: 针对文本到图像生成任务，我们采用鉴别性探查和调整技术，以深入探究模型内部机制，并优化其生成效果。](2024年03月07日/Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation.md)

- [Online Adaptation of Language Models with a Memory of Amortized Contexts](2024年03月07日/Online_Adaptation_of_Language_Models_with_a_Memory_of_Amortized_Contexts.md)

    - [翻译: 通过运用对上下文进行平均化的记忆技术，在线优化语言模型以适应不同场景。](2024年03月07日/Online_Adaptation_of_Language_Models_with_a_Memory_of_Amortized_Contexts.md)

- [Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders](2024年03月07日/Can_Your_Model_Tell_a_Negation_from_an_Implicature_Unravelling_Challenges_With_Intent_Encoders.md)

    - [翻译: 探究模型是否能够有效区分否定表达与蕴含含义，同时揭示在构建意图编码器过程中所遇到的难题。](2024年03月07日/Can_Your_Model_Tell_a_Negation_from_an_Implicature_Unravelling_Challenges_With_Intent_Encoders.md)

- [HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild](2024年03月07日/HaluEval-Wild_Evaluating_Hallucinations_of_Language_Models_in_the_Wild.md)

    - [翻译: HaluEval-Wild 是一项针对真实环境中的语言模型所生成的幻觉内容进行评估的研究项目。](2024年03月07日/HaluEval-Wild_Evaluating_Hallucinations_of_Language_Models_in_the_Wild.md)

- [Effectiveness Assessment of Recent Large Vision-Language Models](2024年03月07日/Effectiveness_Assessment_of_Recent_Large_Vision-Language_Models.md)

    - [翻译: 本研究致力于评估最新大型视觉-语言模型的实际效果，探究其在各类跨模态任务中的表现与价值。](2024年03月07日/Effectiveness_Assessment_of_Recent_Large_Vision-Language_Models.md)

- [Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model with Proxy](2024年03月07日/Proxy-RLHF_Decoupling_Generation_and_Alignment_in_Large_Language_Model_with_Proxy.md)

    - [翻译: Proxy-RLHF 是一种创新方法，它在大型语言模型中巧妙地运用“代理”手段，成功实现了生成能力与对齐目标的解耦合，尤其适用于提升语言模型在保持高质量文本生成的同时，更好地满足预设规范和要求。](2024年03月07日/Proxy-RLHF_Decoupling_Generation_and_Alignment_in_Large_Language_Model_with_Proxy.md)

- [Advancing Biomedical Text Mining with Community Challenges](2024年03月07日/Advancing_Biomedical_Text_Mining_with_Community_Challenges.md)

    - [翻译: 社区挑战驱动生物医学文本挖掘的进步与突破](2024年03月07日/Advancing_Biomedical_Text_Mining_with_Community_Challenges.md)

- [Can Small Language Models be Good Reasoners for Sequential Recommendation?](2024年03月07日/Can_Small_Language_Models_be_Good_Reasoners_for_Sequential_Recommendation.md)

    - [翻译: 小型语言模型能否在序列推荐任务上展现出色的推理能力呢？](2024年03月07日/Can_Small_Language_Models_be_Good_Reasoners_for_Sequential_Recommendation.md)

- [Towards Robustness Analysis of E-Commerce Ranking System](2024年03月07日/Towards_Robustness_Analysis_of_E-Commerce_Ranking_System.md)

    - [翻译: 本研究致力于深入探究电子商务排名系统的鲁棒性，旨在全面分析和提升该系统在复杂环境下的稳定性和可靠性。](2024年03月07日/Towards_Robustness_Analysis_of_E-Commerce_Ranking_System.md)

- [Federated Recommendation via Hybrid Retrieval Augmented Generation](2024年03月07日/Federated_Recommendation_via_Hybrid_Retrieval_Augmented_Generation.md)

    - [翻译: 我们提出了一种混合检索增强生成方法，以实现联邦推荐系统。该方法巧妙结合了检索和生成技术，在保护用户数据隐私的同时，有效提升了推荐系统的性能和准确性。步骤 1：联邦推荐是通过混合检索增强生成技术实现的。步骤 2：在保证用户数据隐私的前提下，一种名为“混合检索增强生成”的创新技术被应用于联邦推荐场景中，旨在融合检索与生成策略，以优化推荐效果并保障数据安全性。](2024年03月07日/Federated_Recommendation_via_Hybrid_Retrieval_Augmented_Generation.md)

- [UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed Entities](2024年03月07日/UltraWiki_Ultra-fine-grained_Entity_Set_Expansion_with_Negative_Seed_Entities.md)

    - [翻译: UltraWiki项目致力于通过引入负向种子实体，实现对实体集进行超精细的扩展探索。](2024年03月07日/UltraWiki_Ultra-fine-grained_Entity_Set_Expansion_with_Negative_Seed_Entities.md)

- [DEEP-ICL: Definition-Enriched Experts for Language Model In-Context Learning](2024年03月07日/DEEP-ICL_Definition-Enriched_Experts_for_Language_Model_In-Context_Learning.md)

    - [翻译: DEEP-ICL：致力于为语言模型的上下文学习注入更多定义性知识的专家系统](2024年03月07日/DEEP-ICL_Definition-Enriched_Experts_for_Language_Model_In-Context_Learning.md)

- [iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries](2024年03月07日/iScore_Visual_Analytics_for_Interpreting_How_Language_Models_Automatically_Score_Summaries.md)

    - [翻译: iScore 是一款可视化分析工具，它帮助我们理解语言模型如何自动评估和打分摘要内容。](2024年03月07日/iScore_Visual_Analytics_for_Interpreting_How_Language_Models_Automatically_Score_Summaries.md)

- [XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution](2024年03月07日/XPSR_Cross-modal_Priors_for_Diffusion-based_Image_Super-Resolution.md)

    - [翻译: XPSR：探索扩散式图像超分辨率技术中的跨模态先验知识，旨在提升图像处理性能和质量。](2024年03月07日/XPSR_Cross-modal_Priors_for_Diffusion-based_Image_Super-Resolution.md)

- [Are Human Conversations Special? A Large Language Model Perspective](2024年03月07日/Are_Human_Conversations_Special_A_Large_Language_Model_Perspective.md)

    - [翻译: 从大型语言模型的角度出发，我们是否能断言人类对话具有某种特殊性呢？](2024年03月07日/Are_Human_Conversations_Special_A_Large_Language_Model_Perspective.md)

- [Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs](2024年03月07日/Is_this_the_real_life_Is_this_just_fantasy_The_Misleading_Success_of_Simulating_Social_Interactions_With_LLMs.md)

    - [翻译: 现实抑或幻象？LLMs在模拟社交互动中取得的成功，其真实性是否存在误导性呢？](2024年03月07日/Is_this_the_real_life_Is_this_just_fantasy_The_Misleading_Success_of_Simulating_Social_Interactions_With_LLMs.md)

- [Can't Remember Details in Long Documents? You Need Some R&R](2024年03月07日/Can't_Remember_Details_in_Long_Documents_You_Need_Some_R&R.md)

    - [翻译: 面对长篇文档，细节总记不住？或许你需要来点“R&R”魔法。 （注：这里的“R&R”在原文中未明确指出含义，可能是“Rest and Relaxation（休息与放松）”或某种解决方法的缩写，在翻译时可根据上下文进行适当推测和解释。）](2024年03月07日/Can't_Remember_Details_in_Long_Documents_You_Need_Some_R&R.md)

- [DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation](2024年03月07日/DiffChat_Learning_to_Chat_with_Text-to-Image_Synthesis_Models_for_Interactive_Image_Creation.md)

    - [翻译: DiffChat 让我们能够通过学习与文本转图像合成模型进行对话，从而实现图像的互动式创作。](2024年03月07日/DiffChat_Learning_to_Chat_with_Text-to-Image_Synthesis_Models_for_Interactive_Image_Creation.md)

- [Embracing Large Language and Multimodal Models for Prosthetic Technologies](2024年03月07日/Embracing_Large_Language_and_Multimodal_Models_for_Prosthetic_Technologies.md)

    - [翻译: 积极采用大型语言及多模态模型赋能假体技术发展](2024年03月07日/Embracing_Large_Language_and_Multimodal_Models_for_Prosthetic_Technologies.md)

- [Tell me the truth: A system to measure the trustworthiness of Large Language Models](2024年03月07日/Tell_me_the_truth_A_system_to_measure_the_trustworthiness_of_Large_Language_Models.md)

    - [翻译: 揭示真相：该系统旨在评测大型语言模型的信任度，以准确衡量其可靠程度。](2024年03月07日/Tell_me_the_truth_A_system_to_measure_the_trustworthiness_of_Large_Language_Models.md)

- [An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment](2024年03月07日/An_In-depth_Evaluation_of_GPT-4_in_Sentence_Simplification_with_Error-based_Human_Assessment.md)

    - [翻译: 通过细致的错误导向人工评估，我们对GPT-4在句子简化任务中的表现进行了深度剖析。](2024年03月07日/An_In-depth_Evaluation_of_GPT-4_in_Sentence_Simplification_with_Error-based_Human_Assessment.md)

- [SecGPT: An Execution Isolation Architecture for LLM-Based Systems](2024年03月07日/SecGPT_An_Execution_Isolation_Architecture_for_LLM-Based_Systems.md)

    - [翻译: SecGPT是一种专为基于大型语言模型（LLM）的系统设计的执行隔离架构，旨在确保其安全性和稳定性。](2024年03月07日/SecGPT_An_Execution_Isolation_Architecture_for_LLM-Based_Systems.md)

- [Automatic and Universal Prompt Injection Attacks against Large Language Models](2024年03月07日/Automatic_and_Universal_Prompt_Injection_Attacks_against_Large_Language_Models.md)

    - [翻译: 自动且普遍性的提示注入攻击，对大型语言模型构成了威胁。这项研究探讨了如何针对大型语言模型实施自动化、普适性的提示注入攻击，揭示其潜在安全风险。](2024年03月07日/Automatic_and_Universal_Prompt_Injection_Attacks_against_Large_Language_Models.md)

- [A Survey on Human-AI Teaming with Large Pre-Trained Models](2024年03月07日/A_Survey_on_Human-AI_Teaming_with_Large_Pre-Trained_Models.md)

    - [翻译: 本篇调研聚焦于大型预训练模型在人机协作中的应用，详尽探讨了这一领域的最新进展与实践。](2024年03月07日/A_Survey_on_Human-AI_Teaming_with_Large_Pre-Trained_Models.md)

- [Self-Adapting Large Visual-Language Models to Edge Devices across Visual Modalities](2024年03月07日/Self-Adapting_Large_Visual-Language_Models_to_Edge_Devices_across_Visual_Modalities.md)

    - [翻译: 该研究致力于将自适应的大型视觉-语言模型推广至不同视觉模态下的边缘设备，实现模型在各类终端上的高效运行。](2024年03月07日/Self-Adapting_Large_Visual-Language_Models_to_Edge_Devices_across_Visual_Modalities.md)

- [ConstitutionalExperts: Training a Mixture of Principle-based Prompts](2024年03月07日/ConstitutionalExperts_Training_a_Mixture_of_Principle-based_Prompts.md)

    - [翻译: 「宪法专家」模型：通过融合原则性提示进行训练，旨在提升模型在处理宪法相关问题时的专业性和准确性。](2024年03月07日/ConstitutionalExperts_Training_a_Mixture_of_Principle-based_Prompts.md)

- [Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question answering](2024年03月07日/Few_shot_chain-of-thought_driven_reasoning_to_prompt_LLMs_for_open_ended_medical_question_answering.md)

    - [翻译: 针对开放式医疗问题解答，我们采用少量示例的链式思考驱动方式来激活LLM的强大推理能力。](2024年03月07日/Few_shot_chain-of-thought_driven_reasoning_to_prompt_LLMs_for_open_ended_medical_question_answering.md)

- [Evaluating Biases in Context-Dependent Health Questions](2024年03月07日/Evaluating_Biases_in_Context-Dependent_Health_Questions.md)

    - [翻译: 本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](2024年03月07日/Evaluating_Biases_in_Context-Dependent_Health_Questions.md)

- [Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks](2024年03月07日/Evaluation_of_LLMs_on_Syntax-Aware_Code_Fill-in-the-Middle_Tasks.md)

    - [翻译: 本研究专注于评估LLMs在处理具有语法感知能力的代码中间填充任务时的表现。](2024年03月07日/Evaluation_of_LLMs_on_Syntax-Aware_Code_Fill-in-the-Middle_Tasks.md)

- [Ducho 2.0: Towards a More Up-to-Date Feature Extraction and Processing Framework for Multimodal Recommendation](2024年03月07日/Ducho_2.0_Towards_a_More_Up-to-Date_Feature_Extraction_and_Processing_Framework_for_Multimodal_Recommendation.md)

    - [翻译: Ducho 2.0，旨在构建一个面向最新技术的多模态推荐特征抽取与处理框架，力求在该领域实现更先进、更实时的性能提升。](2024年03月07日/Ducho_2.0_Towards_a_More_Up-to-Date_Feature_Extraction_and_Processing_Framework_for_Multimodal_Recommendation.md)

- [TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document](2024年03月07日/TextMonkey_An_OCR-Free_Large_Multimodal_Model_for_Understanding_Document.md)

    - [翻译: TextMonkey——一款突破性 OCR 限制的大型多模态模型，致力于深入理解和解析各类文档内容。](2024年03月07日/TextMonkey_An_OCR-Free_Large_Multimodal_Model_for_Understanding_Document.md)

- [CoTBal: Comprehensive Task Balancing for Multi-Task Visual Instruction Tuning](2024年03月07日/CoTBal_Comprehensive_Task_Balancing_for_Multi-Task_Visual_Instruction_Tuning.md)

    - [翻译: CoTBal 是一种针对多任务视觉指令调优的全新方法，致力于实现全面的任务平衡，以优化模型在不同视觉指令任务中的综合表现。](2024年03月07日/CoTBal_Comprehensive_Task_Balancing_for_Multi-Task_Visual_Instruction_Tuning.md)

- [Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study](2024年03月07日/Towards_General_Computer_Control_A_Multimodal_Agent_for_Red_Dead_Redemption_II_as_a_Case_Study.md)

    - [翻译: 为了探索通用计算机控制的可能性，我们以《荒野大镖客2》为例，设计并研发了一个多模态智能体进行深度探究。通过该游戏作为案例研究，旨在揭示多模态智能体在复杂环境下的控制能力与适应性。](2024年03月07日/Towards_General_Computer_Control_A_Multimodal_Agent_for_Red_Dead_Redemption_II_as_a_Case_Study.md)

- [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](2024年03月08日/Gemini_1.5_Unlocking_multimodal_understanding_across_millions_of_tokens_of_context.md)

    - [翻译: Gemini 1.5 开启新篇章，跨过数百万个上下文标记，释放强大的多模态理解潜力](2024年03月08日/Gemini_1.5_Unlocking_multimodal_understanding_across_millions_of_tokens_of_context.md)

- [GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM](2024年03月08日/GEAR_An_Efficient_KV_Cache_Compression_Recipefor_Near-Lossless_Generative_Inference_of_LLM.md)

    - [翻译: GEAR是专为LLM设计的一种有效KV缓存压缩策略，旨在实现近无损的生成推理性能。这款新颖的压缩方案助力LLM在进行生成推理时，既能保持高效性又能实现近乎无损的质量保证。](2024年03月08日/GEAR_An_Efficient_KV_Cache_Compression_Recipefor_Near-Lossless_Generative_Inference_of_LLM.md)

- [Beyond Finite Data: Towards Data-free Out-of-distribution Generalization via Extrapola](2024年03月08日/Beyond_Finite_Data_Towards_Data-free_Out-of-distribution_Generalization_via_Extrapola.md)

    - [翻译: 迈向无限可能：利用外推法突破数据局限，实现对未见过数据分布的泛化能力](2024年03月08日/Beyond_Finite_Data_Towards_Data-free_Out-of-distribution_Generalization_via_Extrapola.md)

- [To Err Is Human, but Llamas Can Learn It Too](2024年03月08日/To_Err_Is_Human,_but_Llamas_Can_Learn_It_Too.md)

    - [翻译: 犯错误是人类的天性，然而羊驼也同样具有学习犯错的能力。](2024年03月08日/To_Err_Is_Human,_but_Llamas_Can_Learn_It_Too.md)

- [Will GPT-4 Run DOOM?](2024年03月08日/Will_GPT-4_Run_DOOM.md)

    - [翻译: GPT-4 是否具备运行经典游戏 DOOM 的能力？](2024年03月08日/Will_GPT-4_Run_DOOM.md)

- [Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs](2024年03月08日/Cost-Performance_Optimization_for_Processing_Low-Resource_Language_Tasks_Using_Commercial_LLMs.md)

    - [翻译: 针对低资源语言任务，本研究探讨如何运用商业大型语言模型进行成本与性能的优化，以期在保证任务完成质量的同时，有效控制处理此类任务的成本。](2024年03月08日/Cost-Performance_Optimization_for_Processing_Low-Resource_Language_Tasks_Using_Commercial_LLMs.md)

- [HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction](2024年03月08日/HistGen_Histopathology_Report_Generation_via_Local-Global_Feature_Encoding_and_Cross-modal_Context_Interaction.md)

    - [翻译: HistGen 是一种创新方法，利用局部-全局特征编码及跨模态上下文互动技术，专为自动生成组织病理学报告而设计。](2024年03月08日/HistGen_Histopathology_Report_Generation_via_Local-Global_Feature_Encoding_and_Cross-modal_Context_Interaction.md)

- [Exploring Robust Features for Few-Shot Object Detection in Satellite Imagery](2024年03月08日/Exploring_Robust_Features_for_Few-Shot_Object_Detection_in_Satellite_Imagery.md)

    - [翻译: 本研究致力于挖掘卫星图像中能够有效应用于少量样本目标检测任务的稳健特征，旨在提升该领域的检测性能和泛化能力。](2024年03月08日/Exploring_Robust_Features_for_Few-Shot_Object_Detection_in_Satellite_Imagery.md)

- [Explaining Pre-Trained Language Models with Attribution Scores: An Analysis in Low-Resource Settings](2024年03月08日/Explaining_Pre-Trained_Language_Models_with_Attribution_Scores_An_Analysis_in_Low-Resource_Settings.md)

    - [翻译: 针对低资源场景，本研究通过归因分数深入剖析预训练语言模型的工作原理。](2024年03月08日/Explaining_Pre-Trained_Language_Models_with_Attribution_Scores_An_Analysis_in_Low-Resource_Settings.md)

- [ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues](2024年03月08日/ChatASU_Evoking_LLM's_Reflexion_to_Truly_Understand_Aspect_Sentiment_in_Dialogues.md)

    - [翻译: ChatASU 研究通过触发 LLM 在对话情境中的深度反思，旨在真实捕捉和理解方面的具体情感倾向。](2024年03月08日/ChatASU_Evoking_LLM's_Reflexion_to_Truly_Understand_Aspect_Sentiment_in_Dialogues.md)

- [RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation](2024年03月08日/RAT_Retrieval_Augmented_Thoughts_Elicit_Context-Aware_Reasoning_in_Long-Horizon_Generation.md)

    - [翻译: RAT技术通过引入检索增强思维，在长时段生成任务中有效激发了情境感知的推理能力。](2024年03月08日/RAT_Retrieval_Augmented_Thoughts_Elicit_Context-Aware_Reasoning_in_Long-Horizon_Generation.md)

- [Tapilot-Crossing: Benchmarking and Evolving LLMs Towards Interactive Data Analysis Agents](2024年03月08日/Tapilot-Crossing_Benchmarking_and_Evolving_LLMs_Towards_Interactive_Data_Analysis_Agents.md)

    - [翻译: Tapilot-Crossing 是一个专注于推动大型语言模型（LLMs）向交互式数据分析代理演进的基准测试项目，旨在评测并提升 LLMS 在此领域的能力。](2024年03月08日/Tapilot-Crossing_Benchmarking_and_Evolving_LLMs_Towards_Interactive_Data_Analysis_Agents.md)

- [ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications](2024年03月08日/ACLSum_A_New_Dataset_for_Aspect-based_Summarization_of_Scientific_Publications.md)

    - [翻译: ACLSum —— 专为科研论文打造的全新方面式摘要数据集](2024年03月08日/ACLSum_A_New_Dataset_for_Aspect-based_Summarization_of_Scientific_Publications.md)

- [LLM4Decompile: Decompiling Binary Code with Large Language Models](2024年03月08日/LLM4Decompile_Decompiling_Binary_Code_with_Large_Language_Models.md)

    - [翻译: LLM4Decompile 是一项利用大型语言模型来实现二进制代码反编译的技术。](2024年03月08日/LLM4Decompile_Decompiling_Binary_Code_with_Large_Language_Models.md)

- [ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models](2024年03月08日/ERBench_An_Entity-Relationship_based_Automatically_Verifiable_Hallucination_Benchmark_for_Large_Language_Models.md)

    - [翻译: ERBench 是专为大型语言模型设计的、基于实体关系的自动化验证幻觉基准测试，旨在精确衡量和评估模型在处理复杂实体关系时出现的幻觉现象。](2024年03月08日/ERBench_An_Entity-Relationship_based_Automatically_Verifiable_Hallucination_Benchmark_for_Large_Language_Models.md)

- [Debiasing Large Visual Language Models](2024年03月08日/Debiasing_Large_Visual_Language_Models.md)

    - [翻译: 本研究致力于探讨如何有效去偏大型视觉语言模型，以提升其准确性和公正性。](2024年03月08日/Debiasing_Large_Visual_Language_Models.md)

- [Cross-lingual Transfer or Machine Translation? On Data Augmentation for Monolingual Semantic Textual Similarity](2024年03月08日/Cross-lingual_Transfer_or_Machine_Translation_On_Data_Augmentation_for_Monolingual_Semantic_Textual_Similarity.md)

    - [翻译: 在探讨单语种语义文本相似度的数据增强方法时，究竟是采用跨语言迁移技术还是机器翻译策略呢？本研究旨在深入探究这一问题。](2024年03月08日/Cross-lingual_Transfer_or_Machine_Translation_On_Data_Augmentation_for_Monolingual_Semantic_Textual_Similarity.md)

- [Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance](2024年03月08日/Tracking_Meets_LoRA_Faster_Training,_Larger_Model,_Stronger_Performance.md)

    - [翻译: 在本次研究中，我们将追踪技术与LoRA相结合，带来更快的训练速度、支持更大规模的模型，并实现了更出色的整体性能。](2024年03月08日/Tracking_Meets_LoRA_Faster_Training,_Larger_Model,_Stronger_Performance.md)

- [Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering](2024年03月08日/Harnessing_Multi-Role_Capabilities_of_Large_Language_Models_for_Open-Domain_Question_Answering.md)

    - [翻译: 为解决开放领域问题回答任务，本研究探讨如何有效地利用大型语言模型所具备的多元角色功能。](2024年03月08日/Harnessing_Multi-Role_Capabilities_of_Large_Language_Models_for_Open-Domain_Question_Answering.md)

- [Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation](2024年03月08日/Overcoming_Reward_Overoptimization_via_Adversarial_Policy_Optimization_with_Lightweight_Uncertainty_Estimation.md)

    - [翻译: 借助轻量级不确定性估计的对抗性策略优化方法，有效解决奖励函数过度优化难题。](2024年03月08日/Overcoming_Reward_Overoptimization_via_Adversarial_Policy_Optimization_with_Lightweight_Uncertainty_Estimation.md)

- [On Protecting the Data Privacy of Large Language Models (LLMs): A Survey](2024年03月08日/On_Protecting_the_Data_Privacy_of_Large_Language_Models_(LLMs)_A_Survey.md)

    - [翻译: 本文对保护LLMs数据隐私的策略进行了一次全面的调查，旨在深入探讨和总结当前针对大型语言模型的数据安全防护措施。](2024年03月08日/On_Protecting_the_Data_Privacy_of_Large_Language_Models_(LLMs)_A_Survey.md)

- [Towards a Psychology of Machines: Large Language Models Predict Human Memory](2024年03月08日/Towards_a_Psychology_of_Machines_Large_Language_Models_Predict_Human_Memory.md)

    - [翻译: 致力于探索机器的心理学层面，大型语言模型已展现出预测人类记忆的能力。](2024年03月08日/Towards_a_Psychology_of_Machines_Large_Language_Models_Predict_Human_Memory.md)

- [Inverse Design of Photonic Crystal Surface Emitting Lasers is a Sequence Modeling Problem](2024年03月08日/Inverse_Design_of_Photonic_Crystal_Surface_Emitting_Lasers_is_a_Sequence_Modeling_Problem.md)

    - [翻译: 设计光子晶体表面发射激光器的逆向工程实质上可视为一个序列模型构建问题。](2024年03月08日/Inverse_Design_of_Photonic_Crystal_Surface_Emitting_Lasers_is_a_Sequence_Modeling_Problem.md)

- [Med3DInsight: Enhancing 3D Medical Image Understanding with 2D Multi-Modal Large Language Models](2024年03月08日/Med3DInsight_Enhancing_3D_Medical_Image_Understanding_with_2D_Multi-Modal_Large_Language_Models.md)

    - [翻译: Med3DInsight项目利用2D多模态大型语言模型的力量，提升三维医学图像的深入理解和分析能力。](2024年03月08日/Med3DInsight_Enhancing_3D_Medical_Image_Understanding_with_2D_Multi-Modal_Large_Language_Models.md)

- [ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment](2024年03月08日/ELLA_Equip_Diffusion_Models_with_LLM_for_Enhanced_Semantic_Alignment.md)

    - [翻译: ELLA项目通过将LLM与扩散模型相结合，旨在提升模型的语义对齐性能。](2024年03月08日/ELLA_Equip_Diffusion_Models_with_LLM_for_Enhanced_Semantic_Alignment.md)

- [ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models](2024年03月08日/ChatUIE_Exploring_Chat-based_Unified_Information_Extraction_using_Large_Language_Models.md)

    - [翻译: ChatUIE 是一项研究，借助大型语言模型的力量，致力于探究和实现基于聊天模式的统一信息抽取技术。](2024年03月08日/ChatUIE_Exploring_Chat-based_Unified_Information_Extraction_using_Large_Language_Models.md)

- [Benchmarking Large Language Models for Molecule Prediction Tasks](2024年03月08日/Benchmarking_Large_Language_Models_for_Molecule_Prediction_Tasks.md)

    - [翻译: 本研究致力于为分子预测任务设定基准，对大型语言模型的表现进行全面评估和对比。](2024年03月08日/Benchmarking_Large_Language_Models_for_Molecule_Prediction_Tasks.md)

- [Can we obtain significant success in RST discourse parsing by using Large Language Models?](2024年03月08日/Can_we_obtain_significant_success_in_RST_discourse_parsing_by_using_Large_Language_Models.md)

    - [翻译: 在 RST 对话解析任务上，大型语言模型能否助力我们实现显著突破？](2024年03月08日/Can_we_obtain_significant_success_in_RST_discourse_parsing_by_using_Large_Language_Models.md)

- [Aligning Large Language Models for Controllable Recommendations](2024年03月08日/Aligning_Large_Language_Models_for_Controllable_Recommendations.md)

    - [翻译: 本研究致力于将大型语言模型与可控推荐相结合，通过调整和优化模型以实现更为精准且可控的推荐效果。](2024年03月08日/Aligning_Large_Language_Models_for_Controllable_Recommendations.md)

- [Multimodal Infusion Tuning for Large Models](2024年03月08日/Multimodal_Infusion_Tuning_for_Large_Models.md)

    - [翻译: 针对大型模型的多模态融合优化技术，旨在通过深度融合不同模态的信息来提升模型性能。](2024年03月08日/Multimodal_Infusion_Tuning_for_Large_Models.md)

- [ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes](2024年03月08日/ClinicalMamba_A_Generative_Clinical_Language_Model_on_Longitudinal_Clinical_Notes.md)

    - [翻译: ClinicalMamba——一款在连续性临床笔记上训练出的生成式临床语言模型，专门针对纵向临床记录进行设计和构建。](2024年03月08日/ClinicalMamba_A_Generative_Clinical_Language_Model_on_Longitudinal_Clinical_Notes.md)

- [ItD: Large Language Models Can Teach Themselves Induction through Deduction](2024年03月08日/ItD_Large_Language_Models_Can_Teach_Themselves_Induction_through_Deduction.md)

    - [翻译: ItD 研究表明，大型语言模型能够通过演绎推理过程来自我发现和掌握归纳能力。](2024年03月08日/ItD_Large_Language_Models_Can_Teach_Themselves_Induction_through_Deduction.md)

- [Extending Activation Steering to Broad Skills and Multiple Behaviours](2024年03月08日/Extending_Activation_Steering_to_Broad_Skills_and_Multiple_Behaviours.md)

    - [翻译: 我们将 Activation Steering 技术推广到更广泛的技能领域和多元行为表现，旨在探究其在不同能力和情境下的应用效果。](2024年03月08日/Extending_Activation_Steering_to_Broad_Skills_and_Multiple_Behaviours.md)

- [Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text](2024年03月08日/Decoding_the_AI_Pen_Techniques_and_Challenges_in_Detecting_AI-Generated_Text.md)

    - [翻译: 揭秘 AI 生成文本：探究检测技术及面临的挑战](2024年03月08日/Decoding_the_AI_Pen_Techniques_and_Challenges_in_Detecting_AI-Generated_Text.md)

- [A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries](2024年03月08日/A_Benchmark_of_Domain-Adapted_Large_Language_Models_for_Generating_Brief_Hospital_Course_Summaries.md)

    - [翻译: 本研究提出了一项针对生成简要住院病程总结的大型语言模型领域适应能力的基准测试，旨在评估和比较各类经过特定医疗领域调整后的大型语言模型的表现。](2024年03月08日/A_Benchmark_of_Domain-Adapted_Large_Language_Models_for_Generating_Brief_Hospital_Course_Summaries.md)

- [Are Large Language Models Aligned with People's Social Intuitions for Human-Robot Interactions?](2024年03月08日/Are_Large_Language_Models_Aligned_with_People's_Social_Intuitions_for_Human-Robot_Interactions.md)

    - [翻译: 对于人机交互，大型语言模型是否能够贴合人们的社交直觉？](2024年03月08日/Are_Large_Language_Models_Aligned_with_People's_Social_Intuitions_for_Human-Robot_Interactions.md)

- [SeeGULL Multilingual: a Dataset of Geo-Culturally Situated Stereotypes](2024年03月08日/SeeGULL_Multilingual_a_Dataset_of_Geo-Culturally_Situated_Stereotypes.md)

    - [翻译: SeeGULL Multilingual 数据集，专门收录了具有地理文化情境的刻板印象实例。](2024年03月08日/SeeGULL_Multilingual_a_Dataset_of_Geo-Culturally_Situated_Stereotypes.md)

- [DP-TabICL: In-Context Learning with Differentially Private Tabular Data](2024年03月08日/DP-TabICL_In-Context_Learning_with_Differentially_Private_Tabular_Data.md)

    - [翻译: DP-TabICL：探索在带有差分隐私保护的表格数据环境中进行上下文学习的能力](2024年03月08日/DP-TabICL_In-Context_Learning_with_Differentially_Private_Tabular_Data.md)

- [Decomposing Vision-based LLM Predictions for Auto-Evaluation with GPT-4](2024年03月08日/Decomposing_Vision-based_LLM_Predictions_for_Auto-Evaluation_with_GPT-4.md)

    - [翻译: 利用GPT-4对基于视觉的LLM预测进行拆解，实现自动评估目标](2024年03月08日/Decomposing_Vision-based_LLM_Predictions_for_Auto-Evaluation_with_GPT-4.md)

- [PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System Co-design](2024年03月08日/PipeRAG_Fast_Retrieval-Augmented_Generation_via_Algorithm-System_Co-design.md)

    - [翻译: PipeRAG 是一种创新方法，借助算法与系统协同设计的策略，高效实现了检索增强生成。这一技术旨在显著提升文本生成的速度，并在保持高质量的同时，充分融合检索与生成的优势。](2024年03月08日/PipeRAG_Fast_Retrieval-Augmented_Generation_via_Algorithm-System_Co-design.md)

- [CFaiRLLM: Consumer Fairness Evaluation in Large-Language Model Recommender System](2024年03月08日/CFaiRLLM_Consumer_Fairness_Evaluation_in_Large-Language_Model_Recommender_System.md)

    - [翻译: CFaiRLLM 是针对大型语言模型推荐系统的消费者公平性评测方案，旨在深入探究和评估该类系统中对消费者公平性的保障程度。](2024年03月08日/CFaiRLLM_Consumer_Fairness_Evaluation_in_Large-Language_Model_Recommender_System.md)

- [Tuning-Free Accountable Intervention for LLM Deployment -- A Metacognitive Approach](2024年03月08日/Tuning-Free_Accountable_Intervention_for_LLM_Deployment_--_A_Metacognitive_Approach.md)

    - [翻译: 面对LLM部署，我们提出了一种无需额外调优且具备可解释性的干预方案，该方案采用元认知方法，旨在提升模型在实际应用中的可靠性和可控性。](2024年03月08日/Tuning-Free_Accountable_Intervention_for_LLM_Deployment_--_A_Metacognitive_Approach.md)

- [Can Large Language Models Play Games? A Case Study of A Self-Play Approach](2024年03月08日/Can_Large_Language_Models_Play_Games_A_Case_Study_of_A_Self-Play_Approach.md)

    - [翻译: 大型语言模型能否涉足游戏领域？我们通过一项以自我对弈法为切入点的案例研究，探索这一可能性。](2024年03月08日/Can_Large_Language_Models_Play_Games_A_Case_Study_of_A_Self-Play_Approach.md)

- [Context-Based Multimodal Fusion](2024年03月08日/Context-Based_Multimodal_Fusion.md)

    - [翻译: 情境化多模态融合技术，是指将不同模态的信息在特定语境下进行有效整合的过程。](2024年03月08日/Context-Based_Multimodal_Fusion.md)

- [FrameQuant: Flexible Low-Bit Quantization for Transformers](2024年03月09日/FrameQuant_Flexible_Low-Bit_Quantization_for_Transformers.md)

    - [翻译: FrameQuant是一种针对Transformer设计的弹性低比特量化方案。](2024年03月09日/FrameQuant_Flexible_Low-Bit_Quantization_for_Transformers.md)

- [Reframe Anything: LLM Agent for Open World Video Reframing](2024年03月09日/Reframe_Anything_LLM_Agent_for_Open_World_Video_Reframing.md)

    - [翻译: 【重塑万物】推出 LLM 视频重构智能代理，针对开放世界场景下的视频重构任务。步骤详解：](2024年03月09日/Reframe_Anything_LLM_Agent_for_Open_World_Video_Reframing.md)

- [Test-time Distribution Learning Adapter for Cross-modal Visual Reasoning](2024年03月09日/Test-time_Distribution_Learning_Adapter_for_Cross-modal_Visual_Reasoning.md)

    - [翻译: 为解决跨模态视觉推理中的适应性问题，我们提出了一种测试阶段分布学习适配器，它能在实际推理过程中动态调整模型对不同分布数据的理解和处理能力。（由于原句较短，从准确翻译到简洁优雅的中文转换时，已尽量保持原意并增加了一些上下文信息以使句子更完整生动。）](2024年03月09日/Test-time_Distribution_Learning_Adapter_for_Cross-modal_Visual_Reasoning.md)

- [Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills](2024年03月09日/Explaining_Code_with_a_Purpose_An_Integrated_Approach_for_Developing_Code_Comprehension_and_Prompting_Skills.md)

    - [翻译: 面向目标的代码解析：一体化方案助力提升代码理解和指令引导能力](2024年03月09日/Explaining_Code_with_a_Purpose_An_Integrated_Approach_for_Developing_Code_Comprehension_and_Prompting_Skills.md)

- [A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation](2024年03月09日/A_Preliminary_Exploration_of_YouTubers'_Use_of_Generative-AI_in_Content_Creation.md)

    - [翻译: 本研究初步探究了YouTubers在制作视频内容时运用生成式AI技术的情况](2024年03月09日/A_Preliminary_Exploration_of_YouTubers'_Use_of_Generative-AI_in_Content_Creation.md)

- [Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages](2024年03月09日/Few-Shot_Cross-Lingual_Transfer_for_Prompting_Large_Language_Models_in_Low-Resource_Languages.md)

    - [翻译: 针对低资源语言，我们探索了少量样本下的跨语言迁移技术，以实现对大型语言模型的有效提示。这项研究旨在通过少量示例，在资源匮乏的语言环境下提升大型语言模型的性能表现。](2024年03月09日/Few-Shot_Cross-Lingual_Transfer_for_Prompting_Large_Language_Models_in_Low-Resource_Languages.md)

- [Detectors for Safe and Reliable LLMs: Implementations, Uses, and Limitations](2024年03月09日/Detectors_for_Safe_and_Reliable_LLMs_Implementations,_Uses,_and_Limitations.md)

    - [翻译: 为确保LLMs的安全与可靠性，本文探讨了相关探测器的实现方法、应用场景及其局限性。](2024年03月09日/Detectors_for_Safe_and_Reliable_LLMs_Implementations,_Uses,_and_Limitations.md)

- [Calibrating Large Language Models Using Their Generations Only](2024年03月09日/Calibrating_Large_Language_Models_Using_Their_Generations_Only.md)

    - [翻译: 本研究专注于仅通过大型语言模型自身生成的内容对其进行校准，探讨无需额外数据辅助即可提升其准确性和可信度的方法。](2024年03月09日/Calibrating_Large_Language_Models_Using_Their_Generations_Only.md)

- [Thread Detection and Response Generation using Transformers with Prompt Optimisation](2024年03月09日/Thread_Detection_and_Response_Generation_using_Transformers_with_Prompt_Optimisation.md)

    - [翻译: 通过优化提示的Transformer模型实现对线程的精准检测与智能响应生成](2024年03月09日/Thread_Detection_and_Response_Generation_using_Transformers_with_Prompt_Optimisation.md)

- [High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models](2024年03月09日/High_Throughput_Phenotyping_of_Physician_Notes_with_Large_Language_and_Hybrid_NLP_Models.md)

    - [翻译: 我们运用大型语言模型与混合NLP技术，高效解析医师笔记中的丰富信息，实现高通量表型特征提取。](2024年03月09日/High_Throughput_Phenotyping_of_Physician_Notes_with_Large_Language_and_Hybrid_NLP_Models.md)

- [Aligning Speech to Languages to Enhance Code-switching Speech Recognition](2024年03月09日/Aligning_Speech_to_Languages_to_Enhance_Code-switching_Speech_Recognition.md)

    - [翻译: 为优化代码切换语音识别，本研究致力于通过将语音与多种语言进行精准对齐，从而增强此类混合语种识别效果。](2024年03月09日/Aligning_Speech_to_Languages_to_Enhance_Code-switching_Speech_Recognition.md)

- [KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge Graphs and Ranking Techniques](2024年03月09日/KG-Rank_Enhancing_Large_Language_Models_for_Medical_QA_with_Knowledge_Graphs_and_Ranking_Techniques.md)

    - [翻译: KG-Rank 是一项研究，通过融合知识图谱与排序技术，提升大型语言模型在处理医学问答任务时的表现力。](2024年03月09日/KG-Rank_Enhancing_Large_Language_Models_for_Medical_QA_with_Knowledge_Graphs_and_Ranking_Techniques.md)

- [LTGC: Long-tail Recognition via Leveraging LLMs-driven Generated Content](2024年03月09日/LTGC_Long-tail_Recognition_via_Leveraging_LLMs-driven_Generated_Content.md)

    - [翻译: LTGC 方法借助LLMs驱动生成的内容，有效应对长尾识别问题。](2024年03月09日/LTGC_Long-tail_Recognition_via_Leveraging_LLMs-driven_Generated_Content.md)

- [Reverse That Number! Decoding Order Matters in Arithmetic Learning](2024年03月09日/Reverse_That_Number!_Decoding_Order_Matters_in_Arithmetic_Learning.md)

    - [翻译: 反转数字有玄机！在数学运算学习过程中，解码顺序确实至关重要。](2024年03月09日/Reverse_That_Number!_Decoding_Order_Matters_in_Arithmetic_Learning.md)

- [Cached Model-as-a-Resource: Provisioning Large Language Model Agents for Edge Intelligence in Space-air-ground Integrated Networks](2024年03月09日/Cached_Model-as-a-Resource_Provisioning_Large_Language_Model_Agents_for_Edge_Intelligence_in_Space-air-ground_Integrated_Networks.md)

    - [翻译: 针对天地一体化网络中的边缘智能场景，我们提出“缓存模型即服务”方案，用于高效部署和供给大型语言模型代理。](2024年03月09日/Cached_Model-as-a-Resource_Provisioning_Large_Language_Model_Agents_for_Edge_Intelligence_in_Space-air-ground_Integrated_Networks.md)

- [Optimizing LLM Queries in Relational Workloads](2024年03月09日/Optimizing_LLM_Queries_in_Relational_Workloads.md)

    - [翻译: 针对关系型工作负载，本研究致力于提升对大型语言模型（LLM）查询的优化效果。](2024年03月09日/Optimizing_LLM_Queries_in_Relational_Workloads.md)

- [LEVA: Using Large Language Models to Enhance Visual Analytics](2024年03月09日/LEVA_Using_Large_Language_Models_to_Enhance_Visual_Analytics.md)

    - [翻译: LEVA项目致力于将大型语言模型应用于视觉分析领域，以增强其性能和洞察力。](2024年03月09日/LEVA_Using_Large_Language_Models_to_Enhance_Visual_Analytics.md)

- [MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs](2024年03月09日/MP2D_An_Automated_Topic_Shift_Dialogue_Generation_Framework_Leveraging_Knowledge_Graphs.md)

    - [翻译: MP2D 是一种创新的自动化对话生成框架，它巧妙运用知识图谱技术来驱动话题的流畅转换，在对话内容生成中展现出强大的智能引导能力。](2024年03月09日/MP2D_An_Automated_Topic_Shift_Dialogue_Generation_Framework_Leveraging_Knowledge_Graphs.md)

- [$\textbf{S}^2$IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting](2024年03月09日/$\textbf{S}^2$IP-LLM_Semantic_Space_Informed_Prompt_Learning_with_LLM_for_Time_Series_Forecasting.md)

    - [翻译: $\textbf{S}^2$IP-LLM 是一种结合了大型语言模型（LLM）的时间序列预测方法，它运用了基于语义空间的提示学习技术，旨在提升对未来时间序列数据的预测能力。](2024年03月09日/$\textbf{S}^2$IP-LLM_Semantic_Space_Informed_Prompt_Learning_with_LLM_for_Time_Series_Forecasting.md)

- [ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes](2024年03月10日/ArgMed-Agents_Explainable_Clinical_Decision_Reasoning_with_Large_Language_Models_via_Argumentation_Schemes.md)

    - [翻译: ArgMed-Agents 是一种运用大型语言模型与论证方案相结合的方法，旨在为临床决策推理提供清晰、可解释的依据。](2024年03月10日/ArgMed-Agents_Explainable_Clinical_Decision_Reasoning_with_Large_Language_Models_via_Argumentation_Schemes.md)

- [Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance](2024年03月10日/Unpacking_Tokenization_Evaluating_Text_Compression_and_its_Correlation_with_Model_Performance.md)

    - [翻译: 本文旨在深入剖析分词技术，通过评估其在文本压缩上的表现，并探究这一过程与模型整体性能之间的内在关联。](2024年03月10日/Unpacking_Tokenization_Evaluating_Text_Compression_and_its_Correlation_with_Model_Performance.md)

- [Editing Conceptual Knowledge for Large Language Models](2024年03月10日/Editing_Conceptual_Knowledge_for_Large_Language_Models.md)

    - [翻译: 优化大型语言模型内部的概念理解能力步骤 1 翻译：编辑大型语言模型 (LLM) 中的概念知识。步骤 2 优化翻译：本研究探讨如何编辑和优化大型语言模型所承载的概念性知识结构，以提升其内在认知能力和表达精准度。](2024年03月10日/Editing_Conceptual_Knowledge_for_Large_Language_Models.md)

- [LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments](2024年03月10日/LLMs_Still_Can't_Avoid_Instanceof_An_Investigation_Into_GPT-3.5,_GPT-4_and_Bard's_Capacity_to_Handle_Object-Oriented_Programming_Assignments.md)

    - [翻译: 探究GPT-3.5、GPT-4与Bard对面向对象编程任务的处理能力，发现即便强大如LLMs，在涉及“instanceof”问题上仍存在局限性。](2024年03月10日/LLMs_Still_Can't_Avoid_Instanceof_An_Investigation_Into_GPT-3.5,_GPT-4_and_Bard's_Capacity_to_Handle_Object-Oriented_Programming_Assignments.md)

- [No Language is an Island: Unifying Chinese and English in Financial Large Language Models, Instruction Data, and Benchmarks](2024年03月10日/No_Language_is_an_Island_Unifying_Chinese_and_English_in_Financial_Large_Language_Models,_Instruction_Data,_and_Benchmarks.md)

    - [翻译: 无论是金融领域的大型语言模型，还是指令数据集，抑或是基准测试，“没有一种语言是孤立的”。本研究旨在打破壁垒，将中文与英文在这些领域中实现深度融合与统一。](2024年03月10日/No_Language_is_an_Island_Unifying_Chinese_and_English_in_Financial_Large_Language_Models,_Instruction_Data,_and_Benchmarks.md)

- [TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision](2024年03月10日/TRAD_Enhancing_LLM_Agents_with_Step-Wise_Thought_Retrieval_and_Aligned_Decision.md)

    - [翻译: TRAD 研究通过逐步骤检索思维及决策对齐策略，提升LLM智能体的表现。](2024年03月10日/TRAD_Enhancing_LLM_Agents_with_Step-Wise_Thought_Retrieval_and_Aligned_Decision.md)

- [Are You Being Tracked? Discover the Power of Zero-Shot Trajectory Tracing with LLMs!](2024年03月10日/Are_You_Being_Tracked_Discover_the_Power_of_Zero-Shot_Trajectory_Tracing_with_LLMs!.md)

    - [翻译: 想知道自己是否正被追踪？来领略一下LLMs在零样本轨迹追踪上的神奇力量吧！](2024年03月10日/Are_You_Being_Tracked_Discover_the_Power_of_Zero-Shot_Trajectory_Tracing_with_LLMs!.md)

- [A Comprehensive Overhaul of Multimodal Assistant with Small Language Models](2024年03月10日/A_Comprehensive_Overhaul_of_Multimodal_Assistant_with_Small_Language_Models.md)

    - [翻译: 对基于小型语言模型的多模态助手进行一次深入彻底的重构与升级](2024年03月10日/A_Comprehensive_Overhaul_of_Multimodal_Assistant_with_Small_Language_Models.md)

- [Speeding up 6-DoF Grasp Sampling with Quality-Diversity](2024年03月10日/Speeding_up_6-DoF_Grasp_Sampling_with_Quality-Diversity.md)

    - [翻译: 通过质量多样性提升 6 自由度抓取采样的效率](2024年03月10日/Speeding_up_6-DoF_Grasp_Sampling_with_Quality-Diversity.md)

- [Are LLMs ready for Visualization?](2024年03月10日/Are_LLMs_ready_for_Visualization.md)

    - [翻译: LLMs 在可视化领域是否已整装待发？](2024年03月10日/Are_LLMs_ready_for_Visualization.md)

- [Can Large Language Models Automatically Score Proficiency of Written Essays?](2024年03月10日/Can_Large_Language_Models_Automatically_Score_Proficiency_of_Written_Essays.md)

    - [翻译: 大型语言模型是否具备自动评分书面作文的能力？](2024年03月10日/Can_Large_Language_Models_Automatically_Score_Proficiency_of_Written_Essays.md)

- [Simulating Family Conversations using LLMs: Demonstration of Parenting Styles](2024年03月10日/Simulating_Family_Conversations_using_LLMs_Demonstration_of_Parenting_Styles.md)

    - [翻译: 本研究运用大型语言模型（LLMs）模拟家庭对话，生动展现不同育儿风格。通过这项演示，我们期望揭示 LLMS 如何捕捉并重现真实世界中多样化的育儿方式。](2024年03月10日/Simulating_Family_Conversations_using_LLMs_Demonstration_of_Parenting_Styles.md)

- [Fine-grainedly Synthesize Streaming Data Based On Large Language Models With Graph Structure Understanding For Data Sparsity](2024年03月10日/Fine-grainedly_Synthesize_Streaming_Data_Based_On_Large_Language_Models_With_Graph_Structure_Understanding_For_Data_Sparsity.md)

    - [翻译: 为了应对数据稀疏性挑战，本研究提出利用具备图结构理解能力的大型语言模型，对流式数据进行精细化合成。](2024年03月10日/Fine-grainedly_Synthesize_Streaming_Data_Based_On_Large_Language_Models_With_Graph_Structure_Understanding_For_Data_Sparsity.md)

- [FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning](2024年03月10日/FedPIT_Towards_Privacy-preserving_and_Few-shot_Federated_Instruction_Tuning.md)

    - [翻译: FedPIT 是一种致力于在保障隐私的同时实现少量样本的联邦指令微调的技术方案。](2024年03月10日/FedPIT_Towards_Privacy-preserving_and_Few-shot_Federated_Instruction_Tuning.md)

- [Low-dose CT Denoising with Language-engaged Dual-space Alignment](2024年03月10日/Low-dose_CT_Denoising_with_Language-engaged_Dual-space_Alignment.md)

    - [翻译: 通过运用语言引导的双空间对齐技术，本研究致力于实现低剂量 CT 图像的有效降噪。](2024年03月10日/Low-dose_CT_Denoising_with_Language-engaged_Dual-space_Alignment.md)

- [FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained Monetary Policy Analysis Framework on Their Language](2024年03月10日/FMPAF_How_Do_Fed_Chairs_Affect_the_Financial_Market_A_Fine-grained_Monetary_Policy_Analysis_Framework_on_Their_Language.md)

    - [翻译: FMPAF：探究美联储主席如何运用语言这一工具对金融市场施加影响，我们提出了一种针对货币政策的精细化分析框架。](2024年03月10日/FMPAF_How_Do_Fed_Chairs_Affect_the_Financial_Market_A_Fine-grained_Monetary_Policy_Analysis_Framework_on_Their_Language.md)

- [Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning](2024年03月10日/Large_Language_Models_on_Fine-grained_Emotion_Detection_Dataset_with_Data_Augmentation_and_Transfer_Learning.md)

    - [翻译: 通过运用数据增强和迁移学习技术，大型语言模型在细粒度情感检测数据集上展现出了强大的性能。本研究聚焦于此类模型如何在丰富且精细的情感识别任务中，通过增强数据集和借用预训练知识实现更优表现。](2024年03月10日/Large_Language_Models_on_Fine-grained_Emotion_Detection_Dataset_with_Data_Augmentation_and_Transfer_Learning.md)

- [RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion](2024年03月10日/RepoHyper_Better_Context_Retrieval_Is_All_You_Need_for_Repository-Level_Code_Completion.md)

    - [翻译: RepoHyper 提出，在仓库级别实现高效的代码补全，关键在于提升上下文检索能力，仅此一项改进就能满足需求。](2024年03月10日/RepoHyper_Better_Context_Retrieval_Is_All_You_Need_for_Repository-Level_Code_Completion.md)

- [Can LLMs' Tuning Methods Work in Medical Multimodal Domain?](2024年03月10日/Can_LLMs'_Tuning_Methods_Work_in_Medical_Multimodal_Domain.md)

    - [翻译: LLMs 的微调技术是否能在医学多模态领域奏效呢？](2024年03月10日/Can_LLMs'_Tuning_Methods_Work_in_Medical_Multimodal_Domain.md)

- [Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages](2024年03月10日/Amharic_LLaMA_and_LLaVA_Multimodal_LLMs_for_Low_Resource_Languages.md)

    - [翻译: 针对低资源语言，我们推出了 Amharic LLaMA 和 LLaVA 多模态大型语言模型。这两个模型旨在为资源匮乏的语言提供强大的自然语言理解和生成能力，通过整合多种模态信息以提升性能表现。](2024年03月10日/Amharic_LLaMA_and_LLaVA_Multimodal_LLMs_for_Low_Resource_Languages.md)

- [Development of a Reliable and Accessible Caregiving Language Model (CaLM)](2024年03月11日/Development_of_a_Reliable_and_Accessible_Caregiving_Language_Model_(CaLM).md)

    - [翻译: 致力于构建一款既可靠又便于使用的照护语言模型（CaLM），旨在提升照护服务领域的沟通与智能化水平。](2024年03月11日/Development_of_a_Reliable_and_Accessible_Caregiving_Language_Model_(CaLM).md)

- [RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback](2024年03月11日/RA-ISF_Learning_to_Answer_and_Understand_from_Retrieval_Augmentation_via_Iterative_Self-Feedback.md)

    - [翻译: RA-ISF 模型致力于借助迭代自反馈机制，从检索增强中学习并掌握回答与理解的能力。](2024年03月11日/RA-ISF_Learning_to_Answer_and_Understand_from_Retrieval_Augmentation_via_Iterative_Self-Feedback.md)

- [Hybrid Human-LLM Corpus Construction and LLM Evaluation for Rare Linguistic Phenomena](2024年03月11日/Hybrid_Human-LLM_Corpus_Construction_and_LLM_Evaluation_for_Rare_Linguistic_Phenomena.md)

    - [翻译: 针对罕见语言现象，我们进行混合人类专家与大型语言模型（LLM）协同构建语料库，并通过此方法对LLM进行深入评估。](2024年03月11日/Hybrid_Human-LLM_Corpus_Construction_and_LLM_Evaluation_for_Rare_Linguistic_Phenomena.md)

- [Materials science in the era of large language models: a perspective](2024年03月11日/Materials_science_in_the_era_of_large_language_models_a_perspective.md)

    - [翻译: 在大型语言模型盛行的时代，本文提供了一种关于材料科学的独特视角。](2024年03月11日/Materials_science_in_the_era_of_large_language_models_a_perspective.md)

- [Split to Merge: Unifying Separated Modalities for Unsupervised Domain Adaptation](2024年03月11日/Split_to_Merge_Unifying_Separated_Modalities_for_Unsupervised_Domain_Adaptation.md)

    - [翻译: 通过“分裂至合并”策略，我们旨在将分离的模态融合以实现无监督领域适应的统一。这一方法旨在解决不同模态在无标签数据上进行领域适应时的问题，从而提升模型性能和泛化能力。](2024年03月11日/Split_to_Merge_Unifying_Separated_Modalities_for_Unsupervised_Domain_Adaptation.md)

- [Naming, Describing, and Quantifying Visual Objects in Humans and LLMs](2024年03月11日/Naming,_Describing,_and_Quantifying_Visual_Objects_in_Humans_and_LLMs.md)

    - [翻译: 本研究探讨人类和大型语言模型（LLMs）如何对视觉对象进行命名、细致描述以及量化处理。](2024年03月11日/Naming,_Describing,_and_Quantifying_Visual_Objects_in_Humans_and_LLMs.md)

- [ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis](2024年03月11日/ERA-CoT_Improving_Chain-of-Thought_through_Entity_Relationship_Analysis.md)

    - [翻译: ERA-CoT 是一种创新方法，它借助实体关系分析技术来提升思维链（Chain-of-Thought）的表现。该方法旨在深入理解并优化大型语言模型在解决复杂问题时的内在逻辑推理过程。](2024年03月11日/ERA-CoT_Improving_Chain-of-Thought_through_Entity_Relationship_Analysis.md)

- [MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning](2024年03月11日/MEND_Meta_dEmonstratioN_Distillation_for_Efficient_and_Effective_In-Context_Learning.md)

    - [翻译: MEND 是一种“元演示蒸馏”方法，专注于提升上下文学习的效率和效果。](2024年03月11日/MEND_Meta_dEmonstratioN_Distillation_for_Efficient_and_Effective_In-Context_Learning.md)

- [Application of Quantum Tensor Networks for Protein Classification](2024年03月11日/Application_of_Quantum_Tensor_Networks_for_Protein_Classification.md)

    - [翻译: 本研究探讨了将量子张量网络应用于蛋白质分类任务的可能性，借助这一前沿技术揭示蛋白质内在结构与功能之间的深层次联系。](2024年03月11日/Application_of_Quantum_Tensor_Networks_for_Protein_Classification.md)

- [Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents](2024年03月11日/Exploring_Large_Language_Models_and_Hierarchical_Frameworks_for_Classification_of_Large_Unstructured_Legal_Documents.md)

    - [翻译: 本研究致力于探究如何利用大型语言模型与层次化框架携手处理大规模非结构化法律文档的分类问题。](2024年03月11日/Exploring_Large_Language_Models_and_Hierarchical_Frameworks_for_Classification_of_Large_Unstructured_Legal_Documents.md)

- [Learning with Noisy Foundation Models](2024年03月11日/Learning_with_Noisy_Foundation_Models.md)

    - [翻译: 探究噪声底层模型下的学习机制](2024年03月11日/Learning_with_Noisy_Foundation_Models.md)

- [DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation](2024年03月11日/DriveDreamer-2_LLM-Enhanced_World_Models_for_Diverse_Driving_Video_Generation.md)

    - [翻译: DriveDreamer-2 是一款基于 LLM 强化的世界模型，专门用于创新且多样的驾驶视频生成任务。](2024年03月11日/DriveDreamer-2_LLM-Enhanced_World_Models_for_Diverse_Driving_Video_Generation.md)

- [ACFIX: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts](2024年03月11日/ACFIX_Guiding_LLMs_with_Mined_Common_RBAC_Practices_for_Context-Aware_Repair_of_Access_Control_Vulnerabilities_in_Smart_Contracts.md)

    - [翻译: ACFIX方案，旨在借助挖掘出的常见RBAC实践引导大型语言模型，针对智能合约中的上下文敏感访问控制漏洞进行精准修复。](2024年03月11日/ACFIX_Guiding_LLMs_with_Mined_Common_RBAC_Practices_for_Context-Aware_Repair_of_Access_Control_Vulnerabilities_in_Smart_Contracts.md)

- [Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?](2024年03月11日/Can_LLMs_Separate_Instructions_From_Data_And_What_Do_We_Even_Mean_By_That.md)

    - [翻译: LLMs 是否具备区分指令与数据的能力？而这个说法背后又蕴含着怎样的深意呢？](2024年03月11日/Can_LLMs_Separate_Instructions_From_Data_And_What_Do_We_Even_Mean_By_That.md)

- [The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework](2024年03月11日/The_Power_of_Noise_Toward_a_Unified_Multi-modal_Knowledge_Graph_Representation_Framework.md)

    - [翻译: 噪声之力：致力于构建一个融合多模态信息的知识图谱表示统一框架](2024年03月11日/The_Power_of_Noise_Toward_a_Unified_Multi-modal_Knowledge_Graph_Representation_Framework.md)

- [Boosting Image Restoration via Priors from Pre-trained Models](2024年03月11日/Boosting_Image_Restoration_via_Priors_from_Pre-trained_Models.md)

    - [翻译: 借助预训练模型中蕴含的先验信息，本研究旨在增强图像恢复技术的效果。](2024年03月11日/Boosting_Image_Restoration_via_Priors_from_Pre-trained_Models.md)

- [ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model](2024年03月11日/ConspEmoLLM_Conspiracy_Theory_Detection_Using_an_Emotion-Based_Large_Language_Model.md)

    - [翻译: ConspEmoLLM是一种运用情感导向的大规模语言模型进行阴谋论检测的技术，它利用深度学习和自然语言处理技术来识别文本中的潜在阴谋论信息。](2024年03月11日/ConspEmoLLM_Conspiracy_Theory_Detection_Using_an_Emotion-Based_Large_Language_Model.md)

- [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](2024年03月11日/An_Image_is_Worth_12_Tokens_After_Layer_2_Plug-and-Play_Inference_Acceleration_for_Large_Vision-Language_Models.md)

    - [翻译: 经过第二层处理后，图像信息可有效压缩为半个标记量级，为此我们提出一种针对大型视觉-语言模型的便捷式推理加速方案。](2024年03月11日/An_Image_is_Worth_12_Tokens_After_Layer_2_Plug-and-Play_Inference_Acceleration_for_Large_Vision-Language_Models.md)

- [ALaRM: Align Language Models via Hierarchical Rewards Modeling](2024年03月11日/ALaRM_Align_Language_Models_via_Hierarchical_Rewards_Modeling.md)

    - [翻译: ALaRM 是一种创新方法，它利用层次化奖励建模技术来对齐和优化语言模型的性能。该策略旨在通过模拟不同层级的奖励机制，更好地指导和调整语言模型的行为表现。步骤 1 翻译：ALaRM: 通过层级奖励建模实现语言模型的对齐步骤 2 翻译：ALaRM 是一项研究提出的技术，通过构建层级化的奖励模型，致力于有效对齐和提升语言模型的表现力，其原理在于运用多层级的激励机制来精细化指导和校准语言模型在各类任务中的行为反应。](2024年03月11日/ALaRM_Align_Language_Models_via_Hierarchical_Rewards_Modeling.md)

- [Evaluating Large Language Models in Process Mining: Capabilities, Benchmarks, Evaluation Strategies, and Future Challenges](2024年03月11日/Evaluating_Large_Language_Models_in_Process_Mining_Capabilities,_Benchmarks,_Evaluation_Strategies,_and_Future_Challenges.md)

    - [翻译: 本研究探讨了大型语言模型在流程挖掘领域的表现，内容涵盖其功能特性、基准测试、评估策略以及未来所面临的挑战。](2024年03月11日/Evaluating_Large_Language_Models_in_Process_Mining_Capabilities,_Benchmarks,_Evaluation_Strategies,_and_Future_Challenges.md)

- [ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation](2024年03月11日/ACT-MNMT_Auto-Constriction_Turning_for_Multilingual_Neural_Machine_Translation.md)

    - [翻译: ACT-MNMT 技术应用于多语言神经机器翻译，通过自动约束转换优化翻译效果。](2024年03月11日/ACT-MNMT_Auto-Constriction_Turning_for_Multilingual_Neural_Machine_Translation.md)

- [Real-Time Multimodal Cognitive Assistant for Emergency Medical Services](2024年03月11日/Real-Time_Multimodal_Cognitive_Assistant_for_Emergency_Medical_Services.md)

    - [翻译: 这款实时多模态认知助手专为急救医疗服务设计，可在紧急医疗场景下提供高效辅助。](2024年03月11日/Real-Time_Multimodal_Cognitive_Assistant_for_Emergency_Medical_Services.md)

- [Large Model driven Radiology Report Generation with Clinical Quality Reinforcement Learning](2024年03月11日/Large_Model_driven_Radiology_Report_Generation_with_Clinical_Quality_Reinforcement_Learning.md)

    - [翻译: 通过运用大型模型及临床质量强化学习驱动的策略，我们致力于实现高质量放射学报告自动生成。](2024年03月11日/Large_Model_driven_Radiology_Report_Generation_with_Clinical_Quality_Reinforcement_Learning.md)

- [Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning](2024年03月11日/Improving_Low-Resource_Knowledge_Tracing_Tasks_by_Supervised_Pre-training_and_Importance_Mechanism_Fine-tuning.md)

    - [翻译: 为解决低资源知识追踪难题，我们提出采用监督预训练结合重要性机制微调的方法以提升任务效果。这项研究旨在探索在有限数据环境下，利用预训练模型与针对性的权重调整策略优化知识追踪任务性能的可能性。](2024年03月11日/Improving_Low-Resource_Knowledge_Tracing_Tasks_by_Supervised_Pre-training_and_Importance_Mechanism_Fine-tuning.md)

- [HILL: A Hallucination Identifier for Large Language Models](2024年03月11日/HILL_A_Hallucination_Identifier_for_Large_Language_Models.md)

    - [翻译: HILL，一款专为大型语言模型设计的幻觉检测工具。](2024年03月11日/HILL_A_Hallucination_Identifier_for_Large_Language_Models.md)

- [Poisoning Programs by Un-Repairing Code: Security Concerns of AI-generated Code](2024年03月11日/Poisoning_Programs_by_Un-Repairing_Code_Security_Concerns_of_AI-generated_Code.md)

    - [翻译: 借助无法修复的代码“下毒”程序：探究 AI 生成代码所带来的安全隐忧](2024年03月11日/Poisoning_Programs_by_Un-Repairing_Code_Security_Concerns_of_AI-generated_Code.md)

- [Smart-Infinity: Fast Large Language Model Training using Near-Storage Processing on a Real System](2024年03月11日/Smart-Infinity_Fast_Large_Language_Model_Training_using_Near-Storage_Processing_on_a_Real_System.md)

    - [翻译: Smart-Infinity：通过在真实系统中应用近存储处理技术，实现大型语言模型的高效快速训练](2024年03月11日/Smart-Infinity_Fast_Large_Language_Model_Training_using_Near-Storage_Processing_on_a_Real_System.md)

- [FashionReGen: LLM-Empowered Fashion Report Generation](2024年03月11日/FashionReGen_LLM-Empowered_Fashion_Report_Generation.md)

    - [翻译: FashionReGen：借助LLM力量，革新时尚报告自动生成领域](2024年03月11日/FashionReGen_LLM-Empowered_Fashion_Report_Generation.md)

- [Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement](2024年03月11日/Zero-Shot_ECG_Classification_with_Multimodal_Learning_and_Test-time_Clinical_Knowledge_Enhancement.md)

    - [翻译: 运用多模态学习与测试阶段临床知识升级技术，我们实现了无需预先训练的心电图分类。这一研究聚焦于在零样本场景下，通过融合多种模态信息并实时提升临床相关知识，以实现对心电图的有效分类。](2024年03月11日/Zero-Shot_ECG_Classification_with_Multimodal_Learning_and_Test-time_Clinical_Knowledge_Enhancement.md)

- [Elephants Never Forget: Testing Language Models for Memorization of Tabular Data](2024年03月11日/Elephants_Never_Forget_Testing_Language_Models_for_Memorization_of_Tabular_Data.md)

    - [翻译: 标题生动翻译：“象群记忆无遗漏：检验语言模型对表格数据的存储能力”进一步优化：](2024年03月11日/Elephants_Never_Forget_Testing_Language_Models_for_Memorization_of_Tabular_Data.md)

- [KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation](2024年03月11日/KELLMRec_Knowledge-Enhanced_Large_Language_Models_for_Recommendation.md)

    - [翻译: KELLMRec 是一种将知识增强技术融入大型语言模型以提升推荐系统性能的方法。](2024年03月11日/KELLMRec_Knowledge-Enhanced_Large_Language_Models_for_Recommendation.md)

- [MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding](2024年03月11日/MedKP_Medical_Dialogue_with_Knowledge_Enhancement_and_Clinical_Pathway_Encoding.md)

    - [翻译: MedKP 是一个通过知识增强和临床路径编码提升性能的医疗对话系统，它旨在借助这些技术改进医疗服务中的对话质量和决策支持。](2024年03月11日/MedKP_Medical_Dialogue_with_Knowledge_Enhancement_and_Clinical_Pathway_Encoding.md)

- [Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds](2024年03月11日/Guiding_Clinical_Reasoning_with_Large_Language_Models_via_Knowledge_Seeds.md)

    - [翻译: 借助“知识种子”，我们探索如何有效利用大型语言模型来指导临床推理过程。](2024年03月11日/Guiding_Clinical_Reasoning_with_Large_Language_Models_via_Knowledge_Seeds.md)

- [Decoding Complexity: Exploring Human-AI Concordance in Qualitative Coding](2024年03月11日/Decoding_Complexity_Exploring_Human-AI_Concordance_in_Qualitative_Coding.md)

    - [翻译: 探究定性编码领域中人类与AI的协同一致性，深入剖析解码复杂性问题。](2024年03月11日/Decoding_Complexity_Exploring_Human-AI_Concordance_in_Qualitative_Coding.md)

- [Authorship and the Politics and Ethics of LLM Watermarks](2024年03月11日/Authorship_and_the_Politics_and_Ethics_of_LLM_Watermarks.md)

    - [翻译: 探讨 LLM 水印背后的作者权问题及其在政治和伦理层面的影响](2024年03月11日/Authorship_and_the_Politics_and_Ethics_of_LLM_Watermarks.md)

- [Academically intelligent LLMs are not necessarily socially intelligent](2024年03月11日/Academically_intelligent_LLMs_are_not_necessarily_socially_intelligent.md)

    - [翻译: LLMs 即便在学术智能上表现出色，却未必具有社交智能。](2024年03月11日/Academically_intelligent_LLMs_are_not_necessarily_socially_intelligent.md)

- [ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models](2024年03月11日/ContextGPT_Infusing_LLMs_Knowledge_into_Neuro-Symbolic_Activity_Recognition_Models.md)

    - [翻译: ContextGPT：巧妙融合LLMs知识至神经符号活动识别模型中，提升模型性能与智能性](2024年03月11日/ContextGPT_Infusing_LLMs_Knowledge_into_Neuro-Symbolic_Activity_Recognition_Models.md)

- [AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models](2024年03月11日/AC-EVAL_Evaluating_Ancient_Chinese_Language_Understanding_in_Large_Language_Models.md)

    - [翻译: AC-EVAL：针对大型语言模型，我们提出一种评估方法，用于衡量其对古代汉语的理解程度。](2024年03月11日/AC-EVAL_Evaluating_Ancient_Chinese_Language_Understanding_in_Large_Language_Models.md)

- [Unraveling the Mystery of Scaling Laws: Part I](2024年03月11日/Unraveling_the_Mystery_of_Scaling_Laws_Part_I.md)

    - [翻译: 揭秘规模定律的奥秘：第一篇章](2024年03月11日/Unraveling_the_Mystery_of_Scaling_Laws_Part_I.md)

- [ToolRerank: Adaptive and Hierarchy-Aware Reranking for Tool Retrieval](2024年03月11日/ToolRerank_Adaptive_and_Hierarchy-Aware_Reranking_for_Tool_Retrieval.md)

    - [翻译: ToolRerank：针对工具检索问题，提出了一种能够自适应调整并具备层次感知能力的重新排序方法，旨在提升检索效果。](2024年03月11日/ToolRerank_Adaptive_and_Hierarchy-Aware_Reranking_for_Tool_Retrieval.md)

- [Adding NVMe SSDs to Enable and Accelerate 100B Model Fine-tuning on a Single GPU](2024年03月11日/Adding_NVMe_SSDs_to_Enable_and_Accelerate_100B_Model_Fine-tuning_on_a_Single_GPU.md)

    - [翻译: 为了在单个GPU上有效且高效地进行百亿模型的微调，我们引入了NVMe SSD技术。这一举措旨在助力并大幅提升大型模型在单一GPU环境下的微调速度。](2024年03月11日/Adding_NVMe_SSDs_to_Enable_and_Accelerate_100B_Model_Fine-tuning_on_a_Single_GPU.md)

- [Automatic Generation of Python Programs Using Context-Free Grammars](2024年03月11日/Automatic_Generation_of_Python_Programs_Using_Context-Free_Grammars.md)

    - [翻译: 本研究探讨运用无上下文文法实现Python程序的自动化生成技术，旨在通过规则解析和程序结构自动生成，提高代码开发效率与灵活性。](2024年03月11日/Automatic_Generation_of_Python_Programs_Using_Context-Free_Grammars.md)

- [Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts](2024年03月11日/Toward_Generalist_Anomaly_Detection_via_In-context_Residual_Learning_with_Few-shot_Sample_Prompts.md)

    - [翻译: 借助少量样例提示的上下文残差学习方法，我们正逐步迈向实现能应对各类异常检测任务的通才模型。](2024年03月11日/Toward_Generalist_Anomaly_Detection_via_In-context_Residual_Learning_with_Few-shot_Sample_Prompts.md)

- [Knowledge-aware Alert Aggregation in Large-scale Cloud Systems: a Hybrid Approach](2024年03月11日/Knowledge-aware_Alert_Aggregation_in_Large-scale_Cloud_Systems_a_Hybrid_Approach.md)

    - [翻译: 针对大规模云系统的警报管理，我们提出了一种融合了知识感知能力的混合警报聚合方法。这一创新方案旨在高效整合各类警报信息，在复杂的云环境中提升问题定位和决策效率。](2024年03月11日/Knowledge-aware_Alert_Aggregation_in_Large-scale_Cloud_Systems_a_Hybrid_Approach.md)

- [RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems](2024年03月11日/RecAI_Leveraging_Large_Language_Models_for_Next-Generation_Recommender_Systems.md)

    - [翻译: RecAI项目通过巧妙运用大型语言模型，为下一代推荐系统的开发注入活力。](2024年03月11日/RecAI_Leveraging_Large_Language_Models_for_Next-Generation_Recommender_Systems.md)

- [FontCLIP: A Semantic Typography Visual-Language Model for Multilingual Font Applications](2024年03月11日/FontCLIP_A_Semantic_Typography_Visual-Language_Model_for_Multilingual_Font_Applications.md)

    - [翻译: FontCLIP，一款创新的多语言字体应用场景下的语义排版视觉-语言模型，旨在通过深度学习技术探索和理解字体设计与自然语言间的语义关联。](2024年03月11日/FontCLIP_A_Semantic_Typography_Visual-Language_Model_for_Multilingual_Font_Applications.md)

- [Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models](2024年03月11日/Unsupervised_Real-Time_Hallucination_Detection_based_on_the_Internal_States_of_Large_Language_Models.md)

    - [翻译: 本研究提出了一种新颖的方法，利用大型语言模型（LLM）的内部状态进行无监督实时幻觉检测。这项技术无需人工标注，在运行过程中直接根据LLM的状态识别出可能的“幻觉”输出，特别适用于对自然语言处理系统的实时监控与优化。](2024年03月11日/Unsupervised_Real-Time_Hallucination_Detection_based_on_the_Internal_States_of_Large_Language_Models.md)

- [CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation](2024年03月11日/CoRAL_Collaborative_Retrieval-Augmented_Large_Language_Models_Improve_Long-tail_Recommendation.md)

    - [翻译: CoRAL 是一种创新的方法，它通过协同检索增强大型语言模型，有效改善了对长尾项目的推荐效果，尤其针对那些稀有和冷启动情境。](2024年03月11日/CoRAL_Collaborative_Retrieval-Augmented_Large_Language_Models_Improve_Long-tail_Recommendation.md)

- [BoostER: Leveraging Large Language Models for Enhancing Entity Resolution](2024年03月11日/BoostER_Leveraging_Large_Language_Models_for_Enhancing_Entity_Resolution.md)

    - [翻译: BoostER 技术巧妙运用大型语言模型，以强化实体解析效能。](2024年03月11日/BoostER_Leveraging_Large_Language_Models_for_Enhancing_Entity_Resolution.md)

- [RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models](2024年03月11日/RLingua_Improving_Reinforcement_Learning_Sample_Efficiency_in_Robotic_Manipulations_With_Large_Language_Models.md)

    - [翻译: RLingua 是一项研究，借助大型语言模型提升机器人操作领域强化学习的样本效率，从而改进了机器人的操控性能。](2024年03月11日/RLingua_Improving_Reinforcement_Learning_Sample_Efficiency_in_Robotic_Manipulations_With_Large_Language_Models.md)

- [A Framework for Cost-Effective and Self-Adaptive LLM Shaking and Recovery Mechanism](2024年03月11日/A_Framework_for_Cost-Effective_and_Self-Adaptive_LLM_Shaking_and_Recovery_Mechanism.md)

    - [翻译: 我们提出了一种兼顾成本效益和自我适应性的 LLM 振荡与恢复机制框架，旨在有效解决大型语言模型在运行过程中可能产生的不稳定性和性能波动问题，并实现模型自我修复与优化。](2024年03月11日/A_Framework_for_Cost-Effective_and_Self-Adaptive_LLM_Shaking_and_Recovery_Mechanism.md)

- [CKERC : Joint Large Language Models with Commonsense Knowledge for Emotion Recognition in Conversation](2024年03月11日/CKERC__Joint_Large_Language_Models_with_Commonsense_Knowledge_for_Emotion_Recognition_in_Conversation.md)

    - [翻译: CKERC项目通过将大型语言模型与常识知识库相结合，旨在提升对话情境中情绪识别的能力。](2024年03月11日/CKERC__Joint_Large_Language_Models_with_Commonsense_Knowledge_for_Emotion_Recognition_in_Conversation.md)

- [Calibrating Multi-modal Representations: A Pursuit of Group Robustness without Annotations](2024年03月11日/Calibrating_Multi-modal_Representations_A_Pursuit_of_Group_Robustness_without_Annotations.md)

    - [翻译: 为实现无需标注的群体鲁棒性，我们致力于校准多模态表示的研究。本研究探讨如何在缺乏人工注释的前提下提升多模态模型对不同群体数据的适应性和稳定性。](2024年03月11日/Calibrating_Multi-modal_Representations_A_Pursuit_of_Group_Robustness_without_Annotations.md)

- [LookupFFN: Making Transformers Compute-lite for CPU inference](2024年03月11日/LookupFFN_Making_Transformers_Compute-lite_for_CPU_inference.md)

    - [翻译: LookupFFN：为CPU推理打造更轻巧的Transformer计算结构](2024年03月11日/LookupFFN_Making_Transformers_Compute-lite_for_CPU_inference.md)

- [Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews](2024年03月11日/Monitoring_AI-Modified_Content_at_Scale_A_Case_Study_on_the_Impact_of_ChatGPT_on_AI_Conference_Peer_Reviews.md)

    - [翻译: 在大规模层面上探究 AI 内容修改，以ChatGPT对AI学术会议同行评审影响为切入点进行深入案例分析。](2024年03月11日/Monitoring_AI-Modified_Content_at_Scale_A_Case_Study_on_the_Impact_of_ChatGPT_on_AI_Conference_Peer_Reviews.md)

- [3M-Diffusion: Latent Multi-Modal Diffusion for Text-Guided Generation of Molecular Graphs](2024年03月11日/3M-Diffusion_Latent_Multi-Modal_Diffusion_for_Text-Guided_Generation_of_Molecular_Graphs.md)

    - [翻译: 3M-Diffusion 是一种创新方法，利用潜在多模态扩散技术，针对文本指导下的分子图生成任务。该模型能够巧妙地结合文本信息与分子结构特征，实现高效、精准的新型分子设计生成。](2024年03月11日/3M-Diffusion_Latent_Multi-Modal_Diffusion_for_Text-Guided_Generation_of_Molecular_Graphs.md)

- [Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing](2024年03月11日/Rebuilding_ROME__Resolving_Model_Collapse_during_Sequential_Model_Editing.md)

    - [翻译: 本研究致力于“重建 ROME”，旨在解决在对模型进行连续编辑时出现的模型坍塌问题。](2024年03月11日/Rebuilding_ROME__Resolving_Model_Collapse_during_Sequential_Model_Editing.md)

- [Mapping High-level Semantic Regions in Indoor Environments without Object Recognition](2024年03月11日/Mapping_High-level_Semantic_Regions_in_Indoor_Environments_without_Object_Recognition.md)

    - [翻译: 本研究致力于在不依赖物体识别的前提下，精准描绘室内环境中的高层语义区域分布。](2024年03月11日/Mapping_High-level_Semantic_Regions_in_Indoor_Environments_without_Object_Recognition.md)

- [The Dawn of AI-Native EDA: Promises and Challenges of Large Circuit Models](2024年03月11日/The_Dawn_of_AI-Native_EDA_Promises_and_Challenges_of_Large_Circuit_Models.md)

    - [翻译: 随着AI原生EDA时代的来临，大型电路模型展现出了诱人前景和艰巨挑战。本研究探讨这一新兴领域中大型电路模型带来的承诺以及所面临的难题。](2024年03月11日/The_Dawn_of_AI-Native_EDA_Promises_and_Challenges_of_Large_Circuit_Models.md)

- [GuideGen: A Text-guided Framework for Joint CT Volume and Anatomical structure Generation](2024年03月11日/GuideGen_A_Text-guided_Framework_for_Joint_CT_Volume_and_Anatomical_structure_Generation.md)

    - [翻译: GuideGen，一款创新的文本导向框架，专为协同生成CT体积数据与解剖结构而设计。](2024年03月11日/GuideGen_A_Text-guided_Framework_for_Joint_CT_Volume_and_Anatomical_structure_Generation.md)

- [SMART: Automatically Scaling Down Language Models with Accuracy Guarantees for Reduced Processing Fees](2024年03月11日/SMART_Automatically_Scaling_Down_Language_Models_with_Accuracy_Guarantees_for_Reduced_Processing_Fees.md)

    - [翻译: SMART 技术能够自动缩减语言模型的规模，同时确保模型精度，从而有效降低处理成本。](2024年03月11日/SMART_Automatically_Scaling_Down_Language_Models_with_Accuracy_Guarantees_for_Reduced_Processing_Fees.md)

- [Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations](2024年03月12日/Transforming_Competition_into_Collaboration_The_Revolutionary_Role_of_Multi-Agent_Systems_and_Language_Models_in_Modern_Organizations.md)

    - [翻译: 在现代组织中，多智能体系统与语言模型正发挥着革命性的作用，它们能够巧妙地将竞争关系转变为协作模式。](2024年03月12日/Transforming_Competition_into_Collaboration_The_Revolutionary_Role_of_Multi-Agent_Systems_and_Language_Models_in_Modern_Organizations.md)

- [Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings](2024年03月12日/Synth$^2$_Boosting_Visual-Language_Models_with_Synthetic_Captions_and_Image_Embeddings.md)

    - [翻译: Synth$^2$：借助于合成的图片说明和图像嵌入技术，有力地增强了视觉-语言模型的功能与性能。](2024年03月12日/Synth$^2$_Boosting_Visual-Language_Models_with_Synthetic_Captions_and_Image_Embeddings.md)

- [FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models](2024年03月12日/FineMath_A_Fine-Grained_Mathematical_Evaluation_Benchmark_for_Chinese_Large_Language_Models.md)

    - [翻译: FineMath 是专为评测中文大型语言模型而设计的精细数学评估基准，旨在从更细致的角度衡量和检验模型在数学相关任务上的表现。](2024年03月12日/FineMath_A_Fine-Grained_Mathematical_Evaluation_Benchmark_for_Chinese_Large_Language_Models.md)

- [Multi-modal Auto-regressive Modeling via Visual Words](2024年03月12日/Multi-modal_Auto-regressive_Modeling_via_Visual_Words.md)

    - [翻译: 借助“视觉词汇”，我们探索多模态自回归模型的构建，旨在整合图像与文本信息，实现跨模态的联合建模与预测。](2024年03月12日/Multi-modal_Auto-regressive_Modeling_via_Visual_Words.md)

- [WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?](2024年03月12日/WorkArena_How_Capable_Are_Web_Agents_at_Solving_Common_Knowledge_Work_Tasks.md)

    - [翻译: WorkArena 探究：Web 代理在处理日常知识工作任务时，其能力表现究竟如何？](2024年03月12日/WorkArena_How_Capable_Are_Web_Agents_at_Solving_Common_Knowledge_Work_Tasks.md)

- [StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models](2024年03月12日/StableToolBench_Towards_Stable_Large-Scale_Benchmarking_on_Tool_Learning_of_Large_Language_Models.md)

    - [翻译: StableToolBench项目旨在为大型语言模型的工具学习提供一个稳定且具备大规模基准测试能力的平台。](2024年03月12日/StableToolBench_Towards_Stable_Large-Scale_Benchmarking_on_Tool_Learning_of_Large_Language_Models.md)

- [Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards](2024年03月12日/Improving_Reinforcement_Learning_from_Human_Feedback_Using_Contrastive_Rewards.md)

    - [翻译: 利用对比性奖励优化基于人类反馈的强化学习方法，以提升其效果。](2024年03月12日/Improving_Reinforcement_Learning_from_Human_Feedback_Using_Contrastive_Rewards.md)

- [Large, Small or Both: A Novel Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization](2024年03月12日/Large,_Small_or_Both_A_Novel_Data_Augmentation_Framework_Based_on_Language_Models_for_Debiasing_Opinion_Summarization.md)

    - [翻译: 创新提出了一种新的数据增强框架，它结合了大、小规模语言模型的力量，旨在有效消除意见摘要中的偏见问题。](2024年03月12日/Large,_Small_or_Both_A_Novel_Data_Augmentation_Framework_Based_on_Language_Models_for_Debiasing_Opinion_Summarization.md)

- [Annotations on a Budget: Leveraging Geo-Data Similarity to Balance Model Performance and Annotation Cost](2024年03月12日/Annotations_on_a_Budget_Leveraging_Geo-Data_Similarity_to_Balance_Model_Performance_and_Annotation_Cost.md)

    - [翻译: 面对预算限制，我们提出一种创新的注释策略，巧妙运用地理数据相似性原理，在保证模型性能的同时有效控制标注成本。](2024年03月12日/Annotations_on_a_Budget_Leveraging_Geo-Data_Similarity_to_Balance_Model_Performance_and_Annotation_Cost.md)

- [Enabling self-identification in intelligent agent: insights from computational psychoanalysis](2024年03月12日/Enabling_self-identification_in_intelligent_agent_insights_from_computational_psychoanalysis.md)

    - [翻译: 探究智能体自我识别能力，通过汲取计算精神分析学领域的洞见，本研究旨在揭示如何在智能代理中实现这一特性。](2024年03月12日/Enabling_self-identification_in_intelligent_agent_insights_from_computational_psychoanalysis.md)

- [Characterization of Large Language Model Development in the Datacenter](2024年03月12日/Characterization_of_Large_Language_Model_Development_in_the_Datacenter.md)

    - [翻译: 探究数据中心中大型语言模型开发过程的特点与特征分析](2024年03月12日/Characterization_of_Large_Language_Model_Development_in_the_Datacenter.md)

- [Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Matching Framework](2024年03月12日/Decomposing_Disease_Descriptions_for_Enhanced_Pathology_Detection_A_Multi-Aspect_Vision-Language_Matching_Framework.md)

    - [翻译: 为了提升病理检测的准确性，我们提出了一种分解疾病描述的方法，并构建了一个结合多方面视觉信息与语言描述匹配的框架。该框架旨在通过深度理解和匹配病灶特征与医学文本描述的不同方面，从而强化病理检测效能。](2024年03月12日/Decomposing_Disease_Descriptions_for_Enhanced_Pathology_Detection_A_Multi-Aspect_Vision-Language_Matching_Framework.md)

- [generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation](2024年03月12日/generAItor_Tree-in-the-Loop_Text_Generation_for_Language_Model_Explainability_and_Adaptation.md)

    - [翻译: Generator：一种“循环中树”文本生成技术，旨在提升语言模型的可解释性及适应能力](2024年03月12日/generAItor_Tree-in-the-Loop_Text_Generation_for_Language_Model_Explainability_and_Adaptation.md)

- [Couler: Unified Machine Learning Workflow Optimization in Cloud](2024年03月12日/Couler_Unified_Machine_Learning_Workflow_Optimization_in_Cloud.md)

    - [翻译: Couler——致力于在云端实现机器学习工作流程的一体化优化，提升效率与性能。](2024年03月12日/Couler_Unified_Machine_Learning_Workflow_Optimization_in_Cloud.md)

- [LLMvsSmall Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model](2024年03月12日/LLMvsSmall_Model_Large_Language_Model_Based_Text_Augmentation_Enhanced_Personality_Detection_Model.md)

    - [翻译: 在个性化检测模型领域，采用大型语言模型（LLM）进行文本增强显著提升了性能。本文探讨了以LLM为核心的文本增强技术如何相较于小型模型，在这一任务上展现更优效果。](2024年03月12日/LLMvsSmall_Model_Large_Language_Model_Based_Text_Augmentation_Enhanced_Personality_Detection_Model.md)

- [Triples-to-isiXhosa (T2X): Addressing the Challenges of Low-Resource Agglutinative Data-to-Text Generation](2024年03月12日/Triples-to-isiXhosa_(T2X)_Addressing_the_Challenges_of_Low-Resource_Agglutinative_Data-to-Text_Generation.md)

    - [翻译: T2X项目专注于解决低资源环境下将三元组数据转化为isiXhosa文本这一难题，特别是在处理粘着语特性时所面临的挑战。](2024年03月12日/Triples-to-isiXhosa_(T2X)_Addressing_the_Challenges_of_Low-Resource_Agglutinative_Data-to-Text_Generation.md)

- [SIFiD: Reassess Summary Factual Inconsistency Detection with LLM](2024年03月12日/SIFiD_Reassess_Summary_Factual_Inconsistency_Detection_with_LLM.md)

    - [翻译: SIFiD：借助LLM技术，我们对摘要中事实不一致性检测进行重新审视和评估。](2024年03月12日/SIFiD_Reassess_Summary_Factual_Inconsistency_Detection_with_LLM.md)

- [Truth-Aware Context Selection: Mitigating the Hallucinations of Large Language Models Being Misled by Untruthful Contexts](2024年03月12日/Truth-Aware_Context_Selection_Mitigating_the_Hallucinations_of_Large_Language_Models_Being_Misled_by_Untruthful_Contexts.md)

    - [翻译: 为了解决大型语言模型在虚假上下文中易产生误导性内容的问题，我们提出“真实意识上下文选择”策略，旨在有效抑制其受不实背景影响而生成的幻觉式输出。](2024年03月12日/Truth-Aware_Context_Selection_Mitigating_the_Hallucinations_of_Large_Language_Models_Being_Misled_by_Untruthful_Contexts.md)

- [The future of document indexing: GPT and Donut revolutionize table of content processing](2024年03月12日/The_future_of_document_indexing_GPT_and_Donut_revolutionize_table_of_content_processing.md)

    - [翻译: GPT 和 Donut 引领未来，革新了文档索引领域，以崭新的方式重塑目录处理技术。](2024年03月12日/The_future_of_document_indexing_GPT_and_Donut_revolutionize_table_of_content_processing.md)

- [MAMMOTH: Massively Multilingual Modular Open Translation @ Helsinki](2024年03月12日/MAMMOTH_Massively_Multilingual_Modular_Open_Translation_@_Helsinki.md)

    - [翻译: MAMMOTH 是赫尔辛基研发的一款大规模、多语言且模块化的开源翻译工具，致力于推动翻译技术的创新与发展。](2024年03月12日/MAMMOTH_Massively_Multilingual_Modular_Open_Translation_@_Helsinki.md)

- [Process Modeling With Large Language Models](2024年03月12日/Process_Modeling_With_Large_Language_Models.md)

    - [翻译: 探索大型语言模型在过程建模中的应用](2024年03月12日/Process_Modeling_With_Large_Language_Models.md)

- [MoAI: Mixture of All Intelligence for Large Language and Vision Models](2024年03月12日/MoAI_Mixture_of_All_Intelligence_for_Large_Language_and_Vision_Models.md)

    - [翻译: MoAI——集多种智能于一体的解决方案，专为大型语言和视觉模型设计，融合了多元化的智能技术。](2024年03月12日/MoAI_Mixture_of_All_Intelligence_for_Large_Language_and_Vision_Models.md)

- [Robustness, Security, Privacy, Explainability, Efficiency, and Usability of Large Language Models for Code](2024年03月12日/Robustness,_Security,_Privacy,_Explainability,_Efficiency,_and_Usability_of_Large_Language_Models_for_Code.md)

    - [翻译: 针对大型语言模型应用于代码场景时，其稳健性、安全防护、隐私保护、可解释性、效能及易用性等方面的探讨与研究](2024年03月12日/Robustness,_Security,_Privacy,_Explainability,_Efficiency,_and_Usability_of_Large_Language_Models_for_Code.md)

- [Towards Graph Foundation Models for Personalization](2024年03月12日/Towards_Graph_Foundation_Models_for_Personalization.md)

    - [翻译: 本研究致力于探索用于个性化的图基础模型，旨在构建能够适应个性化需求的图神经网络模型，以挖掘和利用大规模图数据中的深层次关系与模式。](2024年03月12日/Towards_Graph_Foundation_Models_for_Personalization.md)

- [DrPlanner: Diagnosis and Repair of Motion Planners Using Large Language Models](2024年03月12日/DrPlanner_Diagnosis_and_Repair_of_Motion_Planners_Using_Large_Language_Models.md)

    - [翻译: DrPlanner 是一款利用大型语言模型，针对运动规划器进行高效诊断并实施修复的工具。](2024年03月12日/DrPlanner_Diagnosis_and_Repair_of_Motion_Planners_Using_Large_Language_Models.md)

- [Matrix-Transformation Based Low-Rank Adaptation (MTLoRA): A Brain-Inspired Method for Parameter-Efficient Fine-Tuning](2024年03月12日/Matrix-Transformation_Based_Low-Rank_Adaptation_(MTLoRA)_A_Brain-Inspired_Method_for_Parameter-Efficient_Fine-Tuning.md)

    - [翻译: MTLoRA，一种借鉴脑科学原理的创新方法，采用矩阵变换实现低秩适应，在保持参数高效的同时完成精准微调任务。](2024年03月12日/Matrix-Transformation_Based_Low-Rank_Adaptation_(MTLoRA)_A_Brain-Inspired_Method_for_Parameter-Efficient_Fine-Tuning.md)

- [In-context learning enables multimodal large language models to classify cancer pathology images](2024年03月12日/In-context_learning_enables_multimodal_large_language_models_to_classify_cancer_pathology_images.md)

    - [翻译: ICL 技术赋能多模态 LLM，使其能够对癌症病理图片进行精准分类](2024年03月12日/In-context_learning_enables_multimodal_large_language_models_to_classify_cancer_pathology_images.md)

- [Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs](2024年03月12日/Complex_Reasoning_over_Logical_Queries_on_Commonsense_Knowledge_Graphs.md)

    - [翻译: 在本研究中，我们专注于在常识知识图谱上对逻辑查询进行深入复杂的推理探索。](2024年03月12日/Complex_Reasoning_over_Logical_Queries_on_Commonsense_Knowledge_Graphs.md)

- [SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models](2024年03月12日/SmallToLarge_(S2L)_Scalable_Data_Selection_for_Fine-tuning_Large_Language_Models_by_Summarizing_Training_Trajectories_of_Small_Models.md)

    - [翻译: S2L 方法通过提炼小型模型训练历程，为大型语言模型的精细化微调提供可扩展的数据筛选方案。](2024年03月12日/SmallToLarge_(S2L)_Scalable_Data_Selection_for_Fine-tuning_Large_Language_Models_by_Summarizing_Training_Trajectories_of_Small_Models.md)

- [Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends](2024年03月12日/Hallmarks_of_Optimization_Trajectories_in_Neural_Networks_and_LLMs_The_Lengths,_Bends,_and_Dead_Ends.md)

    - [翻译: 在神经网络及大型语言模型内部，优化路径具有显著特征，表现为路径长度、曲率变化以及无解的死胡同。本研究聚焦于揭示这些路径特性在深度学习训练过程中的规律及其对LLMs的影响。](2024年03月12日/Hallmarks_of_Optimization_Trajectories_in_Neural_Networks_and_LLMs_The_Lengths,_Bends,_and_Dead_Ends.md)

- [SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression](2024年03月12日/SVD-LLM_Truncation-aware_Singular_Value_Decomposition_for_Large_Language_Model_Compression.md)

    - [翻译: SVD-LLM 是一种考虑截断影响的奇异值分解方法，专门用于大型语言模型的高效压缩。](2024年03月12日/SVD-LLM_Truncation-aware_Singular_Value_Decomposition_for_Large_Language_Model_Compression.md)

- [NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning](2024年03月12日/NavCoT_Boosting_LLM-Based_Vision-and-Language_Navigation_via_Learning_Disentangled_Reasoning.md)

    - [翻译: NavCoT 项目致力于增强大型语言模型（LLM）在视觉与语言导航任务中的表现，其策略是通过学习分离式的推理机制实现这一目标。](2024年03月12日/NavCoT_Boosting_LLM-Based_Vision-and-Language_Navigation_via_Learning_Disentangled_Reasoning.md)

- [Textual Knowledge Matters: Cross-Modality Co-Teaching for Generalized Visual Class Discovery](2024年03月12日/Textual_Knowledge_Matters_Cross-Modality_Co-Teaching_for_Generalized_Visual_Class_Discovery.md)

    - [翻译: 文本信息在其中起着关键作用，我们提出了一种名为“跨模态协同教学”的方法，旨在助力广泛而有效的视觉类别发现。这种方法充分利用了文本与视觉信息之间的相互作用，以实现对各类视觉概念的泛化发现能力。](2024年03月12日/Textual_Knowledge_Matters_Cross-Modality_Co-Teaching_for_Generalized_Visual_Class_Discovery.md)

- [Premonition: Using Generative Models to Preempt Future Data Changes in Continual Learning](2024年03月12日/Premonition_Using_Generative_Models_to_Preempt_Future_Data_Changes_in_Continual_Learning.md)

    - [翻译: 预见未来：本文探讨如何在连续学习场景下运用生成模型预判未来数据变化，以应对持续学习中的挑战。](2024年03月12日/Premonition_Using_Generative_Models_to_Preempt_Future_Data_Changes_in_Continual_Learning.md)

- [KEBench: A Benchmark on Knowledge Editing for Large Vision-Language Models](2024年03月12日/KEBench_A_Benchmark_on_Knowledge_Editing_for_Large_Vision-Language_Models.md)

    - [翻译: KEBench——专为评估大型视觉-语言模型在知识编辑任务上的表现而设立的权威基准](2024年03月12日/KEBench_A_Benchmark_on_Knowledge_Editing_for_Large_Vision-Language_Models.md)

- [Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive Learning](2024年03月12日/Rethinking_ASTE_A_Minimalist_Tagging_Scheme_Alongside_Contrastive_Learning.md)

    - [翻译: 我们对 ASTE 进行重新审视，提出了一种与对比学习并行运作的简约标签方案。](2024年03月12日/Rethinking_ASTE_A_Minimalist_Tagging_Scheme_Alongside_Contrastive_Learning.md)

- [Multi-task Manipulation Policy Modeling with Visuomotor Latent Diffusion](2024年03月12日/Multi-task_Manipulation_Policy_Modeling_with_Visuomotor_Latent_Diffusion.md)

    - [翻译: 运用视觉运动潜在扩散技术进行多任务操控策略模型构建，旨在探索在不同任务中灵活高效地实现操作策略的方法。](2024年03月12日/Multi-task_Manipulation_Policy_Modeling_with_Visuomotor_Latent_Diffusion.md)

- [Knowledge Graph Large Language Model (KG-LLM) for Link Prediction](2024年03月12日/Knowledge_Graph_Large_Language_Model_(KG-LLM)_for_Link_Prediction.md)

    - [翻译: 面向链接预测的KG-LLM，即知识图谱与大型语言模型结合的新颖框架，专注于通过大型语言模型对知识图谱中的实体间关系进行精准预测。](2024年03月12日/Knowledge_Graph_Large_Language_Model_(KG-LLM)_for_Link_Prediction.md)

- [Lumen: Unleashing Versatile Vision-Centric Capabilities of Large Multimodal Models](2024年03月12日/Lumen_Unleashing_Versatile_Vision-Centric_Capabilities_of_Large_Multimodal_Models.md)

    - [翻译: Lumen：致力于解锁大型多模态模型中蕴含的强大且多样的视觉核心功能](2024年03月12日/Lumen_Unleashing_Versatile_Vision-Centric_Capabilities_of_Large_Multimodal_Models.md)

- [Taming Pre-trained LLMs for Generalised Time Series Forecasting via Cross-modal Knowledge Distillation](2024年03月12日/Taming_Pre-trained_LLMs_for_Generalised_Time_Series_Forecasting_via_Cross-modal_Knowledge_Distillation.md)

    - [翻译: 运用跨模态知识蒸馏技术，让预训练的大型语言模型（LLM）更好地服务于通用时间序列预测任务，实现对此类预测的有效驾驭和提升。](2024年03月12日/Taming_Pre-trained_LLMs_for_Generalised_Time_Series_Forecasting_via_Cross-modal_Knowledge_Distillation.md)

- [Beyond Text: Frozen Large Language Models in Visual Signal Comprehension](2024年03月12日/Beyond_Text_Frozen_Large_Language_Models_in_Visual_Signal_Comprehension.md)

    - [翻译: 进一步探索，我们发现大型语言模型（LLM）在解析视觉信号方面也展现出潜力。本文探讨了“Frozen Large Language Models”在非文本领域——视觉信号理解上的应用，揭示其在图像、视频等多模态信息处理中的新可能。](2024年03月12日/Beyond_Text_Frozen_Large_Language_Models_in_Visual_Signal_Comprehension.md)

- [Rethinking Generative Large Language Model Evaluation for Semantic Comprehension](2024年03月12日/Rethinking_Generative_Large_Language_Model_Evaluation_for_Semantic_Comprehension.md)

    - [翻译: 为深入探究语义理解能力，本研究对大型语言模型生成评估方法进行重新审视与思考。](2024年03月12日/Rethinking_Generative_Large_Language_Model_Evaluation_for_Semantic_Comprehension.md)

- [Exploring Safety Generalization Challenges of Large Language Models via Code](2024年03月12日/Exploring_Safety_Generalization_Challenges_of_Large_Language_Models_via_Code.md)

    - [翻译: 我们通过编码实践深入探究大型语言模型在安全性泛化方面所面临的挑战。](2024年03月12日/Exploring_Safety_Generalization_Challenges_of_Large_Language_Models_via_Code.md)

- [MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric](2024年03月12日/MoPE-CLIP_Structured_Pruning_for_Efficient_Vision-Language_Models_with_Module-wise_Pruning_Error_Metric.md)

    - [翻译: MoPE-CLIP 是一种创新方法，它通过模块化剪枝误差度量实现了对高效视觉-语言模型的结构化剪枝优化。这一技术针对视觉-语言模型进行精细化处理，采用模块化剪枝策略并引入特定的误差评估指标，旨在提升模型性能的同时减少计算资源消耗。](2024年03月12日/MoPE-CLIP_Structured_Pruning_for_Efficient_Vision-Language_Models_with_Module-wise_Pruning_Error_Metric.md)

- [DeliGrasp: Inferring Object Mass, Friction, and Compliance with LLMs for Adaptive and Minimally Deforming Grasp Policies](2024年03月12日/DeliGrasp_Inferring_Object_Mass,_Friction,_and_Compliance_with_LLMs_for_Adaptive_and_Minimally_Deforming_Grasp_Policies.md)

    - [翻译: DeliGrasp 是一项技术，通过大型语言模型（LLMs）推算物体的质量、摩擦系数及顺应性，从而制定出能适应不同物体且抓取时变形极小的智能抓取策略。](2024年03月12日/DeliGrasp_Inferring_Object_Mass,_Friction,_and_Compliance_with_LLMs_for_Adaptive_and_Minimally_Deforming_Grasp_Policies.md)

- [The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage Brought By Model Editing](2024年03月12日/The_Missing_Piece_in_Model_Editing_A_Deep_Dive_into_the_Hidden_Damage_Brought_By_Model_Editing.md)

    - [翻译: 在模型编辑领域，尚有一片待深挖的盲区——即由编辑操作所带来的隐藏损害。本研究将对此进行深度剖析，揭示模型编辑过程中可能产生的无形伤害。](2024年03月12日/The_Missing_Piece_in_Model_Editing_A_Deep_Dive_into_the_Hidden_Damage_Brought_By_Model_Editing.md)

- [Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM](2024年03月12日/Branch-Train-MiX_Mixing_Expert_LLMs_into_a_Mixture-of-Experts_LLM.md)

    - [翻译: Branch-Train-MiX 技术，旨在将多个专家级大型语言模型融合为一个混合型专家 LLM，通过该方法，各专家模型的优势得以有机结合，共同提升整体性能。](2024年03月12日/Branch-Train-MiX_Mixing_Expert_LLMs_into_a_Mixture-of-Experts_LLM.md)

- [Chronos: Learning the Language of Time Series](2024年03月12日/Chronos_Learning_the_Language_of_Time_Series.md)

    - [翻译: Chronos项目致力于探索和掌握时间序列背后的“语言”，揭示其内在规律与模式。](2024年03月12日/Chronos_Learning_the_Language_of_Time_Series.md)

- [Fine-tuning Large Language Models with Sequential Instructions](2024年03月12日/Fine-tuning_Large_Language_Models_with_Sequential_Instructions.md)

    - [翻译: 针对大型语言模型，我们采用连续指令进行微调，旨在探究这种微调方式如何提升模型性能和适应性。](2024年03月12日/Fine-tuning_Large_Language_Models_with_Sequential_Instructions.md)

- [Data Interpreter: An LLM Agent For Data Science](2024年03月12日/Data_Interpreter_An_LLM_Agent_For_Data_Science.md)

    - [翻译: 数据解释员：一款专为数据科学打造的 LLM 智能助手](2024年03月12日/Data_Interpreter_An_LLM_Agent_For_Data_Science.md)

- [Can Large Language Models Identify Authorship?](2024年03月12日/Can_Large_Language_Models_Identify_Authorship.md)

    - [翻译: 大型语言模型是否具备鉴别文本作者的能力？](2024年03月12日/Can_Large_Language_Models_Identify_Authorship.md)

- [Large Language Models are Contrastive Reasoners](2024年03月12日/Large_Language_Models_are_Contrastive_Reasoners.md)

    - [翻译: 大型语言模型展现出了显著的对比推理能力](2024年03月12日/Large_Language_Models_are_Contrastive_Reasoners.md)

- [MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension](2024年03月12日/MoleculeQA_A_Dataset_to_Evaluate_Factual_Accuracy_in_Molecular_Comprehension.md)

    - [翻译: MoleculeQA 是专为检验分子理解领域中事实准确性而设计的数据集，旨在助力科研人员评测模型在解析分子信息时的精准度。](2024年03月12日/MoleculeQA_A_Dataset_to_Evaluate_Factual_Accuracy_in_Molecular_Comprehension.md)

- [Embedded Translations for Low-resource Automated Glossing](2024年03月12日/Embedded_Translations_for_Low-resource_Automated_Glossing.md)

    - [翻译: 为解决低资源环境下自动术语注解问题，我们提出嵌入式翻译方法。该方法旨在利用嵌入技术，高效实现对稀有语言或词汇的精准翻译和注解。](2024年03月12日/Embedded_Translations_for_Low-resource_Automated_Glossing.md)

- [VANP: Learning Where to See for Navigation with Self-Supervised Vision-Action Pre-Training](2024年03月12日/VANP_Learning_Where_to_See_for_Navigation_with_Self-Supervised_Vision-Action_Pre-Training.md)

    - [翻译: VANP 方法利用自我监督的视觉-动作预训练技术，教导模型在进行导航时学会自主发现关键观察点，从而提升导航能力。](2024年03月12日/VANP_Learning_Where_to_See_for_Navigation_with_Self-Supervised_Vision-Action_Pre-Training.md)

- [Generating Clarification Questions for Disambiguating Contracts](2024年03月12日/Generating_Clarification_Questions_for_Disambiguating_Contracts.md)

    - [翻译: 为解决合同中的歧义，我们致力于生成有针对性的澄清问题。](2024年03月12日/Generating_Clarification_Questions_for_Disambiguating_Contracts.md)

- [Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging](2024年03月12日/Training_Small_Multimodal_Models_to_Bridge_Biomedical_Competency_Gap_A_Case_Study_in_Radiology_Imaging.md)

    - [翻译: 为缩小生物医学领域的能力差距，我们进行了一项针对放射影像学的案例研究，通过训练小巧而强大的多模态模型来实现这一目标。](2024年03月12日/Training_Small_Multimodal_Models_to_Bridge_Biomedical_Competency_Gap_A_Case_Study_in_Radiology_Imaging.md)

- [Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems](2024年03月12日/Investigating_the_performance_of_Retrieval-Augmented_Generation_and_fine-tuning_for_the_development_of_AI-driven_knowledge-based_systems.md)

    - [翻译: 本研究探讨了检索增强生成与微调技术在构建AI驱动的知识系统中的性能表现，旨在深入理解并提升相关系统的效能。](2024年03月12日/Investigating_the_performance_of_Retrieval-Augmented_Generation_and_fine-tuning_for_the_development_of_AI-driven_knowledge-based_systems.md)

- [Simple and Scalable Strategies to Continually Pre-train Large Language Models](2024年03月13日/Simple_and_Scalable_Strategies_to_Continually_Pre-train_Large_Language_Models.md)

    - [翻译: 本研究提出了一种简洁且易于扩展的方法，用于持续预训练大型语言模型，旨在提升模型在不断变化的数据环境中的适应性和性能。](2024年03月13日/Simple_and_Scalable_Strategies_to_Continually_Pre-train_Large_Language_Models.md)

- [DAM: Dynamic Adapter Merging for Continual Video QA Learning](2024年03月13日/DAM_Dynamic_Adapter_Merging_for_Continual_Video_QA_Learning.md)

    - [翻译: DAM 技术，即动态适配器融合，旨在解决连续视频问答学习场景下的问题，通过整合并适时调整适配器模块以适应不断变化的学习需求。](2024年03月13日/DAM_Dynamic_Adapter_Merging_for_Continual_Video_QA_Learning.md)

- [Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework](2024年03月13日/Steering_LLMs_Towards_Unbiased_Responses_A_Causality-Guided_Debiasing_Framework.md)

    - [翻译: 为了引导 LLM 输出公正无偏的答案，我们提出了一种基于因果关系指导的去偏见框架。](2024年03月13日/Steering_LLMs_Towards_Unbiased_Responses_A_Causality-Guided_Debiasing_Framework.md)

- [The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models](2024年03月13日/The_Garden_of_Forking_Paths_Observing_Dynamic_Parameters_Distribution_in_Large_Language_Models.md)

    - [翻译: 在“分叉路径的花园”中，我们深入探究大型语言模型内部的动态参数分布，揭示其内在变化规律与特性。](2024年03月13日/The_Garden_of_Forking_Paths_Observing_Dynamic_Parameters_Distribution_in_Large_Language_Models.md)

- [Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization](2024年03月13日/Strengthening_Multimodal_Large_Language_Model_with_Bootstrapped_Preference_Optimization.md)

    - [翻译: 运用引导式偏好优化策略，提升多模态大型语言模型的表现力和效能。](2024年03月13日/Strengthening_Multimodal_Large_Language_Model_with_Bootstrapped_Preference_Optimization.md)

- [SOTOPIA-$π$: Interactive Learning of Socially Intelligent Language Agents](2024年03月13日/SOTOPIA-$π$_Interactive_Learning_of_Socially_Intelligent_Language_Agents.md)

    - [翻译: SOTOPIA-$π$项目致力于研究如何通过交互式学习培养具备社交智能的语言代理。](2024年03月13日/SOTOPIA-$π$_Interactive_Learning_of_Socially_Intelligent_Language_Agents.md)

- [Review of Generative AI Methods in Cybersecurity](2024年03月13日/Review_of_Generative_AI_Methods_in_Cybersecurity.md)

    - [翻译: 本文将对应用于网络安全领域的生成式人工智能方法进行全面探讨和评析。](2024年03月13日/Review_of_Generative_AI_Methods_in_Cybersecurity.md)

- [TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning](2024年03月13日/TeaMs-RL_Teaching_LLMs_to_Teach_Themselves_Better_Instructions_via_Reinforcement_Learning.md)

    - [翻译: TeaMs-RL项目利用强化学习，让大型语言模型（LLMs）学会自我优化和改进指令。这项研究旨在通过RL机制使LLMs能够更有效地进行自我教学，不断提升其理解与生成高质量指令的能力。](2024年03月13日/TeaMs-RL_Teaching_LLMs_to_Teach_Themselves_Better_Instructions_via_Reinforcement_Learning.md)

- [Do Language Models Care About Text Quality? Evaluating Web-Crawled Corpora Across 11 Languages](2024年03月13日/Do_Language_Models_Care_About_Text_Quality_Evaluating_Web-Crawled_Corpora_Across_11_Languages.md)

    - [翻译: 语言模型对文本质量有多在意？我们针对 11 种语言的网络抓取语料库进行评估，以探究其对文本质量的关注程度。](2024年03月13日/Do_Language_Models_Care_About_Text_Quality_Evaluating_Web-Crawled_Corpora_Across_11_Languages.md)

- [Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records](2024年03月13日/Zero-shot_and_Few-shot_Generation_Strategies_for_Artificial_Clinical_Records.md)

    - [翻译: 针对人工临床记录，我们探讨了零样本与少量样本生成策略，旨在实现更高效、精准的模拟数据生成。](2024年03月13日/Zero-shot_and_Few-shot_Generation_Strategies_for_Artificial_Clinical_Records.md)

- [An Efficient End-to-End Approach to Noise Invariant Speech Features via Multi-Task Learning](2024年03月13日/An_Efficient_End-to-End_Approach_to_Noise_Invariant_Speech_Features_via_Multi-Task_Learning.md)

    - [翻译: 本研究提出了一种新颖高效的端到端解决方案，利用多任务学习技术来提取对噪声具有鲁棒性的语音特征。](2024年03月13日/An_Efficient_End-to-End_Approach_to_Noise_Invariant_Speech_Features_via_Multi-Task_Learning.md)

- [Human Alignment of Large Language Models through Online Preference Optimisation](2024年03月13日/Human_Alignment_of_Large_Language_Models_through_Online_Preference_Optimisation.md)

    - [翻译: 借助在线偏好优化技术，本研究探讨如何实现大型语言模型与人类需求的精准对齐。](2024年03月13日/Human_Alignment_of_Large_Language_Models_through_Online_Preference_Optimisation.md)

- [MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models](2024年03月13日/MedInsight_A_Multi-Source_Context_Augmentation_Framework_for_Generating_Patient-Centric_Medical_Responses_using_Large_Language_Models.md)

    - [翻译: MedInsight：针对大型语言模型，我们提出了一种创新的多源上下文增强框架，旨在借助该框架为生成个性化、以患者为中心的医疗回复提供有力支持。](2024年03月13日/MedInsight_A_Multi-Source_Context_Augmentation_Framework_for_Generating_Patient-Centric_Medical_Responses_using_Large_Language_Models.md)

- [Language-Grounded Dynamic Scene Graphs for Interactive Object Search with Mobile Manipulation](2024年03月13日/Language-Grounded_Dynamic_Scene_Graphs_for_Interactive_Object_Search_with_Mobile_Manipulation.md)

    - [翻译: 为实现结合移动操作的交互式物体搜索，我们提出了一种基于语言引导的动态场景图方法。该方法利用语言信息构建动态场景图，以高效指导机器人在复杂环境中进行目标物体搜索和交互。](2024年03月13日/Language-Grounded_Dynamic_Scene_Graphs_for_Interactive_Object_Search_with_Mobile_Manipulation.md)

- [DevBench: A Comprehensive Benchmark for Software Development](2024年03月13日/DevBench_A_Comprehensive_Benchmark_for_Software_Development.md)

    - [翻译: DevBench 是一款综合全面的软件开发基准测试平台，旨在为开发者提供衡量和比较不同开发环境、工具及实践效果的标准参照。](2024年03月13日/DevBench_A_Comprehensive_Benchmark_for_Software_Development.md)

- [Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments](2024年03月13日/Call_Me_When_Necessary_LLMs_can_Efficiently_and_Faithfully_Reason_over_Structured_Environments.md)

    - [翻译: 无论是处理结构化环境还是应对复杂需求，LLMs 都能以高效而精准的方式进行推理。不妨视其为“必要时随时呼叫”的可靠智能工具。](2024年03月13日/Call_Me_When_Necessary_LLMs_can_Efficiently_and_Faithfully_Reason_over_Structured_Environments.md)

- [Non-discrimination Criteria for Generative Language Models](2024年03月13日/Non-discrimination_Criteria_for_Generative_Language_Models.md)

    - [翻译: 针对生成式语言模型，探究其应遵循的非歧视性准则。](2024年03月13日/Non-discrimination_Criteria_for_Generative_Language_Models.md)

- [AIGCs Confuse AI Too: Investigating and Explaining Synthetic Image-induced Hallucinations in Large Vision-Language Models](2024年03月13日/AIGCs_Confuse_AI_Too_Investigating_and_Explaining_Synthetic_Image-induced_Hallucinations_in_Large_Vision-Language_Models.md)

    - [翻译: AIGC 生成的内容同样能迷惑 AI，我们正致力于探究大型视觉-语言模型在面对合成图像时产生的幻觉现象，并对其进行深入解析。](2024年03月13日/AIGCs_Confuse_AI_Too_Investigating_and_Explaining_Synthetic_Image-induced_Hallucinations_in_Large_Vision-Language_Models.md)

- [Masked Generative Story Transformer with Character Guidance and Caption Augmentation](2024年03月13日/Masked_Generative_Story_Transformer_with_Character_Guidance_and_Caption_Augmentation.md)

    - [翻译: 通过采用字符引导与标题增强技术，我们提出了一种掩码生成故事Transformer模型。该模型在生成连贯故事的同时，能够借助字符级别的指引以及标题信息的补充，以提升文本生成质量和叙事逻辑性。](2024年03月13日/Masked_Generative_Story_Transformer_with_Character_Guidance_and_Caption_Augmentation.md)

- [Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator](2024年03月13日/Automatic_Interactive_Evaluation_for_Large_Language_Models_with_State_Aware_Patient_Simulator.md)

    - [翻译: 针对大型语言模型，我们提出了一种结合了状态感知病人模拟器的自动交互评估方法。这种方法能够模拟真实世界中病人的复杂状态变化，从而对大型语言模型进行深入细致的互动性评估。](2024年03月13日/Automatic_Interactive_Evaluation_for_Large_Language_Models_with_State_Aware_Patient_Simulator.md)

- [Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking](2024年03月13日/Rich_Semantic_Knowledge_Enhanced_Large_Language_Models_for_Few-shot_Chinese_Spell_Checking.md)

    - [翻译: 通过融入丰富语义知识以提升大型语言模型能力，我们致力于实现针对少量样本的高效中文拼写纠错。](2024年03月13日/Rich_Semantic_Knowledge_Enhanced_Large_Language_Models_for_Few-shot_Chinese_Spell_Checking.md)

- [Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH Mask based Efficient Fine-tuning](2024年03月13日/Data-oriented_Dynamic_Fine-tuning_Parameter_Selection_Strategy_for_FISH_Mask_based_Efficient_Fine-tuning.md)

    - [翻译: 本研究提出一种面向数据的动态微调参数选取策略，专为FISH Mask高效微调设计。该策略旨在针对不同的数据集特性，智能地选取并调整FISH Mask模型的微调参数，以实现更高效、精准的模型优化。](2024年03月13日/Data-oriented_Dynamic_Fine-tuning_Parameter_Selection_Strategy_for_FISH_Mask_based_Efficient_Fine-tuning.md)

- [SoK: Reducing the Vulnerability of Fine-tuned Language Models to Membership Inference Attacks](2024年03月13日/SoK_Reducing_the_Vulnerability_of_Fine-tuned_Language_Models_to_Membership_Inference_Attacks.md)

    - [翻译: SoK（系统化知识）：致力于降低微调语言模型遭受成员推断攻击的风险步骤 1 翻译：SoK（Systematization of Knowledge）探究了如何减少微调语言模型在面对成员推断攻击时所表现出的脆弱性问题。步骤 2 翻译优化：本文为 SoK（系统化知识）研究，专注于解决微调语言模型对成员推断攻击的易感性问题，旨在提出有效方法以降低此类模型在此类安全威胁下的风险。](2024年03月13日/SoK_Reducing_the_Vulnerability_of_Fine-tuned_Language_Models_to_Membership_Inference_Attacks.md)

- [Authorship Verification based on the Likelihood Ratio of Grammar Models](2024年03月13日/Authorship_Verification_based_on_the_Likelihood_Ratio_of_Grammar_Models.md)

    - [翻译: 通过对语法模型的似然比分析进行作者身份验证的研究](2024年03月13日/Authorship_Verification_based_on_the_Likelihood_Ratio_of_Grammar_Models.md)

- [Search-based Optimisation of LLM Learning Shots for Story Point Estimation](2024年03月13日/Search-based_Optimisation_of_LLM_Learning_Shots_for_Story_Point_Estimation.md)

    - [翻译: 针对故事点估算任务，我们提出了一种通过搜索策略优化大型语言模型（LLM）学习次数的方法，旨在提升其估算效能。](2024年03月13日/Search-based_Optimisation_of_LLM_Learning_Shots_for_Story_Point_Estimation.md)

- [Software Vulnerability and Functionality Assessment using LLMs](2024年03月13日/Software_Vulnerability_and_Functionality_Assessment_using_LLMs.md)

    - [翻译: 运用大型语言模型（LLMs）对软件的脆弱性及功能进行全面评估](2024年03月13日/Software_Vulnerability_and_Functionality_Assessment_using_LLMs.md)

- [Tastle: Distract Large Language Models for Automatic Jailbreak Attack](2024年03月13日/Tastle_Distract_Large_Language_Models_for_Automatic_Jailbreak_Attack.md)

    - [翻译: Tastle 是一种技术，通过干扰大型语言模型以实现针对目标系统的自动越狱攻击。](2024年03月13日/Tastle_Distract_Large_Language_Models_for_Automatic_Jailbreak_Attack.md)

- [System for systematic literature review using multiple AI agents: Concept and an empirical evaluation](2024年03月13日/System_for_systematic_literature_review_using_multiple_AI_agents_Concept_and_an_empirical_evaluation.md)

    - [翻译: 本研究提出了一种采用多个AI代理进行系统性文献综述的创新系统，并对其进行了深入的概念阐述和严谨的实证评估。](2024年03月13日/System_for_systematic_literature_review_using_multiple_AI_agents_Concept_and_an_empirical_evaluation.md)

- [A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance](2024年03月13日/A_Picture_Is_Worth_a_Thousand_Words_Exploring_Diagram_and_Video-Based_OOP_Exercises_to_Counter_LLM_Over-Reliance.md)

    - [翻译: 在对抗大型语言模型过度依赖的过程中，我们发现“一图胜千言”。为此，我们探索了利用图表和视频进行面向对象编程练习的新途径，以减轻LLM过度依赖现象。](2024年03月13日/A_Picture_Is_Worth_a_Thousand_Words_Exploring_Diagram_and_Video-Based_OOP_Exercises_to_Counter_LLM_Over-Reliance.md)

- [CoIN: A Benchmark of Continual Instruction tuNing for Multimodel Large Language Model](2024年03月13日/CoIN_A_Benchmark_of_Continual_Instruction_tuNing_for_Multimodel_Large_Language_Model.md)

    - [翻译: CoIN 是一个针对多模态大型语言模型的连续指令优化基准，旨在衡量和推进此类模型在不断学习和适应新指令任务中的性能。](2024年03月13日/CoIN_A_Benchmark_of_Continual_Instruction_tuNing_for_Multimodel_Large_Language_Model.md)

- [From human experts to machines: An LLM supported approach to ontology and knowledge graph construction](2024年03月13日/From_human_experts_to_machines_An_LLM_supported_approach_to_ontology_and_knowledge_graph_construction.md)

    - [翻译: 跃迁至机器智能：运用大型语言模型助力本体与知识图谱构建之旅](2024年03月13日/From_human_experts_to_machines_An_LLM_supported_approach_to_ontology_and_knowledge_graph_construction.md)

- [LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments](2024年03月13日/LLM-Assisted_Light_Leveraging_Large_Language_Model_Capabilities_for_Human-Mimetic_Traffic_Signal_Control_in_Complex_Urban_Environments.md)

    - [翻译: 在复杂的城市环境中，我们提出了一项利用大型语言模型（LLM）能力来实现仿真人智能的交通信号控制系统——LLM辅助式智慧信号灯，以应对复杂的交通环境挑战。](2024年03月13日/LLM-Assisted_Light_Leveraging_Large_Language_Model_Capabilities_for_Human-Mimetic_Traffic_Signal_Control_in_Complex_Urban_Environments.md)

- [Positive Lynden-Bell derivative as a ticket to the bar trap?](2024年03月13日/Positive_Lynden-Bell_derivative_as_a_ticket_to_the_bar_trap.md)

    - [翻译: 正值的Lynden-Bell导数，是否意味着通往“粒子陷阱”酒吧的入场券？](2024年03月13日/Positive_Lynden-Bell_derivative_as_a_ticket_to_the_bar_trap.md)

- [Knowledge Conflicts for LLMs: A Survey](2024年03月13日/Knowledge_Conflicts_for_LLMs_A_Survey.md)

    - [翻译: 针对 LLMs 的知识冲突研究概述](2024年03月13日/Knowledge_Conflicts_for_LLMs_A_Survey.md)

- [Is Context Helpful for Chat Translation Evaluation?](2024年03月13日/Is_Context_Helpful_for_Chat_Translation_Evaluation.md)

    - [翻译: 在聊天翻译评估中，引入上下文真的能起到积极作用吗？](2024年03月13日/Is_Context_Helpful_for_Chat_Translation_Evaluation.md)

- [StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses](2024年03月13日/StreamingDialogue_Prolonged_Dialogue_Learning_via_Long_Context_Compression_with_Minimal_Losses.md)

    - [翻译: StreamingDialogue 方法借助于最小损失的长上下文高效压缩技术，实现了对话模型对长时间、连续对话的深入学习。](2024年03月13日/StreamingDialogue_Prolonged_Dialogue_Learning_via_Long_Context_Compression_with_Minimal_Losses.md)

- [HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback](2024年03月13日/HRLAIF_Improvements_in_Helpfulness_and_Harmlessness_in_Open-domain_Reinforcement_Learning_From_AI_Feedback.md)

    - [翻译: HRLAIF 是一种创新方法，它利用 AI 反馈，在开放域强化学习中显著提升了模型的有用性和减少潜在危害。该研究致力于优化人工智能在复杂环境下的决策行为，确保其更加有益且无害。](2024年03月13日/HRLAIF_Improvements_in_Helpfulness_and_Harmlessness_in_Open-domain_Reinforcement_Learning_From_AI_Feedback.md)

- [Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform](2024年03月13日/Towards_Personalized_Evaluation_of_Large_Language_Models_with_An_Anonymous_Crowd-Sourcing_Platform.md)

    - [翻译: 本研究利用匿名众包平台，旨在探索针对大型语言模型的个性化评估方法。](2024年03月13日/Towards_Personalized_Evaluation_of_Large_Language_Models_with_An_Anonymous_Crowd-Sourcing_Platform.md)

- [CleanAgent: Automating Data Standardization with LLM-based Agents](2024年03月13日/CleanAgent_Automating_Data_Standardization_with_LLM-based_Agents.md)

    - [翻译: CleanAgent是一款利用大型语言模型（LLM）构建的数据标准化自动化工具，它借助LLM智能代理技术，实现高效、自动化的数据清洗与标准化。](2024年03月13日/CleanAgent_Automating_Data_Standardization_with_LLM-based_Agents.md)

- [Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models](2024年03月13日/Mastering_Text,_Code_and_Math_Simultaneously_via_Fusing_Highly_Specialized_Language_Models.md)

    - [翻译: 通过深度融合各领域的高度专业化语言模型，实现对文本、代码与数学的同时精通](2024年03月13日/Mastering_Text,_Code_and_Math_Simultaneously_via_Fusing_Highly_Specialized_Language_Models.md)

- [Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification](2024年03月13日/Efficient_Prompt_Tuning_of_Large_Vision-Language_Model_for_Fine-Grained_Ship_Classification.md)

    - [翻译: 在细粒度船舶分类任务上，我们提出了一种高效的方法来对大型视觉-语言模型进行提示调优，以提升其性能表现。](2024年03月13日/Efficient_Prompt_Tuning_of_Large_Vision-Language_Model_for_Fine-Grained_Ship_Classification.md)

- [Emergence of Social Norms in Large Language Model-based Agent Societies](2024年03月13日/Emergence_of_Social_Norms_in_Large_Language_Model-based_Agent_Societies.md)

    - [翻译: 探究大型语言模型驱动的智能体社会中社会规范如何自然形成与发展](2024年03月13日/Emergence_of_Social_Norms_in_Large_Language_Model-based_Agent_Societies.md)

- [Continuous Object State Recognition for Cooking Robots Using Pre-Trained Vision-Language Models and Black-box Optimization](2024年03月13日/Continuous_Object_State_Recognition_for_Cooking_Robots_Using_Pre-Trained_Vision-Language_Models_and_Black-box_Optimization.md)

    - [翻译: 本研究运用预训练的视觉-语言模型与黑盒优化方法，助力烹饪机器人实现对连续物体状态的精准识别。](2024年03月13日/Continuous_Object_State_Recognition_for_Cooking_Robots_Using_Pre-Trained_Vision-Language_Models_and_Black-box_Optimization.md)

- [Boosting Disfluency Detection with Large Language Model as Disfluency Generator](2024年03月13日/Boosting_Disfluency_Detection_with_Large_Language_Model_as_Disfluency_Generator.md)

    - [翻译: 通过将大型语言模型用作不流畅生成器，我们能够显著提升对不流畅性的检测效果。这项研究旨在借助LLM的力量，探索其在模拟和识别语言表达中的不流畅性方面的潜力，从而改进不流畅检测技术。](2024年03月13日/Boosting_Disfluency_Detection_with_Large_Language_Model_as_Disfluency_Generator.md)

- [Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs](2024年03月13日/Empowering_Robotics_with_Large_Language_Models_osmAG_Map_Comprehension_with_LLMs.md)

    - [翻译: 借助大型语言模型的力量，我们正在革新机器人技术领域，特别是在运用LLMs实现对osmAG地图的深度理解方面。](2024年03月13日/Empowering_Robotics_with_Large_Language_Models_osmAG_Map_Comprehension_with_LLMs.md)

- [Large Language Models are Parallel Multilingual Learners](2024年03月13日/Large_Language_Models_are_Parallel_Multilingual_Learners.md)

    - [翻译: 大型语言模型能够实现并行多语言学习，揭示了其在多种语言环境中同步掌握知识的能力。](2024年03月13日/Large_Language_Models_are_Parallel_Multilingual_Learners.md)

- [UniCode: Learning a Unified Codebook for Multimodal Large Language Models](2024年03月13日/UniCode_Learning_a_Unified_Codebook_for_Multimodal_Large_Language_Models.md)

    - [翻译: UniCode项目致力于为多模态大型语言模型打造一个统一的码本，旨在整合和优化不同模态数据在模型中的表示与处理。](2024年03月13日/UniCode_Learning_a_Unified_Codebook_for_Multimodal_Large_Language_Models.md)

- [Query Rewriting via Large Language Models](2024年03月13日/Query_Rewriting_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现查询改写技术](2024年03月13日/Query_Rewriting_via_Large_Language_Models.md)

- [RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems](2024年03月13日/RAGGED_Towards_Informed_Design_of_Retrieval_Augmented_Generation_Systems.md)

    - [翻译: RAGGED：致力于实现知情设计的检索增强生成系统研究，旨在深入理解并改进此类系统的构建方式。](2024年03月13日/RAGGED_Towards_Informed_Design_of_Retrieval_Augmented_Generation_Systems.md)

- [Detecting Hallucination and Coverage Errors in Retrieval Augmented Generation for Controversial Topics](2024年03月13日/Detecting_Hallucination_and_Coverage_Errors_in_Retrieval_Augmented_Generation_for_Controversial_Topics.md)

    - [翻译: 针对争议性话题的检索增强生成技术，本研究致力于揭示其中的幻觉现象与覆盖错误，并对其进行有效检测。](2024年03月13日/Detecting_Hallucination_and_Coverage_Errors_in_Retrieval_Augmented_Generation_for_Controversial_Topics.md)

- [VisionGPT: Vision-Language Understanding Agent Using Generalized Multimodal Framework](2024年03月13日/VisionGPT_Vision-Language_Understanding_Agent_Using_Generalized_Multimodal_Framework.md)

    - [翻译: VisionGPT 是一款基于通用多模态框架构建的视觉-语言理解利器，旨在高效融合视觉与语言信息，实现深度理解。](2024年03月13日/VisionGPT_Vision-Language_Understanding_Agent_Using_Generalized_Multimodal_Framework.md)

- [AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents](2024年03月13日/AutoGuide_Automated_Generation_and_Selection_of_State-Aware_Guidelines_for_Large_Language_Model_Agents.md)

    - [翻译: AutoGuide 是一项技术，它能自动为大型语言模型智能体生成并优选具备状态感知能力的操作指南。](2024年03月13日/AutoGuide_Automated_Generation_and_Selection_of_State-Aware_Guidelines_for_Large_Language_Model_Agents.md)

- [Cultural evolution in populations of Large Language Models](2024年03月13日/Cultural_evolution_in_populations_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型群体中文化演进的现象](2024年03月13日/Cultural_evolution_in_populations_of_Large_Language_Models.md)

- [TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation](2024年03月13日/TINA_Think,_Interaction,_and_Action_Framework_for_Zero-Shot_Vision_Language_Navigation.md)

    - [翻译: TINA 是一个专为零样本视觉语言导航设计的框架，涵盖了思考（Think）、交互（Interaction）和行动（Action）三个关键维度。](2024年03月13日/TINA_Think,_Interaction,_and_Action_Framework_for_Zero-Shot_Vision_Language_Navigation.md)

- [Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors](2024年03月13日/Re-Search_for_The_Truth_Multi-round_Retrieval-augmented_Large_Language_Models_are_Strong_Fake_News_Detectors.md)

    - [翻译: 《重新搜索真相：通过多次检索增强的大规模语言模型在假新闻识别中展现强大实力》注：由于原句标题简短且具有一定的修辞特点，从准确性和生动性角度出发，在第一步直译的基础上，第二步仅做了微调以符合中文标题通常的行文习惯，保持了原有的紧凑与有力的表达风格。](2024年03月13日/Re-Search_for_The_Truth_Multi-round_Retrieval-augmented_Large_Language_Models_are_Strong_Fake_News_Detectors.md)

- [OverleafCopilot: Empowering Academic Writing in Overleaf with Large Language Models](2024年03月13日/OverleafCopilot_Empowering_Academic_Writing_in_Overleaf_with_Large_Language_Models.md)

    - [翻译: OverleafCopilot：借助大型语言模型的力量，让 Overleaf 上的学术写作如虎添翼步骤详解：](2024年03月13日/OverleafCopilot_Empowering_Academic_Writing_in_Overleaf_with_Large_Language_Models.md)

- [Circuit Transformer: End-to-end Circuit Design by Predicting the Next Gate](2024年03月13日/Circuit_Transformer_End-to-end_Circuit_Design_by_Predicting_the_Next_Gate.md)

    - [翻译: 电路Transformer，通过精准预测下一个组件门，实现全程自动化的电路设计。](2024年03月13日/Circuit_Transformer_End-to-end_Circuit_Design_by_Predicting_the_Next_Gate.md)

- [A Moral Imperative: The Need for Continual Superalignment of Large Language Models](2024年03月13日/A_Moral_Imperative_The_Need_for_Continual_Superalignment_of_Large_Language_Models.md)

    - [翻译: 面对大型语言模型的发展，一项不容忽视的道德责任是实现其持续超对齐。这一“道德使命”强调了在模型迭代过程中不断校准其价值观与人类伦理规范的重要性。（注：由于原句较短，经过一步翻译后已经较为通顺，故步骤2在此基础上稍作润色以增强表达效果。）](2024年03月13日/A_Moral_Imperative_The_Need_for_Continual_Superalignment_of_Large_Language_Models.md)

- [GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping](2024年03月14日/GaussianGrasper_3D_Language_Gaussian_Splatting_for_Open-vocabulary_Robotic_Grasping.md)

    - [翻译: GaussianGrasper 是一项创新技术，通过三维语言高斯扩散方法赋予机器人以开放式词汇理解能力，从而实现更灵活精准的物体抓取。](2024年03月14日/GaussianGrasper_3D_Language_Gaussian_Splatting_for_Open-vocabulary_Robotic_Grasping.md)

- [Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference](2024年03月14日/Dynamic_Memory_Compression_Retrofitting_LLMs_for_Accelerated_Inference.md)

    - [翻译: 动态内存压缩技术应用于LLMs，旨在实现快速推理优化。这项技术是对大型语言模型进行改造升级，以适应更高效的推理需求。](2024年03月14日/Dynamic_Memory_Compression_Retrofitting_LLMs_for_Accelerated_Inference.md)

- [3D-VLA: A 3D Vision-Language-Action Generative World Model](2024年03月14日/3D-VLA_A_3D_Vision-Language-Action_Generative_World_Model.md)

    - [翻译: 3D-VLA，一款创新的三维视觉-语言-动作生成世界模型，它将三维视觉信息、自然语言理解和执行动作的能力整合于一体。](2024年03月14日/3D-VLA_A_3D_Vision-Language-Action_Generative_World_Model.md)

- [PosSAM: Panoptic Open-vocabulary Segment Anything](2024年03月14日/PosSAM_Panoptic_Open-vocabulary_Segment_Anything.md)

    - [翻译: PosSAM：一款能够对任意目标进行泛视觉、开词汇表的全方位分割技术](2024年03月14日/PosSAM_Panoptic_Open-vocabulary_Segment_Anything.md)

- [MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](2024年03月14日/MM1_Methods,_Analysis_&_Insights_from_Multimodal_LLM_Pre-training.md)

    - [翻译: MM1 探究了多模态 LLM 预训练中的方法策略、深度分析及其带来的独到见解。](2024年03月14日/MM1_Methods,_Analysis_&_Insights_from_Multimodal_LLM_Pre-training.md)

- [Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey](2024年03月14日/Large_Language_Models_and_Causal_Inference_in_Collaboration_A_Comprehensive_Survey.md)

    - [翻译: 针对大型语言模型在协作场景下的因果推断应用，本研究提供了一份详尽的综述。](2024年03月14日/Large_Language_Models_and_Causal_Inference_in_Collaboration_A_Comprehensive_Survey.md)

- [Logical Discrete Graphical Models Must Supplement Large Language Models for Information Synthesis](2024年03月14日/Logical_Discrete_Graphical_Models_Must_Supplement_Large_Language_Models_for_Information_Synthesis.md)

    - [翻译: 为了实现有效信息综合，在处理大型语言模型时，逻辑离散图形模型不可或缺。它们能够辅助和增强LLM在整合信息方面的表现。](2024年03月14日/Logical_Discrete_Graphical_Models_Must_Supplement_Large_Language_Models_for_Information_Synthesis.md)

- [ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models](2024年03月14日/ExploRLLM_Guiding_Exploration_in_Reinforcement_Learning_with_Large_Language_Models.md)

    - [翻译: ExploRLLM 是一项研究，旨在利用大型语言模型（LLMs）来引导强化学习过程中的有效探索。](2024年03月14日/ExploRLLM_Guiding_Exploration_in_Reinforcement_Learning_with_Large_Language_Models.md)

- [Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation](2024年03月14日/Eyes_Closed,_Safety_On_Protecting_Multimodal_LLMs_via_Image-to-Text_Transformation.md)

    - [翻译: 在“闭眼”状态下保障安全：探索利用图像转文本技术来保护多模态大型语言模型（LLMs）的方案](2024年03月14日/Eyes_Closed,_Safety_On_Protecting_Multimodal_LLMs_via_Image-to-Text_Transformation.md)

- [Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models](2024年03月14日/Enhancing_Trust_in_Autonomous_Agents_An_Architecture_for_Accountability_and_Explainability_through_Blockchain_and_Large_Language_Models.md)

    - [翻译: 为提升对自主智能体的信任，我们提出了一种结合区块链技术和大型语言模型的新型架构，旨在实现自主智能体的责任追溯与可解释性。](2024年03月14日/Enhancing_Trust_in_Autonomous_Agents_An_Architecture_for_Accountability_and_Explainability_through_Blockchain_and_Large_Language_Models.md)

- [Welcome Your New AI Teammate: On Safety Analysis by Leashing Large Language Models](2024年03月14日/Welcome_Your_New_AI_Teammate_On_Safety_Analysis_by_Leashing_Large_Language_Models.md)

    - [翻译: 向您介绍您的新晋AI队友，它将通过约束大型语言模型的方式助力安全分析工作。](2024年03月14日/Welcome_Your_New_AI_Teammate_On_Safety_Analysis_by_Leashing_Large_Language_Models.md)

- [Less is More: Data Value Estimation for Visual Instruction Tuning](2024年03月14日/Less_is_More_Data_Value_Estimation_for_Visual_Instruction_Tuning.md)

    - [翻译: 在视觉指令微调中，我们提出“少即是多”的理念，专注于对数据价值的精准估算。这项研究旨在探讨和挖掘少量高质量数据在优化视觉指令模型性能方面的重要作用。](2024年03月14日/Less_is_More_Data_Value_Estimation_for_Visual_Instruction_Tuning.md)

- [Logits of API-Protected LLMs Leak Proprietary Information](2024年03月14日/Logits_of_API-Protected_LLMs_Leak_Proprietary_Information.md)

    - [翻译: 研究表明，受 API 保护的大规模语言模型（LLMs）的 logits 输出可能泄露其内部所包含的专有信息。](2024年03月14日/Logits_of_API-Protected_LLMs_Leak_Proprietary_Information.md)

- [VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding](2024年03月14日/VisionGPT-3D_A_Generalized_Multimodal_Agent_for_Enhanced_3D_Vision_Understanding.md)

    - [翻译: VisionGPT-3D：一款强大而全面的多模态智能体，旨在提升三维视觉理解能力](2024年03月14日/VisionGPT-3D_A_Generalized_Multimodal_Agent_for_Enhanced_3D_Vision_Understanding.md)

- [WavCraft: Audio Editing and Generation with Natural Language Prompts](2024年03月14日/WavCraft_Audio_Editing_and_Generation_with_Natural_Language_Prompts.md)

    - [翻译: WavCraft——通过自然语言指令实现音频编辑与生成](2024年03月14日/WavCraft_Audio_Editing_and_Generation_with_Natural_Language_Prompts.md)

- [MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation](2024年03月14日/MT-PATCHER_Selective_and_Extendable_Knowledge_Distillation_from_Large_Language_Models_for_Machine_Translation.md)

    - [翻译: MT-PATCHER：针对机器翻译任务，该技术实现了从大型语言模型中进行选择性且可扩展的知识蒸馏，旨在提炼和有效利用大规模模型中的宝贵知识。](2024年03月14日/MT-PATCHER_Selective_and_Extendable_Knowledge_Distillation_from_Large_Language_Models_for_Machine_Translation.md)

- [AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting](2024年03月14日/AdaShield_Safeguarding_Multimodal_Large_Language_Models_from_Structure-based_Attack_via_Adaptive_Shield_Prompting.md)

    - [翻译: AdaShield方案：针对多模态大型语言模型，利用自适应防护提示技术有效抵御基于结构的攻击威胁。](2024年03月14日/AdaShield_Safeguarding_Multimodal_Large_Language_Models_from_Structure-based_Attack_via_Adaptive_Shield_Prompting.md)

- [From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News](2024年03月14日/From_Skepticism_to_Acceptance_Simulating_the_Attitude_Dynamics_Toward_Fake_News.md)

    - [翻译: 本研究模拟了人们对假新闻从怀疑到接受这一态度转变的动态过程。](2024年03月14日/From_Skepticism_to_Acceptance_Simulating_the_Attitude_Dynamics_Toward_Fake_News.md)

- [Anomaly Detection by Adapting a pre-trained Vision Language Model](2024年03月14日/Anomaly_Detection_by_Adapting_a_pre-trained_Vision_Language_Model.md)

    - [翻译: 我们采用预训练的视觉语言模型并对其进行适应性调整，以实现对异常的有效检测。](2024年03月14日/Anomaly_Detection_by_Adapting_a_pre-trained_Vision_Language_Model.md)

- [Rectifying Demonstration Shortcut in In-Context Learning](2024年03月14日/Rectifying_Demonstration_Shortcut_in_In-Context_Learning.md)

    - [翻译: 本研究致力于纠正ICL中的“演示捷径”问题，探讨如何改进上下文学习方法，以消除对示例的过度依赖，并提升其在各类任务中的泛化性能。](2024年03月14日/Rectifying_Demonstration_Shortcut_in_In-Context_Learning.md)

- [LLM-based agents for automating the enhancement of user story quality: An early report](2024年03月14日/LLM-based_agents_for_automating_the_enhancement_of_user_story_quality_An_early_report.md)

    - [翻译: 一份早期报告显示，利用 LLM 技术开发的智能代理能够实现用户故事质量的自动化优化。](2024年03月14日/LLM-based_agents_for_automating_the_enhancement_of_user_story_quality_An_early_report.md)

- [GPT on a Quantum Computer](2024年03月14日/GPT_on_a_Quantum_Computer.md)

    - [翻译: GPT 与量子计算的邂逅：探究 GPT 在量子计算机环境下的表现与应用](2024年03月14日/GPT_on_a_Quantum_Computer.md)

- [OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments](2024年03月14日/OpenGraph_Open-Vocabulary_Hierarchical_3D_Graph_Representation_in_Large-Scale_Outdoor_Environments.md)

    - [翻译: OpenGraph是一种在大规模户外环境中实现开放词汇、分层三维图形表达的方法。](2024年03月14日/OpenGraph_Open-Vocabulary_Hierarchical_3D_Graph_Representation_in_Large-Scale_Outdoor_Environments.md)

- [XCoOp: Explainable Prompt Learning for Computer-Aided Diagnosis via Concept-guided Context Optimization](2024年03月14日/XCoOp_Explainable_Prompt_Learning_for_Computer-Aided_Diagnosis_via_Concept-guided_Context_Optimization.md)

    - [翻译: XCoOp：借助于概念指导下的上下文优化技术，实现对计算机辅助诊断任务具有可解释性的提示学习。](2024年03月14日/XCoOp_Explainable_Prompt_Learning_for_Computer-Aided_Diagnosis_via_Concept-guided_Context_Optimization.md)

- ["Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students using Large Language Models](2024年03月14日/Like_a_Nesting_Doll_Analyzing_Recursion_Analogies_Generated_by_CS_Students_using_Large_Language_Models.md)

    - [翻译: 本研究以“套娃”为喻，借助大型语言模型，深入剖析了计算机科学学生在运用大型语言模型时所创造出的递归类比实例。](2024年03月14日/Like_a_Nesting_Doll_Analyzing_Recursion_Analogies_Generated_by_CS_Students_using_Large_Language_Models.md)

- [An Extensible Framework for Architecture-Based Data Flow Analysis for Information Security](2024年03月14日/An_Extensible_Framework_for_Architecture-Based_Data_Flow_Analysis_for_Information_Security.md)

    - [翻译: 为探究信息安全中的数据流动规律，我们提出了一种灵活可扩展的架构导向数据流分析框架。](2024年03月14日/An_Extensible_Framework_for_Architecture-Based_Data_Flow_Analysis_for_Information_Security.md)

- [GiT: Towards Generalist Vision Transformer through Universal Language Interface](2024年03月14日/GiT_Towards_Generalist_Vision_Transformer_through_Universal_Language_Interface.md)

    - [翻译: GiT项目致力于打造一款全能型视觉Transformer，借助统一语言接口实现这一目标。](2024年03月14日/GiT_Towards_Generalist_Vision_Transformer_through_Universal_Language_Interface.md)

- [Introducing Routing Functions to Vision-Language Parameter-Efficient Fine-Tuning with Low-Rank Bottlenecks](2024年03月14日/Introducing_Routing_Functions_to_Vision-Language_Parameter-Efficient_Fine-Tuning_with_Low-Rank_Bottlenecks.md)

    - [翻译: 为了提升视觉-语言模型的参数效率与微调性能，我们提出在具有低秩瓶颈的视觉-语言模型微调过程中引入路由函数技术。](2024年03月14日/Introducing_Routing_Functions_to_Vision-Language_Parameter-Efficient_Fine-Tuning_with_Low-Rank_Bottlenecks.md)

- [Komodo: A Linguistic Expedition into Indonesia's Regional Languages](2024年03月14日/Komodo_A_Linguistic_Expedition_into_Indonesia's_Regional_Languages.md)

    - [翻译: Komodo项目：一场探索印尼区域语言的深度语言学之旅](2024年03月14日/Komodo_A_Linguistic_Expedition_into_Indonesia's_Regional_Languages.md)

- [BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences](2024年03月14日/BurstAttention_An_Efficient_Distributed_Attention_Framework_for_Extremely_Long_Sequences.md)

    - [翻译: BurstAttention 是专为处理超长序列而设计的一种高效分布式注意力机制架构。](2024年03月14日/BurstAttention_An_Efficient_Distributed_Attention_Framework_for_Extremely_Long_Sequences.md)

- [AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions](2024年03月14日/AVIBench_Towards_Evaluating_the_Robustness_of_Large_Vision-Language_Model_on_Adversarial_Visual-Instructions.md)

    - [翻译: AVIBench 是一个专注于评估大型视觉-语言模型在面对对抗性视觉指令时的稳健性的研究项目，旨在揭示模型在此挑战性场景下的表现和适应能力。](2024年03月14日/AVIBench_Towards_Evaluating_the_Robustness_of_Large_Vision-Language_Model_on_Adversarial_Visual-Instructions.md)

- [Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring](2024年03月14日/Griffon_v2_Advancing_Multimodal_Perception_with_High-Resolution_Scaling_and_Visual-Language_Co-Referring.md)

    - [翻译: Griffon v2 引领进步，利用高分辨率缩放与视觉-语言共指技术提升多模态感知能力](2024年03月14日/Griffon_v2_Advancing_Multimodal_Perception_with_High-Resolution_Scaling_and_Visual-Language_Co-Referring.md)

- [Enabling Waypoint Generation for Collaborative Robots using LLMs and Mixed Reality](2024年03月14日/Enabling_Waypoint_Generation_for_Collaborative_Robots_using_LLMs_and_Mixed_Reality.md)

    - [翻译: 借助 LLM 和混合现实技术，我们能够为协作机器人赋予路径点自动生成能力，让其在协同工作中更加智能化和灵活。](2024年03月14日/Enabling_Waypoint_Generation_for_Collaborative_Robots_using_LLMs_and_Mixed_Reality.md)

- [Annotation Free Semantic Segmentation with Vision Foundation Models](2024年03月14日/Annotation_Free_Semantic_Segmentation_with_Vision_Foundation_Models.md)

    - [翻译: 利用视觉基础模型实现无需标注的语义分割技术](2024年03月14日/Annotation_Free_Semantic_Segmentation_with_Vision_Foundation_Models.md)

- [Select and Distill: Selective Dual-Teacher Knowledge Transfer for Continual Learning on Vision-Language Models](2024年03月14日/Select_and_Distill_Selective_Dual-Teacher_Knowledge_Transfer_for_Continual_Learning_on_Vision-Language_Models.md)

    - [翻译: 为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](2024年03月14日/Select_and_Distill_Selective_Dual-Teacher_Knowledge_Transfer_for_Continual_Learning_on_Vision-Language_Models.md)

- [VIVID: Human-AI Collaborative Authoring of Vicarious Dialogues from Lecture Videos](2024年03月14日/VIVID_Human-AI_Collaborative_Authoring_of_Vicarious_Dialogues_from_Lecture_Videos.md)

    - [翻译: VIVID项目致力于实现人机协作，共同从讲座视频中创作生动的、身临其境的对话内容。](2024年03月14日/VIVID_Human-AI_Collaborative_Authoring_of_Vicarious_Dialogues_from_Lecture_Videos.md)

- [Dial-insight: Fine-tuning Large Language Models with High-Quality Domain-Specific Data Preventing Capability Collapse](2024年03月14日/Dial-insight_Fine-tuning_Large_Language_Models_with_High-Quality_Domain-Specific_Data_Preventing_Capability_Collapse.md)

    - [翻译: Dial-insight 方法，通过采用高质量的特定领域数据对大型语言模型进行微调，有效防止模型能力退化。](2024年03月14日/Dial-insight_Fine-tuning_Large_Language_Models_with_High-Quality_Domain-Specific_Data_Preventing_Capability_Collapse.md)

- [Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine Knowledge](2024年03月14日/Exploring_the_Comprehension_of_ChatGPT_in_Traditional_Chinese_Medicine_Knowledge.md)

    - [翻译: 本研究致力于探究ChatGPT在理解中医知识方面的表现，深入探索其对于传统中医药学领域知识的掌握和应用能力。](2024年03月14日/Exploring_the_Comprehension_of_ChatGPT_in_Traditional_Chinese_Medicine_Knowledge.md)

- [Caveat Lector: Large Language Models in Legal Practice](2024年03月14日/Caveat_Lector_Large_Language_Models_in_Legal_Practice.md)

    - [翻译: 审慎阅读：大型语言模型在法律实务领域的探索与应用](2024年03月14日/Caveat_Lector_Large_Language_Models_in_Legal_Practice.md)

- [Unveiling the Generalization Power of Fine-Tuned Large Language Models](2024年03月14日/Unveiling_the_Generalization_Power_of_Fine-Tuned_Large_Language_Models.md)

    - [翻译: 探究微调后大型语言模型的普遍适用性力量](2024年03月14日/Unveiling_the_Generalization_Power_of_Fine-Tuned_Large_Language_Models.md)

- [Evaluating LLMs for Gender Disparities in Notable Persons](2024年03月14日/Evaluating_LLMs_for_Gender_Disparities_in_Notable_Persons.md)

    - [翻译: 本研究旨在评估大型语言模型（LLMs）在描述著名人物时是否存在性别差异问题。](2024年03月14日/Evaluating_LLMs_for_Gender_Disparities_in_Notable_Persons.md)

- [USimAgent: Large Language Models for Simulating Search Users](2024年03月14日/USimAgent_Large_Language_Models_for_Simulating_Search_Users.md)

    - [翻译: USimAgent 是一款专门针对模拟搜索用户而设计的大规模语言模型，它利用强大的自然语言处理能力来仿真用户的搜索行为与意图。](2024年03月14日/USimAgent_Large_Language_Models_for_Simulating_Search_Users.md)

- [Towards Proactive Interactions for In-Vehicle Conversational Assistants Utilizing Large Language Models](2024年03月14日/Towards_Proactive_Interactions_for_In-Vehicle_Conversational_Assistants_Utilizing_Large_Language_Models.md)

    - [翻译: 本研究致力于借助大型语言模型，开发能够主动发起互动的车载对话助手，提升车内交互体验。](2024年03月14日/Towards_Proactive_Interactions_for_In-Vehicle_Conversational_Assistants_Utilizing_Large_Language_Models.md)

- [ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate Professional and Non-Professional Styled Text](2024年03月14日/ProSwitch_Knowledge-Guided_Language_Model_Fine-Tuning_to_Generate_Professional_and_Non-Professional_Styled_Text.md)

    - [翻译: ProSwitch 是一种创新方法，它运用知识指导对语言模型进行精细调整，旨在实现生成兼具专业和非专业写作风格的文本。](2024年03月14日/ProSwitch_Knowledge-Guided_Language_Model_Fine-Tuning_to_Generate_Professional_and_Non-Professional_Styled_Text.md)

- [Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector](2024年03月14日/Exploring_the_Capabilities_and_Limitations_of_Large_Language_Models_in_the_Electric_Energy_Sector.md)

    - [翻译: 本研究致力于揭示大型语言模型在电力能源行业的潜力与局限，深入探讨其在该领域的表现特征及应用场景。](2024年03月14日/Exploring_the_Capabilities_and_Limitations_of_Large_Language_Models_in_the_Electric_Energy_Sector.md)

- [AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning](2024年03月14日/AutoLoRA_Automatically_Tuning_Matrix_Ranks_in_Low-Rank_Adaptation_Based_on_Meta_Learning.md)

    - [翻译: AutoLoRA 是一种创新方法，它运用元学习技术，在低秩适应过程中自动化地优化矩阵的秩。这项研究旨在解决在模型适应时对矩阵秩高效且智能调节的问题。](2024年03月14日/AutoLoRA_Automatically_Tuning_Matrix_Ranks_in_Low-Rank_Adaptation_Based_on_Meta_Learning.md)

- [Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance](2024年03月14日/Meaningful_Learning_Advancing_Abstract_Reasoning_in_Large_Language_Models_via_Generic_Fact_Guidance.md)

    - [翻译: 借助通用事实引导，促进大型语言模型在抽象推理方面的提升——“有意义学习”崭新探索](2024年03月14日/Meaningful_Learning_Advancing_Abstract_Reasoning_in_Large_Language_Models_via_Generic_Fact_Guidance.md)

- [Retrieval augmented text-to-SQL generation for epidemiological question answering using electronic health records](2024年03月14日/Retrieval_augmented_text-to-SQL_generation_for_epidemiological_question_answering_using_electronic_health_records.md)

    - [翻译: 本研究专注于利用电子健康记录，通过增强检索技术改进文本转SQL生成方法，应用于流行病学问题解答。](2024年03月14日/Retrieval_augmented_text-to-SQL_generation_for_epidemiological_question_answering_using_electronic_health_records.md)

- [BjTT: A Large-scale Multimodal Dataset for Traffic Prediction](2024年03月14日/BjTT_A_Large-scale_Multimodal_Dataset_for_Traffic_Prediction.md)

    - [翻译: BjTT 是一个专为交通预测打造的大规模多模态数据集，通过整合多元信息助力提升预测准确性。](2024年03月14日/BjTT_A_Large-scale_Multimodal_Dataset_for_Traffic_Prediction.md)

- [Identifying Health Risks from Family History: A Survey of Natural Language Processing Techniques](2024年03月14日/Identifying_Health_Risks_from_Family_History_A_Survey_of_Natural_Language_Processing_Techniques.md)

    - [翻译: 本研究针对通过家庭史识别健康风险这一主题，对自然语言处理技术进行了全面梳理和探讨。](2024年03月14日/Identifying_Health_Risks_from_Family_History_A_Survey_of_Natural_Language_Processing_Techniques.md)

- [Trusting the Search: Unraveling Human Trust in Health Information from Google and ChatGPT](2024年03月14日/Trusting_the_Search_Unraveling_Human_Trust_in_Health_Information_from_Google_and_ChatGPT.md)

    - [翻译: 探究搜索背后的信任——深入理解人们在使用谷歌和ChatGPT获取健康信息时的信任构建机制](2024年03月14日/Trusting_the_Search_Unraveling_Human_Trust_in_Health_Information_from_Google_and_ChatGPT.md)

- [EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba](2024年03月14日/EfficientVMamba_Atrous_Selective_Scan_for_Light_Weight_Visual_Mamba.md)

    - [翻译: EfficientVMamba，一种专为轻量级视觉Mamba设计的创新技术，通过采用空洞选择性扫描机制，实现高效处理。](2024年03月14日/EfficientVMamba_Atrous_Selective_Scan_for_Light_Weight_Visual_Mamba.md)

- [Think Twice Before Assure: Confidence Estimation for Large Language Models through Reflection on Multiple Answers](2024年03月14日/Think_Twice_Before_Assure_Confidence_Estimation_for_Large_Language_Models_through_Reflection_on_Multiple_Answers.md)

    - [翻译: 面对大型语言模型，请审慎决策，我们提出了一种方法，通过对多个答案的反思实现对模型输出的信心度评估。](2024年03月14日/Think_Twice_Before_Assure_Confidence_Estimation_for_Large_Language_Models_through_Reflection_on_Multiple_Answers.md)

- [Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer](2024年03月14日/Advancing_Object_Goal_Navigation_Through_LLM-enhanced_Object_Affinities_Transfer.md)

    - [翻译: 本研究借助LLM强化的对象亲和力转移技术，推进物体目标导航的发展。](2024年03月14日/Advancing_Object_Goal_Navigation_Through_LLM-enhanced_Object_Affinities_Transfer.md)

- [ViTCN: Vision Transformer Contrastive Network For Reasoning](2024年03月14日/ViTCN_Vision_Transformer_Contrastive_Network_For_Reasoning.md)

    - [翻译: ViTCN 是一种视觉Transformer对比网络，专为推理任务设计。](2024年03月14日/ViTCN_Vision_Transformer_Contrastive_Network_For_Reasoning.md)

- [Recurrent Drafter for Fast Speculative Decoding in Large Language Models](2024年03月14日/Recurrent_Drafter_for_Fast_Speculative_Decoding_in_Large_Language_Models.md)

    - [翻译: 针对大型语言模型，一种名为“循环草稿器”的技术被应用于快速推测性解码过程。](2024年03月14日/Recurrent_Drafter_for_Fast_Speculative_Decoding_in_Large_Language_Models.md)

- [Reality Bites: Assessing the Realism of Driving Scenarios with Large Language Models](2024年03月14日/Reality_Bites_Assessing_the_Realism_of_Driving_Scenarios_with_Large_Language_Models.md)

    - [翻译: 面对现实：借助大型语言模型深入探究驾驶场景的真实程度](2024年03月14日/Reality_Bites_Assessing_the_Realism_of_Driving_Scenarios_with_Large_Language_Models.md)

- [Geographically-Informed Language Identification](2024年03月14日/Geographically-Informed_Language_Identification.md)

    - [翻译: 基于地理位置的语言识别技术](2024年03月14日/Geographically-Informed_Language_Identification.md)

- [Sabiá-2: A New Generation of Portuguese Large Language Models](2024年03月14日/Sabiá-2_A_New_Generation_of_Portuguese_Large_Language_Models.md)

    - [翻译: Sabiá-2：引领潮流的全新一代葡萄牙大型语言模型](2024年03月14日/Sabiá-2_A_New_Generation_of_Portuguese_Large_Language_Models.md)

- [Scaling Behavior of Machine Translation with Large Language Models under Prompt Injection Attacks](2024年03月14日/Scaling_Behavior_of_Machine_Translation_with_Large_Language_Models_under_Prompt_Injection_Attacks.md)

    - [翻译: 面对提示注入攻击，探究大规模语言模型应用于机器翻译任务时的性能变化规律](2024年03月14日/Scaling_Behavior_of_Machine_Translation_with_Large_Language_Models_under_Prompt_Injection_Attacks.md)

- [Comparing Rationality Between Large Language Models and Humans: Insights and Open Questions](2024年03月14日/Comparing_Rationality_Between_Large_Language_Models_and_Humans_Insights_and_Open_Questions.md)

    - [翻译: 探究大型语言模型与人类在理性层面的对比，揭示其中的深刻洞见与亟待解答的问题。](2024年03月14日/Comparing_Rationality_Between_Large_Language_Models_and_Humans_Insights_and_Open_Questions.md)

- [Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention](2024年03月14日/Helpful_or_Harmful_Exploring_the_Efficacy_of_Large_Language_Models_for_Online_Grooming_Prevention.md)

    - [翻译: 大型语言模型在防止网络诱导行为方面是利大于弊还是弊大于利？本研究深入探讨其实际效用。步骤分解：](2024年03月14日/Helpful_or_Harmful_Exploring_the_Efficacy_of_Large_Language_Models_for_Online_Grooming_Prevention.md)

- [Images are Achilles' Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models](2024年03月14日/Images_are_Achilles'_Heel_of_Alignment_Exploiting_Visual_Vulnerabilities_for_Jailbreaking_Multimodal_Large_Language_Models.md)

    - [翻译: 在多模态大型语言模型中，图像识别环节成为了其“阿喀琉斯之踵”，本研究通过揭示并利用视觉层面的安全漏洞，旨在突破和“越狱”这类模型的既有对齐限制。](2024年03月14日/Images_are_Achilles'_Heel_of_Alignment_Exploiting_Visual_Vulnerabilities_for_Jailbreaking_Multimodal_Large_Language_Models.md)

- [VideoAgent: Long-form Video Understanding with Large Language Model as Agent](2024年03月15日/VideoAgent_Long-form_Video_Understanding_with_Large_Language_Model_as_Agent.md)

    - [翻译: VideoAgent 是一项通过运用大型语言模型作为智能代理，实现对长格式视频内容深度理解的技术方案。](2024年03月15日/VideoAgent_Long-form_Video_Understanding_with_Large_Language_Model_as_Agent.md)

- [Demystifying Faulty Code with LLM: Step-by-Step Reasoning for Explainable Fault Localization](2024年03月15日/Demystifying_Faulty_Code_with_LLM_Step-by-Step_Reasoning_for_Explainable_Fault_Localization.md)

    - [翻译: 通过 LLM 逐步揭秘错误代码，提供可理解的故障定位机制步骤 1：利用 LLM 解析错误代码：针对可解释性故障定位的逐层深入分析步骤 2：本研究借助 LLM，对错误代码进行逐行剖析和逻辑解读，致力于实现可解释的故障定位过程。](2024年03月15日/Demystifying_Faulty_Code_with_LLM_Step-by-Step_Reasoning_for_Explainable_Fault_Localization.md)

- [ATOM: Asynchronous Training of Massive Models for Deep Learning in a Decentralized Environment](2024年03月15日/ATOM_Asynchronous_Training_of_Massive_Models_for_Deep_Learning_in_a_Decentralized_Environment.md)

    - [翻译: ATOM 技术专为去中心化环境中的深度学习设计，实现了大规模模型的异步训练，赋予其高效处理能力。](2024年03月15日/ATOM_Asynchronous_Training_of_Massive_Models_for_Deep_Learning_in_a_Decentralized_Environment.md)

- [Reconfigurable Robot Identification from Motion Data](2024年03月15日/Reconfigurable_Robot_Identification_from_Motion_Data.md)

    - [翻译: 通过对运动数据的分析，本研究致力于识别和解析可重构机器人的特性。](2024年03月15日/Reconfigurable_Robot_Identification_from_Motion_Data.md)

- [Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution Analyst?](2024年03月15日/Can_a_GPT4-Powered_AI_Agent_Be_a_Good_Enough_Performance_Attribution_Analyst.md)

    - [翻译: GPT4 驱动的 AI 代理是否有能力成为卓越的绩效归因分析师？](2024年03月15日/Can_a_GPT4-Powered_AI_Agent_Be_a_Good_Enough_Performance_Attribution_Analyst.md)

- [Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases](2024年03月15日/Enhancing_LLM_Factual_Accuracy_with_RAG_to_Counter_Hallucinations_A_Case_Study_on_Domain-Specific_Queries_in_Private_Knowledge-Bases.md)

    - [翻译: 为解决LLM在处理特定领域查询时可能出现的虚构问题，本研究运用RAG技术提升其在私有知识库上的事实准确性，并进行了深入案例分析。](2024年03月15日/Enhancing_LLM_Factual_Accuracy_with_RAG_to_Counter_Hallucinations_A_Case_Study_on_Domain-Specific_Queries_in_Private_Knowledge-Bases.md)

- [Optimal Block-Level Draft Verification for Accelerating Speculative Decoding](2024年03月15日/Optimal_Block-Level_Draft_Verification_for_Accelerating_Speculative_Decoding.md)

    - [翻译: 为加快推测性解码的速度，我们提出了一种针对块级草稿的最优验证方法。](2024年03月15日/Optimal_Block-Level_Draft_Verification_for_Accelerating_Speculative_Decoding.md)

- [Using an LLM to Turn Sign Spottings into Spoken Language Sentences](2024年03月15日/Using_an_LLM_to_Turn_Sign_Spottings_into_Spoken_Language_Sentences.md)

    - [翻译: 通过运用 LLM 技术，我们可以将手语识别直接转化为流畅的口语句子。](2024年03月15日/Using_an_LLM_to_Turn_Sign_Spottings_into_Spoken_Language_Sentences.md)

- [How to train your ears: Auditory-model emulation for large-dynamic-range inputs and mild-to-severe hearing losses](2024年03月15日/How_to_train_your_ears_Auditory-model_emulation_for_large-dynamic-range_inputs_and_mild-to-severe_hearing_losses.md)

    - [翻译: 本研究探讨如何通过模拟听觉模型，有效提升对大动态范围声音输入以及应对轻度至重度听力损失情况下的听力理解能力。](2024年03月15日/How_to_train_your_ears_Auditory-model_emulation_for_large-dynamic-range_inputs_and_mild-to-severe_hearing_losses.md)

- [SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores](2024年03月15日/SocialGenPod_Privacy-Friendly_Generative_AI_Social_Web_Applications_with_Decentralised_Personal_Data_Stores.md)

    - [翻译: SocialGenPod 是一款注重隐私保护的生成式 AI 社交网络应用，它利用去中心化的个人数据存储技术。这款应用致力于在保障用户隐私的同时，提供基于 AI 的创新社交体验。](2024年03月15日/SocialGenPod_Privacy-Friendly_Generative_AI_Social_Web_Applications_with_Decentralised_Personal_Data_Stores.md)

- [A Thorough Comparison of Cross-Encoders and LLMs for Reranking SPLADE](2024年03月15日/A_Thorough_Comparison_of_Cross-Encoders_and_LLMs_for_Reranking_SPLADE.md)

    - [翻译: 为了重新排名 SPLADE 系统，我们深入对比了跨编码器与大型语言模型在该任务中的性能表现。](2024年03月15日/A_Thorough_Comparison_of_Cross-Encoders_and_LLMs_for_Reranking_SPLADE.md)

- [TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale](2024年03月15日/TriSum_Learning_Summarization_Ability_from_Large_Language_Models_with_Structured_Rationale.md)

    - [翻译: TriSum 方法致力于在大型语言模型中汲取摘要能力，借助结构化的推理方式实现这一目标。进一步细化步骤2的翻译：TriSum 是一项研究，它探索如何利用大型语言模型中的结构化推理机制来培养和提升文本摘要能力。](2024年03月15日/TriSum_Learning_Summarization_Ability_from_Large_Language_Models_with_Structured_Rationale.md)

- [Uni-SMART: Universal Science Multimodal Analysis and Research Transformer](2024年03月15日/Uni-SMART_Universal_Science_Multimodal_Analysis_and_Research_Transformer.md)

    - [翻译: Uni-SMART 是一款致力于科学领域多模态数据分析与研究的通用Transformer模型。步骤解释：1. 直译：Uni-SMART 这个术语保持不变，"Universal Science Multimodal Analysis and Research Transformer" 翻译为“通用科学多模态分析与研究Transformer”，确保了专业术语的准确传达。2. 优化：在直译的基础上，简化并调整语序以符合中文表达习惯，使整体表述更加流畅、易懂，同时强调了Uni-SMART模型在科学领域多模态数据分析与研究方面的应用特点。](2024年03月15日/Uni-SMART_Universal_Science_Multimodal_Analysis_and_Research_Transformer.md)

- [Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning](2024年03月15日/Team_Trifecta_at_Factify5WQA_Setting_the_Standard_in_Fact_Verification_with_Fine-Tuning.md)

    - [翻译: Team Trifecta 在 Factify5WQA 项目中以微调技术树立了事实核查的新标杆](2024年03月15日/Team_Trifecta_at_Factify5WQA_Setting_the_Standard_in_Fact_Verification_with_Fine-Tuning.md)

- [A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption](2024年03月15日/A_Question_on_the_Explainability_of_Large_Language_Models_and_the_Word-Level_Univariate_First-Order_Plausibility_Assumption.md)

    - [翻译: 探究大型语言模型的可解释性难题，及其涉及词级别的单变量一阶合理性假设](2024年03月15日/A_Question_on_the_Explainability_of_Large_Language_Models_and_the_Word-Level_Univariate_First-Order_Plausibility_Assumption.md)

- [DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers](2024年03月15日/DSP_Dynamic_Sequence_Parallelism_for_Multi-Dimensional_Transformers.md)

    - [翻译: DSP技术为多维变换器引入了动态序列并行机制，旨在优化处理效率和性能。](2024年03月15日/DSP_Dynamic_Sequence_Parallelism_for_Multi-Dimensional_Transformers.md)

- [Is Translation All You Need? A Study on Solving Multilingual Tasks with Large Language Models](2024年03月15日/Is_Translation_All_You_Need_A_Study_on_Solving_Multilingual_Tasks_with_Large_Language_Models.md)

    - [翻译: 是否只需运用翻译即可应对各类多语言任务？本研究探讨了通过大型语言模型解决此类任务的可能性。](2024年03月15日/Is_Translation_All_You_Need_A_Study_on_Solving_Multilingual_Tasks_with_Large_Language_Models.md)

- [A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges](2024年03月15日/A_Survey_on_Game_Playing_Agents_and_Large_Models_Methods,_Applications,_and_Challenges.md)

    - [翻译: 本研究综述了游戏智能体和大型模型的研究进展，探讨了各类方法、应用场景以及面临的挑战。](2024年03月15日/A_Survey_on_Game_Playing_Agents_and_Large_Models_Methods,_Applications,_and_Challenges.md)

- [CoLeCLIP: Open-Domain Continual Learning via Joint Task Prompt and Vocabulary Learning](2024年03月15日/CoLeCLIP_Open-Domain_Continual_Learning_via_Joint_Task_Prompt_and_Vocabulary_Learning.md)

    - [翻译: CoLeCLIP 是一种创新方法，通过结合任务提示与词汇学习技术，在开放领域内实现持续学习能力。](2024年03月15日/CoLeCLIP_Open-Domain_Continual_Learning_via_Joint_Task_Prompt_and_Vocabulary_Learning.md)

- [HawkEye: Training Video-Text LLMs for Grounding Text in Videos](2024年03月15日/HawkEye_Training_Video-Text_LLMs_for_Grounding_Text_in_Videos.md)

    - [翻译: HawkEye项目致力于训练能够将文本内容有效定位到对应视频片段的视频-文本大型语言模型。](2024年03月15日/HawkEye_Training_Video-Text_LLMs_for_Grounding_Text_in_Videos.md)

- [Read between the lines -- Functionality Extraction From READMEs](2024年03月15日/Read_between_the_lines_--_Functionality_Extraction_From_READMEs.md)

    - [翻译: 深入研读README，挖掘其中隐含的功能信息](2024年03月15日/Read_between_the_lines_--_Functionality_Extraction_From_READMEs.md)

- [Generative Region-Language Pretraining for Open-Ended Object Detection](2024年03月15日/Generative_Region-Language_Pretraining_for_Open-Ended_Object_Detection.md)

    - [翻译: 为了解决开放式物体检测的挑战，我们提出了一种“生成区域-语言预训练”方法。该技术旨在通过联合学习图像区域特征与相关描述性语言表达，以实现更强大、更具开放性的物体检测能力。](2024年03月15日/Generative_Region-Language_Pretraining_for_Open-Ended_Object_Detection.md)

- [AUTONODE: A Neuro-Graphic Self-Learnable Engine for Cognitive GUI Automation](2024年03月15日/AUTONODE_A_Neuro-Graphic_Self-Learnable_Engine_for_Cognitive_GUI_Automation.md)

    - [翻译: AUTONODE——一款面向认知GUI自动化的自我学习型神经图形引擎](2024年03月15日/AUTONODE_A_Neuro-Graphic_Self-Learnable_Engine_for_Cognitive_GUI_Automation.md)

- [Improving Medical Multi-modal Contrastive Learning with Expert Annotations](2024年03月15日/Improving_Medical_Multi-modal_Contrastive_Learning_with_Expert_Annotations.md)

    - [翻译: 借助专家标注优化医疗多模态对比学习技术，提升模型性能和准确性。](2024年03月15日/Improving_Medical_Multi-modal_Contrastive_Learning_with_Expert_Annotations.md)

- [The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation](2024年03月15日/The_Whole_is_Better_than_the_Sum_Using_Aggregated_Demonstrations_in_In-Context_Learning_for_Sequential_Recommendation.md)

    - [翻译: 整体胜于局部：本研究探讨将聚合演示应用于序列推荐任务的上下文学习，以期实现超越单个示例之和的效果。](2024年03月15日/The_Whole_is_Better_than_the_Sum_Using_Aggregated_Demonstrations_in_In-Context_Learning_for_Sequential_Recommendation.md)

- [RAFT: Adapting Language Model to Domain Specific RAG](2024年03月15日/RAFT_Adapting_Language_Model_to_Domain_Specific_RAG.md)

    - [翻译: RAFT 方法致力于让语言模型更好地适应特定领域的 RAG。](2024年03月15日/RAFT_Adapting_Language_Model_to_Domain_Specific_RAG.md)

- [Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning](2024年03月15日/Enhancing_Human-Centered_Dynamic_Scene_Understanding_via_Multiple_LLMs_Collaborated_Reasoning.md)

    - [翻译: 通过多台 LLM（大型语言模型）协同推理的方式，提升对以人类为中心的动态场景理解能力进一步优化后的](2024年03月15日/Enhancing_Human-Centered_Dynamic_Scene_Understanding_via_Multiple_LLMs_Collaborated_Reasoning.md)

- [Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties](2024年03月15日/Large_Language_Models_to_Generate_System-Level_Test_Programs_Targeting_Non-functional_Properties.md)

    - [翻译: 我们探索利用大型语言模型来创作针对非功能性属性的系统级测试程序，旨在通过智能化手段提升软件质量保障效能。](2024年03月15日/Large_Language_Models_to_Generate_System-Level_Test_Programs_Targeting_Non-functional_Properties.md)

- [CrossGLG: LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner](2024年03月15日/CrossGLG_LLM_Guides_One-shot_Skeleton-based_3D_Action_Recognition_in_a_Cross-level_Manner.md)

    - [翻译: CrossGLG 是一种创新方法，利用大型语言模型（LLM）以跨层次的方式实现仅通过一次示例就能指导基于骨架的3D动作识别。](2024年03月15日/CrossGLG_LLM_Guides_One-shot_Skeleton-based_3D_Action_Recognition_in_a_Cross-level_Manner.md)

- [DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models](2024年03月15日/DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Real-time_Information_Needs_of_Large_Language_Models.md)

    - [翻译: DRAGIN 是一项创新技术，它依据大型语言模型的实际信息需求进行动态检索增强生成。这项技术能够实时捕捉并满足LLM在生成过程中的信息需求，从而提升其表现力和准确性。](2024年03月15日/DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Real-time_Information_Needs_of_Large_Language_Models.md)

- [Codebook Transfer with Part-of-Speech for Vector-Quantized Image Modeling](2024年03月15日/Codebook_Transfer_with_Part-of-Speech_for_Vector-Quantized_Image_Modeling.md)

    - [翻译: 在向量量化图像模型中，我们引入了一种结合词性标签进行码本迁移的方法。这一技术旨在优化码本在不同场景下的表现，特别是在向量量化图像建模任务中。](2024年03月15日/Codebook_Transfer_with_Part-of-Speech_for_Vector-Quantized_Image_Modeling.md)

- [Repoformer: Selective Retrieval for Repository-Level Code Completion](2024年03月15日/Repoformer_Selective_Retrieval_for_Repository-Level_Code_Completion.md)

    - [翻译: Repoformer，一种专为仓库级别代码补全设计的选择性检索技术，旨在提升代码补全任务的效果和精准度。](2024年03月15日/Repoformer_Selective_Retrieval_for_Repository-Level_Code_Completion.md)

- [Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning](2024年03月15日/Don't_Half-listen_Capturing_Key-part_Information_in_Continual_Instruction_Tuning.md)

    - [翻译: 切勿一知半解：在连续指令调优过程中精准捕获关键信息要素](2024年03月15日/Don't_Half-listen_Capturing_Key-part_Information_in_Continual_Instruction_Tuning.md)

- [TextBlockV2: Towards Precise-Detection-Free Scene Text Spotting with Pre-trained Language Model](2024年03月15日/TextBlockV2_Towards_Precise-Detection-Free_Scene_Text_Spotting_with_Pre-trained_Language_Model.md)

    - [翻译: TextBlockV2：迈向基于预训练语言模型、无需精细检测的精准场景文字识别技术](2024年03月15日/TextBlockV2_Towards_Precise-Detection-Free_Scene_Text_Spotting_with_Pre-trained_Language_Model.md)

- [Knowledge Condensation and Reasoning for Knowledge-based VQA](2024年03月15日/Knowledge_Condensation_and_Reasoning_for_Knowledge-based_VQA.md)

    - [翻译: 在知识驱动的视觉问答（VQA）中，知识提炼与推理技术发挥着关键作用。该研究专注于如何有效地整合和提炼相关知识，并运用高级推理方法以提升 VQA 的准确性和智能性。](2024年03月15日/Knowledge_Condensation_and_Reasoning_for_Knowledge-based_VQA.md)

- [Lost in Overlap: Exploring Watermark Collision in LLMs](2024年03月15日/Lost_in_Overlap_Exploring_Watermark_Collision_in_LLMs.md)

    - [翻译: 探究 LLMS 中的水印碰撞现象，揭示隐藏在模型重叠区域的奥秘。](2024年03月15日/Lost_in_Overlap_Exploring_Watermark_Collision_in_LLMs.md)

- [Language to Map: Topological map generation from natural language path instructions](2024年03月15日/Language_to_Map_Topological_map_generation_from_natural_language_path_instructions.md)

    - [翻译: 将语言指令转化为地图：探究如何从自然语言路径指示中生成拓扑地图](2024年03月15日/Language_to_Map_Topological_map_generation_from_natural_language_path_instructions.md)

- [Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study](2024年03月15日/Benchmarking_Zero-Shot_Robustness_of_Multimodal_Foundation_Models_A_Pilot_Study.md)

    - [翻译: 本研究作为一项先导性探索，致力于对多模态基础模型在零样本条件下的鲁棒性进行基准评估。](2024年03月15日/Benchmarking_Zero-Shot_Robustness_of_Multimodal_Foundation_Models_A_Pilot_Study.md)

- [Emotion-Aware Multimodal Fusion for Meme Emotion Detection](2024年03月15日/Emotion-Aware_Multimodal_Fusion_for_Meme_Emotion_Detection.md)

    - [翻译: 为了提升表情包情感检测的准确性，我们提出了一种情绪感知的多模态融合方法，通过深度融合图像与文本信息，精准捕捉表情包中蕴含的情感色彩。](2024年03月15日/Emotion-Aware_Multimodal_Fusion_for_Meme_Emotion_Detection.md)

- [S3LLM: Large-Scale Scientific Software Understanding with LLMs using Source, Metadata, and Document](2024年03月15日/S3LLM_Large-Scale_Scientific_Software_Understanding_with_LLMs_using_Source,_Metadata,_and_Document.md)

    - [翻译: S3LLM项目借助LLMs的力量，整合了源代码、元数据与相关文档资源，以实现对大型科学软件深层次、全方位的理解。](2024年03月15日/S3LLM_Large-Scale_Scientific_Software_Understanding_with_LLMs_using_Source,_Metadata,_and_Document.md)

- [Whose Side Are You On? Investigating the Political Stance of Large Language Models](2024年03月15日/Whose_Side_Are_You_On_Investigating_the_Political_Stance_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型所持的政治倾向：它们究竟“站”在哪一方？](2024年03月15日/Whose_Side_Are_You_On_Investigating_the_Political_Stance_of_Large_Language_Models.md)

- [Large Language Models and User Trust: Focus on Healthcare](2024年03月15日/Large_Language_Models_and_User_Trust_Focus_on_Healthcare.md)

    - [翻译: 在医疗保健领域，大型语言模型（LLMs）与用户信任的关系备受关注。本研究将重点探讨LLMs如何赢得并维持用户信任，特别是在关乎健康信息处理的关键场景中。](2024年03月15日/Large_Language_Models_and_User_Trust_Focus_on_Healthcare.md)

- [ChatPattern: Layout Pattern Customization via Natural Language](2024年03月15日/ChatPattern_Layout_Pattern_Customization_via_Natural_Language.md)

    - [翻译: ChatPattern 是一项创新技术，允许用户借助自然语言轻松自定义布局模式。这项技术使得用户能够以更加直观和灵活的方式调整界面布局，只需通过简单的语言指令即可实现个性化定制。](2024年03月15日/ChatPattern_Layout_Pattern_Customization_via_Natural_Language.md)

- [GOMA: Proactive Embodied Cooperative Communication via Goal-Oriented Mental Alignment](2024年03月16日/GOMA_Proactive_Embodied_Cooperative_Communication_via_Goal-Oriented_Mental_Alignment.md)

    - [翻译: GOMA 是一种创新方法，通过目标导向的心理对齐机制实现积极主动的具身化合作沟通。](2024年03月16日/GOMA_Proactive_Embodied_Cooperative_Communication_via_Goal-Oriented_Mental_Alignment.md)

- [Fine-Grained Engine Fault Sound Event Detection Using Multimodal Signals](2024年03月16日/Fine-Grained_Engine_Fault_Sound_Event_Detection_Using_Multimodal_Signals.md)

    - [翻译: 针对发动机故障声音事件的精准识别，本研究采用多模态信号技术，旨在实现对各类微小故障声音细节的敏锐捕捉与精确判断。](2024年03月16日/Fine-Grained_Engine_Fault_Sound_Event_Detection_Using_Multimodal_Signals.md)

- [MIntRec2.0: A Large-scale Benchmark Dataset for Multimodal Intent Recognition and Out-of-scope Detection in Conversations](2024年03月16日/MIntRec2.0_A_Large-scale_Benchmark_Dataset_for_Multimodal_Intent_Recognition_and_Out-of-scope_Detection_in_Conversations.md)

    - [翻译: MIntRec2.0 是专为对话场景打造的大规模基准数据集，它聚焦于多模态意图识别及范围外检测两大挑战性任务。](2024年03月16日/MIntRec2.0_A_Large-scale_Benchmark_Dataset_for_Multimodal_Intent_Recognition_and_Out-of-scope_Detection_in_Conversations.md)

- [A Comprehensive Study of Multimodal Large Language Models for Image Quality Assessment](2024年03月16日/A_Comprehensive_Study_of_Multimodal_Large_Language_Models_for_Image_Quality_Assessment.md)

    - [翻译: 本研究全方位探究了应用于图像质量评估任务的多模态大型语言模型，旨在深入理解此类模型在该领域的性能与潜力。](2024年03月16日/A_Comprehensive_Study_of_Multimodal_Large_Language_Models_for_Image_Quality_Assessment.md)

- [Large language model-powered chatbots for internationalizing student support in higher education](2024年03月16日/Large_language_model-powered_chatbots_for_internationalizing_student_support_in_higher_education.md)

    - [翻译: 在高等教育领域，我们借助大型语言模型驱动的聊天机器人，为学生提供国际化的支持服务。](2024年03月16日/Large_language_model-powered_chatbots_for_internationalizing_student_support_in_higher_education.md)

- [LLM Guided Evolution - The Automation of Models Advancing Models](2024年03月17日/LLM_Guided_Evolution_-_The_Automation_of_Models_Advancing_Models.md)

    - [翻译: 在LLM引导下，模型驱动模型自动演进的新范式](2024年03月17日/LLM_Guided_Evolution_-_The_Automation_of_Models_Advancing_Models.md)

- [StyleChat: Learning Recitation-Augmented Memory in LLMs for Stylized Dialogue Generation](2024年03月17日/StyleChat_Learning_Recitation-Augmented_Memory_in_LLMs_for_Stylized_Dialogue_Generation.md)

    - [翻译: StyleChat 是一项研究，通过在大型语言模型中融入强化记忆技术，旨在提升模型进行风格化对话生成的能力。](2024年03月17日/StyleChat_Learning_Recitation-Augmented_Memory_in_LLMs_for_Stylized_Dialogue_Generation.md)

- [InsCL: A Data-efficient Continual Learning Paradigm for Fine-tuning Large Language Models with Instructions](2024年03月17日/InsCL_A_Data-efficient_Continual_Learning_Paradigm_for_Fine-tuning_Large_Language_Models_with_Instructions.md)

    - [翻译: InsCL 是一种新型的数据高效持续学习方法，专门针对大型语言模型进行指令引导的微调过程。这一范式有助于在节省数据的前提下，提升大型语言模型应对不断变化任务的学习能力。](2024年03月17日/InsCL_A_Data-efficient_Continual_Learning_Paradigm_for_Fine-tuning_Large_Language_Models_with_Instructions.md)

- [A Novel Paradigm Boosting Translation Capabilities of Large Language Models](2024年03月17日/A_Novel_Paradigm_Boosting_Translation_Capabilities_of_Large_Language_Models.md)

    - [翻译: 一种创新范式助力大型语言模型提升翻译效能](2024年03月17日/A_Novel_Paradigm_Boosting_Translation_Capabilities_of_Large_Language_Models.md)

- [Narrative Feature or Structured Feature? A Study of Large Language Models to Identify Cancer Patients at Risk of Heart Failure](2024年03月17日/Narrative_Feature_or_Structured_Feature_A_Study_of_Large_Language_Models_to_Identify_Cancer_Patients_at_Risk_of_Heart_Failure.md)

    - [翻译: 探究大型语言模型在识别心脏病风险癌症患者方面，究竟是叙事特征更具优势，还是结构化特征更胜一筹。本研究针对这一问题，对大型语言模型进行深入分析，旨在揭示其在处理不同类型特征时，在识别癌症患者并发心力衰竭风险上的效能差异。](2024年03月17日/Narrative_Feature_or_Structured_Feature_A_Study_of_Large_Language_Models_to_Identify_Cancer_Patients_at_Risk_of_Heart_Failure.md)

- [FastDecode: High-Throughput GPU-Efficient LLM Serving using Heterogeneous Pipelines](2024年03月17日/FastDecode_High-Throughput_GPU-Efficient_LLM_Serving_using_Heterogeneous_Pipelines.md)

    - [翻译: FastDecode是一种利用异构流水线技术，大幅提升GPU效率以实现大规模语言模型（LLM）高速服务的方法。](2024年03月17日/FastDecode_High-Throughput_GPU-Efficient_LLM_Serving_using_Heterogeneous_Pipelines.md)

- [Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning](2024年03月17日/Scene-LLM_Extending_Language_Model_for_3D_Visual_Understanding_and_Reasoning.md)

    - [翻译: Scene-LLM：致力于增强语言模型能力，使其能够理解和推理三维视觉场景，从而开启全新的三维视觉智能应用领域。](2024年03月17日/Scene-LLM_Extending_Language_Model_for_3D_Visual_Understanding_and_Reasoning.md)

- [X-LLaVA: Optimizing Bilingual Large Vision-Language Alignment](2024年03月17日/X-LLaVA_Optimizing_Bilingual_Large_Vision-Language_Alignment.md)

    - [翻译: X-LLaVA：致力于优化双语环境下大型视觉与语言模型的深度对齐能力](2024年03月17日/X-LLaVA_Optimizing_Bilingual_Large_Vision-Language_Alignment.md)

- [Can LLM-Augmented autonomous agents cooperate?, An evaluation of their cooperative capabilities through Melting Pot](2024年03月17日/Can_LLM-Augmented_autonomous_agents_cooperate,_An_evaluation_of_their_cooperative_capabilities_through_Melting_Pot.md)

    - [翻译: 在 Melting Pot 环境中检验 LLMA（大型语言模型增强）自主代理能否有效合作？本研究通过一系列实验评估其合作能力。注：这里我将 "Can LLM-Augmented autonomous agents cooperate?" 翻译为“LLM 增强型自主代理能否有效合作？”以更符合中文口语表达，并将 "An evaluation of their cooperative capabilities through Melting Pot" 翻译为“本研究通过一系列 Melting Pot 实验评估其合作能力”，以更贴合中文阅读习惯，同时保持原句主旨。](2024年03月17日/Can_LLM-Augmented_autonomous_agents_cooperate,_An_evaluation_of_their_cooperative_capabilities_through_Melting_Pot.md)

- [What Makes Math Word Problems Challenging for LLMs?](2024年03月17日/What_Makes_Math_Word_Problems_Challenging_for_LLMs.md)

    - [翻译: 究竟为何数学文本题目会对 LLMs 造成困扰呢？](2024年03月17日/What_Makes_Math_Word_Problems_Challenging_for_LLMs.md)

- [Dynamic Contexts for Generating Suggestion Questions in RAG Based Conversational Systems](2024年03月17日/Dynamic_Contexts_for_Generating_Suggestion_Questions_in_RAG_Based_Conversational_Systems.md)

    - [翻译: 本研究探讨了如何在以 RAG 为核心的对话系统中利用动态上下文来生成更具启发性的建议性问题，以提升交互体验和信息检索效率。](2024年03月17日/Dynamic_Contexts_for_Generating_Suggestion_Questions_in_RAG_Based_Conversational_Systems.md)

- [JORA: JAX Tensor-Parallel LoRA Library for Retrieval Augmented Fine-Tuning](2024年03月17日/JORA_JAX_Tensor-Parallel_LoRA_Library_for_Retrieval_Augmented_Fine-Tuning.md)

    - [翻译: JORA 是一个专为提升检索增强微调效果而设计的 JAX 张量并行 LoRA 库。它利用张量并行技术，优化了在检索增强场景下对模型进行细调时的计算效率和性能表现。](2024年03月17日/JORA_JAX_Tensor-Parallel_LoRA_Library_for_Retrieval_Augmented_Fine-Tuning.md)

- [Beyond Static Evaluation: A Dynamic Approach to Assessing AI Assistants' API Invocation Capabilities](2024年03月17日/Beyond_Static_Evaluation_A_Dynamic_Approach_to_Assessing_AI_Assistants'_API_Invocation_Capabilities.md)

    - [翻译: 不仅限于静态评测，本研究提出了一种新颖的动态方法，用于深入探究和评估 AI 助手调用 API 的能力。](2024年03月17日/Beyond_Static_Evaluation_A_Dynamic_Approach_to_Assessing_AI_Assistants'_API_Invocation_Capabilities.md)

- [Few-Shot VQA with Frozen LLMs: A Tale of Two Approaches](2024年03月17日/Few-Shot_VQA_with_Frozen_LLMs_A_Tale_of_Two_Approaches.md)

    - [翻译: 在“少量样本 VQA 与冻结 LLM：两种方法的探析”中，我们探讨了如何利用冻结的大型语言模型，在仅提供少量样本的情况下解决视觉问答（VQA）任务，通过对比两种不同策略来揭示其潜力和特点。](2024年03月17日/Few-Shot_VQA_with_Frozen_LLMs_A_Tale_of_Two_Approaches.md)

- [ManipVQA: Injecting Robotic Affordance and Physically Grounded Information into Multi-Modal Large Language Models](2024年03月17日/ManipVQA_Injecting_Robotic_Affordance_and_Physically_Grounded_Information_into_Multi-Modal_Large_Language_Models.md)

    - [翻译: ManipVQA项目致力于将机器人操作性及物理实证信息巧妙地融入到多模态大型语言模型中，以增强其理解与推理能力。](2024年03月17日/ManipVQA_Injecting_Robotic_Affordance_and_Physically_Grounded_Information_into_Multi-Modal_Large_Language_Models.md)

- [Correcting misinformation on social media with a large language model](2024年03月17日/Correcting_misinformation_on_social_media_with_a_large_language_model.md)

    - [翻译: 本研究探讨如何运用大型语言模型有效纠正社交媒体上流传的误导性信息。](2024年03月17日/Correcting_misinformation_on_social_media_with_a_large_language_model.md)

- [MineDreamer: Learning to Follow Instructions via Chain-of-Imagination for Simulated-World Control](2024年03月18日/MineDreamer_Learning_to_Follow_Instructions_via_Chain-of-Imagination_for_Simulated-World_Control.md)

    - [翻译: MineDreamer，一种创新方法，通过“链式想象”机制，在模拟世界的控制情境中实现对指令的精准跟随。](2024年03月18日/MineDreamer_Learning_to_Follow_Instructions_via_Chain-of-Imagination_for_Simulated-World_Control.md)

- [ROUTERBENCH: A Benchmark for Multi-LLM Routing System](2024年03月18日/ROUTERBENCH_A_Benchmark_for_Multi-LLM_Routing_System.md)

    - [翻译: ROUTERBENCH：专为多大型语言模型（Multi-LLM）路由系统设计的一套权威基准测试方案](2024年03月18日/ROUTERBENCH_A_Benchmark_for_Multi-LLM_Routing_System.md)

- [From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models](2024年03月18日/From_Pixels_to_Insights_A_Survey_on_Automatic_Chart_Understanding_in_the_Era_of_Large_Foundation_Models.md)

    - [翻译: 在大型基础模型盛行的时代，这篇综述文章带领我们探索从原始像素出发，深入理解自动图表解析的历程。](2024年03月18日/From_Pixels_to_Insights_A_Survey_on_Automatic_Chart_Understanding_in_the_Era_of_Large_Foundation_Models.md)

- [FlexCap: Generating Rich, Localized, and Flexible Captions in Images](2024年03月18日/FlexCap_Generating_Rich,_Localized,_and_Flexible_Captions_in_Images.md)

    - [翻译: FlexCap：致力于在图像中生成既丰富多样、定位精准又具备灵活性的标题](2024年03月18日/FlexCap_Generating_Rich,_Localized,_and_Flexible_Captions_in_Images.md)

- [A Toolbox for Surfacing Health Equity Harms and Biases in Large Language Models](2024年03月18日/A_Toolbox_for_Surfacing_Health_Equity_Harms_and_Biases_in_Large_Language_Models.md)

    - [翻译: 针对大型语言模型中的健康公平性损害与偏见问题，我们推出一款专门的工具箱，旨在深度挖掘并揭示其中存在的相关问题。](2024年03月18日/A_Toolbox_for_Surfacing_Health_Equity_Harms_and_Biases_in_Large_Language_Models.md)

- [Supervised Fine-Tuning as Inverse Reinforcement Learning](2024年03月18日/Supervised_Fine-Tuning_as_Inverse_Reinforcement_Learning.md)

    - [翻译: 将监督微调视为逆向强化学习，这一新颖视角揭示了预训练模型在特定任务上微调的潜在机制。通过借鉴强化学习中的逆向方法，我们尝试理解并解析在有监督环境下对大型预训练模型进行调整以优化其在特定下游任务性能背后的“奖励”信号。](2024年03月18日/Supervised_Fine-Tuning_as_Inverse_Reinforcement_Learning.md)

- [EnvGen: Generating and Adapting Environments via LLMs for Training Embodied Agents](2024年03月18日/EnvGen_Generating_and_Adapting_Environments_via_LLMs_for_Training_Embodied_Agents.md)

    - [翻译: EnvGen 是一项利用 LLM 技术，针对具身智能体训练而设计的环境生成与适应方法。它能够动态创建并调整适宜的虚拟环境，以满足具身智能体的学习需求。](2024年03月18日/EnvGen_Generating_and_Adapting_Environments_via_LLMs_for_Training_Embodied_Agents.md)

- [The Value, Benefits, and Concerns of Generative AI-Powered Assistance in Writing](2024年03月18日/The_Value,_Benefits,_and_Concerns_of_Generative_AI-Powered_Assistance_in_Writing.md)

    - [翻译: 探究生成式AI在写作辅助中的价值与优势，同时分析由此引发的关注和挑战。](2024年03月18日/The_Value,_Benefits,_and_Concerns_of_Generative_AI-Powered_Assistance_in_Writing.md)

- [Using Generative Text Models to Create Qualitative Codebooks for Student Evaluations of Teaching](2024年03月18日/Using_Generative_Text_Models_to_Create_Qualitative_Codebooks_for_Student_Evaluations_of_Teaching.md)

    - [翻译: 利用生成式文本模型的力量，我们致力于为学生教学评估构建一套详尽的定性编码手册，以提升评估过程的准确性和深度。](2024年03月18日/Using_Generative_Text_Models_to_Create_Qualitative_Codebooks_for_Student_Evaluations_of_Teaching.md)

- [Subjective-Aligned Dateset and Metric for Text-to-Video Quality Assessment](2024年03月18日/Subjective-Aligned_Dateset_and_Metric_for_Text-to-Video_Quality_Assessment.md)

    - [翻译: 为文本转视频质量评估构建了主观对齐的数据集及相应评估指标。](2024年03月18日/Subjective-Aligned_Dateset_and_Metric_for_Text-to-Video_Quality_Assessment.md)

- [Larimar: Large Language Models with Episodic Memory Control](2024年03月18日/Larimar_Large_Language_Models_with_Episodic_Memory_Control.md)

    - [翻译: Larimar 是一种具备情境记忆控制功能的大型语言模型，它能够在处理和生成文本时利用情境记忆进行更精准、灵活和上下文相关的操作。](2024年03月18日/Larimar_Large_Language_Models_with_Episodic_Memory_Control.md)

- [Investigating Markers and Drivers of Gender Bias in Machine Translations](2024年03月18日/Investigating_Markers_and_Drivers_of_Gender_Bias_in_Machine_Translations.md)

    - [翻译: 本研究深入探究了机器翻译系统中存在的性别偏见标记及其产生原因，旨在揭示驱动这一现象的背后因素。](2024年03月18日/Investigating_Markers_and_Drivers_of_Gender_Bias_in_Machine_Translations.md)

- [SuperLoRA: Parameter-Efficient Unified Adaptation of Multi-Layer Attention Modules](2024年03月18日/SuperLoRA_Parameter-Efficient_Unified_Adaptation_of_Multi-Layer_Attention_Modules.md)

    - [翻译: SuperLoRA：一种针对多层注意力模块的参数高效统一调适技术](2024年03月18日/SuperLoRA_Parameter-Efficient_Unified_Adaptation_of_Multi-Layer_Attention_Modules.md)

- [QueryAgent: A Reliable and Efficient Reasoning Framework with Environmental Feedback based Self-Correction](2024年03月18日/QueryAgent_A_Reliable_and_Efficient_Reasoning_Framework_with_Environmental_Feedback_based_Self-Correction.md)

    - [翻译: QueryAgent 是一个创新的推理框架，它借助环境反馈实现自我校正，既保证了推理过程的可靠性，又提升了效率。步骤详解：](2024年03月18日/QueryAgent_A_Reliable_and_Efficient_Reasoning_Framework_with_Environmental_Feedback_based_Self-Correction.md)

- [Context-aware LLM-based Safe Control Against Latent Risks](2024年03月18日/Context-aware_LLM-based_Safe_Control_Against_Latent_Risks.md)

    - [翻译: 针对隐性风险，本研究探讨了利用上下文感知的大型语言模型进行安全控制的方法。](2024年03月18日/Context-aware_LLM-based_Safe_Control_Against_Latent_Risks.md)

- [GPT-4 as Evaluator: Evaluating Large Language Models on Pest Management in Agriculture](2024年03月18日/GPT-4_as_Evaluator_Evaluating_Large_Language_Models_on_Pest_Management_in_Agriculture.md)

    - [翻译: GPT-4 担纲评估员角色，针对农业害虫管理领域对大型语言模型进行深入测评。](2024年03月18日/GPT-4_as_Evaluator_Evaluating_Large_Language_Models_on_Pest_Management_in_Agriculture.md)

- [Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models](2024年03月18日/Ensuring_Safe_and_High-Quality_Outputs_A_Guideline_Library_Approach_for_Language_Models.md)

    - [翻译: 为确保语言模型产出既安全又高质量，我们提出一种基于指南库的方法。通过构建一套详尽的指南库策略，本研究致力于引导和规范语言模型的输出行为。](2024年03月18日/Ensuring_Safe_and_High-Quality_Outputs_A_Guideline_Library_Approach_for_Language_Models.md)

- [Agent3D-Zero: An Agent for Zero-shot 3D Understanding](2024年03月18日/Agent3D-Zero_An_Agent_for_Zero-shot_3D_Understanding.md)

    - [翻译: Agent3D-Zero，一款专为实现零样本三维理解而设计的智能代理](2024年03月18日/Agent3D-Zero_An_Agent_for_Zero-shot_3D_Understanding.md)

- [Evaluating Text to Image Synthesis: Survey and Taxonomy of Image Quality Metrics](2024年03月18日/Evaluating_Text_to_Image_Synthesis_Survey_and_Taxonomy_of_Image_Quality_Metrics.md)

    - [翻译: 探究文本生成图像的质量评估：本研究对图像质量度量进行详尽梳理，并构建了一套针对文本到图像合成任务的度量指标分类体系。](2024年03月18日/Evaluating_Text_to_Image_Synthesis_Survey_and_Taxonomy_of_Image_Quality_Metrics.md)

- [TCNet: Continuous Sign Language Recognition from Trajectories and Correlated Regions](2024年03月18日/TCNet_Continuous_Sign_Language_Recognition_from_Trajectories_and_Correlated_Regions.md)

    - [翻译: TCNet 是一种用于连续手语识别的模型，它能从手势运动轨迹以及相关联的关键区域中捕捉并解析信息。](2024年03月18日/TCNet_Continuous_Sign_Language_Recognition_from_Trajectories_and_Correlated_Regions.md)

- [Metaphor Understanding Challenge Dataset for LLMs](2024年03月18日/Metaphor_Understanding_Challenge_Dataset_for_LLMs.md)

    - [翻译: LLMs 隐喻理解挑战数据集，专为检验大型语言模型对复杂隐喻的理解能力而设计](2024年03月18日/Metaphor_Understanding_Challenge_Dataset_for_LLMs.md)

- [How Far Are We on the Decision-Making of LLMs? Evaluating LLMs' Gaming Ability in Multi-Agent Environments](2024年03月18日/How_Far_Are_We_on_the_Decision-Making_of_LLMs_Evaluating_LLMs'_Gaming_Ability_in_Multi-Agent_Environments.md)

    - [翻译: 面对多智能体环境下的决策制定，我们对LLMs（大型语言模型）的能力探索到了何种程度？此研究致力于评估LLMs在游戏中展现的多智能体交互决策能力。](2024年03月18日/How_Far_Are_We_on_the_Decision-Making_of_LLMs_Evaluating_LLMs'_Gaming_Ability_in_Multi-Agent_Environments.md)

- [Counting-Stars: A Simple, Efficient, and Reasonable Strategy for Evaluating Long-Context Large Language Models](2024年03月18日/Counting-Stars_A_Simple,_Efficient,_and_Reasonable_Strategy_for_Evaluating_Long-Context_Large_Language_Models.md)

    - [翻译: Counting-Stars——我们提出了一种简洁高效的方案，用以评估长上下文大型语言模型，该策略在评估过程中兼顾了合理性和准确性。](2024年03月18日/Counting-Stars_A_Simple,_Efficient,_and_Reasonable_Strategy_for_Evaluating_Long-Context_Large_Language_Models.md)

- [Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus](2024年03月18日/Reasoning_Abilities_of_Large_Language_Models_In-Depth_Analysis_on_the_Abstraction_and_Reasoning_Corpus.md)

    - [翻译: 深度探究大型语言模型在抽象与推理方面的表现，基于详尽的“抽象和推理语料库”进行分析。](2024年03月18日/Reasoning_Abilities_of_Large_Language_Models_In-Depth_Analysis_on_the_Abstraction_and_Reasoning_Corpus.md)

- [Construction of Hyper-Relational Knowledge Graphs Using Pre-Trained Large Language Models](2024年03月18日/Construction_of_Hyper-Relational_Knowledge_Graphs_Using_Pre-Trained_Large_Language_Models.md)

    - [翻译: 本研究探讨如何运用预训练的大型语言模型构建超关系知识图谱，以期在知识表示和推理领域取得新的突破。](2024年03月18日/Construction_of_Hyper-Relational_Knowledge_Graphs_Using_Pre-Trained_Large_Language_Models.md)

- [Modality-Agnostic fMRI Decoding of Vision and Language](2024年03月18日/Modality-Agnostic_fMRI_Decoding_of_Vision_and_Language.md)

    - [翻译: 跨模态fMRI解码技术应用于视觉与语言研究，实现对不同感知模态信息的有效解码。](2024年03月18日/Modality-Agnostic_fMRI_Decoding_of_Vision_and_Language.md)

- [Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs](2024年03月18日/Meta-Prompting_for_Automating_Zero-shot_Visual_Recognition_with_LLMs.md)

    - [翻译: 运用元提示方法，借助LLMs自动实现零样本视觉识别任务的高效处理。](2024年03月18日/Meta-Prompting_for_Automating_Zero-shot_Visual_Recognition_with_LLMs.md)

- [Revisiting The Classics: A Study on Identifying and Rectifying Gender Stereotypes in Rhymes and Poems](2024年03月18日/Revisiting_The_Classics_A_Study_on_Identifying_and_Rectifying_Gender_Stereotypes_in_Rhymes_and_Poems.md)

    - [翻译: 本研究重读经典，专注于识别并修正儿歌及诗歌中的性别刻板印象，旨在引导读者深入理解并重塑文学作品中的性别表达。](2024年03月18日/Revisiting_The_Classics_A_Study_on_Identifying_and_Rectifying_Gender_Stereotypes_in_Rhymes_and_Poems.md)

- [HDLdebugger: Streamlining HDL debugging with Large Language Models](2024年03月18日/HDLdebugger_Streamlining_HDL_debugging_with_Large_Language_Models.md)

    - [翻译: HDLdebugger——利用大型语言模型实现HDL调试过程的高效化和简化](2024年03月18日/HDLdebugger_Streamlining_HDL_debugging_with_Large_Language_Models.md)

- [Let's Focus on Neuron: Neuron-Level Supervised Fine-tuning for Large Language Model](2024年03月18日/Let's_Focus_on_Neuron_Neuron-Level_Supervised_Fine-tuning_for_Large_Language_Model.md)

    - [翻译: 本文将关注大型语言模型的神经元层级监督微调技术，旨在通过细致到神经元级别的调整，提升其性能表现。](2024年03月18日/Let's_Focus_on_Neuron_Neuron-Level_Supervised_Fine-tuning_for_Large_Language_Model.md)

- [Linguacodus: A Synergistic Framework for Transformative Code Generation in Machine Learning Pipelines](2024年03月18日/Linguacodus_A_Synergistic_Framework_for_Transformative_Code_Generation_in_Machine_Learning_Pipelines.md)

    - [翻译: Linguacodus 是一个专为机器学习流水线设计的协同式框架，致力于实现革命性的代码生成过程。](2024年03月18日/Linguacodus_A_Synergistic_Framework_for_Transformative_Code_Generation_in_Machine_Learning_Pipelines.md)

- [EffiVED:Efficient Video Editing via Text-instruction Diffusion Models](2024年03月18日/EffiVEDEfficient_Video_Editing_via_Text-instruction_Diffusion_Models.md)

    - [翻译: EffiVED 是一种创新技术，借助于文本指令扩散模型，能够高效地进行视频编辑操作。](2024年03月18日/EffiVEDEfficient_Video_Editing_via_Text-instruction_Diffusion_Models.md)

- [Reinforcement Learning with Token-level Feedback for Controllable Text Generation](2024年03月18日/Reinforcement_Learning_with_Token-level_Feedback_for_Controllable_Text_Generation.md)

    - [翻译: 针对可控文本生成任务，我们采用强化学习方法并引入Token级别的精细反馈机制，以实现对文本生成过程的精准控制与优化。](2024年03月18日/Reinforcement_Learning_with_Token-level_Feedback_for_Controllable_Text_Generation.md)

- [LLM^3:Large Language Model-based Task and Motion Planning with Motion Failure Reasoning](2024年03月18日/LLM^3Large_Language_Model-based_Task_and_Motion_Planning_with_Motion_Failure_Reasoning.md)

    - [翻译: LLM^3 是一种将大型语言模型应用于任务与运动规划的方法，并融入了对运动失败原因的深入推理。这一技术旨在利用 LLM 的强大能力，为复杂任务与运动规划提供智能解决方案，同时能够理解和解释可能发生的运动失败原因。](2024年03月18日/LLM^3Large_Language_Model-based_Task_and_Motion_Planning_with_Motion_Failure_Reasoning.md)

- [Boosting Continual Learning of Vision-Language Models via Mixture-of-Experts Adapters](2024年03月18日/Boosting_Continual_Learning_of_Vision-Language_Models_via_Mixture-of-Experts_Adapters.md)

    - [翻译: 利用混合专家适配器技术，我们成功地增强了视觉-语言模型在连续学习任务中的性能。这一方法旨在通过精心设计的适配器结构，有效促进视觉和语言信息融合的模型在不断学习新知识的过程中保持并提升其原有能力。](2024年03月18日/Boosting_Continual_Learning_of_Vision-Language_Models_via_Mixture-of-Experts_Adapters.md)

- [DEE: Dual-stage Explainable Evaluation Method for Text Generation](2024年03月18日/DEE_Dual-stage_Explainable_Evaluation_Method_for_Text_Generation.md)

    - [翻译: DEE 是一种创新的双阶段可解释评估方案，专为评估和解析文本生成任务的效果而设计。](2024年03月18日/DEE_Dual-stage_Explainable_Evaluation_Method_for_Text_Generation.md)

- [Do CLIPs Always Generalize Better than ImageNet Models?](2024年03月18日/Do_CLIPs_Always_Generalize_Better_than_ImageNet_Models.md)

    - [翻译: CLIP 是否总能胜过 ImageNet 模型，展现出更强的泛化性能？](2024年03月18日/Do_CLIPs_Always_Generalize_Better_than_ImageNet_Models.md)

- [VideoAgent: A Memory-augmented Multimodal Agent for Video Understanding](2024年03月18日/VideoAgent_A_Memory-augmented_Multimodal_Agent_for_Video_Understanding.md)

    - [翻译: VideoAgent，一款搭载记忆增强技术的多模态智能体，专为深入理解视频内容而设计。](2024年03月18日/VideoAgent_A_Memory-augmented_Multimodal_Agent_for_Video_Understanding.md)

- [Generative Motion Stylization within Canonical Motion Space](2024年03月18日/Generative_Motion_Stylization_within_Canonical_Motion_Space.md)

    - [翻译: 我们专注于在规范化运动空间中进行生成式运动风格化研究，旨在探索如何在这个框架内实现和控制各种动态运动的风格表现。](2024年03月18日/Generative_Motion_Stylization_within_Canonical_Motion_Space.md)

- [HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models](2024年03月18日/HateCOT_An_Explanation-Enhanced_Dataset_for_Generalizable_Offensive_Speech_Detection_via_Large_Language_Models.md)

    - [翻译: HateCOT 数据集：针对大型语言模型，提供丰富解释以提升对各类攻击性言论检测的泛化能力](2024年03月18日/HateCOT_An_Explanation-Enhanced_Dataset_for_Generalizable_Offensive_Speech_Detection_via_Large_Language_Models.md)

- [Embedded Named Entity Recognition using Probing Classifiers](2024年03月18日/Embedded_Named_Entity_Recognition_using_Probing_Classifiers.md)

    - [翻译: 探查分类器在嵌入式命名实体识别技术中的应用，旨在通过该方法对文本中嵌入的实体进行精准识别。](2024年03月18日/Embedded_Named_Entity_Recognition_using_Probing_Classifiers.md)

- [LLaVA-UHD: an LMM Perceiving Any Aspect Ratio and High-Resolution Images](2024年03月18日/LLaVA-UHD_an_LMM_Perceiving_Any_Aspect_Ratio_and_High-Resolution_Images.md)

    - [翻译: LLaVA-UHD，一款能够灵活处理任意纵横比、高清图像的 LMM 模型。](2024年03月18日/LLaVA-UHD_an_LMM_Perceiving_Any_Aspect_Ratio_and_High-Resolution_Images.md)

- [Diffusion-Based Environment-Aware Trajectory Prediction](2024年03月18日/Diffusion-Based_Environment-Aware_Trajectory_Prediction.md)

    - [翻译: 扩散模型驱动的环境敏感轨迹预测技术](2024年03月18日/Diffusion-Based_Environment-Aware_Trajectory_Prediction.md)

- [NovelQA: A Benchmark for Long-Range Novel Question Answering](2024年03月18日/NovelQA_A_Benchmark_for_Long-Range_Novel_Question_Answering.md)

    - [翻译: NovelQA：针对长篇文本新颖问题回答的基准测试，旨在衡量模型在解答复杂、需要理解全文信息的问题上的表现。](2024年03月18日/NovelQA_A_Benchmark_for_Long-Range_Novel_Question_Answering.md)

- [VisionGPT: LLM-Assisted Real-Time Anomaly Detection for Safe Visual Navigation](2024年03月18日/VisionGPT_LLM-Assisted_Real-Time_Anomaly_Detection_for_Safe_Visual_Navigation.md)

    - [翻译: VisionGPT：运用大型语言模型助力实时视觉导航异常检测，以保障安全行驶](2024年03月18日/VisionGPT_LLM-Assisted_Real-Time_Anomaly_Detection_for_Safe_Visual_Navigation.md)

- [Towards Interpretable Hate Speech Detection using Large Language Model-extracted Rationales](2024年03月18日/Towards_Interpretable_Hate_Speech_Detection_using_Large_Language_Model-extracted_Rationales.md)

    - [翻译: 致力于借助大型语言模型提取的理据实现对仇恨言论检测的可解释性研究](2024年03月18日/Towards_Interpretable_Hate_Speech_Detection_using_Large_Language_Model-extracted_Rationales.md)

- [OV9D: Open-Vocabulary Category-Level 9D Object Pose and Size Estimation](2024年03月18日/OV9D_Open-Vocabulary_Category-Level_9D_Object_Pose_and_Size_Estimation.md)

    - [翻译: OV9D 是一项针对开放词汇类别级的 9 维物体姿态与尺寸估算技术，旨在无需预先训练所有类别的样本，即可准确推断各类物体的位置、方向及大小信息。](2024年03月18日/OV9D_Open-Vocabulary_Category-Level_9D_Object_Pose_and_Size_Estimation.md)

- [Dr3: Ask Large Language Models Not to Give Off-Topic Answers in Open Domain Multi-Hop Question Answering](2024年03月18日/Dr3_Ask_Large_Language_Models_Not_to_Give_Off-Topic_Answers_in_Open_Domain_Multi-Hop_Question_Answering.md)

    - [翻译: Dr3 提议，在处理开放领域多跳问题回答时，应引导大语言模型避免提供与主题无关的答案。](2024年03月18日/Dr3_Ask_Large_Language_Models_Not_to_Give_Off-Topic_Answers_in_Open_Domain_Multi-Hop_Question_Answering.md)

- [Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models](2024年03月18日/Interpretable_User_Satisfaction_Estimation_for_Conversational_Systems_with_Large_Language_Models.md)

    - [翻译: 研究如何利用大型语言模型对对话系统进行用户满意度的可解释性估计](2024年03月18日/Interpretable_User_Satisfaction_Estimation_for_Conversational_Systems_with_Large_Language_Models.md)

- [Improving Generalizability of Extracting Social Determinants of Health Using Large Language Models through Prompt-tuning](2024年03月18日/Improving_Generalizability_of_Extracting_Social_Determinants_of_Health_Using_Large_Language_Models_through_Prompt-tuning.md)

    - [翻译: 借助Prompt微调技术提升大型语言模型在挖掘健康社会决定因素时的泛化性能](2024年03月18日/Improving_Generalizability_of_Extracting_Social_Determinants_of_Health_Using_Large_Language_Models_through_Prompt-tuning.md)

- [RankPrompt: Step-by-Step Comparisons Make Language Models Better Reasoners](2024年03月18日/RankPrompt_Step-by-Step_Comparisons_Make_Language_Models_Better_Reasoners.md)

    - [翻译: RankPrompt方法通过步步对比提升语言模型推理能力步骤 1 翻译：RankPrompt 是一种技术，通过逐级比较的方式使语言模型在推理能力上得到显著提升。步骤 2 翻译：RankPrompt 利用逐步对比机制，助力语言模型提升推理效能。](2024年03月18日/RankPrompt_Step-by-Step_Comparisons_Make_Language_Models_Better_Reasoners.md)

- [Learning Transferable Time Series Classifier with Cross-Domain Pre-training from Language Model](2024年03月18日/Learning_Transferable_Time_Series_Classifier_with_Cross-Domain_Pre-training_from_Language_Model.md)

    - [翻译: 本研究提出利用语言模型进行跨域预训练，以构建能够应用于不同领域的、具有强迁移能力的时间序列分类器。](2024年03月18日/Learning_Transferable_Time_Series_Classifier_with_Cross-Domain_Pre-training_from_Language_Model.md)

- [Characteristic AI Agents via Large Language Models](2024年03月18日/Characteristic_AI_Agents_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型打造特色AI智能体](2024年03月18日/Characteristic_AI_Agents_via_Large_Language_Models.md)

- [Multimodal Human-Autonomous Agents Interaction Using Pre-Trained Language and Visual Foundation Models](2024年03月18日/Multimodal_Human-Autonomous_Agents_Interaction_Using_Pre-Trained_Language_and_Visual_Foundation_Models.md)

    - [翻译: 借助预训练的语言与视觉模型，探究多模态环境下人类与自主智能体的交互机制](2024年03月18日/Multimodal_Human-Autonomous_Agents_Interaction_Using_Pre-Trained_Language_and_Visual_Foundation_Models.md)

- [Compiler generated feedback for Large Language Models](2024年03月18日/Compiler_generated_feedback_for_Large_Language_Models.md)

    - [翻译: 为大型语言模型定制的编译器生成反馈技术](2024年03月18日/Compiler_generated_feedback_for_Large_Language_Models.md)

- [Loops On Retrieval Augmented Generation (LoRAG)](2024年03月18日/Loops_On_Retrieval_Augmented_Generation_(LoRAG).md)

    - [翻译: LoRAG（检索增强生成中的循环机制）是一项技术，通过在文本生成过程中融入检索增强策略形成循环结构，以提升内容质量和生成效果。](2024年03月18日/Loops_On_Retrieval_Augmented_Generation_(LoRAG).md)

- [LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](2024年03月19日/LLMLingua-2_Data_Distillation_for_Efficient_and_Faithful_Task-Agnostic_Prompt_Compression.md)

    - [翻译: LLMLingua-2 是一项关于数据蒸馏技术的研究，致力于实现高效而准确的任务无关型提示压缩。通过数据精炼技术，LLMLingua-2旨在压缩大型语言模型的提示信息，同时保持对各种任务的高度适应性和忠实性。](2024年03月19日/LLMLingua-2_Data_Distillation_for_Efficient_and_Faithful_Task-Agnostic_Prompt_Compression.md)

- [Chain-of-Spot: Interactive Reasoning Improves Large Vision-Language Models](2024年03月19日/Chain-of-Spot_Interactive_Reasoning_Improves_Large_Vision-Language_Models.md)

    - [翻译: Chain-of-Spot研究揭示，通过引入交互式推理机制，可以显著提升大型视觉-语言模型的性能表现。](2024年03月19日/Chain-of-Spot_Interactive_Reasoning_Improves_Large_Vision-Language_Models.md)

- [Negative Yields Positive: Unified Dual-Path Adapter for Vision-Language Models](2024年03月19日/Negative_Yields_Positive_Unified_Dual-Path_Adapter_for_Vision-Language_Models.md)

    - [翻译: 看似“负面”的收益实则产生积极影响，我们提出了适用于视觉-语言模型的统一双路径适配器。该适配器创新性地构建了双向交互路径，旨在提升跨模态任务中的性能表现。](2024年03月19日/Negative_Yields_Positive_Unified_Dual-Path_Adapter_for_Vision-Language_Models.md)

- [Dated Data: Tracing Knowledge Cutoffs in Large Language Models](2024年03月19日/Dated_Data_Tracing_Knowledge_Cutoffs_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中的知识时效性——追踪其“知识截止点”动态步骤详细解释：1. 过时数据：在大型语言模型中追踪知识的截止点2. 翻译调整后：深入研究大型语言模型所承载知识的时效性问题，即追踪其内部的“知识截止点”。](2024年03月19日/Dated_Data_Tracing_Knowledge_Cutoffs_in_Large_Language_Models.md)

- [Automatic Information Extraction From Employment Tribunal Judgements Using Large Language Models](2024年03月19日/Automatic_Information_Extraction_From_Employment_Tribunal_Judgements_Using_Large_Language_Models.md)

    - [翻译: 本研究探索利用大型语言模型自动化提取就业法庭判决书中的关键信息，以提升司法文本处理效率和洞察能力。](2024年03月19日/Automatic_Information_Extraction_From_Employment_Tribunal_Judgements_Using_Large_Language_Models.md)

- [Rapid AIdeation: Generating Ideas With the Self and in Collaboration With Large Language Models](2024年03月19日/Rapid_AIdeation_Generating_Ideas_With_the_Self_and_in_Collaboration_With_Large_Language_Models.md)

    - [翻译: 「快速 AI 创想」探讨了如何在个体独立思考和与大型语言模型协作的双重模式下，高效激发并生成创新想法。](2024年03月19日/Rapid_AIdeation_Generating_Ideas_With_the_Self_and_in_Collaboration_With_Large_Language_Models.md)

- [Supporting Energy Policy Research with Large Language Models](2024年03月19日/Supporting_Energy_Policy_Research_with_Large_Language_Models.md)

    - [翻译: 通过运用大型语言模型，助力能源政策的深度探究与研究](2024年03月19日/Supporting_Energy_Policy_Research_with_Large_Language_Models.md)

- [Semantic Layering in Room Segmentation via LLMs](2024年03月19日/Semantic_Layering_in_Room_Segmentation_via_LLMs.md)

    - [翻译: 本研究探讨了如何借助大型语言模型（LLMs）实现房间分割的语义分层，从而更精确地理解和解析空间结构。](2024年03月19日/Semantic_Layering_in_Room_Segmentation_via_LLMs.md)

- [Toward Sustainable GenAI using Generation Directives for Carbon-Friendly Large Language Model Inference](2024年03月19日/Toward_Sustainable_GenAI_using_Generation_Directives_for_Carbon-Friendly_Large_Language_Model_Inference.md)

    - [翻译: 为实现更加环保的大型语言模型推理，我们正努力通过应用生成指令来促进可持续的GenAI。这一研究旨在探索如何借助生成指令降低大型语言模型推断过程中的碳排放，从而迈向绿色、可持续的人工智能发展方向。](2024年03月19日/Toward_Sustainable_GenAI_using_Generation_Directives_for_Carbon-Friendly_Large_Language_Model_Inference.md)

- [mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding](2024年03月19日/mPLUG-DocOwl_1.5_Unified_Structure_Learning_for_OCR-free_Document_Understanding.md)

    - [翻译: mPLUG-DocOwl 1.5 是一款集成了统一结构学习技术的工具，用于实现无需依赖光学字符识别（OCR）的高效文档理解。](2024年03月19日/mPLUG-DocOwl_1.5_Unified_Structure_Learning_for_OCR-free_Document_Understanding.md)

- [MEDBind: Unifying Language and Multimodal Medical Data Embeddings](2024年03月19日/MEDBind_Unifying_Language_and_Multimodal_Medical_Data_Embeddings.md)

    - [翻译: MEDBind 是一项创新技术，它成功地将语言与多模态医学数据的嵌入融合起来，实现了一体化的信息表示。](2024年03月19日/MEDBind_Unifying_Language_and_Multimodal_Medical_Data_Embeddings.md)

- [HYDRA: A Hyper Agent for Dynamic Compositional Visual Reasoning](2024年03月19日/HYDRA_A_Hyper_Agent_for_Dynamic_Compositional_Visual_Reasoning.md)

    - [翻译: HYDRA——专为解决动态组合视觉推理问题而生的超强智能体，它在复杂视觉场景中展现出卓越的推理能力。](2024年03月19日/HYDRA_A_Hyper_Agent_for_Dynamic_Compositional_Visual_Reasoning.md)

- [Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models](2024年03月19日/Agent-FLAN_Designing_Data_and_Methods_of_Effective_Agent_Tuning_for_Large_Language_Models.md)

    - [翻译: Agent-FLAN：致力于为大型语言模型量身定制高效调优策略，通过精心设计数据集与调优方法，旨在提升其在各类任务中的表现。](2024年03月19日/Agent-FLAN_Designing_Data_and_Methods_of_Effective_Agent_Tuning_for_Large_Language_Models.md)

- [RASP: A Drone-based Reconfigurable Actuation and Sensing Platform Towards Ambient Intelligent Systems](2024年03月19日/RASP_A_Drone-based_Reconfigurable_Actuation_and_Sensing_Platform_Towards_Ambient_Intelligent_Systems.md)

    - [翻译: RASP 是一种以无人机为核心的平台，具备灵活可配置的驱动与感知能力，专为构建适应环境、智能互动的系统而设计。](2024年03月19日/RASP_A_Drone-based_Reconfigurable_Actuation_and_Sensing_Platform_Towards_Ambient_Intelligent_Systems.md)

- [Compositional 3D Scene Synthesis with Scene Graph Guided Layout-Shape Generation](2024年03月19日/Compositional_3D_Scene_Synthesis_with_Scene_Graph_Guided_Layout-Shape_Generation.md)

    - [翻译: 借助场景图指导的布局与形状生成技术，我们致力于实现创新的组合式3D场景合成，这种方法能够有序构建和生成复杂的三维场景结构。](2024年03月19日/Compositional_3D_Scene_Synthesis_with_Scene_Graph_Guided_Layout-Shape_Generation.md)

- [MELTing point: Mobile Evaluation of Language Transformers](2024年03月19日/MELTing_point_Mobile_Evaluation_of_Language_Transformers.md)

    - [翻译: MELTing point：针对语言转换器在移动端性能评估的关键点探究](2024年03月19日/MELTing_point_Mobile_Evaluation_of_Language_Transformers.md)

- [Contextual Moral Value Alignment Through Context-Based Aggregation](2024年03月19日/Contextual_Moral_Value_Alignment_Through_Context-Based_Aggregation.md)

    - [翻译: 我们提出一种通过情境化聚合实现道德价值对齐的方法，该方法能够根据具体情境动态整合和调整模型输出的道德取向。](2024年03月19日/Contextual_Moral_Value_Alignment_Through_Context-Based_Aggregation.md)

- [RelationVLM: Making Large Vision-Language Models Understand Visual Relations](2024年03月19日/RelationVLM_Making_Large_Vision-Language_Models_Understand_Visual_Relations.md)

    - [翻译: RelationVLM 是一个旨在提升大型视觉-语言模型对视觉关系理解能力的模型。](2024年03月19日/RelationVLM_Making_Large_Vision-Language_Models_Understand_Visual_Relations.md)

- [Automated Data Curation for Robust Language Model Fine-Tuning](2024年03月19日/Automated_Data_Curation_for_Robust_Language_Model_Fine-Tuning.md)

    - [翻译: 自动化的数据优选方法助力提升语言模型微调的稳健性](2024年03月19日/Automated_Data_Curation_for_Robust_Language_Model_Fine-Tuning.md)

- [BTGenBot: Behavior Tree Generation for Robotic Tasks with Lightweight LLMs](2024年03月19日/BTGenBot_Behavior_Tree_Generation_for_Robotic_Tasks_with_Lightweight_LLMs.md)

    - [翻译: BTGenBot 是专为机器人任务设计的一款创新工具，它利用轻量级大型语言模型（LLM）自动生成行为树。这一技术旨在简化并优化机器人的任务规划与执行流程。](2024年03月19日/BTGenBot_Behavior_Tree_Generation_for_Robotic_Tasks_with_Lightweight_LLMs.md)

- [Instructing Large Language Models to Identify and Ignore Irrelevant Conditions](2024年03月19日/Instructing_Large_Language_Models_to_Identify_and_Ignore_Irrelevant_Conditions.md)

    - [翻译: 本研究致力于训练大型语言模型，使其能够精准识别并主动忽略无关条件，以提升模型处理复杂任务时的聚焦性和准确性。](2024年03月19日/Instructing_Large_Language_Models_to_Identify_and_Ignore_Irrelevant_Conditions.md)

- [Towards Multimodal In-Context Learning for Vision & Language Models](2024年03月19日/Towards_Multimodal_In-Context_Learning_for_Vision_&_Language_Models.md)

    - [翻译: 致力于探索视觉与语言模型的多模态上下文学习方法，旨在提升模型在不同模态信息融合下的泛化和理解能力。](2024年03月19日/Towards_Multimodal_In-Context_Learning_for_Vision_&_Language_Models.md)

- [SEVEN: Pruning Transformer Model by Reserving Sentinels](2024年03月19日/SEVEN_Pruning_Transformer_Model_by_Reserving_Sentinels.md)

    - [翻译: SEVEN：一种通过保留“哨兵”机制对Transformer模型进行有效剪枝的方法](2024年03月19日/SEVEN_Pruning_Transformer_Model_by_Reserving_Sentinels.md)

- [Pragmatic Competence Evaluation of Large Language Models for Korean](2024年03月19日/Pragmatic_Competence_Evaluation_of_Large_Language_Models_for_Korean.md)

    - [翻译: 本研究专注于对大型语言模型进行韩语语用能力的深入评估，探究其在实际场景中理解和运用语言的智慧程度。](2024年03月19日/Pragmatic_Competence_Evaluation_of_Large_Language_Models_for_Korean.md)

- [ICE: Interactive 3D Game Character Editing via Dialogue](2024年03月19日/ICE_Interactive_3D_Game_Character_Editing_via_Dialogue.md)

    - [翻译: ICE技术实现了通过对话方式实现交互式3D游戏角色的编辑，让玩家能够以自然语言交流的方式塑造游戏角色。](2024年03月19日/ICE_Interactive_3D_Game_Character_Editing_via_Dialogue.md)

- [Enhancing Formal Theorem Proving: A Comprehensive Dataset for Training AI Models on Coq Code](2024年03月19日/Enhancing_Formal_Theorem_Proving_A_Comprehensive_Dataset_for_Training_AI_Models_on_Coq_Code.md)

    - [翻译: 为了提升形式化定理证明能力，我们构建了一个全面的数据集，专为训练 AI 模型以解析和理解 Coq 代码而设计。](2024年03月19日/Enhancing_Formal_Theorem_Proving_A_Comprehensive_Dataset_for_Training_AI_Models_on_Coq_Code.md)

- [LHMKE: A Large-scale Holistic Multi-subject Knowledge Evaluation Benchmark for Chinese Large Language Models](2024年03月19日/LHMKE_A_Large-scale_Holistic_Multi-subject_Knowledge_Evaluation_Benchmark_for_Chinese_Large_Language_Models.md)

    - [翻译: LHMKE 是一个专为中国大型语言模型设计的大规模、全面的多学科知识评估基准。](2024年03月19日/LHMKE_A_Large-scale_Holistic_Multi-subject_Knowledge_Evaluation_Benchmark_for_Chinese_Large_Language_Models.md)

- [Chart-based Reasoning: Transferring Capabilities from LLMs to VLMs](2024年03月19日/Chart-based_Reasoning_Transferring_Capabilities_from_LLMs_to_VLMs.md)

    - [翻译: 通过“基于图表的推理”技术，我们致力于将大型语言模型（LLMs）的能力迁移至视觉语言模型（VLMs），实现跨模态能力的转化与共享。](2024年03月19日/Chart-based_Reasoning_Transferring_Capabilities_from_LLMs_to_VLMs.md)

- [AlphaFin: Benchmarking Financial Analysis with Retrieval-Augmented Stock-Chain Framework](2024年03月19日/AlphaFin_Benchmarking_Financial_Analysis_with_Retrieval-Augmented_Stock-Chain_Framework.md)

    - [翻译: AlphaFin 是一项创新研究，它利用检索增强型股票链框架为财务分析设定新的基准。这一研究致力于通过该框架提升金融分析的精准度与效率，将检索技术与股票产业链深度结合，以实现更高质量的财务数据分析和评估。](2024年03月19日/AlphaFin_Benchmarking_Financial_Analysis_with_Retrieval-Augmented_Stock-Chain_Framework.md)

- [Adapting Visual-Language Models for Generalizable Anomaly Detection in Medical Images](2024年03月19日/Adapting_Visual-Language_Models_for_Generalizable_Anomaly_Detection_in_Medical_Images.md)

    - [翻译: 本研究致力于将视觉-语言模型应用于医疗图像领域，使其能够进行具有泛化能力的异常检测，即针对各种医疗图像场景都能有效识别异常情况。](2024年03月19日/Adapting_Visual-Language_Models_for_Generalizable_Anomaly_Detection_in_Medical_Images.md)

- [Factorized Learning Assisted with Large Language Model for Gloss-free Sign Language Translation](2024年03月19日/Factorized_Learning_Assisted_with_Large_Language_Model_for_Gloss-free_Sign_Language_Translation.md)

    - [翻译: 通过引入大型语言模型协助的分解学习技术，我们致力于开发一种无需依赖词汇表的手语翻译方案。](2024年03月19日/Factorized_Learning_Assisted_with_Large_Language_Model_for_Gloss-free_Sign_Language_Translation.md)

- [AffineQuant: Affine Transformation Quantization for Large Language Models](2024年03月19日/AffineQuant_Affine_Transformation_Quantization_for_Large_Language_Models.md)

    - [翻译: AffineQuant——一种专为大型语言模型设计的仿射变换量化方法，旨在通过仿射变换实现模型量化，提升效率的同时保持模型性能。](2024年03月19日/AffineQuant_Affine_Transformation_Quantization_for_Large_Language_Models.md)

- [To Help or Not to Help: LLM-based Attentive Support for Human-Robot Group Interactions](2024年03月19日/To_Help_or_Not_to_Help_LLM-based_Attentive_Support_for_Human-Robot_Group_Interactions.md)

    - [翻译: 探究在人-机器人小组交互中，是否应借助基于LLM的注意力支持系统进行辅助。](2024年03月19日/To_Help_or_Not_to_Help_LLM-based_Attentive_Support_for_Human-Robot_Group_Interactions.md)

- [UniBind: LLM-Augmented Unified and Balanced Representation Space to Bind Them All](2024年03月19日/UniBind_LLM-Augmented_Unified_and_Balanced_Representation_Space_to_Bind_Them_All.md)

    - [翻译: UniBind 是一种创新的方法，它利用 LLM 增强技术构建了一个统一而均衡的表征空间，旨在“一统天下”，有效整合和绑定各种元素。](2024年03月19日/UniBind_LLM-Augmented_Unified_and_Balanced_Representation_Space_to_Bind_Them_All.md)

- [Dynamic Spatial-Temporal Aggregation for Skeleton-Aware Sign Language Recognition](2024年03月19日/Dynamic_Spatial-Temporal_Aggregation_for_Skeleton-Aware_Sign_Language_Recognition.md)

    - [翻译: 为实现精准手语识别，我们引入了动态时空聚合技术，该技术特别针对包含骨骼信息的手语动作特征进行深度提取和整合。](2024年03月19日/Dynamic_Spatial-Temporal_Aggregation_for_Skeleton-Aware_Sign_Language_Recognition.md)

- [Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices](2024年03月19日/Securing_Large_Language_Models_Threats,_Vulnerabilities_and_Responsible_Practices.md)

    - [翻译: 面对大型语言模型的安全挑战，本文将探讨其存在的威胁与潜在漏洞，并提出一系列负责任的防护实践。](2024年03月19日/Securing_Large_Language_Models_Threats,_Vulnerabilities_and_Responsible_Practices.md)

- [DetToolChain: A New Prompting Paradigm to Unleash Detection Ability of MLLM](2024年03月19日/DetToolChain_A_New_Prompting_Paradigm_to_Unleash_Detection_Ability_of_MLLM.md)

    - [翻译: DetToolChain 是一种创新的提示策略，致力于充分挖掘 MLLM 的检测潜能。](2024年03月19日/DetToolChain_A_New_Prompting_Paradigm_to_Unleash_Detection_Ability_of_MLLM.md)

- [Embodied LLM Agents Learn to Cooperate in Organized Teams](2024年03月19日/Embodied_LLM_Agents_Learn_to_Cooperate_in_Organized_Teams.md)

    - [翻译: 具备实体形态的大型语言模型智能体已能在结构化的团队环境中学会协同合作。（注：由于原始句子较短且语义明确，从直译到优化的过程并未进行大幅度调整，保持了原句的核心含义和生动性。）](2024年03月19日/Embodied_LLM_Agents_Learn_to_Cooperate_in_Organized_Teams.md)

- [CrossTune: Black-Box Few-Shot Classification with Label Enhancement](2024年03月19日/CrossTune_Black-Box_Few-Shot_Classification_with_Label_Enhancement.md)

    - [翻译: CrossTune —— 引入标签增强技术，针对黑盒环境下的少量样本分类任务提供解决方案](2024年03月19日/CrossTune_Black-Box_Few-Shot_Classification_with_Label_Enhancement.md)

- [INSIGHT: End-to-End Neuro-Symbolic Visual Reinforcement Learning with Language Explanations](2024年03月19日/INSIGHT_End-to-End_Neuro-Symbolic_Visual_Reinforcement_Learning_with_Language_Explanations.md)

    - [翻译: 洞见：通过引入语言解释，实现从感知到决策的端对端神经符号视觉强化学习步骤 1 翻译：INSIGHT: 端到端结合神经网络与符号处理的视觉强化学习，并辅以语言解释说明步骤 2 简洁优雅翻译：洞察：研究提出了一种创新方法，即采用端到端神经符号视觉强化学习技术，并融合语言解释元素，旨在深入理解并优化智能体在视觉强化学习过程中的决策机制。](2024年03月19日/INSIGHT_End-to-End_Neuro-Symbolic_Visual_Reinforcement_Learning_with_Language_Explanations.md)

- [On the effectiveness of Large Language Models for GitHub Workflows](2024年03月19日/On_the_effectiveness_of_Large_Language_Models_for_GitHub_Workflows.md)

    - [翻译: 探究大型语言模型在优化GitHub工作流程方面的成效](2024年03月19日/On_the_effectiveness_of_Large_Language_Models_for_GitHub_Workflows.md)

- [TexDreamer: Towards Zero-Shot High-Fidelity 3D Human Texture Generation](2024年03月19日/TexDreamer_Towards_Zero-Shot_High-Fidelity_3D_Human_Texture_Generation.md)

    - [翻译: TexDreamer——面向零样本高保真三维人体纹理生成技术，旨在无需训练样本的情况下实现逼真生动的三维人体纹理创作。](2024年03月19日/TexDreamer_Towards_Zero-Shot_High-Fidelity_3D_Human_Texture_Generation.md)

- [VisualCritic: Making LMMs Perceive Visual Quality Like Humans](2024年03月19日/VisualCritic_Making_LMMs_Perceive_Visual_Quality_Like_Humans.md)

    - [翻译: VisualCritic，这一创新技术致力于使大型多模态模型（LMMs）能够像人类一样敏锐地评估和理解视觉质量。](2024年03月19日/VisualCritic_Making_LMMs_Perceive_Visual_Quality_Like_Humans.md)

- [Community Needs and Assets: A Computational Analysis of Community Conversations](2024年03月19日/Community_Needs_and_Assets_A_Computational_Analysis_of_Community_Conversations.md)

    - [翻译: 通过对社区对话进行深度计算分析，探索社区内需求与资产的分布状况。](2024年03月19日/Community_Needs_and_Assets_A_Computational_Analysis_of_Community_Conversations.md)

- [Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning Ability of LLMs](2024年03月19日/Enhancing_Code_Generation_Performance_of_Smaller_Models_by_Distilling_the_Reasoning_Ability_of_LLMs.md)

    - [翻译: 为了提升小型模型在代码生成任务上的表现，本研究尝试通过提炼大型语言模型（LLM）的深层推理能力，并将其灌输到小型模型中，以实现性能优化。](2024年03月19日/Enhancing_Code_Generation_Performance_of_Smaller_Models_by_Distilling_the_Reasoning_Ability_of_LLMs.md)

- [SC-Tune: Unleashing Self-Consistent Referential Comprehension in Large Vision Language Models](2024年03月19日/SC-Tune_Unleashing_Self-Consistent_Referential_Comprehension_in_Large_Vision_Language_Models.md)

    - [翻译: SC-Tune：旨在揭示大型视觉语言模型内部的自洽参照理解潜力，从而充分释放其在处理复杂参照理解任务时的能力。](2024年03月19日/SC-Tune_Unleashing_Self-Consistent_Referential_Comprehension_in_Large_Vision_Language_Models.md)

- [Arcee's MergeKit: A Toolkit for Merging Large Language Models](2024年03月19日/Arcee's_MergeKit_A_Toolkit_for_Merging_Large_Language_Models.md)

    - [翻译: Arcee 推出 MergeKit，这是一个专为整合大型语言模型而设计的实用工具包。](2024年03月19日/Arcee's_MergeKit_A_Toolkit_for_Merging_Large_Language_Models.md)

- [Facilitating Pornographic Text Detection for Open-Domain Dialogue Systems via Knowledge Distillation of Large Language Models](2024年03月19日/Facilitating_Pornographic_Text_Detection_for_Open-Domain_Dialogue_Systems_via_Knowledge_Distillation_of_Large_Language_Models.md)

    - [翻译: 运用知识蒸馏技术提炼大型语言模型的能力，以提升开放域对话系统对色情文本的识别与检测效能。](2024年03月19日/Facilitating_Pornographic_Text_Detection_for_Open-Domain_Dialogue_Systems_via_Knowledge_Distillation_of_Large_Language_Models.md)

- [Instruction Multi-Constraint Molecular Generation Using a Teacher-Student Large Language Model](2024年03月19日/Instruction_Multi-Constraint_Molecular_Generation_Using_a_Teacher-Student_Large_Language_Model.md)

    - [翻译: 本研究利用教师-学生架构的大型语言模型，针对具有多重约束条件的指令，实现精准的分子生成任务。](2024年03月19日/Instruction_Multi-Constraint_Molecular_Generation_Using_a_Teacher-Student_Large_Language_Model.md)

- [Technical Report: Competition Solution For BetterMixture](2024年03月19日/Technical_Report_Competition_Solution_For_BetterMixture.md)

    - [翻译: 本技术报告详述了针对“BetterMixture”竞赛的解决方案，旨在深入探讨并优化混合模型的表现。](2024年03月19日/Technical_Report_Competition_Solution_For_BetterMixture.md)

- [From Representational Harms to Quality-of-Service Harms: A Case Study on Llama 2 Safety Safeguards](2024年03月19日/From_Representational_Harms_to_Quality-of-Service_Harms_A_Case_Study_on_Llama_2_Safety_Safeguards.md)

    - [翻译: 通过 Llama 2 安全防护机制的深入探究，本案例研究将视线从模型的表征伤害转移至服务质量层面的危害。](2024年03月19日/From_Representational_Harms_to_Quality-of-Service_Harms_A_Case_Study_on_Llama_2_Safety_Safeguards.md)

- [Towards Robots That Know When They Need Help: Affordance-Based Uncertainty for Large Language Model Planners](2024年03月19日/Towards_Robots_That_Know_When_They_Need_Help_Affordance-Based_Uncertainty_for_Large_Language_Model_Planners.md)

    - [翻译: 致力于研发能自我识别何时需要协助的机器人，我们提出了一种面向大型语言模型规划器的功能性不确定性方法。](2024年03月19日/Towards_Robots_That_Know_When_They_Need_Help_Affordance-Based_Uncertainty_for_Large_Language_Model_Planners.md)

- [VL-ICL Bench: The Devil in the Details of Benchmarking Multimodal In-Context Learning](2024年03月19日/VL-ICL_Bench_The_Devil_in_the_Details_of_Benchmarking_Multimodal_In-Context_Learning.md)

    - [翻译: VL-ICL Bench：深入探究多模态 In-Context 学习基准测试中的关键细节，犹如揭示隐藏在其中的“魔鬼”。](2024年03月19日/VL-ICL_Bench_The_Devil_in_the_Details_of_Benchmarking_Multimodal_In-Context_Learning.md)

- [When Do We Not Need Larger Vision Models?](2024年03月19日/When_Do_We_Not_Need_Larger_Vision_Models.md)

    - [翻译: 在哪些情况下，我们无需继续增大视觉模型呢？](2024年03月19日/When_Do_We_Not_Need_Larger_Vision_Models.md)

- [Bypassing LLM Watermarks with Color-Aware Substitutions](2024年03月19日/Bypassing_LLM_Watermarks_with_Color-Aware_Substitutions.md)

    - [翻译: 运用色彩感知替换策略规避LLM水印技术](2024年03月19日/Bypassing_LLM_Watermarks_with_Color-Aware_Substitutions.md)

- [LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction](2024年03月19日/LLMs-based_Few-Shot_Disease_Predictions_using_EHR_A_Novel_Approach_Combining_Predictive_Agent_Reasoning_and_Critical_Agent_Instruction.md)

    - [翻译: 创新运用 EHR 数据，结合预测性智能体推理与关键指令策略，提出了一种基于 LLMs 的少样本疾病预测新方法。](2024年03月19日/LLMs-based_Few-Shot_Disease_Predictions_using_EHR_A_Novel_Approach_Combining_Predictive_Agent_Reasoning_and_Critical_Agent_Instruction.md)

- [RAR: Retrieving And Ranking Augmented MLLMs for Visual Recognition](2024年03月20日/RAR_Retrieving_And_Ranking_Augmented_MLLMs_for_Visual_Recognition.md)

    - [翻译: RAR技术针对视觉识别任务，通过检索与排名策略优化多模态预训练模型（MLLMs），从而增强了其性能。](2024年03月20日/RAR_Retrieving_And_Ranking_Augmented_MLLMs_for_Visual_Recognition.md)

- [Learning from Models and Data for Visual Grounding](2024年03月20日/Learning_from_Models_and_Data_for_Visual_Grounding.md)

    - [翻译: 为实现视觉定位，本研究聚焦于结合模型与数据进行学习。](2024年03月20日/Learning_from_Models_and_Data_for_Visual_Grounding.md)

- [Reverse Training to Nurse the Reversal Curse](2024年03月20日/Reverse_Training_to_Nurse_the_Reversal_Curse.md)

    - [翻译: 为解决反转难题，我们采用反向训练策略。通过逆向训练法，旨在探究和克服大型模型在处理特定任务时所面临的“反转难题”。](2024年03月20日/Reverse_Training_to_Nurse_the_Reversal_Curse.md)

- [Chain-of-Interaction: Enhancing Large Language Models for Psychiatric Behavior Understanding by Dyadic Contexts](2024年03月20日/Chain-of-Interaction_Enhancing_Large_Language_Models_for_Psychiatric_Behavior_Understanding_by_Dyadic_Contexts.md)

    - [翻译: Chain-of-Interaction 方法旨在通过引入双人交互情境，提升大型语言模型在理解和解析精神行为方面的表现。这一技术致力于深入探究和利用对话互动中的上下文信息，从而助力模型更好地捕捉和模拟复杂的心理行为特征。](2024年03月20日/Chain-of-Interaction_Enhancing_Large_Language_Models_for_Psychiatric_Behavior_Understanding_by_Dyadic_Contexts.md)

- [Towards an extension of Fault Trees in the Predictive Maintenance Scenario](2024年03月20日/Towards_an_extension_of_Fault_Trees_in_the_Predictive_Maintenance_Scenario.md)

    - [翻译: 本研究致力于将故障树的概念应用于预测性维护场景，探索其扩展应用的可能性。](2024年03月20日/Towards_an_extension_of_Fault_Trees_in_the_Predictive_Maintenance_Scenario.md)

- [Information-Theoretic Distillation for Reference-less Summarization](2024年03月20日/Information-Theoretic_Distillation_for_Reference-less_Summarization.md)

    - [翻译: 为了解决无参考摘要问题，我们引入了一种基于信息理论的蒸馏技术。该方法旨在通过提炼关键信息，有效提升自动摘要的质量和准确性，即使在缺乏参考标准的情况下也能实现精准总结。](2024年03月20日/Information-Theoretic_Distillation_for_Reference-less_Summarization.md)

- [Embedding Pose Graph, Enabling 3D Foundation Model Capabilities with a Compact Representation](2024年03月20日/Embedding_Pose_Graph,_Enabling_3D_Foundation_Model_Capabilities_with_a_Compact_Representation.md)

    - [翻译: 通过嵌入姿态图并采用紧凑的表达形式，赋予三维基础模型强大的功能能力。](2024年03月20日/Embedding_Pose_Graph,_Enabling_3D_Foundation_Model_Capabilities_with_a_Compact_Representation.md)

- [Enhancing Gait Video Analysis in Neurodegenerative Diseases by Knowledge Augmentation in Vision Language Model](2024年03月20日/Enhancing_Gait_Video_Analysis_in_Neurodegenerative_Diseases_by_Knowledge_Augmentation_in_Vision_Language_Model.md)

    - [翻译: 通过在视觉语言模型中注入更多知识，我们提升对神经退行性疾病步态视频分析的精准度与深度。这项研究聚焦于通过知识增强手段优化视觉语言模型，以期在相关疾病的步态视频分析中取得突破性进展。](2024年03月20日/Enhancing_Gait_Video_Analysis_in_Neurodegenerative_Diseases_by_Knowledge_Augmentation_in_Vision_Language_Model.md)

- [EthioLLM: Multilingual Large Language Models for Ethiopian Languages with Task Evaluation](2024年03月20日/EthioLLM_Multilingual_Large_Language_Models_for_Ethiopian_Languages_with_Task_Evaluation.md)

    - [翻译: EthioLLM 是一款专为埃塞俄比亚多种语言设计的大型多语种语言模型，并通过详尽的任务评估展示了其性能。](2024年03月20日/EthioLLM_Multilingual_Large_Language_Models_for_Ethiopian_Languages_with_Task_Evaluation.md)

- [Large Language Models meet Network Slicing Management and Orchestration](2024年03月20日/Large_Language_Models_meet_Network_Slicing_Management_and_Orchestration.md)

    - [翻译: 大型语言模型邂逅网络切片的管理与编排，共同探索智能优化的新疆界。](2024年03月20日/Large_Language_Models_meet_Network_Slicing_Management_and_Orchestration.md)

- [HyLiMo: A Hybrid Live-Synchronized Modular Diagramming Editor as IDE Extension for Technical and Scientific Publications](2024年03月20日/HyLiMo_A_Hybrid_Live-Synchronized_Modular_Diagramming_Editor_as_IDE_Extension_for_Technical_and_Scientific_Publications.md)

    - [翻译: HyLiMo 是一款创新的模块化绘图编辑器，作为 IDE 的扩展功能，专为技术与科学出版物设计。它实现了混合实时同步技术，使得科研人员在创作过程中能够无缝协作并同步编辑模块化图表。](2024年03月20日/HyLiMo_A_Hybrid_Live-Synchronized_Modular_Diagramming_Editor_as_IDE_Extension_for_Technical_and_Scientific_Publications.md)

- [PARAMANU-AYN: An Efficient Novel Generative and Instruction-tuned Language Model for Indian Legal Case Documents](2024年03月20日/PARAMANU-AYN_An_Efficient_Novel_Generative_and_Instruction-tuned_Language_Model_for_Indian_Legal_Case_Documents.md)

    - [翻译: PARAMANU-AYN，一款专为印度法律案卷打造的高效创新生成模型，其特色在于能够根据指令进行精细调优。](2024年03月20日/PARAMANU-AYN_An_Efficient_Novel_Generative_and_Instruction-tuned_Language_Model_for_Indian_Legal_Case_Documents.md)

- [RoleInteract: Evaluating the Social Interaction of Role-Playing Agents](2024年03月20日/RoleInteract_Evaluating_the_Social_Interaction_of_Role-Playing_Agents.md)

    - [翻译: RoleInteract 是一项旨在评测角色扮演型智能体在社会交互情境中的表现的研究，它专注于探究这类智能体如何进行有效的社交互动。](2024年03月20日/RoleInteract_Evaluating_the_Social_Interaction_of_Role-Playing_Agents.md)

- [Do Not Worry if You Do Not Have Data: Building Pretrained Language Models Using Translationese](2024年03月20日/Do_Not_Worry_if_You_Do_Not_Have_Data_Building_Pretrained_Language_Models_Using_Translationese.md)

    - [翻译: 无需数据也能游刃有余：利用翻译文体打造预训练语言模型](2024年03月20日/Do_Not_Worry_if_You_Do_Not_Have_Data_Building_Pretrained_Language_Models_Using_Translationese.md)

- [VL-Mamba: Exploring State Space Models for Multimodal Learning](2024年03月20日/VL-Mamba_Exploring_State_Space_Models_for_Multimodal_Learning.md)

    - [翻译: VL-Mamba：致力于探究状态空间模型如何赋能多模态学习领域，这一研究深入挖掘此类模型在融合多种信息源以提升学习效果的潜力。](2024年03月20日/VL-Mamba_Exploring_State_Space_Models_for_Multimodal_Learning.md)

- [No more optimization rules: LLM-enabled policy-based multi-modal query optimizer (version 1)](2024年03月20日/No_more_optimization_rules_LLM-enabled_policy-based_multi-modal_query_optimizer_(version_1).md)

    - [翻译: 革新升级，告别繁琐规则——推出基于大型语言模型（LLM）的策略驱动型多模态查询优化器 v1，实现智能化优化。](2024年03月20日/No_more_optimization_rules_LLM-enabled_policy-based_multi-modal_query_optimizer_(version_1).md)

- [Encoding the Subsurface in 3D with Seismic](2024年03月20日/Encoding_the_Subsurface_in_3D_with_Seismic.md)

    - [翻译: 运用三维地震技术揭示地下结构的奥秘](2024年03月20日/Encoding_the_Subsurface_in_3D_with_Seismic.md)

- [Llama meets EU: Investigating the European Political Spectrum through the Lens of LLMs](2024年03月20日/Llama_meets_EU_Investigating_the_European_Political_Spectrum_through_the_Lens_of_LLMs.md)

    - [翻译: 借助 LLM 的洞察力，我们以“Llama meets EU”为题，深入探究欧洲政治光谱的奥秘。](2024年03月20日/Llama_meets_EU_Investigating_the_European_Political_Spectrum_through_the_Lens_of_LLMs.md)

- [Teacher-Student Training for Debiasing: General Permutation Debiasing for Large Language Models](2024年03月20日/Teacher-Student_Training_for_Debiasing_General_Permutation_Debiasing_for_Large_Language_Models.md)

    - [翻译: 通过“教师-学生”训练模式，我们提出了一种通用的排列去偏置方法，旨在为大型语言模型有效减少偏差。这种方法针对大规模语言模型设计，旨在解决其潜在的偏见问题，提升模型的公正性和准确性。](2024年03月20日/Teacher-Student_Training_for_Debiasing_General_Permutation_Debiasing_for_Large_Language_Models.md)

- [CONLINE: Complex Code Generation and Refinement with Online Searching and Correctness Testing](2024年03月20日/CONLINE_Complex_Code_Generation_and_Refinement_with_Online_Searching_and_Correctness_Testing.md)

    - [翻译: CONLINE 是一种结合了在线搜索和正确性测试技术的方法，用于复杂代码的生成与精细化处理。步骤细化：](2024年03月20日/CONLINE_Complex_Code_Generation_and_Refinement_with_Online_Searching_and_Correctness_Testing.md)

- [A Large Language Model Enhanced Sequential Recommender for Joint Video and Comment Recommendation](2024年03月20日/A_Large_Language_Model_Enhanced_Sequential_Recommender_for_Joint_Video_and_Comment_Recommendation.md)

    - [翻译: 我们提出了一种利用大型语言模型强化的序列推荐系统，旨在实现视频与评论的同时精准推荐。](2024年03月20日/A_Large_Language_Model_Enhanced_Sequential_Recommender_for_Joint_Video_and_Comment_Recommendation.md)

- [VCounselor: A Psychological Intervention Chat Agent Based on a Knowledge-Enhanced Large Language Model](2024年03月20日/VCounselor_A_Psychological_Intervention_Chat_Agent_Based_on_a_Knowledge-Enhanced_Large_Language_Model.md)

    - [翻译: VCounselor 是一款基于强化了专业知识的大型语言模型打造的心理咨询聊天助手，专为用户提供心理干预服务。](2024年03月20日/VCounselor_A_Psychological_Intervention_Chat_Agent_Based_on_a_Knowledge-Enhanced_Large_Language_Model.md)

- [Integrating Large Language Models for Severity Classification in Traffic Incident Management: A Machine Learning Approach](2024年03月20日/Integrating_Large_Language_Models_for_Severity_Classification_in_Traffic_Incident_Management_A_Machine_Learning_Approach.md)

    - [翻译: 本研究采用机器学习方法，将大型语言模型整合应用于交通事件管理中的事故严重程度分类。](2024年03月20日/Integrating_Large_Language_Models_for_Severity_Classification_in_Traffic_Incident_Management_A_Machine_Learning_Approach.md)

- [Motion Generation from Fine-grained Textual Descriptions](2024年03月20日/Motion_Generation_from_Fine-grained_Textual_Descriptions.md)

    - [翻译: 运动生成技术能够从详尽的文本描述中实现，本研究关注如何通过精细的文本指令精准地生成相应运动行为。](2024年03月20日/Motion_Generation_from_Fine-grained_Textual_Descriptions.md)

- [How Gender Interacts with Political Values: A Case Study on Czech BERT Models](2024年03月20日/How_Gender_Interacts_with_Political_Values_A_Case_Study_on_Czech_BERT_Models.md)

    - [翻译: 本研究通过捷克 BERT 模型的案例分析，深入探讨了性别因素如何与政治价值观相互作用。](2024年03月20日/How_Gender_Interacts_with_Political_Values_A_Case_Study_on_Czech_BERT_Models.md)

- [FMM-Attack: A Flow-based Multi-modal Adversarial Attack on Video-based LLMs](2024年03月20日/FMM-Attack_A_Flow-based_Multi-modal_Adversarial_Attack_on_Video-based_LLMs.md)

    - [翻译: FMM-Attack是一种创新的多模态对抗攻击方法，专门针对基于视频的大型语言模型，其设计原理基于流畅的流式攻击机制。](2024年03月20日/FMM-Attack_A_Flow-based_Multi-modal_Adversarial_Attack_on_Video-based_LLMs.md)

- [Improved Baselines for Data-efficient Perceptual Augmentation of LLMs](2024年03月20日/Improved_Baselines_for_Data-efficient_Perceptual_Augmentation_of_LLMs.md)

    - [翻译: 我们提出了针对大型语言模型（LLM）的数据高效感知增强的新基准方法，旨在提升模型在有限数据下的表现与泛化能力。](2024年03月20日/Improved_Baselines_for_Data-efficient_Perceptual_Augmentation_of_LLMs.md)

- [An Entropy-based Text Watermarking Detection Method](2024年03月20日/An_Entropy-based_Text_Watermarking_Detection_Method.md)

    - [翻译: 一种熵导向的文本水印检测技术](2024年03月20日/An_Entropy-based_Text_Watermarking_Detection_Method.md)

- [HyperLLaVA: Dynamic Visual and Language Expert Tuning for Multimodal Large Language Models](2024年03月20日/HyperLLaVA_Dynamic_Visual_and_Language_Expert_Tuning_for_Multimodal_Large_Language_Models.md)

    - [翻译: HyperLLaVA 是一项创新技术，专为多模态大型语言模型设计，通过动态调整视觉和语言专家模块，实现模型性能优化。](2024年03月20日/HyperLLaVA_Dynamic_Visual_and_Language_Expert_Tuning_for_Multimodal_Large_Language_Models.md)

- [IndiTag: An Online Media Bias Analysis and Annotation System Using Fine-Grained Bias Indicators](2024年03月20日/IndiTag_An_Online_Media_Bias_Analysis_and_Annotation_System_Using_Fine-Grained_Bias_Indicators.md)

    - [翻译: IndiTag 是一个创新的在线系统，通过运用细粒度的偏见指标对媒体内容进行全面深度分析并提供精准注解，以实现对媒体偏见的实时解析。](2024年03月20日/IndiTag_An_Online_Media_Bias_Analysis_and_Annotation_System_Using_Fine-Grained_Bias_Indicators.md)

- [LlamaFactory: Unified Efficient Fine-Tuning of 100+ Language Models](2024年03月20日/LlamaFactory_Unified_Efficient_Fine-Tuning_of_100+_Language_Models.md)

    - [翻译: LlamaFactory 是一个统一且高效的平台，能够对100多种语言模型进行微调处理。](2024年03月20日/LlamaFactory_Unified_Efficient_Fine-Tuning_of_100+_Language_Models.md)

- [Incentivizing News Consumption on Social Media Platforms Using Large Language Models and Realistic Bot Accounts](2024年03月20日/Incentivizing_News_Consumption_on_Social_Media_Platforms_Using_Large_Language_Models_and_Realistic_Bot_Accounts.md)

    - [翻译: 通过结合大型语言模型与拟人化机器人账户，我们探讨如何在社交媒体平台上有效激发用户对新闻内容的消费兴趣。](2024年03月20日/Incentivizing_News_Consumption_on_Social_Media_Platforms_Using_Large_Language_Models_and_Realistic_Bot_Accounts.md)

- [BadEdit: Backdooring large language models by model editing](2024年03月20日/BadEdit_Backdooring_large_language_models_by_model_editing.md)

    - [翻译: BadEdit 研究揭示了通过模型编辑技术在大型语言模型中植入后门的可能，从而引发了关于模型安全性和对抗性攻击的新思考。](2024年03月20日/BadEdit_Backdooring_large_language_models_by_model_editing.md)

- [Adaptive Ensembles of Fine-Tuned Transformers for LLM-Generated Text Detection](2024年03月20日/Adaptive_Ensembles_of_Fine-Tuned_Transformers_for_LLM-Generated_Text_Detection.md)

    - [翻译: 针对LLM生成文本检测任务，我们提出采用自适应微调的Transformer集合方法。该技术专为识别由大型语言模型（LLM）生成的文本而设计，通过动态整合多个微调后的Transformer模型，以提升检测准确性和鲁棒性。](2024年03月20日/Adaptive_Ensembles_of_Fine-Tuned_Transformers_for_LLM-Generated_Text_Detection.md)

- [Hyacinth6B: A large language model for Traditional Chinese](2024年03月20日/Hyacinth6B_A_large_language_model_for_Traditional_Chinese.md)

    - [翻译: Hyacinth6B，一款专为繁体中文打造的大型语言模型](2024年03月20日/Hyacinth6B_A_large_language_model_for_Traditional_Chinese.md)

- [Harnessing Large Language Models for Text-Rich Sequential Recommendation](2024年03月20日/Harnessing_Large_Language_Models_for_Text-Rich_Sequential_Recommendation.md)

    - [翻译: 驾驭大型语言模型之力，以赋能文本丰富的序列推荐任务](2024年03月20日/Harnessing_Large_Language_Models_for_Text-Rich_Sequential_Recommendation.md)

- [Out-of-Distribution Detection Using Peer-Class Generated by Large Language Model](2024年03月20日/Out-of-Distribution_Detection_Using_Peer-Class_Generated_by_Large_Language_Model.md)

    - [翻译: 本研究探讨利用大型语言模型生成的同类类别进行分布外数据检测的方法，通过此类生成技术来提升模型对于未曾见过的数据类型的识别与判断能力。](2024年03月20日/Out-of-Distribution_Detection_Using_Peer-Class_Generated_by_Large_Language_Model.md)

- [PuzzleVQA: Diagnosing Multimodal Reasoning Challenges of Language Models with Abstract Visual Patterns](2024年03月20日/PuzzleVQA_Diagnosing_Multimodal_Reasoning_Challenges_of_Language_Models_with_Abstract_Visual_Patterns.md)

    - [翻译: PuzzleVQA——借助抽象视觉模式揭示语言模型在处理多模态推理难题时所面临的挑战](2024年03月20日/PuzzleVQA_Diagnosing_Multimodal_Reasoning_Challenges_of_Language_Models_with_Abstract_Visual_Patterns.md)

- [LeanReasoner: Boosting Complex Logical Reasoning with Lean](2024年03月20日/LeanReasoner_Boosting_Complex_Logical_Reasoning_with_Lean.md)

    - [翻译: LeanReasoner 是一种利用 Lean 技术强化复杂逻辑推理性能的方法。](2024年03月20日/LeanReasoner_Boosting_Complex_Logical_Reasoning_with_Lean.md)

- [Mapping LLM Security Landscapes: A Comprehensive Stakeholder Risk Assessment Proposal](2024年03月20日/Mapping_LLM_Security_Landscapes_A_Comprehensive_Stakeholder_Risk_Assessment_Proposal.md)

    - [翻译: 为全面描绘LLM安全态势，我们提出了一项详尽的利益相关者风险评估方案，旨在深入剖析LLM领域的安全风险因素，并为各利益相关方提供针对性的评估参考。](2024年03月20日/Mapping_LLM_Security_Landscapes_A_Comprehensive_Stakeholder_Risk_Assessment_Proposal.md)

- [Reading Users' Minds from What They Say: An Investigation into LLM-based Empathic Mental Inference](2024年03月20日/Reading_Users'_Minds_from_What_They_Say_An_Investigation_into_LLM-based_Empathic_Mental_Inference.md)

    - [翻译: 通过用户的言语洞察其内心世界：探究基于LLM的共情性心理推理技术](2024年03月20日/Reading_Users'_Minds_from_What_They_Say_An_Investigation_into_LLM-based_Empathic_Mental_Inference.md)

- [ZigMa: Zigzag Mamba Diffusion Model](2024年03月20日/ZigMa_Zigzag_Mamba_Diffusion_Model.md)

    - [翻译: ZigMa：一种名为“蛇形曼巴”的扩散模型，该模型以其灵动曲折的特性而得名。](2024年03月20日/ZigMa_Zigzag_Mamba_Diffusion_Model.md)

- [Bridging deep learning force fields and electronic structures with a physics-informed approach](2024年03月20日/Bridging_deep_learning_force_fields_and_electronic_structures_with_a_physics-informed_approach.md)

    - [翻译: 本研究采用物理信息导向的方法，巧妙联结深度学习力场与电子结构，实现两者之间的深度融合。](2024年03月20日/Bridging_deep_learning_force_fields_and_electronic_structures_with_a_physics-informed_approach.md)

- [Multimodal Variational Autoencoder for Low-cost Cardiac Hemodynamics Instability Detection](2024年03月20日/Multimodal_Variational_Autoencoder_for_Low-cost_Cardiac_Hemodynamics_Instability_Detection.md)

    - [翻译: 针对心脏血流动力学不稳定性检测这一问题，我们提出了一种创新的多模态变分自编码器方法，旨在以低成本实现高效准确的检测。该技术旨在整合多种模态的数据信息，以便更精准地识别心脏血流动力学中的不稳定状况。](2024年03月20日/Multimodal_Variational_Autoencoder_for_Low-cost_Cardiac_Hemodynamics_Instability_Detection.md)

- [What if...?: Counterfactual Inception to Mitigate Hallucination Effects in Large Multimodal Models](2024年03月20日/What_if..._Counterfactual_Inception_to_Mitigate_Hallucination_Effects_in_Large_Multimodal_Models.md)

    - [翻译: 试想一下，如果我们采用“反事实启动”策略来缓解大型多模态模型中出现的幻觉效应问题，那将会如何呢？本研究探讨了在大型多模态模型中应用“Counterfactual Inception”技术，以有效减轻其产生的幻觉效应。](2024年03月20日/What_if..._Counterfactual_Inception_to_Mitigate_Hallucination_Effects_in_Large_Multimodal_Models.md)

- [Benchmarking Chinese Commonsense Reasoning of LLMs: From Chinese-Specifics to Reasoning-Memorization Correlations](2024年03月20日/Benchmarking_Chinese_Commonsense_Reasoning_of_LLMs_From_Chinese-Specifics_to_Reasoning-Memorization_Correlations.md)

    - [翻译: 本研究致力于对 LLM 进行中文常识推理基准评测，不仅关注模型处理中文特有情境的能力，还深入探究推理与记忆之间的内在联系。](2024年03月20日/Benchmarking_Chinese_Commonsense_Reasoning_of_LLMs_From_Chinese-Specifics_to_Reasoning-Memorization_Correlations.md)

- [Can ChatGPT Detect DeepFakes? A Study of Using Multimodal Large Language Models for Media Forensics](2024年03月20日/Can_ChatGPT_Detect_DeepFakes_A_Study_of_Using_Multimodal_Large_Language_Models_for_Media_Forensics.md)

    - [翻译: ChatGPT 对抗 DeepFakes 是否有招？本研究探讨了利用多模态大型语言模型在媒体取证领域的应用潜力，探究其能否有效识别 DeepFakes。](2024年03月20日/Can_ChatGPT_Detect_DeepFakes_A_Study_of_Using_Multimodal_Large_Language_Models_for_Media_Forensics.md)

- [Empowering Personalized Learning through a Conversation-based Tutoring System with Student Modeling](2024年03月20日/Empowering_Personalized_Learning_through_a_Conversation-based_Tutoring_System_with_Student_Modeling.md)

    - [翻译: 借助具备学生建模能力的对话式辅导系统，推动个性化学习的发展与深入实施](2024年03月20日/Empowering_Personalized_Learning_through_a_Conversation-based_Tutoring_System_with_Student_Modeling.md)

- [PE-GPT: A Physics-Informed Interactive Large Language Model for Power Converter Modulation Design](2024年03月20日/PE-GPT_A_Physics-Informed_Interactive_Large_Language_Model_for_Power_Converter_Modulation_Design.md)

    - [翻译: PE-GPT 是一款融入物理信息的互动型大型语言模型，专为电力转换器调制设计而研发。](2024年03月20日/PE-GPT_A_Physics-Informed_Interactive_Large_Language_Model_for_Power_Converter_Modulation_Design.md)

- [Semantics from Space: Satellite-Guided Thermal Semantic Segmentation Annotation for Aerial Field Robots](2024年03月20日/Semantics_from_Space_Satellite-Guided_Thermal_Semantic_Segmentation_Annotation_for_Aerial_Field_Robots.md)

    - [翻译: 利用卫星导航技术为空中田间机器人提供热力语义分割注解，实现“从太空到语义”的创新标注方法。](2024年03月20日/Semantics_from_Space_Satellite-Guided_Thermal_Semantic_Segmentation_Annotation_for_Aerial_Field_Robots.md)

- [Ax-to-Grind Urdu: Benchmark Dataset for Urdu Fake News Detection](2024年03月20日/Ax-to-Grind_Urdu_Benchmark_Dataset_for_Urdu_Fake_News_Detection.md)

    - [翻译: Ax-to-Grind Urdu 是一个专门针对乌尔都语假新闻检测的基准数据集，旨在为该领域的研究提供标准参考和评估依据。](2024年03月20日/Ax-to-Grind_Urdu_Benchmark_Dataset_for_Urdu_Fake_News_Detection.md)

- [A New Massive Multilingual Dataset for High-Performance Language Technologies](2024年03月20日/A_New_Massive_Multilingual_Dataset_for_High-Performance_Language_Technologies.md)

    - [翻译: 我们推出了一项新的大型多语种数据集，旨在赋能和提升高性能语言技术的表现。](2024年03月20日/A_New_Massive_Multilingual_Dataset_for_High-Performance_Language_Technologies.md)

- [Evaluating Unsupervised Dimensionality Reduction Methods for Pretrained Sentence Embeddings](2024年03月20日/Evaluating_Unsupervised_Dimensionality_Reduction_Methods_for_Pretrained_Sentence_Embeddings.md)

    - [翻译: 本研究致力于评估预训练句子嵌入在无监督维度降低方法中的表现，旨在探索这些方法对提升句子表示效果的影响。](2024年03月20日/Evaluating_Unsupervised_Dimensionality_Reduction_Methods_for_Pretrained_Sentence_Embeddings.md)

- [Reducing Large Language Model Bias with Emphasis on 'Restricted Industries': Automated Dataset Augmentation and Prejudice Quantification](2024年03月20日/Reducing_Large_Language_Model_Bias_with_Emphasis_on_'Restricted_Industries'_Automated_Dataset_Augmentation_and_Prejudice_Quantification.md)

    - [翻译: 针对“受限行业”，我们采用自动化数据集增强技术并结合偏见量化手段，以期有效降低大型语言模型中的偏差问题。](2024年03月20日/Reducing_Large_Language_Model_Bias_with_Emphasis_on_'Restricted_Industries'_Automated_Dataset_Augmentation_and_Prejudice_Quantification.md)

- [Train & Constrain: Phonologically Informed Tongue-Twister Generation from Topics and Paraphrases](2024年03月20日/Train_&_Constrain_Phonologically_Informed_Tongue-Twister_Generation_from_Topics_and_Paraphrases.md)

    - [翻译: 通过“训练与约束”方法，我们致力于从主题及释义出发，结合语音学原理，智能生成富有挑战性的绕口令。](2024年03月20日/Train_&_Constrain_Phonologically_Informed_Tongue-Twister_Generation_from_Topics_and_Paraphrases.md)

- [CoMo: Controllable Motion Generation through Language Guided Pose Code Editing](2024年03月20日/CoMo_Controllable_Motion_Generation_through_Language_Guided_Pose_Code_Editing.md)

    - [翻译: CoMo 是一种新颖的方法，它借助于语言指导的姿势码编辑技术，实现了对运动生成过程的可控性。简言之，CoMo 通过语言指令精细编辑姿势码，从而在运动生成中达到预期和可控的效果。](2024年03月20日/CoMo_Controllable_Motion_Generation_through_Language_Guided_Pose_Code_Editing.md)

- [Protected group bias and stereotypes in Large Language Models](2024年03月20日/Protected_group_bias_and_stereotypes_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型（LLM）中，受保护群体的偏见与刻板印象问题日益凸显。](2024年03月20日/Protected_group_bias_and_stereotypes_in_Large_Language_Models.md)

- [Automated Extraction and Maturity Analysis of Open Source Clinical Informatics Repositories from Scientific Literature](2024年03月20日/Automated_Extraction_and_Maturity_Analysis_of_Open_Source_Clinical_Informatics_Repositories_from_Scientific_Literature.md)

    - [翻译: 本研究致力于自动从科学文献中挖掘开源临床信息学仓库，并对其成熟度进行深入分析，以揭示其在医疗信息领域的应用与发展状况。](2024年03月20日/Automated_Extraction_and_Maturity_Analysis_of_Open_Source_Clinical_Informatics_Repositories_from_Scientific_Literature.md)

- [Defending Against Indirect Prompt Injection Attacks With Spotlighting](2024年03月20日/Defending_Against_Indirect_Prompt_Injection_Attacks_With_Spotlighting.md)

    - [翻译: 运用“聚光灯”策略防御间接提示注入攻击，以提升模型安全性](2024年03月20日/Defending_Against_Indirect_Prompt_Injection_Attacks_With_Spotlighting.md)

- [Large language models can help boost food production, but be mindful of their risks](2024年03月20日/Large_language_models_can_help_boost_food_production,_but_be_mindful_of_their_risks.md)

    - [翻译: 大型语言模型有望助力食品生产增长，但在应用时务必留意其带来的风险因素。](2024年03月20日/Large_language_models_can_help_boost_food_production,_but_be_mindful_of_their_risks.md)

- [Vi-Mistral-X: Building a Vietnamese Language Model with Advanced Continual Pre-training](2024年03月20日/Vi-Mistral-X_Building_a_Vietnamese_Language_Model_with_Advanced_Continual_Pre-training.md)

    - [翻译: Vi-Mistral-X项目致力于构建一个经过高级持续预训练技术优化的越南语语言模型，以提升其性能和适用性。进一步精炼后的](2024年03月20日/Vi-Mistral-X_Building_a_Vietnamese_Language_Model_with_Advanced_Continual_Pre-training.md)

- [Dermacen Analytica: A Novel Methodology Integrating Multi-Modal Large Language Models with Machine Learning in tele-dermatology](2024年03月21日/Dermacen_Analytica_A_Novel_Methodology_Integrating_Multi-Modal_Large_Language_Models_with_Machine_Learning_in_tele-dermatology.md)

    - [翻译: Dermacen Analytica 是一种创新的方法，它巧妙地融合了多模态大型语言模型和机器学习技术，为远程皮肤病诊疗提供有力支持。](2024年03月21日/Dermacen_Analytica_A_Novel_Methodology_Integrating_Multi-Modal_Large_Language_Models_with_Machine_Learning_in_tele-dermatology.md)

- [PeerGPT: Probing the Roles of LLM-based Peer Agents as Team Moderators and Participants in Children's Collaborative Learning](2024年03月21日/PeerGPT_Probing_the_Roles_of_LLM-based_Peer_Agents_as_Team_Moderators_and_Participants_in_Children's_Collaborative_Learning.md)

    - [翻译: PeerGPT项目专注于研究基于大型语言模型（LLM）的同伴智能体在儿童协作学习中的角色，探索其作为团队调解者和积极参与者对儿童合作学习的影响。](2024年03月21日/PeerGPT_Probing_the_Roles_of_LLM-based_Peer_Agents_as_Team_Moderators_and_Participants_in_Children's_Collaborative_Learning.md)

- [Improving the Robustness of Large Language Models via Consistency Alignment](2024年03月21日/Improving_the_Robustness_of_Large_Language_Models_via_Consistency_Alignment.md)

    - [翻译: 为提升大型语言模型（LLM）的鲁棒性，本研究提出了一种基于一致性对齐的方法。这种方法致力于调整LLM，使其在面临各种输入和情境时表现更为稳定和一致，从而增强模型对于复杂多变场景的适应能力和抗干扰性能。](2024年03月21日/Improving_the_Robustness_of_Large_Language_Models_via_Consistency_Alignment.md)

- [Automatic Annotation of Grammaticality in Child-Caregiver Conversations](2024年03月21日/Automatic_Annotation_of_Grammaticality_in_Child-Caregiver_Conversations.md)

    - [翻译: 本研究致力于实现儿童与照顾者交谈内容的自动语法标注，旨在探索并提升对儿童语言习得过程中语法正确性的自动化识别能力。](2024年03月21日/Automatic_Annotation_of_Grammaticality_in_Child-Caregiver_Conversations.md)

- [MMIDR: Teaching Large Language Model to Interpret Multimodal Misinformation via Knowledge Distillation](2024年03月21日/MMIDR_Teaching_Large_Language_Model_to_Interpret_Multimodal_Misinformation_via_Knowledge_Distillation.md)

    - [翻译: MMIDR 是一种创新方法，通过知识蒸馏技术，教导大型语言模型理解和解析多模态误导信息。](2024年03月21日/MMIDR_Teaching_Large_Language_Model_to_Interpret_Multimodal_Misinformation_via_Knowledge_Distillation.md)

- [Leveraging Large Language Model-based Room-Object Relationships Knowledge for Enhancing Multimodal-Input Object Goal Navigation](2024年03月21日/Leveraging_Large_Language_Model-based_Room-Object_Relationships_Knowledge_for_Enhancing_Multimodal-Input_Object_Goal_Navigation.md)

    - [翻译: 通过汲取大型语言模型中蕴含的房间与物体间关系知识，我们致力于提升多模态输入下的目标对象导航能力。](2024年03月21日/Leveraging_Large_Language_Model-based_Room-Object_Relationships_Knowledge_for_Enhancing_Multimodal-Input_Object_Goal_Navigation.md)

- [Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond](2024年03月21日/Deep_Learning_for_Trajectory_Data_Management_and_Mining_A_Survey_and_Beyond.md)

    - [翻译: 针对轨迹数据管理与挖掘，本研究进行了一项深度学习技术的全面综述，并探讨了该领域的前沿拓展。](2024年03月21日/Deep_Learning_for_Trajectory_Data_Management_and_Mining_A_Survey_and_Beyond.md)

- [Empowering Segmentation Ability to Multi-modal Large Language Models](2024年03月21日/Empowering_Segmentation_Ability_to_Multi-modal_Large_Language_Models.md)

    - [翻译: 赋予多模态大型语言模型强大的分割技能](2024年03月21日/Empowering_Segmentation_Ability_to_Multi-modal_Large_Language_Models.md)

- [C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion](2024年03月21日/C-TPT_Calibrated_Test-Time_Prompt_Tuning_for_Vision-Language_Models_via_Text_Feature_Dispersion.md)

    - [翻译: C-TPT 是一种新颖的方法，它利用文本特征分散技术，在视觉-语言模型的测试阶段进行精确校准的提示调优。](2024年03月21日/C-TPT_Calibrated_Test-Time_Prompt_Tuning_for_Vision-Language_Models_via_Text_Feature_Dispersion.md)

- [From Handcrafted Features to LLMs: A Brief Survey for Machine Translation Quality Estimation](2024年03月21日/From_Handcrafted_Features_to_LLMs_A_Brief_Survey_for_Machine_Translation_Quality_Estimation.md)

    - [翻译: 从精心设计的特征到大型语言模型（LLMs），本篇论文对机器翻译质量评估进行了一次精炼概述。](2024年03月21日/From_Handcrafted_Features_to_LLMs_A_Brief_Survey_for_Machine_Translation_Quality_Estimation.md)

- [DP-RDM: Adapting Diffusion Models to Private Domains Without Fine-Tuning](2024年03月21日/DP-RDM_Adapting_Diffusion_Models_to_Private_Domains_Without_Fine-Tuning.md)

    - [翻译: DP-RDM 方法能够在不进行微调的前提下，成功地将扩散模型应用于专属领域。](2024年03月21日/DP-RDM_Adapting_Diffusion_Models_to_Private_Domains_Without_Fine-Tuning.md)

- [FIT-RAG: Black-Box RAG with Factual Information and Token Reduction](2024年03月21日/FIT-RAG_Black-Box_RAG_with_Factual_Information_and_Token_Reduction.md)

    - [翻译: FIT-RAG是一种改进型黑盒RAG模型，它集成了事实信息并减少了令牌数量，以提升性能。](2024年03月21日/FIT-RAG_Black-Box_RAG_with_Factual_Information_and_Token_Reduction.md)

- [Context Quality Matters in Training Fusion-in-Decoder for Extractive Open-Domain Question Answering](2024年03月21日/Context_Quality_Matters_in_Training_Fusion-in-Decoder_for_Extractive_Open-Domain_Question_Answering.md)

    - [翻译: 对于提取式开放领域问题回答任务中解码器融合技术的训练，上下文质量扮演着举足轻重的角色。](2024年03月21日/Context_Quality_Matters_in_Training_Fusion-in-Decoder_for_Extractive_Open-Domain_Question_Answering.md)

- [ERD: A Framework for Improving LLM Reasoning for Cognitive Distortion Classification](2024年03月21日/ERD_A_Framework_for_Improving_LLM_Reasoning_for_Cognitive_Distortion_Classification.md)

    - [翻译: ERD 框架：旨在提升 LLM 对认知扭曲分类任务推理性能的新方案](2024年03月21日/ERD_A_Framework_for_Improving_LLM_Reasoning_for_Cognitive_Distortion_Classification.md)

- [Cobra: Extending Mamba to Multi-Modal Large Language Model for Efficient Inference](2024年03月21日/Cobra_Extending_Mamba_to_Multi-Modal_Large_Language_Model_for_Efficient_Inference.md)

    - [翻译: Cobra 是对 Mamba 的扩展，旨在构建一个适用于多模态场景的大型语言模型，并致力于提高其推理效率。](2024年03月21日/Cobra_Extending_Mamba_to_Multi-Modal_Large_Language_Model_for_Efficient_Inference.md)

- [A Multimodal Approach to Device-Directed Speech Detection with Large Language Models](2024年03月21日/A_Multimodal_Approach_to_Device-Directed_Speech_Detection_with_Large_Language_Models.md)

    - [翻译: 我们提出一种创新的多模态方法，结合大型语言模型以实现对设备指向性语音的精准检测。](2024年03月21日/A_Multimodal_Approach_to_Device-Directed_Speech_Detection_with_Large_Language_Models.md)

- [LayoutLLM: Large Language Model Instruction Tuning for Visually Rich Document Understanding](2024年03月21日/LayoutLLM_Large_Language_Model_Instruction_Tuning_for_Visually_Rich_Document_Understanding.md)

    - [翻译: LayoutLLM 是一种为提升对富含视觉元素文档理解能力而设计的大型语言模型指令调优方案。](2024年03月21日/LayoutLLM_Large_Language_Model_Instruction_Tuning_for_Visually_Rich_Document_Understanding.md)

- [MathVerse: Does Your Multi-modal LLM Truly See the Diagrams in Visual Math Problems?](2024年03月21日/MathVerse_Does_Your_Multi-modal_LLM_Truly_See_the_Diagrams_in_Visual_Math_Problems.md)

    - [翻译: MathVerse：探究多模态LLM在解决视觉数学问题时，是否真能洞悉其中的图表信息。](2024年03月21日/MathVerse_Does_Your_Multi-modal_LLM_Truly_See_the_Diagrams_in_Visual_Math_Problems.md)

- [Parameter-Efficient Fine-Tuning for Large Models: A Comprehensive Survey](2024年03月21日/Parameter-Efficient_Fine-Tuning_for_Large_Models_A_Comprehensive_Survey.md)

    - [翻译: 全面探讨大型模型参数高效微调技术](2024年03月21日/Parameter-Efficient_Fine-Tuning_for_Large_Models_A_Comprehensive_Survey.md)

- [MyVLM: Personalizing VLMs for User-Specific Queries](2024年03月21日/MyVLM_Personalizing_VLMs_for_User-Specific_Queries.md)

    - [翻译: MyVLM：针对个性化的用户查询，定制视觉语言模型](2024年03月21日/MyVLM_Personalizing_VLMs_for_User-Specific_Queries.md)

- [PSALM: Pixelwise SegmentAtion with Large Multi-Modal Model](2024年03月21日/PSALM_Pixelwise_SegmentAtion_with_Large_Multi-Modal_Model.md)

    - [翻译: PSALM，一项创新技术，利用强大的大型多模态模型实现像素级别的精确分割。](2024年03月21日/PSALM_Pixelwise_SegmentAtion_with_Large_Multi-Modal_Model.md)

- [Large Language Models for Multi-Choice Question Classification of Medical Subjects](2024年03月21日/Large_Language_Models_for_Multi-Choice_Question_Classification_of_Medical_Subjects.md)

    - [翻译: 针对医学主题的多选题分类问题，本研究探讨了大型语言模型的有效应用。](2024年03月21日/Large_Language_Models_for_Multi-Choice_Question_Classification_of_Medical_Subjects.md)

- [RAmBLA: A Framework for Evaluating the Reliability of LLMs as Assistants in the Biomedical Domain](2024年03月21日/RAmBLA_A_Framework_for_Evaluating_the_Reliability_of_LLMs_as_Assistants_in_the_Biomedical_Domain.md)

    - [翻译: RAmBLA 是一个专注于评估大型语言模型（LLM）在生物医学领域作为助手时可靠性的评估框架。](2024年03月21日/RAmBLA_A_Framework_for_Evaluating_the_Reliability_of_LLMs_as_Assistants_in_the_Biomedical_Domain.md)

- [A Chain-of-Thought Prompting Approach with LLMs for Evaluating Students' Formative Assessment Responses in Science](2024年03月21日/A_Chain-of-Thought_Prompting_Approach_with_LLMs_for_Evaluating_Students'_Formative_Assessment_Responses_in_Science.md)

    - [翻译: 我们提出了一种运用LLMs实现的链式思考提示法，专门针对科学学科中学生形成性评价反馈的精准评估。](2024年03月21日/A_Chain-of-Thought_Prompting_Approach_with_LLMs_for_Evaluating_Students'_Formative_Assessment_Responses_in_Science.md)

- [The Era of Semantic Decoding](2024年03月21日/The_Era_of_Semantic_Decoding.md)

    - [翻译: 步入语义解码时代](2024年03月21日/The_Era_of_Semantic_Decoding.md)

- [EDT: Improving Large Language Models' Generation by Entropy-based Dynamic Temperature Sampling](2024年03月21日/EDT_Improving_Large_Language_Models'_Generation_by_Entropy-based_Dynamic_Temperature_Sampling.md)

    - [翻译: EDT 方法利用熵为基础的动态温度采样技术，有效优化大型语言模型在文本生成任务上的表现。](2024年03月21日/EDT_Improving_Large_Language_Models'_Generation_by_Entropy-based_Dynamic_Temperature_Sampling.md)

- [The Ethics of ChatGPT in Medicine and Healthcare: A Systematic Review on Large Language Models (LLMs)](2024年03月21日/The_Ethics_of_ChatGPT_in_Medicine_and_Healthcare_A_Systematic_Review_on_Large_Language_Models_(LLMs).md)

    - [翻译: 本研究通过系统性回顾，探讨了 ChatGPT 在医学和健康照护领域应用中所涉及的伦理议题，尤其聚焦于大型语言模型 LLMS。](2024年03月21日/The_Ethics_of_ChatGPT_in_Medicine_and_Healthcare_A_Systematic_Review_on_Large_Language_Models_(LLMs).md)

- [Detoxifying Large Language Models via Knowledge Editing](2024年03月21日/Detoxifying_Large_Language_Models_via_Knowledge_Editing.md)

    - [翻译: 运用知识编辑技术净化大型语言模型，旨在消除潜在有害内容，提升模型输出的安全性和准确性。](2024年03月21日/Detoxifying_Large_Language_Models_via_Knowledge_Editing.md)

- [ChatGPT Alternative Solutions: Large Language Models Survey](2024年03月21日/ChatGPT_Alternative_Solutions_Large_Language_Models_Survey.md)

    - [翻译: ChatGPT 的替代方案探究：大型语言模型综览](2024年03月21日/ChatGPT_Alternative_Solutions_Large_Language_Models_Survey.md)

- [Towards Single-System Illusion in Software-Defined Vehicles -- Automated, AI-Powered Workflow](2024年03月21日/Towards_Single-System_Illusion_in_Software-Defined_Vehicles_--_Automated,_AI-Powered_Workflow.md)

    - [翻译: 致力于实现软件定义车辆的单体系统化体验，借助自动化与人工智能赋能工作流程，旨在营造一体化的智能操作环境。](2024年03月21日/Towards_Single-System_Illusion_in_Software-Defined_Vehicles_--_Automated,_AI-Powered_Workflow.md)

- [gTBLS: Generating Tables from Text by Conditional Question Answering](2024年03月21日/gTBLS_Generating_Tables_from_Text_by_Conditional_Question_Answering.md)

    - [翻译: gTBLS 是一种利用条件问题回答技术，从文本中自动生成表格的方法。](2024年03月21日/gTBLS_Generating_Tables_from_Text_by_Conditional_Question_Answering.md)

- [Locating and Mitigating Gender Bias in Large Language Models](2024年03月21日/Locating_and_Mitigating_Gender_Bias_in_Large_Language_Models.md)

    - [翻译: 本研究致力于在大型语言模型内部定位并有效减轻性别偏见问题。](2024年03月21日/Locating_and_Mitigating_Gender_Bias_in_Large_Language_Models.md)

- [Adaptive-RAG: Learning to Adapt Retrieval-Augmented Large Language Models through Question Complexity](2024年03月21日/Adaptive-RAG_Learning_to_Adapt_Retrieval-Augmented_Large_Language_Models_through_Question_Complexity.md)

    - [翻译: Adaptive-RAG，一种能够通过识别问题复杂度来自适应调整的检索增强型大型语言模型学习技术。](2024年03月21日/Adaptive-RAG_Learning_to_Adapt_Retrieval-Augmented_Large_Language_Models_through_Question_Complexity.md)

- [Pensieve: Retrospect-then-Compare Mitigates Visual Hallucination](2024年03月21日/Pensieve_Retrospect-then-Compare_Mitigates_Visual_Hallucination.md)

    - [翻译: Pensieve 研究提出“先回顾后比较”的策略，有效缓解了视觉幻觉问题。](2024年03月21日/Pensieve_Retrospect-then-Compare_Mitigates_Visual_Hallucination.md)

- [Building Accurate Translation-Tailored LLMs with Language Aware Instruction Tuning](2024年03月21日/Building_Accurate_Translation-Tailored_LLMs_with_Language_Aware_Instruction_Tuning.md)

    - [翻译: 运用语言感知指令微调技术，我们致力于构建针对翻译任务特别优化、精度更高的LLMs。步骤2改进后：通过“语言感知指令调优”技术，我们专注于打造针对翻译任务精准定制、性能优越的大型语言模型（LLMs）。](2024年03月21日/Building_Accurate_Translation-Tailored_LLMs_with_Language_Aware_Instruction_Tuning.md)

- [Regularized Adaptive Momentum Dual Averaging with an Efficient Inexact Subproblem Solver for Training Structured Neural Network](2024年03月21日/Regularized_Adaptive_Momentum_Dual_Averaging_with_an_Efficient_Inexact_Subproblem_Solver_for_Training_Structured_Neural_Network.md)

    - [翻译: 为优化结构化神经网络训练，我们提出了一种正则化的自适应动量双重平均算法，并配备了高效解决近似子问题的求解器。](2024年03月21日/Regularized_Adaptive_Momentum_Dual_Averaging_with_an_Efficient_Inexact_Subproblem_Solver_for_Training_Structured_Neural_Network.md)

- [From Large to Tiny: Distilling and Refining Mathematical Expertise for Math Word Problems with Weakly Supervision](2024年03月21日/From_Large_to_Tiny_Distilling_and_Refining_Mathematical_Expertise_for_Math_Word_Problems_with_Weakly_Supervision.md)

    - [翻译: 在弱监督下，我们将大型模型中蕴含的数学专业知识浓缩并精细化，应用于解决数学问题，实现从小型模型中高效提取数学专长解决数学词题。](2024年03月21日/From_Large_to_Tiny_Distilling_and_Refining_Mathematical_Expertise_for_Math_Word_Problems_with_Weakly_Supervision.md)

- [On the Conversational Persuasiveness of Large Language Models: A Randomized Controlled Trial](2024年03月21日/On_the_Conversational_Persuasiveness_of_Large_Language_Models_A_Randomized_Controlled_Trial.md)

    - [翻译: 针对大型语言模型（LLM）对话中的说服力，本研究采用随机对照试验方法进行深入探究。](2024年03月21日/On_the_Conversational_Persuasiveness_of_Large_Language_Models_A_Randomized_Controlled_Trial.md)

- [WikiFactDiff: A Large, Realistic, and Temporally Adaptable Dataset for Atomic Factual Knowledge Update in Causal Language Models](2024年03月21日/WikiFactDiff_A_Large,_Realistic,_and_Temporally_Adaptable_Dataset_for_Atomic_Factual_Knowledge_Update_in_Causal_Language_Models.md)

    - [翻译: WikiFactDiff 是专为探究因果语言模型中原子事实知识更新而设计的大型、真实且随时间动态适应的数据集。](2024年03月21日/WikiFactDiff_A_Large,_Realistic,_and_Temporally_Adaptable_Dataset_for_Atomic_Factual_Knowledge_Update_in_Causal_Language_Models.md)

- [Less but Better: Enabling Generalized Zero-shot Learning Towards Unseen Domains by Intrinsic Learning from Redundant LLM Semantics](2024年03月21日/Less_but_Better_Enabling_Generalized_Zero-shot_Learning_Towards_Unseen_Domains_by_Intrinsic_Learning_from_Redundant_LLM_Semantics.md)

    - [翻译: 精简而高效：从冗余的 LLM 语义中提取本质，赋能针对未知领域的泛化零样本学习](2024年03月21日/Less_but_Better_Enabling_Generalized_Zero-shot_Learning_Towards_Unseen_Domains_by_Intrinsic_Learning_from_Redundant_LLM_Semantics.md)

- [Exploring the Potential of Large Language Models in Graph Generation](2024年03月21日/Exploring_the_Potential_of_Large_Language_Models_in_Graph_Generation.md)

    - [翻译: 本研究致力于揭示大型语言模型在图生成领域的可能性，深入探究其在构建和生成图形结构中的能力。](2024年03月21日/Exploring_the_Potential_of_Large_Language_Models_in_Graph_Generation.md)

- [$\nabla τ$: Gradient-based and Task-Agnostic machine Unlearning](2024年03月21日/$\nabla_τ$_Gradient-based_and_Task-Agnostic_machine_Unlearning.md)

    - [翻译: $\nabla τ$ 代表一种基于梯度且与任务无关的机器遗忘方法，该技术旨在实现对机器学习模型中已学内容的有效擦除。](2024年03月21日/$\nabla_τ$_Gradient-based_and_Task-Agnostic_machine_Unlearning.md)

- [ChainLM: Empowering Large Language Models with Improved Chain-of-Thought Prompting](2024年03月21日/ChainLM_Empowering_Large_Language_Models_with_Improved_Chain-of-Thought_Prompting.md)

    - [翻译: ChainLM 引入了改良的链式思维提示法，以提升大型语言模型的表现力。这项技术致力于优化大型语言模型在面对复杂任务时的推理能力，通过加强其链式思考过程的引导，实现更高效、精准的自然语言处理。](2024年03月21日/ChainLM_Empowering_Large_Language_Models_with_Improved_Chain-of-Thought_Prompting.md)

- [From Perils to Possibilities: Understanding how Human (and AI) Biases affect Online Fora](2024年03月21日/From_Perils_to_Possibilities_Understanding_how_Human_(and_AI)_Biases_affect_Online_Fora.md)

    - [翻译: 洞悉偏见的力量：探讨人类与AI的偏见如何塑造在线论坛的可能性与挑战](2024年03月21日/From_Perils_to_Possibilities_Understanding_how_Human_(and_AI)_Biases_affect_Online_Fora.md)

- [Large Language Models for Blockchain Security: A Systematic Literature Review](2024年03月21日/Large_Language_Models_for_Blockchain_Security_A_Systematic_Literature_Review.md)

    - [翻译: 本研究对应用于区块链安全领域的大型语言模型进行了深入的系统性文献回顾。](2024年03月21日/Large_Language_Models_for_Blockchain_Security_A_Systematic_Literature_Review.md)

- [Multi-role Consensus through LLMs Discussions for Vulnerability Detection](2024年03月21日/Multi-role_Consensus_through_LLMs_Discussions_for_Vulnerability_Detection.md)

    - [翻译: 为提升漏洞检测能力，我们提出利用 LLMs 进行多角色讨论并达成共识的方法。](2024年03月21日/Multi-role_Consensus_through_LLMs_Discussions_for_Vulnerability_Detection.md)

- [LLM-based Extraction of Contradictions from Patents](2024年03月21日/LLM-based_Extraction_of_Contradictions_from_Patents.md)

    - [翻译: 本研究致力于运用大型语言模型（LLM）技术从专利文本中高效抽取矛盾信息，以揭示潜在的问题与矛盾点。](2024年03月21日/LLM-based_Extraction_of_Contradictions_from_Patents.md)

- [K-Act2Emo: Korean Commonsense Knowledge Graph for Indirect Emotional Expression](2024年03月21日/K-Act2Emo_Korean_Commonsense_Knowledge_Graph_for_Indirect_Emotional_Expression.md)

    - [翻译: K-Act2Emo 是一款专为解析间接情绪表达而构建的韩语文档常识知识图谱。它通过整合与情绪表达相关的各类情境行为，为理解和推断复杂情感线索提供了有力支持。](2024年03月21日/K-Act2Emo_Korean_Commonsense_Knowledge_Graph_for_Indirect_Emotional_Expression.md)

- [Attention-Driven Reasoning: Unlocking the Potential of Large Language Models](2024年03月21日/Attention-Driven_Reasoning_Unlocking_the_Potential_of_Large_Language_Models.md)

    - [翻译: 聚焦注意力推理：发掘大型语言模型的潜在力量](2024年03月21日/Attention-Driven_Reasoning_Unlocking_the_Potential_of_Large_Language_Models.md)

- [Investigating Bias in LLM-Based Bias Detection: Disparities between LLMs and Human Perception](2024年03月21日/Investigating_Bias_in_LLM-Based_Bias_Detection_Disparities_between_LLMs_and_Human_Perception.md)

    - [翻译: 探究LLM在偏见检测中的潜在偏差问题，对比分析LLM与人类感知之间的显著差异。（注：此处根据上下文及语境，将“Disparities”翻译为“差异”，而非严格意义上的“不平等”。若需强调两者间的不平等性，可将“差异”改为“不平等现象”。）](2024年03月21日/Investigating_Bias_in_LLM-Based_Bias_Detection_Disparities_between_LLMs_and_Human_Perception.md)

- [AutoRE: Document-Level Relation Extraction with Large Language Models](2024年03月21日/AutoRE_Document-Level_Relation_Extraction_with_Large_Language_Models.md)

    - [翻译: AutoRE 是一种运用大型语言模型实现的文档级关系抽取技术。](2024年03月21日/AutoRE_Document-Level_Relation_Extraction_with_Large_Language_Models.md)

- [WeatherProof: Leveraging Language Guidance for Semantic Segmentation in Adverse Weather](2024年03月21日/WeatherProof_Leveraging_Language_Guidance_for_Semantic_Segmentation_in_Adverse_Weather.md)

    - [翻译: WeatherProof——借力语言引导优化恶劣天气下的语义分割能力](2024年03月21日/WeatherProof_Leveraging_Language_Guidance_for_Semantic_Segmentation_in_Adverse_Weather.md)

- [VidLA: Video-Language Alignment at Scale](2024年03月21日/VidLA_Video-Language_Alignment_at_Scale.md)

    - [翻译: VidLA 是一种针对大规模视频与语言深度对齐的技术。](2024年03月21日/VidLA_Video-Language_Alignment_at_Scale.md)

- [Comparing Plausibility Estimates in Base and Instruction-Tuned Large Language Models](2024年03月21日/Comparing_Plausibility_Estimates_in_Base_and_Instruction-Tuned_Large_Language_Models.md)

    - [翻译: 本研究对比了未经特殊调优的基础大型语言模型与经过指令调优后的模型，在评估语句可信度上的差异。](2024年03月21日/Comparing_Plausibility_Estimates_in_Base_and_Instruction-Tuned_Large_Language_Models.md)

- [The opportunities and risks of large language models in mental health](2024年03月21日/The_opportunities_and_risks_of_large_language_models_in_mental_health.md)

    - [翻译: 大型语言模型（LLMs）在心理健康领域既带来了诸多机遇，也潜藏着一定风险。这项研究探讨了LLMs在该领域中的应用可能性以及其可能带来的挑战与隐患。](2024年03月21日/The_opportunities_and_risks_of_large_language_models_in_mental_health.md)

- [Assessing the Utility of Large Language Models for Phenotype-Driven Gene Prioritization in Rare Genetic Disorder Diagnosis](2024年03月21日/Assessing_the_Utility_of_Large_Language_Models_for_Phenotype-Driven_Gene_Prioritization_in_Rare_Genetic_Disorder_Diagnosis.md)

    - [翻译: 探究大型语言模型在罕见遗传病诊断中对基于表型指导基因优先级排序的实际应用价值进一步优化后：在罕见遗传疾病诊断过程中，本研究旨在评估大型语言模型在基于表型驱动基因优先级排序中的实用性和有效性。](2024年03月21日/Assessing_the_Utility_of_Large_Language_Models_for_Phenotype-Driven_Gene_Prioritization_in_Rare_Genetic_Disorder_Diagnosis.md)

- [VURF: A General-purpose Reasoning and Self-refinement Framework for Video Understanding](2024年03月21日/VURF_A_General-purpose_Reasoning_and_Self-refinement_Framework_for_Video_Understanding.md)

    - [翻译: VURF 是一个广泛适用于视频理解的推理与自我优化框架，致力于深入理解和解析视频内容。步骤2改进后的翻译：VURF 是一款通用型视频理解推理与自适应优化框架，旨在高效地处理并深化对各类视频内容的理解与解析。](2024年03月21日/VURF_A_General-purpose_Reasoning_and_Self-refinement_Framework_for_Video_Understanding.md)

- [A Survey of Neural Code Intelligence: Paradigms, Advances and Beyond](2024年03月21日/A_Survey_of_Neural_Code_Intelligence_Paradigms,_Advances_and_Beyond.md)

    - [翻译: 本文对神经代码智能进行了一次全面综述，探讨了其核心范式、最新进展以及未来可能超越的范围。](2024年03月21日/A_Survey_of_Neural_Code_Intelligence_Paradigms,_Advances_and_Beyond.md)

- [Open Knowledge Base Canonicalization with Multi-task Learning](2024年03月21日/Open_Knowledge_Base_Canonicalization_with_Multi-task_Learning.md)

    - [翻译: 运用多任务学习方法进行开放知识库的标准化处理](2024年03月21日/Open_Knowledge_Base_Canonicalization_with_Multi-task_Learning.md)

- [Privacy-Preserving End-to-End Spoken Language Understanding](2024年03月21日/Privacy-Preserving_End-to-End_Spoken_Language_Understanding.md)

    - [翻译: 面向隐私保护的端到端口语理解方案](2024年03月21日/Privacy-Preserving_End-to-End_Spoken_Language_Understanding.md)

- [Open Source Conversational LLMs do not know most Spanish words](2024年03月21日/Open_Source_Conversational_LLMs_do_not_know_most_Spanish_words.md)

    - [翻译: 开源对话型LLM对大多数西班牙语词汇并不熟悉](2024年03月21日/Open_Source_Conversational_LLMs_do_not_know_most_Spanish_words.md)

- [Sequence-to-Sequence Language Models for Character and Emotion Detection in Dream Narratives](2024年03月21日/Sequence-to-Sequence_Language_Models_for_Character_and_Emotion_Detection_in_Dream_Narratives.md)

    - [翻译: 针对梦境叙述中角色与情绪识别问题，本研究采用序列到序列语言模型进行探索，以期精准揭示其中的人物特征与情感变化。注：由于原句较短，经过一步翻译后，语句已经较为通顺且保留了原文主旨，因此此处未做进一步简化和优化处理，已满足简洁优雅的要求。如果需要根据具体上下文进行调整，请提供更多信息。](2024年03月21日/Sequence-to-Sequence_Language_Models_for_Character_and_Emotion_Detection_in_Dream_Narratives.md)

- [RakutenAI-7B: Extending Large Language Models for Japanese](2024年03月21日/RakutenAI-7B_Extending_Large_Language_Models_for_Japanese.md)

    - [翻译: RakutenAI-7B 是一款专为日语扩展的大型语言模型，旨在提升和优化针对日语场景下的处理与理解能力。（注：由于原始句子较短，且已经较为简洁明了，在保持准确性的前提下，步骤2的翻译与](2024年03月21日/RakutenAI-7B_Extending_Large_Language_Models_for_Japanese.md)

- [Multi-Level Feedback Generation with Large Language Models for Empowering Novice Peer Counselors](2024年03月21日/Multi-Level_Feedback_Generation_with_Large_Language_Models_for_Empowering_Novice_Peer_Counselors.md)

    - [翻译: 为了助力新手同伴咨询师，我们采用大型语言模型实现多层级反馈生成技术，以期提升其咨询服务效能。](2024年03月21日/Multi-Level_Feedback_Generation_with_Large_Language_Models_for_Empowering_Novice_Peer_Counselors.md)

- [Sphere Neural-Networks for Rational Reasoning](2024年03月22日/Sphere_Neural-Networks_for_Rational_Reasoning.md)

    - [翻译: 面向理性推理的球形神经网络技术（注：由于原文标题较为简洁，从准确性和生动性角度考虑，经过一步翻译即可较好地保留原文含义且符合中文标题的表达习惯。如果需要进一步丰富内容，可以参考以下拓展版本）结果2细化版：球形神经网络架构在理性推理任务中的应用与探索](2024年03月22日/Sphere_Neural-Networks_for_Rational_Reasoning.md)

- [Measuring Gender and Racial Biases in Large Language Models](2024年03月22日/Measuring_Gender_and_Racial_Biases_in_Large_Language_Models.md)

    - [翻译: 本研究致力于揭示大型语言模型中存在的性别与种族偏见问题，通过量化评估方法，深入探究其内在的不公平性特征。](2024年03月22日/Measuring_Gender_and_Racial_Biases_in_Large_Language_Models.md)

- [Bioinformatics and Biomedical Informatics with ChatGPT: Year One Review](2024年03月22日/Bioinformatics_and_Biomedical_Informatics_with_ChatGPT_Year_One_Review.md)

    - [翻译: 一年回顾：借助ChatGPT在生物信息学与生物医学信息学领域的探索与实践](2024年03月22日/Bioinformatics_and_Biomedical_Informatics_with_ChatGPT_Year_One_Review.md)

- [Event Temporal Relation Extraction based on Retrieval-Augmented on LLMs](2024年03月22日/Event_Temporal_Relation_Extraction_based_on_Retrieval-Augmented_on_LLMs.md)

    - [翻译: 借助检索增强的LLMs技术进行事件时序关系抽取，本研究聚焦于利用大规模语言模型抽取事件间的时间顺序关系，通过检索辅助提升抽取效能。](2024年03月22日/Event_Temporal_Relation_Extraction_based_on_Retrieval-Augmented_on_LLMs.md)

- [Imagination Augmented Generation: Learning to Imagine Richer Context for Question Answering over Large Language Models](2024年03月22日/Imagination_Augmented_Generation_Learning_to_Imagine_Richer_Context_for_Question_Answering_over_Large_Language_Models.md)

    - [翻译: 想象增强生成技术：针对大型语言模型上的问答任务，我们致力于学习构建更加丰富的上下文环境。这项研究聚焦于如何借助想象力，在大规模语言模型上提升解答问题的能力，通过构建更为详实多元的语境信息。](2024年03月22日/Imagination_Augmented_Generation_Learning_to_Imagine_Richer_Context_for_Question_Answering_over_Large_Language_Models.md)

- [FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions](2024年03月22日/FollowIR_Evaluating_and_Teaching_Information_Retrieval_Models_to_Follow_Instructions.md)

    - [翻译: FollowIR：评估并指导信息检索模型如何按照指令行动步骤详解：](2024年03月22日/FollowIR_Evaluating_and_Teaching_Information_Retrieval_Models_to_Follow_Instructions.md)

- [An Exploratory Investigation into Code License Infringements in Large Language Model Training Datasets](2024年03月22日/An_Exploratory_Investigation_into_Code_License_Infringements_in_Large_Language_Model_Training_Datasets.md)

    - [翻译: 针对大型语言模型训练数据集中代码许可侵权现象的探索性研究](2024年03月22日/An_Exploratory_Investigation_into_Code_License_Infringements_in_Large_Language_Model_Training_Datasets.md)

- [Not All Attention is Needed: Parameter and Computation Efficient Transfer Learning for Multi-modal Large Language Models](2024年03月22日/Not_All_Attention_is_Needed_Parameter_and_Computation_Efficient_Transfer_Learning_for_Multi-modal_Large_Language_Models.md)

    - [翻译: 并非所有注意力都不可或缺，在多模态大型语言模型中，我们追求一种参数高效且计算经济的迁移学习方法。](2024年03月22日/Not_All_Attention_is_Needed_Parameter_and_Computation_Efficient_Transfer_Learning_for_Multi-modal_Large_Language_Models.md)

- [InstaSynth: Opportunities and Challenges in Generating Synthetic Instagram Data with ChatGPT for Sponsored Content Detection](2024年03月22日/InstaSynth_Opportunities_and_Challenges_in_Generating_Synthetic_Instagram_Data_with_ChatGPT_for_Sponsored_Content_Detection.md)

    - [翻译: InstaSynth项目探讨了利用ChatGPT技术生成合成Instagram数据以支持赞助内容检测的可能性与面临的难题。](2024年03月22日/InstaSynth_Opportunities_and_Challenges_in_Generating_Synthetic_Instagram_Data_with_ChatGPT_for_Sponsored_Content_Detection.md)

- [MSCoTDet: Language-driven Multi-modal Fusion for Improved Multispectral Pedestrian Detection](2024年03月22日/MSCoTDet_Language-driven_Multi-modal_Fusion_for_Improved_Multispectral_Pedestrian_Detection.md)

    - [翻译: MSCoTDet 是一种创新方法，通过运用语言驱动的多模态融合技术，优化并提升了在多光谱环境下行人检测的能力。](2024年03月22日/MSCoTDet_Language-driven_Multi-modal_Fusion_for_Improved_Multispectral_Pedestrian_Detection.md)

- [AllHands: Ask Me Anything on Large-scale Verbatim Feedback via Large Language Models](2024年03月22日/AllHands_Ask_Me_Anything_on_Large-scale_Verbatim_Feedback_via_Large_Language_Models.md)

    - [翻译: 【AllHands 环节】借助大型语言模型，探讨大规模逐字反馈相关问题，欢迎提出您的任何疑问！](2024年03月22日/AllHands_Ask_Me_Anything_on_Large-scale_Verbatim_Feedback_via_Large_Language_Models.md)

- [A Multimodal Approach for Cross-Domain Image Retrieval](2024年03月22日/A_Multimodal_Approach_for_Cross-Domain_Image_Retrieval.md)

    - [翻译: 针对跨领域图像检索问题，我们采用了一种创新的多模态方法。这种方法巧妙地融合了多种信息模式，以实现更为精准且高效的图像检索效果。](2024年03月22日/A_Multimodal_Approach_for_Cross-Domain_Image_Retrieval.md)

- [CACA Agent: Capability Collaboration based AI Agent](2024年03月22日/CACA_Agent_Capability_Collaboration_based_AI_Agent.md)

    - [翻译: CACA 代理是一种基于能力协作的人工智能代理，它通过整合多种技能和功能以实现高效的任务执行和智能决策。](2024年03月22日/CACA_Agent_Capability_Collaboration_based_AI_Agent.md)

- [Transfer CLIP for Generalizable Image Denoising](2024年03月22日/Transfer_CLIP_for_Generalizable_Image_Denoising.md)

    - [翻译: Transfer CLIP 应用于通用图像去噪领域，旨在提升模型的泛化能力，使其能够有效处理各类噪声图像问题。](2024年03月22日/Transfer_CLIP_for_Generalizable_Image_Denoising.md)

- [Text clustering with LLM embeddings](2024年03月22日/Text_clustering_with_LLM_embeddings.md)

    - [翻译: 运用 LLM 生成的嵌入进行文本聚类技术的研究与应用步骤详解：](2024年03月22日/Text_clustering_with_LLM_embeddings.md)

- [LLM-Driven Agents for Influencer Selection in Digital Advertising Campaigns](2024年03月22日/LLM-Driven_Agents_for_Influencer_Selection_in_Digital_Advertising_Campaigns.md)

    - [翻译: 针对数字广告战役中的影响者选择问题，我们采用 LLM 驱动的智能代理方案。这种方案利用 LLM 的强大能力，在影响者筛选过程中提供精准而高效的决策支持。](2024年03月22日/LLM-Driven_Agents_for_Influencer_Selection_in_Digital_Advertising_Campaigns.md)

- [CHisIEC: An Information Extraction Corpus for Ancient Chinese History](2024年03月22日/CHisIEC_An_Information_Extraction_Corpus_for_Ancient_Chinese_History.md)

    - [翻译: CHisIEC 是专为古代中国历史打造的信息抽取语料库，旨在服务于对中国古代文献中丰富历史信息的精准抽取与分析。](2024年03月22日/CHisIEC_An_Information_Extraction_Corpus_for_Ancient_Chinese_History.md)

- [Comprehensive Lipidomic Automation Workflow using Large Language Models](2024年03月22日/Comprehensive_Lipidomic_Automation_Workflow_using_Large_Language_Models.md)

    - [翻译: 借助大型语言模型实现全方位脂质组学自动化流程](2024年03月22日/Comprehensive_Lipidomic_Automation_Workflow_using_Large_Language_Models.md)

- [Construction of a Japanese Financial Benchmark for Large Language Models](2024年03月22日/Construction_of_a_Japanese_Financial_Benchmark_for_Large_Language_Models.md)

    - [翻译: 针对大型语言模型（LLM），我们致力于构建一个日本金融基准，以衡量其在相关领域内的表现与适应性。步骤细化：结果1：针对大型语言模型（LLM），关于构建日本金融基准的研究正在进行，旨在提供一个评估其在金融领域内性能的标准参照。](2024年03月22日/Construction_of_a_Japanese_Financial_Benchmark_for_Large_Language_Models.md)

- [Cartoon Hallucinations Detection: Pose-aware In Context Visual Learning](2024年03月22日/Cartoon_Hallucinations_Detection_Pose-aware_In_Context_Visual_Learning.md)

    - [翻译: 面向姿态感知的上下文视觉学习应用于卡通幻觉检测技术，旨在通过深入理解图像中对象的姿势信息，有效识别并检测出卡通图像中的幻觉内容。](2024年03月22日/Cartoon_Hallucinations_Detection_Pose-aware_In_Context_Visual_Learning.md)

- [LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement](2024年03月22日/LLM2LLM_Boosting_LLMs_with_Novel_Iterative_Data_Enhancement.md)

    - [翻译: LLM2LLM 方法通过创新的迭代式数据增强技术，有力地提升了大型语言模型的表现力。](2024年03月22日/LLM2LLM_Boosting_LLMs_with_Novel_Iterative_Data_Enhancement.md)

- [Magic for the Age of Quantized DNNs](2024年03月22日/Magic_for_the_Age_of_Quantized_DNNs.md)

    - [翻译: 在深度神经网络量化时代下施展魔法注：由于原文“Magic for the Age of Quantized DNNs”是个标题性质的内容，且具有一定的抽象性和创意性，直译可能无法完全展现原文的意蕴和修辞效果。在此基础上进行简化和本地化时，尽可能保留其神秘感和技术感，因此给出了如上的“在深度神经网络量化时代下施展魔法”这一翻译建议。如果是在正式场合或需要更准确表述的情况下，也可以翻译为“面向量化深度神经网络时代的高效技术探索”。](2024年03月22日/Magic_for_the_Age_of_Quantized_DNNs.md)

- [Risk and Response in Large Language Models: Evaluating Key Threat Categories](2024年03月22日/Risk_and_Response_in_Large_Language_Models_Evaluating_Key_Threat_Categories.md)

    - [翻译: 在大型语言模型领域，我们聚焦于评估各类关键风险，并探讨相应的应对策略。这项研究旨在深入剖析大型语言模型所面临的多种威胁类别及其应对措施。](2024年03月22日/Risk_and_Response_in_Large_Language_Models_Evaluating_Key_Threat_Categories.md)

- [AI Teaches the Art of Elegant Coding: Timely, Fair, and Helpful Style Feedback in a Global Course](2024年03月22日/AI_Teaches_the_Art_of_Elegant_Coding_Timely,_Fair,_and_Helpful_Style_Feedback_in_a_Global_Course.md)

    - [翻译: 在一项全球课程中，AI 教授如何实现优雅编码，通过适时、公正且具有建设性的风格反馈，提升学员编程水平。（注：由于原句较短，已一步到位进行生动活泼、简洁优雅的翻译，无需额外步骤。）](2024年03月22日/AI_Teaches_the_Art_of_Elegant_Coding_Timely,_Fair,_and_Helpful_Style_Feedback_in_a_Global_Course.md)

- [MasonTigers at SemEval-2024 Task 9: Solving Puzzles with an Ensemble of Chain-of-Thoughts](2024年03月22日/MasonTigers_at_SemEval-2024_Task_9_Solving_Puzzles_with_an_Ensemble_of_Chain-of-Thoughts.md)

    - [翻译: 在SemEval-2024年第九项任务中，MasonTigers团队采用链式思考集合方法破解谜题挑战](2024年03月22日/MasonTigers_at_SemEval-2024_Task_9_Solving_Puzzles_with_an_Ensemble_of_Chain-of-Thoughts.md)

- [Learners Teaching Novices: An Uplifting Alternative Assessment](2024年03月22日/Learners_Teaching_Novices_An_Uplifting_Alternative_Assessment.md)

    - [翻译: 让学习者指导新手：一种激发潜力的新型替代评估策略](2024年03月22日/Learners_Teaching_Novices_An_Uplifting_Alternative_Assessment.md)

- [Comprehensive Evaluation and Insights into the Use of Large Language Models in the Automation of Behavior-Driven Development Acceptance Test Formulation](2024年03月22日/Comprehensive_Evaluation_and_Insights_into_the_Use_of_Large_Language_Models_in_the_Automation_of_Behavior-Driven_Development_Acceptance_Test_Formulation.md)

    - [翻译: 深入探索大型语言模型在自动化行为驱动开发验收测试设计中的应用及其全面评估](2024年03月22日/Comprehensive_Evaluation_and_Insights_into_the_Use_of_Large_Language_Models_in_the_Automation_of_Behavior-Driven_Development_Acceptance_Test_Formulation.md)

- [Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation](2024年03月22日/Evidence-Driven_Retrieval_Augmented_Response_Generation_for_Online_Misinformation.md)

    - [翻译: 面对在线虚假信息挑战，我们提出了一种证据驱动的检索增强响应生成方法，通过整合有效证据信息以提高对抗虚假信息时的回应质量与准确性。](2024年03月22日/Evidence-Driven_Retrieval_Augmented_Response_Generation_for_Online_Misinformation.md)

- [KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation](2024年03月22日/KnowLA_Enhancing_Parameter-efficient_Finetuning_with_Knowledgeable_Adaptation.md)

    - [翻译: KnowLA 是一项创新技术，它借助知识性适应提升参数高效微调的能力，旨在在减少参数调整的同时，更好地融入领域知识以优化模型性能。](2024年03月22日/KnowLA_Enhancing_Parameter-efficient_Finetuning_with_Knowledgeable_Adaptation.md)

- [On Zero-Shot Counterspeech Generation by LLMs](2024年03月22日/On_Zero-Shot_Counterspeech_Generation_by_LLMs.md)

    - [翻译: 探讨LLMs在零样本情境下生成反仇恨言论的能力](2024年03月22日/On_Zero-Shot_Counterspeech_Generation_by_LLMs.md)

- [FastCAD: Real-Time CAD Retrieval and Alignment from Scans and Videos](2024年03月22日/FastCAD_Real-Time_CAD_Retrieval_and_Alignment_from_Scans_and_Videos.md)

    - [翻译: FastCAD 系统实现了从扫描和视频数据中实时检索和精确对齐 CAD 模型的技术突破。](2024年03月22日/FastCAD_Real-Time_CAD_Retrieval_and_Alignment_from_Scans_and_Videos.md)

- [Can large language models explore in-context?](2024年03月22日/Can_large_language_models_explore_in-context.md)

    - [翻译: 大型语言模型能否深入探究并运用上下文学习机制呢？](2024年03月22日/Can_large_language_models_explore_in-context.md)

- [LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models](2024年03月22日/LLaVA-PruMerge_Adaptive_Token_Reduction_for_Efficient_Large_Multimodal_Models.md)

    - [翻译: LLaVA-PruMerge 是一种针对大型多模态模型的自适应令牌缩减方案，旨在提升模型运行效率。进一步优化后的](2024年03月22日/LLaVA-PruMerge_Adaptive_Token_Reduction_for_Efficient_Large_Multimodal_Models.md)

- [Multimodal Fusion with Pre-Trained Model Features in Affective Behaviour Analysis In-the-wild](2024年03月22日/Multimodal_Fusion_with_Pre-Trained_Model_Features_in_Affective_Behaviour_Analysis_In-the-wild.md)

    - [翻译: 针对真实场景下的情感行为分析，本研究探索了预训练模型特征在多模态融合中的应用，以揭示和整合多种感官信息对情感识别的影响。](2024年03月22日/Multimodal_Fusion_with_Pre-Trained_Model_Features_in_Affective_Behaviour_Analysis_In-the-wild.md)

- [CoLLEGe: Concept Embedding Generation for Large Language Models](2024年03月22日/CoLLEGe_Concept_Embedding_Generation_for_Large_Language_Models.md)

    - [翻译: CoLLEGe 是一种专为大型语言模型设计的概念嵌入生成方法，致力于提升模型对各类概念的理解与表达能力。](2024年03月22日/CoLLEGe_Concept_Embedding_Generation_for_Large_Language_Models.md)

- [FEEL: A Framework for Evaluating Emotional Support Capability with Large Language Models](2024年03月22日/FEEL_A_Framework_for_Evaluating_Emotional_Support_Capability_with_Large_Language_Models.md)

    - [翻译: FEEL 是一个专门针对大型语言模型（LLMs）的情感支持能力评估框架，旨在深入探究和量化LLMs在提供情绪支持方面的表现。](2024年03月22日/FEEL_A_Framework_for_Evaluating_Emotional_Support_Capability_with_Large_Language_Models.md)

- [SceneX:Procedural Controllable Large-scale Scene Generation via Large-language Models](2024年03月22日/SceneXProcedural_Controllable_Large-scale_Scene_Generation_via_Large-language_Models.md)

    - [翻译: SceneX项目利用大型语言模型，开创性地实现了大规模场景的程序化可控生成技术。](2024年03月22日/SceneXProcedural_Controllable_Large-scale_Scene_Generation_via_Large-language_Models.md)

- [MixRED: A Mix-lingual Relation Extraction Dataset](2024年03月22日/MixRED_A_Mix-lingual_Relation_Extraction_Dataset.md)

    - [翻译: MixRED 是一个创新的混合型跨语言关系抽取数据集，旨在提供丰富的跨语言环境下的实体关系抽取训练资源。](2024年03月22日/MixRED_A_Mix-lingual_Relation_Extraction_Dataset.md)

- [EAGLE: A Domain Generalization Framework for AI-generated Text Detection](2024年03月22日/EAGLE_A_Domain_Generalization_Framework_for_AI-generated_Text_Detection.md)

    - [翻译: EAGLE 是一个专为识别AI生成文本而设计的领域泛化框架，致力于解决跨不同领域的AI文本检测问题。](2024年03月22日/EAGLE_A_Domain_Generalization_Framework_for_AI-generated_Text_Detection.md)

- [AI for Biomedicine in the Era of Large Language Models](2024年03月22日/AI_for_Biomedicine_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 大型语言模型时代的生物医学AI前沿探索](2024年03月22日/AI_for_Biomedicine_in_the_Era_of_Large_Language_Models.md)

- [SRLM: Human-in-Loop Interactive Social Robot Navigation with Large Language Model and Deep Reinforcement Learning](2024年03月22日/SRLM_Human-in-Loop_Interactive_Social_Robot_Navigation_with_Large_Language_Model_and_Deep_Reinforcement_Learning.md)

    - [翻译: SRLM 是一项创新技术，它运用大型语言模型与深度强化学习，实现人机交互式社交机器人导航，让机器人在人类引导下灵活适应复杂社交环境中的移动需求。](2024年03月22日/SRLM_Human-in-Loop_Interactive_Social_Robot_Navigation_with_Large_Language_Model_and_Deep_Reinforcement_Learning.md)

- [Differentially Private Next-Token Prediction of Large Language Models](2024年03月22日/Differentially_Private_Next-Token_Prediction_of_Large_Language_Models.md)

    - [翻译: 针对大型语言模型，研究其在保护隐私的前提下进行下一个标记预测的能力。这项研究聚焦于探索如何在保证差异隐私的同时，有效实现大规模语言模型的下一个词汇预测功能。](2024年03月22日/Differentially_Private_Next-Token_Prediction_of_Large_Language_Models.md)

- [Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers](2024年03月22日/Just_another_copy_and_paste_Comparing_the_security_vulnerabilities_of_ChatGPT_generated_code_and_StackOverflow_answers.md)

    - [翻译: ChatGPT生成的代码与StackOverflow上的答案，是否同样存在安全漏洞问题呢？本文将对此进行对比探究。](2024年03月22日/Just_another_copy_and_paste_Comparing_the_security_vulnerabilities_of_ChatGPT_generated_code_and_StackOverflow_answers.md)

- [FairerCLIP: Debiasing CLIP's Zero-Shot Predictions using Functions in RKHSs](2024年03月22日/FairerCLIP_Debiasing_CLIP's_Zero-Shot_Predictions_using_Functions_in_RKHSs.md)

    - [翻译: FairerCLIP是一种方法，它利用RKHS（ reproducing kernel Hilbert spaces）中的函数来减少CLIP在零样本预测中的偏差问题，以实现更加公正的图像-文本匹配效果。进一步润色后的](2024年03月22日/FairerCLIP_Debiasing_CLIP's_Zero-Shot_Predictions_using_Functions_in_RKHSs.md)

- [Large language models for crowd decision making based on prompt design strategies using ChatGPT: models, analysis and challenges](2024年03月22日/Large_language_models_for_crowd_decision_making_based_on_prompt_design_strategies_using_ChatGPT_models,_analysis_and_challenges.md)

    - [翻译: 借助ChatGPT的提示设计策略，大规模语言模型应用于群体决策场景，涉及模型构建、效果分析以及面临的挑战。](2024年03月22日/Large_language_models_for_crowd_decision_making_based_on_prompt_design_strategies_using_ChatGPT_models,_analysis_and_challenges.md)

- [Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors](2024年03月22日/Generative_AI_in_Education_A_Study_of_Educators'_Awareness,_Sentiments,_and_Influencing_Factors.md)

    - [翻译: 本研究聚焦于生成式AI在教育领域的应用，深入探讨了教育工作者对此的认知程度、情感倾向及其背后的影响因素。](2024年03月22日/Generative_AI_in_Education_A_Study_of_Educators'_Awareness,_Sentiments,_and_Influencing_Factors.md)

- [MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis](2024年03月22日/MedPromptX_Grounded_Multimodal_Prompting_for_Chest_X-ray_Diagnosis.md)

    - [翻译: MedPromptX 是一项创新技术，它利用基于实证的多模态提示方法，助力于胸部X射线诊断工作。](2024年03月22日/MedPromptX_Grounded_Multimodal_Prompting_for_Chest_X-ray_Diagnosis.md)

- [LimGen: Probing the LLMs for Generating Suggestive Limitations of Research Papers](2024年03月22日/LimGen_Probing_the_LLMs_for_Generating_Suggestive_Limitations_of_Research_Papers.md)

    - [翻译: LimGen 是一项研究，旨在探索 LLM 如何揭示并生成科研论文的潜在局限性提示。](2024年03月22日/LimGen_Probing_the_LLMs_for_Generating_Suggestive_Limitations_of_Research_Papers.md)

- [Evaluating GPT-4 with Vision on Detection of Radiological Findings on Chest Radiographs](2024年03月22日/Evaluating_GPT-4_with_Vision_on_Detection_of_Radiological_Findings_on_Chest_Radiographs.md)

    - [翻译: 在胸部X线片放射学发现检测任务中，我们运用视力评估了 GPT-4 的表现能力。进一步优化后的](2024年03月22日/Evaluating_GPT-4_with_Vision_on_Detection_of_Radiological_Findings_on_Chest_Radiographs.md)

- [BIMCV-R: A Landmark Dataset for 3D CT Text-Image Retrieval](2024年03月23日/BIMCV-R_A_Landmark_Dataset_for_3D_CT_Text-Image_Retrieval.md)

    - [翻译: BIMCV-R 是一个专为三维CT文本-图像检索打造的里程碑式数据集。](2024年03月23日/BIMCV-R_A_Landmark_Dataset_for_3D_CT_Text-Image_Retrieval.md)

- [Explore until Confident: Efficient Exploration for Embodied Question Answering](2024年03月23日/Explore_until_Confident_Efficient_Exploration_for_Embodied_Question_Answering.md)

    - [翻译: 提出“探索直至自信”策略，旨在提升具身问题回答任务中的高效探索能力。](2024年03月23日/Explore_until_Confident_Efficient_Exploration_for_Embodied_Question_Answering.md)

- [LlamBERT: Large-scale low-cost data annotation in NLP](2024年03月23日/LlamBERT_Large-scale_low-cost_data_annotation_in_NLP.md)

    - [翻译: LlamBERT 是一项致力于在自然语言处理（NLP）领域实现大规模、低成本数据标注的研究成果。通过创新方法，LlamBERT 实现了高效且经济的数据标注过程，极大地降低了 NLP 项目中的数据标注成本。](2024年03月23日/LlamBERT_Large-scale_low-cost_data_annotation_in_NLP.md)

- [TrustSQL: A Reliability Benchmark for Text-to-SQL Models with Diverse Unanswerable Questions](2024年03月23日/TrustSQL_A_Reliability_Benchmark_for_Text-to-SQL_Models_with_Diverse_Unanswerable_Questions.md)

    - [翻译: TrustSQL 是一个专为评估Text-to-SQL模型可靠性的基准，它特别设计了多样化的无法回答问题，以全面检验模型在面对复杂SQL查询挑战时的性能与可靠性。](2024年03月23日/TrustSQL_A_Reliability_Benchmark_for_Text-to-SQL_Models_with_Diverse_Unanswerable_Questions.md)

- [RAAMove: A Corpus for Analyzing Moves in Research Article Abstracts](2024年03月23日/RAAMove_A_Corpus_for_Analyzing_Moves_in_Research_Article_Abstracts.md)

    - [翻译: RAAMove——专为解析科研论文摘要中各类动作行为而构建的语料库](2024年03月23日/RAAMove_A_Corpus_for_Analyzing_Moves_in_Research_Article_Abstracts.md)

- [Using Large Language Models for OntoClean-based Ontology Refinement](2024年03月23日/Using_Large_Language_Models_for_OntoClean-based_Ontology_Refinement.md)

    - [翻译: 利用大规模语言模型助力OntoClean方法进行本体精细化改进](2024年03月23日/Using_Large_Language_Models_for_OntoClean-based_Ontology_Refinement.md)

- [When LLM-based Code Generation Meets the Software Development Process](2024年03月23日/When_LLM-based_Code_Generation_Meets_the_Software_Development_Process.md)

    - [翻译: 当LLM驱动的代码生成融入软件开发流程之际](2024年03月23日/When_LLM-based_Code_Generation_Meets_the_Software_Development_Process.md)

- [VLM-CPL: Consensus Pseudo Labels from Vision-Language Models for Human Annotation-Free Pathological Image Classification](2024年03月23日/VLM-CPL_Consensus_Pseudo_Labels_from_Vision-Language_Models_for_Human_Annotation-Free_Pathological_Image_Classification.md)

    - [翻译: VLM-CPL 方法利用视觉-语言模型生成共识伪标签，实现无需人工标注的病理图像分类任务。这一创新技术旨在通过整合视觉与语言信息，在病理图像分类领域减少对人工标注的依赖。](2024年03月23日/VLM-CPL_Consensus_Pseudo_Labels_from_Vision-Language_Models_for_Human_Annotation-Free_Pathological_Image_Classification.md)

- [ARO: Large Language Model Supervised Robotics Text2Skill Autonomous Learning](2024年03月23日/ARO_Large_Language_Model_Supervised_Robotics_Text2Skill_Autonomous_Learning.md)

    - [翻译: ARO项目专注于利用大型语言模型指导下的文本到技能转换技术，实现机器人的自主学习能力。](2024年03月23日/ARO_Large_Language_Model_Supervised_Robotics_Text2Skill_Autonomous_Learning.md)

- [Computational Sentence-level Metrics Predicting Human Sentence Comprehension](2024年03月23日/Computational_Sentence-level_Metrics_Predicting_Human_Sentence_Comprehension.md)

    - [翻译: 计算法句级度量可有效预测人类对句子的理解程度步骤 1 翻译：计算级别的句子度量被用于预测人类在理解句子时的表现。步骤 2 翻译优化：通过计算句子层面的评测指标，我们可以有效地预测人类对句子的理解水平。](2024年03月23日/Computational_Sentence-level_Metrics_Predicting_Human_Sentence_Comprehension.md)

- [Understanding Emergent Abilities of Language Models from the Loss Perspective](2024年03月23日/Understanding_Emergent_Abilities_of_Language_Models_from_the_Loss_Perspective.md)

    - [翻译: 通过深入探究损失视角，本研究旨在揭示语言模型所展现的新兴能力，剖析其内在机制及其在实际应用中的表现。](2024年03月23日/Understanding_Emergent_Abilities_of_Language_Models_from_the_Loss_Perspective.md)

- [The Frontier of Data Erasure: Machine Unlearning for Large Language Models](2024年03月23日/The_Frontier_of_Data_Erasure_Machine_Unlearning_for_Large_Language_Models.md)

    - [翻译: 探寻数据擦除边界：面向大型语言模型的机器遗忘机制](2024年03月23日/The_Frontier_of_Data_Erasure_Machine_Unlearning_for_Large_Language_Models.md)

- [Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study](2024年03月23日/Leveraging_Large_Language_Models_for_Preliminary_Security_Risk_Analysis_A_Mission-Critical_Case_Study.md)

    - [翻译: 通过运用大型语言模型，我们对初步安全风险分析进行了探索，并呈现一项以关键任务为核心的实证研究案例。步骤详解：1. 直译：利用大型语言模型（Large Language Models）进行初步的安全风险分析，在此提出一个对任务至关重要的案例研究（Mission-Critical Case Study）。2. 简洁优雅翻译：在关键任务安全风险评估领域，本研究借助大型语言模型的力量，开展了一项初步且具有代表性的案例研究。](2024年03月23日/Leveraging_Large_Language_Models_for_Preliminary_Security_Risk_Analysis_A_Mission-Critical_Case_Study.md)

- [CodeShell Technical Report](2024年03月23日/CodeShell_Technical_Report.md)

    - [翻译: 《CodeShell 技术研究报告》](2024年03月23日/CodeShell_Technical_Report.md)

- [Ghost Sentence: A Tool for Everyday Users to Copyright Data from Large Language Models](2024年03月23日/Ghost_Sentence_A_Tool_for_Everyday_Users_to_Copyright_Data_from_Large_Language_Models.md)

    - [翻译: Ghost Sentence——专为日常用户打造，用于从大型语言模型中为数据赋予版权保护的实用工具](2024年03月23日/Ghost_Sentence_A_Tool_for_Everyday_Users_to_Copyright_Data_from_Large_Language_Models.md)

- [Few-shot Dialogue Strategy Learning for Motivational Interviewing via Inductive Reasoning](2024年03月23日/Few-shot_Dialogue_Strategy_Learning_for_Motivational_Interviewing_via_Inductive_Reasoning.md)

    - [翻译: 借助归纳推理，我们提出一种方法，能够在少量样本情况下学习动机访谈中的对话策略，实现高效灵活的对话策略学习应用于动机访谈场景。](2024年03月23日/Few-shot_Dialogue_Strategy_Learning_for_Motivational_Interviewing_via_Inductive_Reasoning.md)

- [LLMs Instruct LLMs:An Extraction and Editing Method](2024年03月23日/LLMs_Instruct_LLMsAn_Extraction_and_Editing_Method.md)

    - [翻译: LLMs 指导 LLMS：探索一种从LLMs中提取与编辑的新方法](2024年03月23日/LLMs_Instruct_LLMsAn_Extraction_and_Editing_Method.md)

- [Spatio-Temporal Graph Convolutional Network Combined Large Language Model: A Deep Learning Framework for Bike Demand Forecasting](2024年03月23日/Spatio-Temporal_Graph_Convolutional_Network_Combined_Large_Language_Model_A_Deep_Learning_Framework_for_Bike_Demand_Forecasting.md)

    - [翻译: 结合时空图卷积网络与大型语言模型的创新框架，构建了一种深入探究自行车需求预测问题的深度学习方案。](2024年03月23日/Spatio-Temporal_Graph_Convolutional_Network_Combined_Large_Language_Model_A_Deep_Learning_Framework_for_Bike_Demand_Forecasting.md)

- [Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider](2024年03月23日/Towards_a_\textbf{RAG}-based_Summarization_Agent_for_the_Electron-Ion_Collider.md)

    - [翻译: 致力于研发基于 RAG 的电子-离子对撞机摘要生成代理技术解释：](2024年03月23日/Towards_a_\textbf{RAG}-based_Summarization_Agent_for_the_Electron-Ion_Collider.md)

- [A hybrid LLM workflow can help identify user privilege related variables in programs of any size](2024年03月23日/A_hybrid_LLM_workflow_can_help_identify_user_privilege_related_variables_in_programs_of_any_size.md)

    - [翻译: 采用混合型LLM工作流，能够有效探测任意大小程序中的用户权限相关变量。](2024年03月23日/A_hybrid_LLM_workflow_can_help_identify_user_privilege_related_variables_in_programs_of_any_size.md)

- [EDDA: A Encoder-Decoder Data Augmentation Framework for Zero-Shot Stance Detection](2024年03月23日/EDDA_A_Encoder-Decoder_Data_Augmentation_Framework_for_Zero-Shot_Stance_Detection.md)

    - [翻译: EDDA 是一个专为零样本立场检测设计的编码器-解码器数据增强方案。它通过创新的数据增强策略，致力于提升模型在未见过的立场检测任务上的性能表现。](2024年03月23日/EDDA_A_Encoder-Decoder_Data_Augmentation_Framework_for_Zero-Shot_Stance_Detection.md)

- [Can Language Models Pretend Solvers? Logic Code Simulation with LLMs](2024年03月24日/Can_Language_Models_Pretend_Solvers_Logic_Code_Simulation_with_LLMs.md)

    - [翻译: 语言模型是否可以扮演解算器角色？此研究聚焦于LLMs如何模拟逻辑代码运行，并探索其在此领域的潜力。](2024年03月24日/Can_Language_Models_Pretend_Solvers_Logic_Code_Simulation_with_LLMs.md)

- [LLMs as Compiler for Arabic Programming Language](2024年03月24日/LLMs_as_Compiler_for_Arabic_Programming_Language.md)

    - [翻译: LLMs 助力阿拉伯编程语言，担任“编译器”角色进一步优化：在最新的技术探索中，大型语言模型(LLMs)正在展现其潜力，担当起阿拉伯编程语言的编译器角色，助力这一语种在程序开发领域的高效运用与转化。](2024年03月24日/LLMs_as_Compiler_for_Arabic_Programming_Language.md)

- [Argument Quality Assessment in the Age of Instruction-Following Large Language Models](2024年03月24日/Argument_Quality_Assessment_in_the_Age_of_Instruction-Following_Large_Language_Models.md)

    - [翻译: 在当前遵循指令的大规模语言模型时代，针对论据质量评估的研究](2024年03月24日/Argument_Quality_Assessment_in_the_Age_of_Instruction-Following_Large_Language_Models.md)

- [Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing with Justifications](2024年03月24日/Combining_Fine-Tuning_and_LLM-based_Agents_for_Intuitive_Smart_Contract_Auditing_with_Justifications.md)

    - [翻译: 通过融合微调技术和基于大型语言模型（LLM）的代理，我们致力于打造一种直观且附带充分解释的智能合约审计方案。](2024年03月24日/Combining_Fine-Tuning_and_LLM-based_Agents_for_Intuitive_Smart_Contract_Auditing_with_Justifications.md)

- [Qibo: A Large Language Model for Traditional Chinese Medicine](2024年03月24日/Qibo_A_Large_Language_Model_for_Traditional_Chinese_Medicine.md)

    - [翻译: Qibo 是一款专为中医药领域打造的大规模语言模型，致力于提供准确、全面的中医药知识理解和应用能力。](2024年03月24日/Qibo_A_Large_Language_Model_for_Traditional_Chinese_Medicine.md)

- [Monotonic Paraphrasing Improves Generalization of Language Model Prompting](2024年03月24日/Monotonic_Paraphrasing_Improves_Generalization_of_Language_Model_Prompting.md)

    - [翻译: 通过单调性释义优化，语言模型的提示泛化性能得到显著提升步骤详解：](2024年03月24日/Monotonic_Paraphrasing_Improves_Generalization_of_Language_Model_Prompting.md)

- [CBT-LLM: A Chinese Large Language Model for Cognitive Behavioral Therapy-based Mental Health Question Answering](2024年03月24日/CBT-LLM_A_Chinese_Large_Language_Model_for_Cognitive_Behavioral_Therapy-based_Mental_Health_Question_Answering.md)

    - [翻译: CBT-LLM 是一款专为精神健康问答打造的大型中文语言模型，其核心技术融入了认知行为疗法理念。这款模型旨在提升针对心理健康问题的智能答疑能力。](2024年03月24日/CBT-LLM_A_Chinese_Large_Language_Model_for_Cognitive_Behavioral_Therapy-based_Mental_Health_Question_Answering.md)

- [LexDrafter: Terminology Drafting for Legislative Documents using Retrieval Augmented Generation](2024年03月24日/LexDrafter_Terminology_Drafting_for_Legislative_Documents_using_Retrieval_Augmented_Generation.md)

    - [翻译: LexDrafter 是一项利用检索增强生成技术的专业工具，专门用于为立法文件精准高效地起草术语内容。](2024年03月24日/LexDrafter_Terminology_Drafting_for_Legislative_Documents_using_Retrieval_Augmented_Generation.md)

- [AgentFL: Scaling LLM-based Fault Localization to Project-Level Context](2024年03月24日/AgentFL_Scaling_LLM-based_Fault_Localization_to_Project-Level_Context.md)

    - [翻译: AgentFL：致力于将基于大型语言模型（LLM）的故障定位技术推广至项目层面的全局上下文环境中。](2024年03月24日/AgentFL_Scaling_LLM-based_Fault_Localization_to_Project-Level_Context.md)

- [AVicuna: Audio-Visual LLM with Interleaver and Context-Boundary Alignment for Temporal Referential Dialogue](2024年03月24日/AVicuna_Audio-Visual_LLM_with_Interleaver_and_Context-Boundary_Alignment_for_Temporal_Referential_Dialogue.md)

    - [翻译: AVicuna 是一种音频-视觉LLM模型，通过集成交错器与上下文边界对齐技术，专为解决时间参照对话问题而设计。](2024年03月24日/AVicuna_Audio-Visual_LLM_with_Interleaver_and_Context-Boundary_Alignment_for_Temporal_Referential_Dialogue.md)

- [EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World](2024年03月24日/EgoExoLearn_A_Dataset_for_Bridging_Asynchronous_Ego-_and_Exo-centric_View_of_Procedural_Activities_in_Real_World.md)

    - [翻译: EgoExoLearn 数据集致力于衔接现实世界中程序性活动的自我中心与外部中心两种异步视角，为研究两者间的关联提供支持。](2024年03月24日/EgoExoLearn_A_Dataset_for_Bridging_Asynchronous_Ego-_and_Exo-centric_View_of_Procedural_Activities_in_Real_World.md)

- [Opportunities and challenges in the application of large artificial intelligence models in radiology](2024年03月24日/Opportunities_and_challenges_in_the_application_of_large_artificial_intelligence_models_in_radiology.md)

    - [翻译: 在放射学领域，大型AI模型的应用既带来了诸多机遇，也伴随着一系列挑战。](2024年03月24日/Opportunities_and_challenges_in_the_application_of_large_artificial_intelligence_models_in_radiology.md)

- [Is There a One-Model-Fits-All Approach to Information Extraction? Revisiting Task Definition Biases](2024年03月24日/Is_There_a_One-Model-Fits-All_Approach_to_Information_Extraction_Revisiting_Task_Definition_Biases.md)

    - [翻译: 是否有一种“一模通用”的信息抽取解决方案？让我们再次探讨任务定义偏差在其中的作用。](2024年03月24日/Is_There_a_One-Model-Fits-All_Approach_to_Information_Extraction_Revisiting_Task_Definition_Biases.md)

- [Concurrent Linguistic Error Detection (CLED) for Large Language Models](2024年03月24日/Concurrent_Linguistic_Error_Detection_(CLED)_for_Large_Language_Models.md)

    - [翻译: CLED技术应用于大型语言模型，旨在实时检测并修正其中的语言错误。](2024年03月24日/Concurrent_Linguistic_Error_Detection_(CLED)_for_Large_Language_Models.md)

- [Dia-LLaMA: Towards Large Language Model-driven CT Report Generation](2024年03月24日/Dia-LLaMA_Towards_Large_Language_Model-driven_CT_Report_Generation.md)

    - [翻译: 迈向由大型语言模型驱动的CT报告自动生成—— Dia-LLaMA项目，旨在利用大型语言模型的力量提升CT报告生成的质量与效率。](2024年03月24日/Dia-LLaMA_Towards_Large_Language_Model-driven_CT_Report_Generation.md)

- [Synthesize Step-by-Step: Tools, Templates and LLMs as Data Generators for Reasoning-Based Chart VQA](2024年03月24日/Synthesize_Step-by-Step_Tools,_Templates_and_LLMs_as_Data_Generators_for_Reasoning-Based_Chart_VQA.md)

    - [翻译: 步步解析法：利用工具、模板以及大型语言模型作为数据生成器，助力基于推理的图表视觉问答研究进一步优化后的](2024年03月24日/Synthesize_Step-by-Step_Tools,_Templates_and_LLMs_as_Data_Generators_for_Reasoning-Based_Chart_VQA.md)

- [Play to Your Strengths: Collaborative Intelligence of Conventional Recommender Models and Large Language Models](2024年03月24日/Play_to_Your_Strengths_Collaborative_Intelligence_of_Conventional_Recommender_Models_and_Large_Language_Models.md)

    - [翻译: 协同智慧，尽显所长：探究传统推荐模型与大型语言模型的合作潜力步骤详细解释：1. 翻译：发挥自身优势：常规推荐模型与大型语言模型之间的协同智能2. 优化：根据中文的语言表达习惯进行调整，使得语句更加流畅并具有吸引力。“发挥优势”这一表达更能体现“Play to Your Strengths”的含义，“探究合作潜力”则比“协同智能”更具生动性，因此得到最终的翻译结果为“协同智慧，尽显所长：探究传统推荐模型与大型语言模型的合作潜力”。](2024年03月24日/Play_to_Your_Strengths_Collaborative_Intelligence_of_Conventional_Recommender_Models_and_Large_Language_Models.md)

- [ChatDBG: An AI-Powered Debugging Assistant](2024年03月24日/ChatDBG_An_AI-Powered_Debugging_Assistant.md)

    - [翻译: ChatDBG 是一款集成了先进 AI 技术的智能调试助手。](2024年03月24日/ChatDBG_An_AI-Powered_Debugging_Assistant.md)

- [Enhanced Facet Generation with LLM Editing](2024年03月24日/Enhanced_Facet_Generation_with_LLM_Editing.md)

    - [翻译: 利用 LLM 编辑技术提升特征生成效果](2024年03月24日/Enhanced_Facet_Generation_with_LLM_Editing.md)

- [NonlinearSolve.jl: High-Performance and Robust Solvers for Systems of Nonlinear Equations in Julia](2024年03月24日/NonlinearSolve.jl_High-Performance_and_Robust_Solvers_for_Systems_of_Nonlinear_Equations_in_Julia.md)

    - [翻译: NonlinearSolve.jl 是一款专为 Julia 语言设计的高性能、强健的非线性方程组求解工具，致力于解决各类复杂的非线性系统问题。](2024年03月24日/NonlinearSolve.jl_High-Performance_and_Robust_Solvers_for_Systems_of_Nonlinear_Equations_in_Julia.md)

- [Large Language Models in Biomedical and Health Informatics: A Bibliometric Review](2024年03月24日/Large_Language_Models_in_Biomedical_and_Health_Informatics_A_Bibliometric_Review.md)

    - [翻译: 针对生物医学与健康信息学领域，本文进行了一项基于引文计量学的大型语言模型综述研究。](2024年03月24日/Large_Language_Models_in_Biomedical_and_Health_Informatics_A_Bibliometric_Review.md)

- [Engineering Safety Requirements for Autonomous Driving with Large Language Models](2024年03月24日/Engineering_Safety_Requirements_for_Autonomous_Driving_with_Large_Language_Models.md)

    - [翻译: 在利用大型语言模型开发自动驾驶技术时，制定和满足相应的安全工程要求至关重要。这项工作致力于探讨此类需求，并深入研究如何在大规模语言模型驱动的自动驾驶系统中确保其安全性。](2024年03月24日/Engineering_Safety_Requirements_for_Autonomous_Driving_with_Large_Language_Models.md)

- [Large Language Models Offer an Alternative to the Traditional Approach of Topic Modelling](2024年03月24日/Large_Language_Models_Offer_an_Alternative_to_the_Traditional_Approach_of_Topic_Modelling.md)

    - [翻译: 大型语言模型为传统主题建模开辟了新的路径，成为一种颇具吸引力的替代选择。](2024年03月24日/Large_Language_Models_Offer_an_Alternative_to_the_Traditional_Approach_of_Topic_Modelling.md)

- [CoverUp: Coverage-Guided LLM-Based Test Generation](2024年03月24日/CoverUp_Coverage-Guided_LLM-Based_Test_Generation.md)

    - [翻译: CoverUp：一种以覆盖率为导向的大规模语言模型测试生成技术，旨在利用覆盖率信息引导LLM进行高效的测试用例生成。](2024年03月24日/CoverUp_Coverage-Guided_LLM-Based_Test_Generation.md)

- [ALoRA: Allocating Low-Rank Adaptation for Fine-tuning Large Language Models](2024年03月24日/ALoRA_Allocating_Low-Rank_Adaptation_for_Fine-tuning_Large_Language_Models.md)

    - [翻译: ALoRA 是一种为大型语言模型微调分配低秩适应的技术。这一方法旨在通过合理分配低秩适应，优化大型语言模型在微调过程中的性能与效率。进一步优化：结果1：ALoRA（低秩适应分配法）专为大型语言模型的微调过程设计，致力于实现高效的低秩适应分配。](2024年03月24日/ALoRA_Allocating_Low-Rank_Adaptation_for_Fine-tuning_Large_Language_Models.md)

- [Designing Child-Centric AI Learning Environments: Insights from LLM-Enhanced Creative Project-Based Learning](2024年03月24日/Designing_Child-Centric_AI_Learning_Environments_Insights_from_LLM-Enhanced_Creative_Project-Based_Learning.md)

    - [翻译: 借鉴 LLW 强化创新项目实践教学的智慧，我们致力于设计更加注重儿童需求的人工智能学习环境。（注：此处将“LLM”误写为“LLW”，若原文是“LLM”，则应为“基于LLM强化的创新项目式学习带来的启示，我们专注于打造以孩子为核心的AI学习环境”。）](2024年03月24日/Designing_Child-Centric_AI_Learning_Environments_Insights_from_LLM-Enhanced_Creative_Project-Based_Learning.md)

- [A Little Leak Will Sink a Great Ship: Survey of Transparency for Large Language Models from Start to Finish](2024年03月24日/A_Little_Leak_Will_Sink_a_Great_Ship_Survey_of_Transparency_for_Large_Language_Models_from_Start_to_Finish.md)

    - [翻译: 细小疏漏足以倾覆巨轮：全面剖析大型语言模型全程透明度难题](2024年03月24日/A_Little_Leak_Will_Sink_a_Great_Ship_Survey_of_Transparency_for_Large_Language_Models_from_Start_to_Finish.md)

- [A Survey on Self-Supervised Pre-Training of Graph Foundation Models: A Knowledge-Based Perspective](2024年03月24日/A_Survey_on_Self-Supervised_Pre-Training_of_Graph_Foundation_Models_A_Knowledge-Based_Perspective.md)

    - [翻译: 本研究综述聚焦于从知识驱动的角度探讨图基础模型的自我监督预训练技术。](2024年03月24日/A_Survey_on_Self-Supervised_Pre-Training_of_Graph_Foundation_Models_A_Knowledge-Based_Perspective.md)

- [A Survey on Lexical Ambiguity Detection and Word Sense Disambiguation](2024年03月24日/A_Survey_on_Lexical_Ambiguity_Detection_and_Word_Sense_Disambiguation.md)

    - [翻译: 本篇综述深入探讨了词汇歧义检测与词义消解这一主题，涵盖了该领域的主要研究成果与技术进展。](2024年03月24日/A_Survey_on_Lexical_Ambiguity_Detection_and_Word_Sense_Disambiguation.md)

- [Enhancing Visual Continual Learning with Language-Guided Supervision](2024年03月24日/Enhancing_Visual_Continual_Learning_with_Language-Guided_Supervision.md)

    - [翻译: 借助语言引导的监督方式，提升视觉连续学习效果](2024年03月24日/Enhancing_Visual_Continual_Learning_with_Language-Guided_Supervision.md)

- [Conversational Grounding: Annotation and Analysis of Grounding Acts and Grounding Units](2024年03月25日/Conversational_Grounding_Annotation_and_Analysis_of_Grounding_Acts_and_Grounding_Units.md)

    - [翻译: 对话锚定研究：深入标注与分析锚定行为及锚定单元](2024年03月25日/Conversational_Grounding_Annotation_and_Analysis_of_Grounding_Acts_and_Grounding_Units.md)

- [Harnessing the power of LLMs for normative reasoning in MASs](2024年03月25日/Harnessing_the_power_of_LLMs_for_normative_reasoning_in_MASs.md)

    - [翻译: 我们致力于驾驭 LLMs 的力量，以应用于 MASs 中的规范推理环节，探索其在多智能体协作与决策过程中的潜力。进一步优化后的](2024年03月25日/Harnessing_the_power_of_LLMs_for_normative_reasoning_in_MASs.md)

- [Norm Violation Detection in Multi-Agent Systems using Large Language Models: A Pilot Study](2024年03月25日/Norm_Violation_Detection_in_Multi-Agent_Systems_using_Large_Language_Models_A_Pilot_Study.md)

    - [翻译: 本研究采用大型语言模型，针对多智能体系统中的规范违反行为检测开展了一项开创性探索。](2024年03月25日/Norm_Violation_Detection_in_Multi-Agent_Systems_using_Large_Language_Models_A_Pilot_Study.md)

- [Towards Automatic Evaluation for LLMs' Clinical Capabilities: Metric, Data, and Algorithm](2024年03月25日/Towards_Automatic_Evaluation_for_LLMs'_Clinical_Capabilities_Metric,_Data,_and_Algorithm.md)

    - [翻译: 迈向自动评估 LLMs 临床能力的新阶段，我们将深入探讨度量标准的选择、数据集的构建以及适用于该场景的算法设计。](2024年03月25日/Towards_Automatic_Evaluation_for_LLMs'_Clinical_Capabilities_Metric,_Data,_and_Algorithm.md)

- [Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation](2024年03月25日/Re2LLM_Reflective_Reinforcement_Large_Language_Model_for_Session-based_Recommendation.md)

    - [翻译: Re2LLM 是一种专为基于会话的推荐场景设计的反射强化大型语言模型。通过结合强化学习与大型语言模型的优势，Re2LLM 实现了在会话过程中动态理解和优化推荐效果的能力。](2024年03月25日/Re2LLM_Reflective_Reinforcement_Large_Language_Model_for_Session-based_Recommendation.md)

- [A Robotic Skill Learning System Built Upon Diffusion Policies and Foundation Models](2024年03月25日/A_Robotic_Skill_Learning_System_Built_Upon_Diffusion_Policies_and_Foundation_Models.md)

    - [翻译: 我们构建了一种创新的机器人技能学习系统，该系统巧妙融合了扩散策略与基础模型的优势。这一系统利用扩散策略进行高效决策制定，同时借助基础模型的强大泛化能力，共同促进机器人的技能习得与提升。](2024年03月25日/A_Robotic_Skill_Learning_System_Built_Upon_Diffusion_Policies_and_Foundation_Models.md)

- [Virtual Co-Pilot: Multimodal Large Language Model-enabled Quick-access Procedures for Single Pilot Operations](2024年03月25日/Virtual_Co-Pilot_Multimodal_Large_Language_Model-enabled_Quick-access_Procedures_for_Single_Pilot_Operations.md)

    - [翻译: 虚拟副驾驶：利用多模态大型语言模型赋能单飞行员操作，实现快速访问程序解释说明：](2024年03月25日/Virtual_Co-Pilot_Multimodal_Large_Language_Model-enabled_Quick-access_Procedures_for_Single_Pilot_Operations.md)

- [All Artificial, Less Intelligence: GenAI through the Lens of Formal Verification](2024年03月25日/All_Artificial,_Less_Intelligence_GenAI_through_the_Lens_of_Formal_Verification.md)

    - [翻译: 一切皆人工打造，智能尚欠火候——透过形式验证镜头透视GenAI](2024年03月25日/All_Artificial,_Less_Intelligence_GenAI_through_the_Lens_of_Formal_Verification.md)

- [ProCQA: A Large-scale Community-based Programming Question Answering Dataset for Code Search](2024年03月25日/ProCQA_A_Large-scale_Community-based_Programming_Question_Answering_Dataset_for_Code_Search.md)

    - [翻译: ProCQA 是一个面向代码搜索的大规模社区编程问答数据集，涵盖了丰富的编程问题与解答资源。](2024年03月25日/ProCQA_A_Large-scale_Community-based_Programming_Question_Answering_Dataset_for_Code_Search.md)

- [Synapse: Learning Preferential Concepts from Visual Demonstrations](2024年03月25日/Synapse_Learning_Preferential_Concepts_from_Visual_Demonstrations.md)

    - [翻译: Synapse项目致力于从视觉演示中提炼并学习优先级较高的概念。](2024年03月25日/Synapse_Learning_Preferential_Concepts_from_Visual_Demonstrations.md)

- [Investigation of the effectiveness of applying ChatGPT in Dialogic Teaching Using Electroencephalography](2024年03月25日/Investigation_of_the_effectiveness_of_applying_ChatGPT_in_Dialogic_Teaching_Using_Electroencephalography.md)

    - [翻译: 本研究采用脑电图技术，深入探讨了将ChatGPT应用于对话式教学的有效性。](2024年03月25日/Investigation_of_the_effectiveness_of_applying_ChatGPT_in_Dialogic_Teaching_Using_Electroencephalography.md)

- [RU22Fact: Optimizing Evidence for Multilingual Explainable Fact-Checking on Russia-Ukraine Conflict](2024年03月25日/RU22Fact_Optimizing_Evidence_for_Multilingual_Explainable_Fact-Checking_on_Russia-Ukraine_Conflict.md)

    - [翻译: RU22Fact项目致力于优化在俄乌冲突相关多语种环境下进行可解释事实核查的证据，提升核查效能与准确性。](2024年03月25日/RU22Fact_Optimizing_Evidence_for_Multilingual_Explainable_Fact-Checking_on_Russia-Ukraine_Conflict.md)

- [CLHA: A Simple yet Effective Contrastive Learning Framework for Human Alignment](2024年03月25日/CLHA_A_Simple_yet_Effective_Contrastive_Learning_Framework_for_Human_Alignment.md)

    - [翻译: CLHA 是一种针对人类行为对齐的简洁高效对比学习方案。](2024年03月25日/CLHA_A_Simple_yet_Effective_Contrastive_Learning_Framework_for_Human_Alignment.md)

- [TrustAI at SemEval-2024 Task 8: A Comprehensive Analysis of Multi-domain Machine Generated Text Detection Techniques](2024年03月25日/TrustAI_at_SemEval-2024_Task_8_A_Comprehensive_Analysis_of_Multi-domain_Machine_Generated_Text_Detection_Techniques.md)

    - [翻译: 在 SemEval-2024 第 8 项任务中，TrustAI 对多领域机器生成文本检测技术进行了深入且全面的研究分析。](2024年03月25日/TrustAI_at_SemEval-2024_Task_8_A_Comprehensive_Analysis_of_Multi-domain_Machine_Generated_Text_Detection_Techniques.md)

- [Can Large Language Models (or Humans) Distill Text?](2024年03月25日/Can_Large_Language_Models_(or_Humans)_Distill_Text.md)

    - [翻译: 大型语言模型乃至人类是否具备提炼文本的能力？](2024年03月25日/Can_Large_Language_Models_(or_Humans)_Distill_Text.md)

- [NSINA: A News Corpus for Sinhala](2024年03月25日/NSINA_A_News_Corpus_for_Sinhala.md)

    - [翻译: NSINA 是一个专门针对僧伽罗语新闻领域的语料库，旨在为该语言的研究与应用提供丰富的新闻文本资源。](2024年03月25日/NSINA_A_News_Corpus_for_Sinhala.md)

- [Elysium: Exploring Object-level Perception in Videos via MLLM](2024年03月25日/Elysium_Exploring_Object-level_Perception_in_Videos_via_MLLM.md)

    - [翻译: Elysium项目致力于借助多模态预训练语言模型，在视频内容中深入探究对象级别的感知能力。](2024年03月25日/Elysium_Exploring_Object-level_Perception_in_Videos_via_MLLM.md)

- [DOrA: 3D Visual Grounding with Order-Aware Referring](2024年03月25日/DOrA_3D_Visual_Grounding_with_Order-Aware_Referring.md)

    - [翻译: DOrA 是一种创新的三维视觉定位方法，它特别强调并利用了顺序感知引用机制，实现了对三维空间中目标对象的精准定位。](2024年03月25日/DOrA_3D_Visual_Grounding_with_Order-Aware_Referring.md)

- [Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art](2024年03月25日/Hallucination_Detection_in_Foundation_Models_for_Decision-Making_A_Flexible_Definition_and_Review_of_the_State_of_the_Art.md)

    - [翻译: 针对决策型基础模型中的幻觉检测问题，本研究提出了一种灵活的定义，并对该领域的最新进展进行了全面回顾与总结。](2024年03月25日/Hallucination_Detection_in_Foundation_Models_for_Decision-Making_A_Flexible_Definition_and_Review_of_the_State_of_the_Art.md)

- [LLMs Are Few-Shot In-Context Low-Resource Language Learners](2024年03月25日/LLMs_Are_Few-Shot_In-Context_Low-Resource_Language_Learners.md)

    - [翻译: LLMs能够以少量示例，在上下文中高效学习低资源语言。](2024年03月25日/LLMs_Are_Few-Shot_In-Context_Low-Resource_Language_Learners.md)

- [LARA: Linguistic-Adaptive Retrieval-Augmented LLMs for Multi-Turn Intent Classification](2024年03月25日/LARA_Linguistic-Adaptive_Retrieval-Augmented_LLMs_for_Multi-Turn_Intent_Classification.md)

    - [翻译: LARA 是一种针对多轮意图分类任务设计的适应性语言检索增强型大型语言模型。它通过融合语言理解和检索增强技术，有效提升多轮对话场景下的意图识别能力。（注：在给出的结果2中，我尽可能保留了原文的术语并使其更符合中文表述习惯，但未提供具体研究内容的详细描述，因为原句是标题形式，为了简洁与生动，通常会在翻译时强调核心概念和应用场景。）](2024年03月25日/LARA_Linguistic-Adaptive_Retrieval-Augmented_LLMs_for_Multi-Turn_Intent_Classification.md)

- [KIT-19: A Comprehensive Korean Instruction Toolkit on 19 Tasks for Fine-Tuning Korean Large Language Models](2024年03月25日/KIT-19_A_Comprehensive_Korean_Instruction_Toolkit_on_19_Tasks_for_Fine-Tuning_Korean_Large_Language_Models.md)

    - [翻译: KIT-19 是一套综合性的工具包，专注于通过19项任务对韩国大型语言模型进行精细调整训练，提供全方位的韩语文本处理支持。](2024年03月25日/KIT-19_A_Comprehensive_Korean_Instruction_Toolkit_on_19_Tasks_for_Fine-Tuning_Korean_Large_Language_Models.md)

- [CodeS: Natural Language to Code Repository via Multi-Layer Sketch](2024年03月25日/CodeS_Natural_Language_to_Code_Repository_via_Multi-Layer_Sketch.md)

    - [翻译: CodeS 是一个创新方法，通过多层草图机制，实现从自然语言描述到代码仓库的精准转化。](2024年03月25日/CodeS_Natural_Language_to_Code_Repository_via_Multi-Layer_Sketch.md)

- [If CLIP Could Talk: Understanding Vision-Language Model Representations Through Their Preferred Concept Descriptions](2024年03月25日/If_CLIP_Could_Talk_Understanding_Vision-Language_Model_Representations_Through_Their_Preferred_Concept_Descriptions.md)

    - [翻译: 设想 CLIP 能言，我们通过探究其倾向使用的概念描述方式，以深入理解视觉-语言模型的内在表征机制。（注：由于原句较短且生动活泼，直译已经相对简洁优雅，因此步骤2在保持原意的基础上稍作调整，使其更符合中文阅读习惯。）](2024年03月25日/If_CLIP_Could_Talk_Understanding_Vision-Language_Model_Representations_Through_Their_Preferred_Concept_Descriptions.md)

- [Evaluating Large Language Models with Runtime Behavior of Program Execution](2024年03月25日/Evaluating_Large_Language_Models_with_Runtime_Behavior_of_Program_Execution.md)

    - [翻译: 在本研究中，我们提出通过程序执行过程中的实际运行时行为来评估大型语言模型的表现，从而揭示模型在真实应用环境下的性能与适应性。](2024年03月25日/Evaluating_Large_Language_Models_with_Runtime_Behavior_of_Program_Execution.md)

- [InstUPR : Instruction-based Unsupervised Passage Reranking with Large Language Models](2024年03月25日/InstUPR__Instruction-based_Unsupervised_Passage_Reranking_with_Large_Language_Models.md)

    - [翻译: InstUPR 是一种创新的无监督段落重排序技术，通过利用大型语言模型的力量，仅依赖于指令信息就能有效提升排序效果。](2024年03月25日/InstUPR__Instruction-based_Unsupervised_Passage_Reranking_with_Large_Language_Models.md)

- [: Natural and Universal Adversarial Attacks on Prompt-based Language Models](2024年03月25日/_Natural_and_Universal_Adversarial_Attacks_on_Prompt-based_Language_Models.md)

    - [翻译: 针对基于提示的语言模型，探究其面临的自然且普适的对抗性攻击策略](2024年03月25日/_Natural_and_Universal_Adversarial_Attacks_on_Prompt-based_Language_Models.md)

- [An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations](2024年03月25日/An_Experiment_with_the_Use_of_ChatGPT_for_LCSH_Subject_Assignment_on_Electronic_Theses_and_Dissertations.md)

    - [翻译: 本实验探讨了利用ChatGPT为电子学位论文自动赋予LCSH主题标签的可能性，通过实际操作探究其在该任务中的效果与潜力。](2024年03月25日/An_Experiment_with_the_Use_of_ChatGPT_for_LCSH_Subject_Assignment_on_Electronic_Theses_and_Dissertations.md)

- [Leveraging Large Language Model to Generate a Novel Metaheuristic Algorithm with CRISPE Framework](2024年03月25日/Leveraging_Large_Language_Model_to_Generate_a_Novel_Metaheuristic_Algorithm_with_CRISPE_Framework.md)

    - [翻译: 运用CRISPE框架及大型语言模型的力量，创新性地生成一种新的元启发式算法](2024年03月25日/Leveraging_Large_Language_Model_to_Generate_a_Novel_Metaheuristic_Algorithm_with_CRISPE_Framework.md)

- [How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation](2024年03月25日/How_Reliable_is_Your_Simulator_Analysis_on_the_Limitations_of_Current_LLM-based_User_Simulators_for_Conversational_Recommendation.md)

    - [翻译: 探究当今基于LLM的用户模拟器在对话式推荐情境下的可靠性，深入分析其局限性所在。](2024年03月25日/How_Reliable_is_Your_Simulator_Analysis_on_the_Limitations_of_Current_LLM-based_User_Simulators_for_Conversational_Recommendation.md)

- [LLM Agent Operating System](2024年03月25日/LLM_Agent_Operating_System.md)

    - [翻译: LLM 智能体操作系统是指专为大型语言模型设计的操作系统，它能够支持和管理 LLM 的运行环境与功能，以实现高效的交互和控制。进一步优化： LLMAgentOS（大型语言模型智能体操作系统）是针对 LLM 系统量身打造的操作系统，致力于优化其功能管理和运行环境，从而在各类应用场景下提供更为流畅、智能的交互体验。](2024年03月25日/LLM_Agent_Operating_System.md)

- [Do LLM Agents Have Regret? A Case Study in Online Learning and Games](2024年03月25日/Do_LLM_Agents_Have_Regret_A_Case_Study_in_Online_Learning_and_Games.md)

    - [翻译: 在在线学习和游戏中，LLM 代理是否会产生“遗憾”？本文以案例研究的方式对此进行探讨。](2024年03月25日/Do_LLM_Agents_Have_Regret_A_Case_Study_in_Online_Learning_and_Games.md)

- [An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems](2024年03月25日/An_LLM-Based_Digital_Twin_for_Optimizing_Human-in-the_Loop_Systems.md)

    - [翻译: 针对人机协同系统的优化，我们提出了一种基于大型语言模型（LLM）的数字孪生方案。该技术利用LLM的强大能力，旨在提升人机交互系统的效能与智能性。](2024年03月25日/An_LLM-Based_Digital_Twin_for_Optimizing_Human-in-the_Loop_Systems.md)

- [Understanding Long Videos in One Multimodal Language Model Pass](2024年03月25日/Understanding_Long_Videos_in_One_Multimodal_Language_Model_Pass.md)

    - [翻译: 通过单次多模态语言模型推理解析长视频内容](2024年03月25日/Understanding_Long_Videos_in_One_Multimodal_Language_Model_Pass.md)

- [DreamLIP: Language-Image Pre-training with Long Captions](2024年03月25日/DreamLIP_Language-Image_Pre-training_with_Long_Captions.md)

    - [翻译: DreamLIP：通过长篇描述实现语言与图像的联合预训练](2024年03月25日/DreamLIP_Language-Image_Pre-training_with_Long_Captions.md)

- [Visual CoT: Unleashing Chain-of-Thought Reasoning in Multi-Modal Language Models](2024年03月25日/Visual_CoT_Unleashing_Chain-of-Thought_Reasoning_in_Multi-Modal_Language_Models.md)

    - [翻译: Visual CoT：激活多模态语言模型中的链式思维推理能力，旨在解锁其在处理多模态信息时进行深度逻辑推理的潜力。](2024年03月25日/Visual_CoT_Unleashing_Chain-of-Thought_Reasoning_in_Multi-Modal_Language_Models.md)

- [Composed Video Retrieval via Enriched Context and Discriminative Embeddings](2024年03月25日/Composed_Video_Retrieval_via_Enriched_Context_and_Discriminative_Embeddings.md)

    - [翻译: 通过增强上下文信息与区分性嵌入技术，本研究提出了一种新型的视频片段检索方法。](2024年03月25日/Composed_Video_Retrieval_via_Enriched_Context_and_Discriminative_Embeddings.md)

- [Comp4D: LLM-Guided Compositional 4D Scene Generation](2024年03月25日/Comp4D_LLM-Guided_Compositional_4D_Scene_Generation.md)

    - [翻译: Comp4D 是一项利用大型语言模型（LLM）指导的组合式 4D 场景生成技术，旨在通过 LLN 的智能引导，构建并生成具有时间维度的复杂场景内容。](2024年03月25日/Comp4D_LLM-Guided_Compositional_4D_Scene_Generation.md)

- [Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance](2024年03月25日/Data_Mixing_Laws_Optimizing_Data_Mixtures_by_Predicting_Language_Modeling_Performance.md)

    - [翻译: 数据混合定律：探究通过预测语言模型性能来优化数据混合的方法进一步优化后的翻译结果2（更简洁优雅通顺）：“数据混合法则：通过预估语言模型表现优化数据组合”](2024年03月25日/Data_Mixing_Laws_Optimizing_Data_Mixtures_by_Predicting_Language_Modeling_Performance.md)

- [Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators](2024年03月25日/Aligning_with_Human_Judgement_The_Role_of_Pairwise_Preference_in_Large_Language_Model_Evaluators.md)

    - [翻译: 探究大型语言模型评估器如何通过成对偏好与人类判断保持一致，揭示成对偏好在决定模型质量中的关键作用。](2024年03月25日/Aligning_with_Human_Judgement_The_Role_of_Pairwise_Preference_in_Large_Language_Model_Evaluators.md)

- [Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling](2024年03月25日/Reinforcement_Learning-based_Recommender_Systems_with_Large_Language_Models_for_State_Reward_and_Action_Modeling.md)

    - [翻译: 运用大型语言模型实现强化学习推荐系统，以精准模拟状态奖励及动作策略，提升系统智能性和个性化推荐效果。](2024年03月25日/Reinforcement_Learning-based_Recommender_Systems_with_Large_Language_Models_for_State_Reward_and_Action_Modeling.md)

- [SPACE-IDEAS: A Dataset for Salient Information Detection in Space Innovation](2024年03月25日/SPACE-IDEAS_A_Dataset_for_Salient_Information_Detection_in_Space_Innovation.md)

    - [翻译: SPACE-IDEAS 数据集：专为探索太空创新领域内关键信息检测而设计。](2024年03月25日/SPACE-IDEAS_A_Dataset_for_Salient_Information_Detection_in_Space_Innovation.md)

- [PropTest: Automatic Property Testing for Improved Visual Programming](2024年03月25日/PropTest_Automatic_Property_Testing_for_Improved_Visual_Programming.md)

    - [翻译: PropTest 是一种自动属性测试工具，旨在提升视觉编程体验。它通过自动化检测和验证程序属性，助力优化视觉编程过程。](2024年03月25日/PropTest_Automatic_Property_Testing_for_Improved_Visual_Programming.md)

- [New Intent Discovery with Attracting and Dispersing Prototype](2024年03月25日/New_Intent_Discovery_with_Attracting_and_Dispersing_Prototype.md)

    - [翻译: 新颖意图发现技术引入了“吸引与分散原型”方法，旨在有效探索并揭示潜在的新意图。](2024年03月25日/New_Intent_Discovery_with_Attracting_and_Dispersing_Prototype.md)

- [ChatGPT "contamination": estimating the prevalence of LLMs in the scholarly literature](2024年03月25日/ChatGPT_contamination_estimating_the_prevalence_of_LLMs_in_the_scholarly_literature.md)

    - [翻译: ChatGPT 的“污染效应”：探究 LLM 在学术文献领域的普遍渗透率步骤分解：](2024年03月25日/ChatGPT_contamination_estimating_the_prevalence_of_LLMs_in_the_scholarly_literature.md)

- [SIP: Autotuning GPU Native Schedules via Stochastic Instruction Perturbation](2024年03月25日/SIP_Autotuning_GPU_Native_Schedules_via_Stochastic_Instruction_Perturbation.md)

    - [翻译: SIP 方法提出通过随机指令扰动技术实现 GPU 本地调度方案的自动化调优。进一步精炼：](2024年03月25日/SIP_Autotuning_GPU_Native_Schedules_via_Stochastic_Instruction_Perturbation.md)

- [Cross-lingual Contextualized Phrase Retrieval](2024年03月25日/Cross-lingual_Contextualized_Phrase_Retrieval.md)

    - [翻译: 跨语言情境化短语检索技术步骤解释：](2024年03月25日/Cross-lingual_Contextualized_Phrase_Retrieval.md)

- [Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making](2024年03月25日/Towards_Human-AI_Deliberation_Design_and_Evaluation_of_LLM-Empowered_Deliberative_AI_for_AI-Assisted_Decision-Making.md)

    - [翻译: 致力于打造人机协同决策的新高度，本研究设计并评估了一种基于大型语言模型赋能的审议式人工智能系统，以助力于人工智能辅助决策过程。](2024年03月25日/Towards_Human-AI_Deliberation_Design_and_Evaluation_of_LLM-Empowered_Deliberative_AI_for_AI-Assisted_Decision-Making.md)

- [TEI2GO: A Multilingual Approach for Fast Temporal Expression Identification](2024年03月25日/TEI2GO_A_Multilingual_Approach_for_Fast_Temporal_Expression_Identification.md)

    - [翻译: TEI2GO 是一个针对多语种环境设计的快速时间表达识别方案。](2024年03月25日/TEI2GO_A_Multilingual_Approach_for_Fast_Temporal_Expression_Identification.md)

- [Iterative Refinement of Project-Level Code Context for Precise Code Generation with Compiler Feedback](2024年03月25日/Iterative_Refinement_of_Project-Level_Code_Context_for_Precise_Code_Generation_with_Compiler_Feedback.md)

    - [翻译: 利用编译器反馈，在项目级别的代码上下文中进行迭代优化，以提高代码生成的精准度。](2024年03月25日/Iterative_Refinement_of_Project-Level_Code_Context_for_Precise_Code_Generation_with_Compiler_Feedback.md)

- [GloSIS: The Global Soil Information System Web Ontology](2024年03月25日/GloSIS_The_Global_Soil_Information_System_Web_Ontology.md)

    - [翻译: GloSIS——全球土壤信息系统的网络本体构建，旨在创建一个统一、结构化的土壤知识体系，通过网络本体的方式组织与关联全球范围内的土壤信息资源。](2024年03月25日/GloSIS_The_Global_Soil_Information_System_Web_Ontology.md)

- [Chain-of-Action: Faithful and Multimodal Question Answering through Large Language Models](2024年03月25日/Chain-of-Action_Faithful_and_Multimodal_Question_Answering_through_Large_Language_Models.md)

    - [翻译: Chain-of-Action：借助大型语言模型，实现准确且多模态的问题解答](2024年03月25日/Chain-of-Action_Faithful_and_Multimodal_Question_Answering_through_Large_Language_Models.md)

- [Disambiguate Entity Matching through Relation Discovery with Large Language Models](2024年03月25日/Disambiguate_Entity_Matching_through_Relation_Discovery_with_Large_Language_Models.md)

    - [翻译: 利用大型语言模型发掘关系，实现实体匹配的精确区分](2024年03月25日/Disambiguate_Entity_Matching_through_Relation_Discovery_with_Large_Language_Models.md)

- [Language Models are Free Boosters for Biomedical Imaging Tasks](2024年03月25日/Language_Models_are_Free_Boosters_for_Biomedical_Imaging_Tasks.md)

    - [翻译: 语言模型为生物医学成像任务提供了免费的加速支持。](2024年03月25日/Language_Models_are_Free_Boosters_for_Biomedical_Imaging_Tasks.md)

- [Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models](2024年03月25日/Don't_Listen_To_Me_Understanding_and_Exploring_Jailbreak_Prompts_of_Large_Language_Models.md)

    - [翻译: 别听我的：深入探究大型语言模型的越狱指令](2024年03月25日/Don't_Listen_To_Me_Understanding_and_Exploring_Jailbreak_Prompts_of_Large_Language_Models.md)

- [JMultiWOZ: A Large-Scale Japanese Multi-Domain Task-Oriented Dialogue Dataset](2024年03月25日/JMultiWOZ_A_Large-Scale_Japanese_Multi-Domain_Task-Oriented_Dialogue_Dataset.md)

    - [翻译: JMultiWOZ：涵盖多个领域的大规模日语任务导向对话数据集](2024年03月25日/JMultiWOZ_A_Large-Scale_Japanese_Multi-Domain_Task-Oriented_Dialogue_Dataset.md)

- [ALISA: Accelerating Large Language Model Inference via Sparsity-Aware KV Caching](2024年03月25日/ALISA_Accelerating_Large_Language_Model_Inference_via_Sparsity-Aware_KV_Caching.md)

    - [翻译: ALISA技术：利用键值缓存的稀疏性特性，加速大型语言模型的推理过程。](2024年03月25日/ALISA_Accelerating_Large_Language_Model_Inference_via_Sparsity-Aware_KV_Caching.md)

- [Visual Hallucination: Definition, Quantification, and Prescriptive Remediations](2024年03月25日/Visual_Hallucination_Definition,_Quantification,_and_Prescriptive_Remediations.md)

    - [翻译: 视觉幻觉是指在没有相应外部刺激的情况下，人脑产生的虚假视觉体验。对这种现象的量化研究有助于我们更好地理解其产生机制，并为制定有效的干预措施提供依据。](2024年03月25日/Visual_Hallucination_Definition,_Quantification,_and_Prescriptive_Remediations.md)

- [InternLM2 Technical Report](2024年03月25日/InternLM2_Technical_Report.md)

    - [翻译: InternLM2 技术研究报告](2024年03月25日/InternLM2_Technical_Report.md)

- [Automate Knowledge Concept Tagging on Math Questions with LLMs](2024年03月25日/Automate_Knowledge_Concept_Tagging_on_Math_Questions_with_LLMs.md)

    - [翻译: 借助大型语言模型，实现数学问题知识概念的自动标注。](2024年03月25日/Automate_Knowledge_Concept_Tagging_on_Math_Questions_with_LLMs.md)

- [A Hybrid Approach To Aspect Based Sentiment Analysis Using Transfer Learning](2024年03月25日/A_Hybrid_Approach_To_Aspect_Based_Sentiment_Analysis_Using_Transfer_Learning.md)

    - [翻译: 本研究提出了一种融合方法，通过迁移学习来加强基于方面的情感分析，旨在提升情感识别的准确性和效率。](2024年03月25日/A_Hybrid_Approach_To_Aspect_Based_Sentiment_Analysis_Using_Transfer_Learning.md)

- [TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models](2024年03月25日/TwoStep_Multi-agent_Task_Planning_using_Classical_Planners_and_Large_Language_Models.md)

    - [翻译: TwoStep：结合传统规划器与大型语言模型实现多智能体任务协同规划](2024年03月25日/TwoStep_Multi-agent_Task_Planning_using_Classical_Planners_and_Large_Language_Models.md)

- [Temporal and Semantic Evaluation Metrics for Foundation Models in Post-Hoc Analysis of Robotic Sub-tasks](2024年03月25日/Temporal_and_Semantic_Evaluation_Metrics_for_Foundation_Models_in_Post-Hoc_Analysis_of_Robotic_Sub-tasks.md)

    - [翻译: 在对机器人子任务进行事后分析时，我们关注基础模型的时间和语义评估指标。](2024年03月25日/Temporal_and_Semantic_Evaluation_Metrics_for_Foundation_Models_in_Post-Hoc_Analysis_of_Robotic_Sub-tasks.md)

- [SeSaMe: A Framework to Simulate Self-Reported Ground Truth for Mental Health Sensing Studies](2024年03月25日/SeSaMe_A_Framework_to_Simulate_Self-Reported_Ground_Truth_for_Mental_Health_Sensing_Studies.md)

    - [翻译: SeSaMe：构建模拟心理健康自评真实数据的框架](2024年03月25日/SeSaMe_A_Framework_to_Simulate_Self-Reported_Ground_Truth_for_Mental_Health_Sensing_Studies.md)

- [A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection](2024年03月25日/A_Comprehensive_Study_of_the_Capabilities_of_Large_Language_Models_for_Vulnerability_Detection.md)

    - [翻译: 本研究全面探讨了大型语言模型在识别安全漏洞方面的能力。](2024年03月25日/A_Comprehensive_Study_of_the_Capabilities_of_Large_Language_Models_for_Vulnerability_Detection.md)

- [Generation of Asset Administration Shell with Large Language Model Agents: Interoperability in Digital Twins with Semantic Node](2024年03月25日/Generation_of_Asset_Administration_Shell_with_Large_Language_Model_Agents_Interoperability_in_Digital_Twins_with_Semantic_Node.md)

    - [翻译: 借助大型语言模型代理，我们能够生成资产管理壳，实现数字孪生中带有语义节点的无缝互操作性。](2024年03月25日/Generation_of_Asset_Administration_Shell_with_Large_Language_Model_Agents_Interoperability_in_Digital_Twins_with_Semantic_Node.md)

- [CYGENT: A cybersecurity conversational agent with log summarization powered by GPT-3](2024年03月25日/CYGENT_A_cybersecurity_conversational_agent_with_log_summarization_powered_by_GPT-3.md)

    - [翻译: CYGENT：一款搭载了GPT-3技术的网络安全智能对话助手，擅长进行日志智能摘要。](2024年03月25日/CYGENT_A_cybersecurity_conversational_agent_with_log_summarization_powered_by_GPT-3.md)

- [RepairAgent: An Autonomous, LLM-Based Agent for Program Repair](2024年03月25日/RepairAgent_An_Autonomous,_LLM-Based_Agent_for_Program_Repair.md)

    - [翻译: RepairAgent：一款利用大型语言模型技术的自动程序修复智能代理。](2024年03月25日/RepairAgent_An_Autonomous,_LLM-Based_Agent_for_Program_Repair.md)

- [MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution](2024年03月26日/MAGIS_LLM-Based_Multi-Agent_Framework_for_GitHub_Issue_Resolution.md)

    - [翻译: MAGIS：一款以大型语言模型为基础，专为GitHub问题处理设计的多智能体框架。](2024年03月26日/MAGIS_LLM-Based_Multi-Agent_Framework_for_GitHub_Issue_Resolution.md)

- [LISA: Layerwise Importance Sampling for Memory-Efficient Large Language Model Fine-Tuning](2024年03月26日/LISA_Layerwise_Importance_Sampling_for_Memory-Efficient_Large_Language_Model_Fine-Tuning.md)

    - [翻译: LISA：逐层重要性抽样技术，助力内存优化的大型语言模型精调](2024年03月26日/LISA_Layerwise_Importance_Sampling_for_Memory-Efficient_Large_Language_Model_Fine-Tuning.md)

- [Large scale paired antibody language models](2024年03月26日/Large_scale_paired_antibody_language_models.md)

    - [翻译: 在抗体语言模型领域，我们采用了大规模的配对方法，以提高模型的性能和准确性。](2024年03月26日/Large_scale_paired_antibody_language_models.md)

- [Addressing Social Misattributions of Large Language Models: An HCXAI-based Approach](2024年03月26日/Addressing_Social_Misattributions_of_Large_Language_Models_An_HCXAI-based_Approach.md)

    - [翻译: 应对大型语言模型的社会误解：采用HCXAI策略进行解决](2024年03月26日/Addressing_Social_Misattributions_of_Large_Language_Models_An_HCXAI-based_Approach.md)

- [Exploring LLMs as a Source of Targeted Synthetic Textual Data to Minimize High Confidence Misclassifications](2024年03月26日/Exploring_LLMs_as_a_Source_of_Targeted_Synthetic_Textual_Data_to_Minimize_High_Confidence_Misclassifications.md)

    - [翻译: 本研究致力于研究大型语言模型，将其作为生成针对性合成文本数据的新途径，目的是减少那些过于自信的错误分类情况。](2024年03月26日/Exploring_LLMs_as_a_Source_of_Targeted_Synthetic_Textual_Data_to_Minimize_High_Confidence_Misclassifications.md)

- [ChroniclingAmericaQA: A Large-scale Question Answering Dataset based on Historical American Newspaper Pages](2024年03月26日/ChroniclingAmericaQA_A_Large-scale_Question_Answering_Dataset_based_on_Historical_American_Newspaper_Pages.md)

    - [翻译: 《美国纪事》问答：源自历史报纸的大规模问答数据集](2024年03月26日/ChroniclingAmericaQA_A_Large-scale_Question_Answering_Dataset_based_on_Historical_American_Newspaper_Pages.md)

- [Verbing Weirds Language (Models): Evaluation of English Zero-Derivation in Five LLMs](2024年03月26日/Verbing_Weirds_Language_(Models)_Evaluation_of_English_Zero-Derivation_in_Five_LLMs.md)

    - [翻译: 动词化让语言变得古怪（模型也受影响）：探究五种大型语言模型对英语零派生词的评估。](2024年03月26日/Verbing_Weirds_Language_(Models)_Evaluation_of_English_Zero-Derivation_in_Five_LLMs.md)

- [ArabicaQA: A Comprehensive Dataset for Arabic Question Answering](2024年03月26日/ArabicaQA_A_Comprehensive_Dataset_for_Arabic_Question_Answering.md)

    - [翻译: ArabicaQA：一个全面的阿拉伯语问答数据集](2024年03月26日/ArabicaQA_A_Comprehensive_Dataset_for_Arabic_Question_Answering.md)

- [Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation](2024年03月26日/Hierarchical_Open-Vocabulary_3D_Scene_Graphs_for_Language-Grounded_Robot_Navigation.md)

    - [翻译: 为实现与语言相关的机器人导航，我们构建了分层的开放词汇三维场景图。](2024年03月26日/Hierarchical_Open-Vocabulary_3D_Scene_Graphs_for_Language-Grounded_Robot_Navigation.md)

- [Assessment of Multimodal Large Language Models in Alignment with Human Values](2024年03月26日/Assessment_of_Multimodal_Large_Language_Models_in_Alignment_with_Human_Values.md)

    - [翻译: 本文探讨了多模态大型语言模型与人类价值观的契合度，旨在评估这些模型在理解和体现人类价值方面的表现。](2024年03月26日/Assessment_of_Multimodal_Large_Language_Models_in_Alignment_with_Human_Values.md)

- [Accelerating Radio Spectrum Regulation Workflows with Large Language Models (LLMs)](2024年03月26日/Accelerating_Radio_Spectrum_Regulation_Workflows_with_Large_Language_Models_(LLMs).md)

    - [翻译: 借助大型语言模型（LLMs），我们能够加快无线电频谱监管的工作流程，提升效率。](2024年03月26日/Accelerating_Radio_Spectrum_Regulation_Workflows_with_Large_Language_Models_(LLMs).md)

- [Are Compressed Language Models Less Subgroup Robust?](2024年03月26日/Are_Compressed_Language_Models_Less_Subgroup_Robust.md)

    - [翻译: 压缩后的语言模型是否在子群体上的鲁棒性有所下降？](2024年03月26日/Are_Compressed_Language_Models_Less_Subgroup_Robust.md)

- [Improving Text-to-Image Consistency via Automatic Prompt Optimization](2024年03月26日/Improving_Text-to-Image_Consistency_via_Automatic_Prompt_Optimization.md)

    - [翻译: 自动优化提示以提升文本与图像间的协调性](2024年03月26日/Improving_Text-to-Image_Consistency_via_Automatic_Prompt_Optimization.md)

- [Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications](2024年03月26日/Evaluating_the_Efficacy_of_Prompt-Engineered_Large_Multimodal_Models_Versus_Fine-Tuned_Vision_Transformers_in_Image-Based_Security_Applications.md)

    - [翻译: 在基于图像的安全应用中，本研究评估了经过精心设计的提示的大型多模态模型与经过微调的视觉变换模型的有效性。](2024年03月26日/Evaluating_the_Efficacy_of_Prompt-Engineered_Large_Multimodal_Models_Versus_Fine-Tuned_Vision_Transformers_in_Image-Based_Security_Applications.md)

- [Constructions Are So Difficult That Even Large Language Models Get Them Right for the Wrong Reasons](2024年03月26日/Constructions_Are_So_Difficult_That_Even_Large_Language_Models_Get_Them_Right_for_the_Wrong_Reasons.md)

    - [翻译: 即便是先进的大型语言模型，在处理复杂构建（Constructions）时也常误打误撞地得出正确结果。](2024年03月26日/Constructions_Are_So_Difficult_That_Even_Large_Language_Models_Get_Them_Right_for_the_Wrong_Reasons.md)

- [TWOLAR: a TWO-step LLM-Augmented distillation method for passage Reranking](2024年03月26日/TWOLAR_a_TWO-step_LLM-Augmented_distillation_method_for_passage_Reranking.md)

    - [翻译: TWOLAR：一种两步法，通过LLM增强的蒸馏技术，对文章段落进行重新排序。](2024年03月26日/TWOLAR_a_TWO-step_LLM-Augmented_distillation_method_for_passage_Reranking.md)

- [Can multiple-choice questions really be useful in detecting the abilities of LLMs?](2024年03月26日/Can_multiple-choice_questions_really_be_useful_in_detecting_the_abilities_of_LLMs.md)

    - [翻译: 多项选择题是否真的有助于评估大型语言模型的能力？](2024年03月26日/Can_multiple-choice_questions_really_be_useful_in_detecting_the_abilities_of_LLMs.md)

- [Optimization-based Prompt Injection Attack to LLM-as-a-Judge](2024年03月26日/Optimization-based_Prompt_Injection_Attack_to_LLM-as-a-Judge.md)

    - [翻译: 针对作为裁判的大型语言模型（LLM），采用基于优化的提示注入攻击策略。](2024年03月26日/Optimization-based_Prompt_Injection_Attack_to_LLM-as-a-Judge.md)

- [Enhanced Short Text Modeling: Leveraging Large Language Models for Topic Refinement](2024年03月26日/Enhanced_Short_Text_Modeling_Leveraging_Large_Language_Models_for_Topic_Refinement.md)

    - [翻译: 通过运用大型语言模型，本文探讨了如何提升短文本的主题建模能力，实现主题的精准优化。](2024年03月26日/Enhanced_Short_Text_Modeling_Leveraging_Large_Language_Models_for_Topic_Refinement.md)

- [Large Language Models Enhanced Collaborative Filtering](2024年03月26日/Large_Language_Models_Enhanced_Collaborative_Filtering.md)

    - [翻译: 通过大型语言模型，我们提升了协同过滤的效果。](2024年03月26日/Large_Language_Models_Enhanced_Collaborative_Filtering.md)

- [Language Models for Text Classification: Is In-Context Learning Enough?](2024年03月26日/Language_Models_for_Text_Classification_Is_In-Context_Learning_Enough.md)

    - [翻译: 在文本分类的语言模型中，仅依靠上下文学习是否足够呢？](2024年03月26日/Language_Models_for_Text_Classification_Is_In-Context_Learning_Enough.md)

- [Intrinsic Subgraph Generation for Interpretable Graph based Visual Question Answering](2024年03月26日/Intrinsic_Subgraph_Generation_for_Interpretable_Graph_based_Visual_Question_Answering.md)

    - [翻译: 探索内在子图生成，助力可解读的图形视觉问答系统](2024年03月26日/Intrinsic_Subgraph_Generation_for_Interpretable_Graph_based_Visual_Question_Answering.md)

- ["You are an expert annotator": Automatic Best-Worst-Scaling Annotations for Emotion Intensity Modeling](2024年03月26日/You_are_an_expert_annotator_Automatic_Best-Worst-Scaling_Annotations_for_Emotion_Intensity_Modeling.md)

    - [翻译: "专家级标注师"：自动采用最佳-最差量表法进行情感强度建模标注](2024年03月26日/You_are_an_expert_annotator_Automatic_Best-Worst-Scaling_Annotations_for_Emotion_Intensity_Modeling.md)

- [Towards a Zero-Data, Controllable, Adaptive Dialog System](2024年03月26日/Towards_a_Zero-Data,_Controllable,_Adaptive_Dialog_System.md)

    - [翻译: 迈向零数据输入、可控制、能自动调整的对话系统](2024年03月26日/Towards_a_Zero-Data,_Controllable,_Adaptive_Dialog_System.md)

- [RuBia: A Russian Language Bias Detection Dataset](2024年03月26日/RuBia_A_Russian_Language_Bias_Detection_Dataset.md)

    - [翻译: RuBia：俄罗斯语言偏见检测数据集](2024年03月26日/RuBia_A_Russian_Language_Bias_Detection_Dataset.md)

- [Naive Bayes-based Context Extension for Large Language Models](2024年03月26日/Naive_Bayes-based_Context_Extension_for_Large_Language_Models.md)

    - [翻译: 利用朴素贝叶斯算法，我们对大型语言模型的上下文进行了扩展。](2024年03月26日/Naive_Bayes-based_Context_Extension_for_Large_Language_Models.md)

- [Large Language Models Are State-of-the-Art Evaluator for Grammatical Error Correction](2024年03月26日/Large_Language_Models_Are_State-of-the-Art_Evaluator_for_Grammatical_Error_Correction.md)

    - [翻译: 大型语言模型已成为语法错误纠正领域的顶尖评估工具。](2024年03月26日/Large_Language_Models_Are_State-of-the-Art_Evaluator_for_Grammatical_Error_Correction.md)

- [ILLUMINER: Instruction-tuned Large Language Models as Few-shot Intent Classifier and Slot Filler](2024年03月26日/ILLUMINER_Instruction-tuned_Large_Language_Models_as_Few-shot_Intent_Classifier_and_Slot_Filler.md)

    - [翻译: ILLUMINER：指令调优的大型语言模型，用作少样本意图识别和槽位填充工具](2024年03月26日/ILLUMINER_Instruction-tuned_Large_Language_Models_as_Few-shot_Intent_Classifier_and_Slot_Filler.md)

- [Sparse Logistic Regression with High-order Features for Automatic Grammar Rule Extraction from Treebanks](2024年03月26日/Sparse_Logistic_Regression_with_High-order_Features_for_Automatic_Grammar_Rule_Extraction_from_Treebanks.md)

    - [翻译: 本研究提出了一种基于稀疏逻辑回归的方法，通过高阶特征自动从树库中提取语法规则。](2024年03月26日/Sparse_Logistic_Regression_with_High-order_Features_for_Automatic_Grammar_Rule_Extraction_from_Treebanks.md)

- [KC-GenRe: A Knowledge-constrained Generative Re-ranking Method Based on Large Language Models for Knowledge Graph Completion](2024年03月26日/KC-GenRe_A_Knowledge-constrained_Generative_Re-ranking_Method_Based_on_Large_Language_Models_for_Knowledge_Graph_Completion.md)

    - [翻译: KC-GenRe：借助大型语言模型，推出一种知识约束的生成式重排技术，旨在完善知识图谱。](2024年03月26日/KC-GenRe_A_Knowledge-constrained_Generative_Re-ranking_Method_Based_on_Large_Language_Models_for_Knowledge_Graph_Completion.md)

- [DGoT: Dynamic Graph of Thoughts for Scientific Abstract Generation](2024年03月26日/DGoT_Dynamic_Graph_of_Thoughts_for_Scientific_Abstract_Generation.md)

    - [翻译: DGoT：动态思维图谱，助力科学摘要自动生成](2024年03月26日/DGoT_Dynamic_Graph_of_Thoughts_for_Scientific_Abstract_Generation.md)

- [Robust and Scalable Model Editing for Large Language Models](2024年03月26日/Robust_and_Scalable_Model_Editing_for_Large_Language_Models.md)

    - [翻译: 为了大型语言模型，我们研究了一种既稳健又可扩展的模型编辑方法。](2024年03月26日/Robust_and_Scalable_Model_Editing_for_Large_Language_Models.md)

- [Aligning Large Language Models for Enhancing Psychiatric Interviews through Symptom Delineation and Summarization](2024年03月26日/Aligning_Large_Language_Models_for_Enhancing_Psychiatric_Interviews_through_Symptom_Delineation_and_Summarization.md)

    - [翻译: 为了提升精神病学访谈的质量，本研究致力于调整大型语言模型，以便更准确地描绘症状并进行有效总结。](2024年03月26日/Aligning_Large_Language_Models_for_Enhancing_Psychiatric_Interviews_through_Symptom_Delineation_and_Summarization.md)

- [PCToolkit: A Unified Plug-and-Play Prompt Compression Toolkit of Large Language Models](2024年03月26日/PCToolkit_A_Unified_Plug-and-Play_Prompt_Compression_Toolkit_of_Large_Language_Models.md)

    - [翻译: PCToolkit：一款适用于大型语言模型的集成式、即插即用型提示压缩工具集。](2024年03月26日/PCToolkit_A_Unified_Plug-and-Play_Prompt_Compression_Toolkit_of_Large_Language_Models.md)

- [AIDE: An Automatic Data Engine for Object Detection in Autonomous Driving](2024年03月26日/AIDE_An_Automatic_Data_Engine_for_Object_Detection_in_Autonomous_Driving.md)

    - [翻译: AIDE：自动驾驶领域中的物体检测自动化数据引擎](2024年03月26日/AIDE_An_Automatic_Data_Engine_for_Object_Detection_in_Autonomous_Driving.md)

- [ChatGPT Rates Natural Language Explanation Quality Like Humans: But on Which Scales?](2024年03月26日/ChatGPT_Rates_Natural_Language_Explanation_Quality_Like_Humans_But_on_Which_Scales.md)

    - [翻译: ChatGPT 如同人类般评定自然语言解释的质量：然而，它在哪些方面与人类评价标准相符？](2024年03月26日/ChatGPT_Rates_Natural_Language_Explanation_Quality_Like_Humans_But_on_Which_Scales.md)