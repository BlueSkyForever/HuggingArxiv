# 2024年03月

- [Hierarchical Indexing for Retrieval-Augmented Opinion Summarization](2024年03月01日/Hierarchical_Indexing_for_Retrieval-Augmented_Opinion_Summarization.md)

    - [翻译: 为提升检索增强型观点摘要的效果，我们引入了层次化索引技术。该方法旨在通过构建多层次的索引结构，有效组织和检索相关文本信息，从而优化观点总结的质量与效率。](2024年03月01日/Hierarchical_Indexing_for_Retrieval-Augmented_Opinion_Summarization.md)

- [HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding](2024年03月01日/HALC_Object_Hallucination_Reduction_via_Adaptive_Focal-Contrast_Decoding.md)

    - [翻译: HALC 方法提出了一种新颖的自适应焦点对比解码技术，旨在有效减少对象幻觉现象。该方法针对图像识别中的错误预测问题，通过优化解码过程来提升模型对真实目标的区分能力和鲁棒性。](2024年03月01日/HALC_Object_Hallucination_Reduction_via_Adaptive_Focal-Contrast_Decoding.md)

- [Rethinking Tokenization: Crafting Better Tokenizers for Large Language Models](2024年03月01日/Rethinking_Tokenization_Crafting_Better_Tokenizers_for_Large_Language_Models.md)

    - [翻译: 面对大型语言模型，我们有必要重新审视和改进分词方法，以创造出更能满足其需求的高性能分词器。](2024年03月01日/Rethinking_Tokenization_Crafting_Better_Tokenizers_for_Large_Language_Models.md)

- [Cross-Lingual Learning vs. Low-Resource Fine-Tuning: A Case Study with Fact-Checking in Turkish](2024年03月01日/Cross-Lingual_Learning_vs._Low-Resource_Fine-Tuning_A_Case_Study_with_Fact-Checking_in_Turkish.md)

    - [翻译: 本研究通过土耳其语的事实查证案例，探讨了跨语言学习与低资源微调两种方法的优劣。](2024年03月01日/Cross-Lingual_Learning_vs._Low-Resource_Fine-Tuning_A_Case_Study_with_Fact-Checking_in_Turkish.md)

- [Post-decoder Biasing for End-to-End Speech Recognition of Multi-turn Medical Interview](2024年03月01日/Post-decoder_Biasing_for_End-to-End_Speech_Recognition_of_Multi-turn_Medical_Interview.md)

    - [翻译: 在多轮医疗访谈端到端语音识别技术中，我们采用了解码器后置偏置策略以优化识别效果。](2024年03月01日/Post-decoder_Biasing_for_End-to-End_Speech_Recognition_of_Multi-turn_Medical_Interview.md)

- [Semi-Instruct: Bridging Natural-Instruct and Self-Instruct for Code Large Language Models](2024年03月01日/Semi-Instruct_Bridging_Natural-Instruct_and_Self-Instruct_for_Code_Large_Language_Models.md)

    - [翻译: Semi-Instruct 方法旨在弥合自然指令与自我指令之间的鸿沟，以提升代码大型语言模型的表现。它通过结合两种教学模式的优势，探索在代码理解和生成任务中更高效地引导大型语言模型的新途径。](2024年03月01日/Semi-Instruct_Bridging_Natural-Instruct_and_Self-Instruct_for_Code_Large_Language_Models.md)

- [Never-Ending Embodied Robot Learning](2024年03月01日/Never-Ending_Embodied_Robot_Learning.md)

    - [翻译: 无尽的实体化机器人学习](2024年03月01日/Never-Ending_Embodied_Robot_Learning.md)

- [Self-Consistent Decoding for More Factual Open Responses](2024年03月01日/Self-Consistent_Decoding_for_More_Factual_Open_Responses.md)

    - [翻译: 为了生成更为事实准确的开放式回答，我们采用“自我一致性解码”方法。](2024年03月01日/Self-Consistent_Decoding_for_More_Factual_Open_Responses.md)

- [Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents](2024年03月01日/Playing_NetHack_with_LLMs_Potential_&_Limitations_as_Zero-Shot_Agents.md)

    - [翻译: 在运用 LLMs 探索 NetHack 游戏中，我们发掘其作为零样本代理的潜力与局限。这项研究聚焦于 LLMS 在未经专门训练情况下，即“零样本”状态下应对复杂游戏环境的能力及其限制。](2024年03月01日/Playing_NetHack_with_LLMs_Potential_&_Limitations_as_Zero-Shot_Agents.md)

- [Diff-Plugin: Revitalizing Details for Diffusion-based Low-level Tasks](2024年03月01日/Diff-Plugin_Revitalizing_Details_for_Diffusion-based_Low-level_Tasks.md)

    - [翻译: Diff-Plugin：激活扩散式底层任务中的精细细节，赋予其新的生命力](2024年03月01日/Diff-Plugin_Revitalizing_Details_for_Diffusion-based_Low-level_Tasks.md)

- [NeuPIMs: A NPU-PIM Heterogeneous Acceleration for Batched Inference of Large Language Model](2024年03月01日/NeuPIMs_A_NPU-PIM_Heterogeneous_Acceleration_for_Batched_Inference_of_Large_Language_Model.md)

    - [翻译: NeuPIMs，为解决大型语言模型批量推理问题而生，是一种融合了NPU与PIM技术的高效异构加速方案。](2024年03月01日/NeuPIMs_A_NPU-PIM_Heterogeneous_Acceleration_for_Batched_Inference_of_Large_Language_Model.md)

- [Standardizing the Measurement of Text Diversity: A Tool and a Comparative Analysis of Scores](2024年03月01日/Standardizing_the_Measurement_of_Text_Diversity_A_Tool_and_a_Comparative_Analysis_of_Scores.md)

    - [翻译: 为了更准确、直观地评估文本多样性，本研究提出了一种标准化测量工具，并对不同方法所得分数进行了深入对比分析。](2024年03月01日/Standardizing_the_Measurement_of_Text_Diversity_A_Tool_and_a_Comparative_Analysis_of_Scores.md)

- [DyPyBench: A Benchmark of Executable Python Software](2024年03月01日/DyPyBench_A_Benchmark_of_Executable_Python_Software.md)

    - [翻译: DyPyBench 是一款专注于可执行 Python 软件性能评估的基准测试工具，用于衡量各类 Python 应用程序的实际运行效果。](2024年03月01日/DyPyBench_A_Benchmark_of_Executable_Python_Software.md)

- [Large Language Models for Simultaneous Named Entity Extraction and Spelling Correction](2024年03月01日/Large_Language_Models_for_Simultaneous_Named_Entity_Extraction_and_Spelling_Correction.md)

    - [翻译: 针对同时执行命名实体提取与拼写修正任务，本研究探讨了大型语言模型的应用潜力。通过利用大型语言模型的力量，我们旨在提升模型在面对实体抽取与拼写错误修正双重挑战时的表现。](2024年03月01日/Large_Language_Models_for_Simultaneous_Named_Entity_Extraction_and_Spelling_Correction.md)

- [VisionLLaMA: A Unified LLaMA Interface for Vision Tasks](2024年03月01日/VisionLLaMA_A_Unified_LLaMA_Interface_for_Vision_Tasks.md)

    - [翻译: VisionLLaMA 是一个为各类视觉任务打造的统一 LLaMA（大规模预训练语言模型）接口，旨在整合并发挥 LLama 在视觉领域的强大功能。](2024年03月01日/VisionLLaMA_A_Unified_LLaMA_Interface_for_Vision_Tasks.md)

- [ROME: Memorization Insights from Text, Probability and Hidden State in Large Language Models](2024年03月01日/ROME_Memorization_Insights_from_Text,_Probability_and_Hidden_State_in_Large_Language_Models.md)

    - [翻译: ROME 研究深入探索大型语言模型中，通过分析文本、概率分布以及隐藏状态揭示其内在的记忆机制。](2024年03月01日/ROME_Memorization_Insights_from_Text,_Probability_and_Hidden_State_in_Large_Language_Models.md)

- [TempCompass: Do Video LLMs Really Understand Videos?](2024年03月01日/TempCompass_Do_Video_LLMs_Really_Understand_Videos.md)

    - [翻译: TempCompass——探究视频 LLM 是否真正具备理解视频内容的能力。](2024年03月01日/TempCompass_Do_Video_LLMs_Really_Understand_Videos.md)

- [LUCID: LLM-Generated Utterances for Complex and Interesting Dialogues](2024年03月01日/LUCID_LLM-Generated_Utterances_for_Complex_and_Interesting_Dialogues.md)

    - [翻译: LUCID：针对复杂且引人入胜的对话，利用LLM技术生成高质量话语](2024年03月01日/LUCID_LLM-Generated_Utterances_for_Complex_and_Interesting_Dialogues.md)

- [When Large Language Models Confront Repository-Level Automatic Program Repair: How Well They Done?](2024年03月01日/When_Large_Language_Models_Confront_Repository-Level_Automatic_Program_Repair_How_Well_They_Done.md)

    - [翻译: 面对仓库级自动程序修复任务，大型语言模型的表现究竟如何呢？](2024年03月01日/When_Large_Language_Models_Confront_Repository-Level_Automatic_Program_Repair_How_Well_They_Done.md)

- [Mitigating Reversal Curse via Semantic-aware Permutation Training](2024年03月01日/Mitigating_Reversal_Curse_via_Semantic-aware_Permutation_Training.md)

    - [翻译: 为了解决反转诅咒问题，我们提出了一种基于语义感知排列训练的方法。该方法通过精心设计的训练策略，能够有效抑制模型在处理特定任务时出现的反转诅咒效应，从而提升模型性能和鲁棒性。](2024年03月01日/Mitigating_Reversal_Curse_via_Semantic-aware_Permutation_Training.md)

- [AtP*: An efficient and scalable method for localizing LLM behaviour to components](2024年03月01日/AtP_An_efficient_and_scalable_method_for_localizing_LLM_behaviour_to_components.md)

    - [翻译: AtP*：一项创新技术，高效且易于规模化应用，旨在对大型语言模型（LLM）的行为进行精细化组件定位。](2024年03月01日/AtP_An_efficient_and_scalable_method_for_localizing_LLM_behaviour_to_components.md)

- [LAB: Large-Scale Alignment for ChatBots](2024年03月01日/LAB_Large-Scale_Alignment_for_ChatBots.md)

    - [翻译: LAB项目致力于为聊天机器人开发大规模的对齐技术，旨在提升其对话理解和生成能力。](2024年03月01日/LAB_Large-Scale_Alignment_for_ChatBots.md)

- [LLMCRIT: Teaching Large Language Models to Use Criteria](2024年03月01日/LLMCRIT_Teaching_Large_Language_Models_to_Use_Criteria.md)

    - [翻译: LLMCRIT 计划旨在教授大型语言模型如何运用评判标准。](2024年03月01日/LLMCRIT_Teaching_Large_Language_Models_to_Use_Criteria.md)

- [FaiMA: Feature-aware In-context Learning for Multi-domain Aspect-based Sentiment Analysis](2024年03月01日/FaiMA_Feature-aware_In-context_Learning_for_Multi-domain_Aspect-based_Sentiment_Analysis.md)

    - [翻译: FaiMA 是一项创新技术，专注于在多领域情境下进行特征感知的上下文学习，以提升基于方面的观点分析效果。](2024年03月01日/FaiMA_Feature-aware_In-context_Learning_for_Multi-domain_Aspect-based_Sentiment_Analysis.md)

- [Reading Subtext: Evaluating Large Language Models on Short Story Summarization with Writers](2024年03月01日/Reading_Subtext_Evaluating_Large_Language_Models_on_Short_Story_Summarization_with_Writers.md)

    - [翻译: 在“解读言外之意”的研究中，我们通过让大型语言模型处理由作家编写的短篇小说摘要，来评估其在该任务上的表现能力。](2024年03月01日/Reading_Subtext_Evaluating_Large_Language_Models_on_Short_Story_Summarization_with_Writers.md)

- [Towards Full Authorship with AI: Supporting Revision with AI-Generated Views](2024年03月01日/Towards_Full_Authorship_with_AI_Supporting_Revision_with_AI-Generated_Views.md)

    - [翻译: 向着以AI驱动的完全创作迈进，我们探讨如何借助AI生成的视角来有效支持文章修订过程。](2024年03月01日/Towards_Full_Authorship_with_AI_Supporting_Revision_with_AI-Generated_Views.md)

- [AutoAttacker: A Large Language Model Guided System to Implement Automatic Cyber-attacks](2024年03月01日/AutoAttacker_A_Large_Language_Model_Guided_System_to_Implement_Automatic_Cyber-attacks.md)

    - [翻译: AutoAttacker 是一套在大型语言模型指导下运作的智能系统，致力于执行自动化网络攻击任务。](2024年03月01日/AutoAttacker_A_Large_Language_Model_Guided_System_to_Implement_Automatic_Cyber-attacks.md)

- [Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks](2024年03月01日/Peacock_A_Family_of_Arabic_Multimodal_Large_Language_Models_and_Benchmarks.md)

    - [翻译: 孔雀系列：展现了一族专为阿拉伯语设计的多模态大型语言模型及其对应的基准测试标准](2024年03月01日/Peacock_A_Family_of_Arabic_Multimodal_Large_Language_Models_and_Benchmarks.md)

- [BasedAI: A decentralized P2P network for Zero Knowledge Large Language Models (ZK-LLMs)](2024年03月01日/BasedAI_A_decentralized_P2P_network_for_Zero_Knowledge_Large_Language_Models_(ZK-LLMs).md)

    - [翻译: BasedAI 是一个专为零知识大型语言模型打造的去中心化P2P网络，旨在为ZK-LLMs提供高效、安全的分布式运行环境。](2024年03月01日/BasedAI_A_decentralized_P2P_network_for_Zero_Knowledge_Large_Language_Models_(ZK-LLMs).md)

- [Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries](2024年03月01日/Attribute_Structuring_Improves_LLM-Based_Evaluation_of_Clinical_Text_Summaries.md)

    - [翻译: 通过属性结构化优化，我们能够提升LLM在评估临床文本摘要时的表现。](2024年03月01日/Attribute_Structuring_Improves_LLM-Based_Evaluation_of_Clinical_Text_Summaries.md)

- [Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language](2024年03月01日/Leveraging_Prompt-Based_Large_Language_Models_Predicting_Pandemic_Health_Decisions_and_Outcomes_Through_Social_Media_Language.md)

    - [翻译: 利用 prompt 优化的大型语言模型，我们可以从社交媒体的语言中洞悉并预测疫情期间人们的健康决策与相应结果。](2024年03月01日/Leveraging_Prompt-Based_Large_Language_Models_Predicting_Pandemic_Health_Decisions_and_Outcomes_Through_Social_Media_Language.md)

- [LocalRQA: From Generating Data to Locally Training, Testing, and Deploying Retrieval-Augmented QA Systems](2024年03月01日/LocalRQA_From_Generating_Data_to_Locally_Training,_Testing,_and_Deploying_Retrieval-Augmented_QA_Systems.md)

    - [翻译: LocalRQA：一站式方案，从构建数据集到本地完成增强检索型问答系统的训练、测试与部署。](2024年03月01日/LocalRQA_From_Generating_Data_to_Locally_Training,_Testing,_and_Deploying_Retrieval-Augmented_QA_Systems.md)

- [MALTO at SemEval-2024 Task 6: Leveraging Synthetic Data for LLM Hallucination Detection](2024年03月01日/MALTO_at_SemEval-2024_Task_6_Leveraging_Synthetic_Data_for_LLM_Hallucination_Detection.md)

    - [翻译: SemEval-2024第六项任务中，MALTO团队采用创新策略，借助合成数据增强大型语言模型对幻觉内容的识别能力。](2024年03月01日/MALTO_at_SemEval-2024_Task_6_Leveraging_Synthetic_Data_for_LLM_Hallucination_Detection.md)

- [AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models](2024年03月01日/AutoRD_An_Automatic_and_End-to-End_System_for_Rare_Disease_Knowledge_Graph_Construction_Based_on_Ontologies-enhanced_Large_Language_Models.md)

    - [翻译: AutoRD 是一款创新的全自动端到端系统，它利用了本体增强的大型语言模型技术，专注于高效构建罕见病知识图谱。](2024年03月01日/AutoRD_An_Automatic_and_End-to-End_System_for_Rare_Disease_Knowledge_Graph_Construction_Based_on_Ontologies-enhanced_Large_Language_Models.md)

- [MediSwift: Efficient Sparse Pre-trained Biomedical Language Models](2024年03月01日/MediSwift_Efficient_Sparse_Pre-trained_Biomedical_Language_Models.md)

    - [翻译: MediSwift 是一种高效、预先训练的稀疏型生物医学语言模型，专为提升处理领域内大规模数据的效率而设计。](2024年03月01日/MediSwift_Efficient_Sparse_Pre-trained_Biomedical_Language_Models.md)

- [Differentially Private Knowledge Distillation via Synthetic Text Generation](2024年03月01日/Differentially_Private_Knowledge_Distillation_via_Synthetic_Text_Generation.md)

    - [翻译: 我们提出了一种新颖的方法，利用合成文本生成技术来实现差异隐私保护下的知识蒸馏，这种方法能够在保护数据隐私的同时提取和传递模型知识。](2024年03月01日/Differentially_Private_Knowledge_Distillation_via_Synthetic_Text_Generation.md)

- [DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models](2024年03月01日/DiaHalu_A_Dialogue-level_Hallucination_Evaluation_Benchmark_for_Large_Language_Models.md)

    - [翻译: DiaHalu：一款针对大型语言模型设计的对话级 hallucination 评估基准工具，旨在精准衡量其在对话生成中的幻觉现象表现。](2024年03月01日/DiaHalu_A_Dialogue-level_Hallucination_Evaluation_Benchmark_for_Large_Language_Models.md)

- [A systematic evaluation of large language models for generating programming code](2024年03月01日/A_systematic_evaluation_of_large_language_models_for_generating_programming_code.md)

    - [翻译: 本研究对大型语言模型在生成编程代码任务上的表现进行了全面而系统的评估。](2024年03月01日/A_systematic_evaluation_of_large_language_models_for_generating_programming_code.md)

- [Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment](2024年03月01日/Text_classification_of_column_headers_with_a_controlled_vocabulary_leveraging_LLMs_for_metadata_enrichment.md)

    - [翻译: 借助LLMs，本研究探讨如何运用受控词汇对列标题进行文本分类，以实现元数据的有效丰富。](2024年03月01日/Text_classification_of_column_headers_with_a_controlled_vocabulary_leveraging_LLMs_for_metadata_enrichment.md)

- [Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models](2024年03月01日/Crimson_Empowering_Strategic_Reasoning_in_Cybersecurity_through_Large_Language_Models.md)

    - [翻译: Crimson项目致力于运用大型语言模型来增强网络安全领域中的战略推理，以期在应对网络威胁时提供更为精准且深思熟虑的解决方案。](2024年03月01日/Crimson_Empowering_Strategic_Reasoning_in_Cybersecurity_through_Large_Language_Models.md)

- [DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases](2024年03月01日/DFIN-SQL_Integrating_Focused_Schema_with_DIN-SQL_for_Superior_Accuracy_in_Large-Scale_Databases.md)

    - [翻译: DFIN-SQL 是一项创新技术，它将聚焦模式与 DIN-SQL 整合，旨在提升在处理大型数据库时的查询精确度。](2024年03月01日/DFIN-SQL_Integrating_Focused_Schema_with_DIN-SQL_for_Superior_Accuracy_in_Large-Scale_Databases.md)

- [Teach LLMs to Phish: Stealing Private Information from Language Models](2024年03月01日/Teach_LLMs_to_Phish_Stealing_Private_Information_from_Language_Models.md)

    - [翻译: 让 LLM 学会“垂钓”隐私：探究如何从语言模型中获取敏感信息](2024年03月01日/Teach_LLMs_to_Phish_Stealing_Private_Information_from_Language_Models.md)

- [Open Assistant Toolkit -- version 2](2024年03月01日/Open_Assistant_Toolkit_--_version_2.md)

    - [翻译: Open Assistant Toolkit 第二版](2024年03月01日/Open_Assistant_Toolkit_--_version_2.md)

- [Accelerating Greedy Coordinate Gradient via Probe Sampling](2024年03月02日/Accelerating_Greedy_Coordinate_Gradient_via_Probe_Sampling.md)

    - [翻译: 我们提出了一种利用探针采样技术来提升贪婪坐标梯度法的效率，即“加速贪婪坐标梯度探针采样方法”，尤其在处理大规模优化问题时，有效提高了算法的运行速度与性能。](2024年03月02日/Accelerating_Greedy_Coordinate_Gradient_via_Probe_Sampling.md)

- [SceneCraft: An LLM Agent for Synthesizing 3D Scene as Blender Code](2024年03月02日/SceneCraft_An_LLM_Agent_for_Synthesizing_3D_Scene_as_Blender_Code.md)

    - [翻译: SceneCraft——专为生成Blender代码而设计的3D场景构建LLM智能体](2024年03月02日/SceneCraft_An_LLM_Agent_for_Synthesizing_3D_Scene_as_Blender_Code.md)

- [Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal](2024年03月02日/Mitigating_Catastrophic_Forgetting_in_Large_Language_Models_with_Self-Synthesized_Rehearsal.md)

    - [翻译: 在大型语言模型中，采用自合成复习方法有效减轻灾难性遗忘问题。](2024年03月02日/Mitigating_Catastrophic_Forgetting_in_Large_Language_Models_with_Self-Synthesized_Rehearsal.md)

- [IntactKV: Improving Large Language Model Quantization by Keeping Pivot Tokens Intact](2024年03月02日/IntactKV_Improving_Large_Language_Model_Quantization_by_Keeping_Pivot_Tokens_Intact.md)

    - [翻译: IntactKV 方法旨在提升大型语言模型量化性能，其核心在于保留枢轴令牌的完整性。](2024年03月02日/IntactKV_Improving_Large_Language_Model_Quantization_by_Keeping_Pivot_Tokens_Intact.md)

- [Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy](2024年03月02日/Inexact_Unlearning_Needs_More_Careful_Evaluations_to_Avoid_a_False_Sense_of_Privacy.md)

    - [翻译: 针对 Inexact Unlearning，为了防止对隐私安全产生误解，我们必须对其进行更为细致的评估。](2024年03月02日/Inexact_Unlearning_Needs_More_Careful_Evaluations_to_Avoid_a_False_Sense_of_Privacy.md)

- [API Is Enough: Conformal Prediction for Large Language Models Without Logit-Access](2024年03月02日/API_Is_Enough_Conformal_Prediction_for_Large_Language_Models_Without_Logit-Access.md)

    - [翻译: 仅使用 API 即可实现：无需访问 logits，也能为大型语言模型应用相符预测技术。](2024年03月02日/API_Is_Enough_Conformal_Prediction_for_Large_Language_Models_Without_Logit-Access.md)

- [Data-free Multi-label Image Recognition via LLM-powered Prompt Tuning](2024年03月02日/Data-free_Multi-label_Image_Recognition_via_LLM-powered_Prompt_Tuning.md)

    - [翻译: 借助 LLM 强大的提示调优技术，我们能够实现无需原始数据的多标签图像识别。这项研究探讨了如何在没有数据的情况下，利用 LLM 的能力进行多标签图像识别任务的优化和提升。](2024年03月02日/Data-free_Multi-label_Image_Recognition_via_LLM-powered_Prompt_Tuning.md)

- [The Case for Animal-Friendly AI](2024年03月02日/The_Case_for_Animal-Friendly_AI.md)

    - [翻译: 倡导动物友好型 AI：为何我们需要关注并研发对动物友好的人工智能技术？](2024年03月02日/The_Case_for_Animal-Friendly_AI.md)

- [DMoERM: Recipes of Mixture-of-Experts for Effective Reward Modeling](2024年03月02日/DMoERM_Recipes_of_Mixture-of-Experts_for_Effective_Reward_Modeling.md)

    - [翻译: DMoERM：揭秘混合专家模型在高效奖励建模中的秘籍](2024年03月02日/DMoERM_Recipes_of_Mixture-of-Experts_for_Effective_Reward_Modeling.md)

- [RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots](2024年03月02日/RAGged_Edges_The_Double-Edged_Sword_of_Retrieval-Augmented_Chatbots.md)

    - [翻译: 标题：“RAGged Edges”揭示了检索增强型聊天机器人这一把双刃剑的复杂性。该研究探讨了在提升聊天机器人性能的同时，检索增强技术所带来的挑战与局限性。](2024年03月02日/RAGged_Edges_The_Double-Edged_Sword_of_Retrieval-Augmented_Chatbots.md)

- [STAR: Constraint LoRA with Dynamic Active Learning for Data-Efficient Fine-Tuning of Large Language Models](2024年03月02日/STAR_Constraint_LoRA_with_Dynamic_Active_Learning_for_Data-Efficient_Fine-Tuning_of_Large_Language_Models.md)

    - [翻译: STAR 方法将动态主动学习与约束版的 LoRA 结合，旨在提升大型语言模型在数据有限条件下的微调效率。](2024年03月02日/STAR_Constraint_LoRA_with_Dynamic_Active_Learning_for_Data-Efficient_Fine-Tuning_of_Large_Language_Models.md)

- [HeteGen: Heterogeneous Parallel Inference for Large Language Models on Resource-Constrained Devices](2024年03月02日/HeteGen_Heterogeneous_Parallel_Inference_for_Large_Language_Models_on_Resource-Constrained_Devices.md)

    - [翻译: HeteGen 是专为资源有限的设备设计的，能够实现大型语言模型的异构并行推理技术。这项技术针对大模型在资源受限环境下的高效运行，提供了一种创新的并行处理方案。](2024年03月02日/HeteGen_Heterogeneous_Parallel_Inference_for_Large_Language_Models_on_Resource-Constrained_Devices.md)

- [A Survey of AI-generated Text Forensic Systems: Detection, Attribution, and Characterization](2024年03月02日/A_Survey_of_AI-generated_Text_Forensic_Systems_Detection,_Attribution,_and_Characterization.md)

    - [翻译: 本篇综述聚焦于人工智能生成文本的取证系统，涵盖了检测、归属及其特性分析三大核心领域。](2024年03月02日/A_Survey_of_AI-generated_Text_Forensic_Systems_Detection,_Attribution,_and_Characterization.md)

- [ParallelPARC: A Scalable Pipeline for Generating Natural-Language Analogies](2024年03月02日/ParallelPARC_A_Scalable_Pipeline_for_Generating_Natural-Language_Analogies.md)

    - [翻译: ParallelPARC，一款专为高效生成自然语言类比而设计的可扩展式处理流程](2024年03月02日/ParallelPARC_A_Scalable_Pipeline_for_Generating_Natural-Language_Analogies.md)

- [LLM-PQ: Serving LLM on Heterogeneous Clusters with Phase-Aware Partition and Adaptive Quantization](2024年03月02日/LLM-PQ_Serving_LLM_on_Heterogeneous_Clusters_with_Phase-Aware_Partition_and_Adaptive_Quantization.md)

    - [翻译: LLM-PQ方案，针对异构集群环境，采用阶段感知分区与自适应量化技术，有效服务于大型语言模型，提升其在各类集群上的运行效率。](2024年03月02日/LLM-PQ_Serving_LLM_on_Heterogeneous_Clusters_with_Phase-Aware_Partition_and_Adaptive_Quantization.md)

- [Evaluating Large Language Models as Virtual Annotators for Time-series Physical Sensing Data](2024年03月02日/Evaluating_Large_Language_Models_as_Virtual_Annotators_for_Time-series_Physical_Sensing_Data.md)

    - [翻译: 本研究探讨将大型语言模型应用于时间序列物理传感数据的虚拟标注任务，以评估其作为有效标注工具的能力。](2024年03月02日/Evaluating_Large_Language_Models_as_Virtual_Annotators_for_Time-series_Physical_Sensing_Data.md)

- [LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation](2024年03月02日/LLaMoCo_Instruction_Tuning_of_Large_Language_Models_for_Optimization_Code_Generation.md)

    - [翻译: LLaMoCo 是一项研究，专注于通过指令微调大规模语言模型，以提升其生成优化代码的能力。](2024年03月02日/LLaMoCo_Instruction_Tuning_of_Large_Language_Models_for_Optimization_Code_Generation.md)

- [Text-guided Explorable Image Super-resolution](2024年03月02日/Text-guided_Explorable_Image_Super-resolution.md)

    - [翻译: Text-guided Explorable Image Super-resolution，即借助文本引导实现可交互式探索的图像超分辨率技术。](2024年03月02日/Text-guided_Explorable_Image_Super-resolution.md)

- [Distilling Text Style Transfer With Self-Explanation From LLMs](2024年03月02日/Distilling_Text_Style_Transfer_With_Self-Explanation_From_LLMs.md)

    - [翻译: 本研究致力于从大型语言模型（LLM）中提炼出带有自我解释功能的文本风格转换技术，旨在探索如何有效利用LLM进行文本风格迁移，并通过自我解释机制提升其可解释性和应用效果。](2024年03月02日/Distilling_Text_Style_Transfer_With_Self-Explanation_From_LLMs.md)

- [CR-LT-KGQA: A Knowledge Graph Question Answering Dataset Requiring Commonsense Reasoning and Long-Tail Knowledge](2024年03月02日/CR-LT-KGQA_A_Knowledge_Graph_Question_Answering_Dataset_Requiring_Commonsense_Reasoning_and_Long-Tail_Knowledge.md)

    - [翻译: CR-LT-KGQA 是一个专注于常识推理与长尾知识需求的知识图谱问答数据集，旨在提升模型在解决复杂问题时兼顾广泛而稀疏知识的能力。](2024年03月02日/CR-LT-KGQA_A_Knowledge_Graph_Question_Answering_Dataset_Requiring_Commonsense_Reasoning_and_Long-Tail_Knowledge.md)

- [Right for Right Reasons: Large Language Models for Verifiable Commonsense Knowledge Graph Question Answering](2024年03月02日/Right_for_Right_Reasons_Large_Language_Models_for_Verifiable_Commonsense_Knowledge_Graph_Question_Answering.md)

    - [翻译: 追求“因为对所以对”——大型语言模型助力可靠解答常识知识图谱问题](2024年03月02日/Right_for_Right_Reasons_Large_Language_Models_for_Verifiable_Commonsense_Knowledge_Graph_Question_Answering.md)

- [On the Compressibility of Quantized Large Language Models](2024年03月02日/On_the_Compressibility_of_Quantized_Large_Language_Models.md)

    - [翻译: 本研究探讨了量化后的大型语言模型（LLM）的压缩潜力，深入分析其在降低存储需求和计算开销方面的可能性。](2024年03月02日/On_the_Compressibility_of_Quantized_Large_Language_Models.md)

- [Automatic Question-Answer Generation for Long-Tail Knowledge](2024年03月02日/Automatic_Question-Answer_Generation_for_Long-Tail_Knowledge.md)

    - [翻译: 为解决长尾知识难题，本研究致力于探索自动问题与答案生成技术，旨在高效精准地生成针对海量且分布稀疏的长尾知识的问题与答案对。](2024年03月02日/Automatic_Question-Answer_Generation_for_Long-Tail_Knowledge.md)

- [Evaluating and Mitigating Number Hallucinations in Large Vision-Language Models: A Consistency Perspective](2024年03月02日/Evaluating_and_Mitigating_Number_Hallucinations_in_Large_Vision-Language_Models_A_Consistency_Perspective.md)

    - [翻译: 本研究从一致性视角出发，探讨并解决大型视觉-语言模型在处理过程中出现的数字幻觉现象。](2024年03月02日/Evaluating_and_Mitigating_Number_Hallucinations_in_Large_Vision-Language_Models_A_Consistency_Perspective.md)

- [LM4OPT: Unveiling the Potential of Large Language Models in Formulating Mathematical Optimization Problems](2024年03月02日/LM4OPT_Unveiling_the_Potential_of_Large_Language_Models_in_Formulating_Mathematical_Optimization_Problems.md)

    - [翻译: LM4OPT项目揭示了大型语言模型在解决数学优化问题时所蕴含的巨大潜能，探索其如何有效用于构建这类问题的解决方案。](2024年03月02日/LM4OPT_Unveiling_the_Potential_of_Large_Language_Models_in_Formulating_Mathematical_Optimization_Problems.md)

- [Chaining thoughts and LLMs to learn DNA structural biophysics](2024年03月02日/Chaining_thoughts_and_LLMs_to_learn_DNA_structural_biophysics.md)

    - [翻译: 通过联动思维与大型语言模型（LLM），我们致力于探索和学习DNA结构生物物理学的奥秘。](2024年03月02日/Chaining_thoughts_and_LLMs_to_learn_DNA_structural_biophysics.md)

- [VBART: The Turkish LLM](2024年03月02日/VBART_The_Turkish_LLM.md)

    - [翻译: VBART——探究土耳其的大型语言模型](2024年03月02日/VBART_The_Turkish_LLM.md)

- [Improving the Validity of Automatically Generated Feedback via Reinforcement Learning](2024年03月02日/Improving_the_Validity_of_Automatically_Generated_Feedback_via_Reinforcement_Learning.md)

    - [翻译: 本研究运用强化学习技术，致力于提升自动化生成反馈的可靠性和准确性。](2024年03月02日/Improving_the_Validity_of_Automatically_Generated_Feedback_via_Reinforcement_Learning.md)

- [NoMAD-Attention: Efficient LLM Inference on CPUs Through Multiply-add-free Attention](2024年03月02日/NoMAD-Attention_Efficient_LLM_Inference_on_CPUs_Through_Multiply-add-free_Attention.md)

    - [翻译: NoMAD-Attention技术致力于提升CPU环境下LLM推理效率，它采用无需乘加操作的注意力机制，实现大型语言模型在CPU上的高效推理。](2024年03月02日/NoMAD-Attention_Efficient_LLM_Inference_on_CPUs_Through_Multiply-add-free_Attention.md)

- [Employing LLMs for Incident Response Planning and Review](2024年03月02日/Employing_LLMs_for_Incident_Response_Planning_and_Review.md)

    - [翻译: 在事件响应规划与复盘中运用 LLMs 技术，以提升效率和精准度。](2024年03月02日/Employing_LLMs_for_Incident_Response_Planning_and_Review.md)

- [Dissecting Language Models: Machine Unlearning via Selective Pruning](2024年03月02日/Dissecting_Language_Models_Machine_Unlearning_via_Selective_Pruning.md)

    - [翻译: 本文探讨通过选择性剪枝技术深入剖析并“卸载”语言模型中的特定知识，实现机器的“忘却”过程。](2024年03月02日/Dissecting_Language_Models_Machine_Unlearning_via_Selective_Pruning.md)

- [AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks](2024年03月02日/AutoDefense_Multi-Agent_LLM_Defense_against_Jailbreak_Attacks.md)

    - [翻译: AutoDefense：一款针对越狱攻击设计的多智能体防御方案，专门用于保护大型语言模型（LLM）的安全。](2024年03月02日/AutoDefense_Multi-Agent_LLM_Defense_against_Jailbreak_Attacks.md)

- [A Cross-Modal Approach to Silent Speech with LLM-Enhanced Recognition](2024年03月02日/A_Cross-Modal_Approach_to_Silent_Speech_with_LLM-Enhanced_Recognition.md)

    - [翻译: 我们提出了一种创新的跨模态方法，借助 LLM 强化技术来提升无声语音的识别能力。](2024年03月02日/A_Cross-Modal_Approach_to_Silent_Speech_with_LLM-Enhanced_Recognition.md)

- [Large Language Multimodal Models for 5-Year Chronic Disease Cohort Prediction Using EHR Data](2024年03月02日/Large_Language_Multimodal_Models_for_5-Year_Chronic_Disease_Cohort_Prediction_Using_EHR_Data.md)

    - [翻译: 本研究采用大规模多模态语言模型，利用电子健康记录数据来预测五年内慢性疾病队列的发展趋势。](2024年03月02日/Large_Language_Multimodal_Models_for_5-Year_Chronic_Disease_Cohort_Prediction_Using_EHR_Data.md)

- [GuardT2I: Defending Text-to-Image Models from Adversarial Prompts](2024年03月03日/GuardT2I_Defending_Text-to-Image_Models_from_Adversarial_Prompts.md)

    - [翻译: GuardT2I：针对对抗性文本提示对文本到图像模型的防御机制](2024年03月03日/GuardT2I_Defending_Text-to-Image_Models_from_Adversarial_Prompts.md)

- [GPTSee: Enhancing Moment Retrieval and Highlight Detection via Description-Based Similarity Features](2024年03月03日/GPTSee_Enhancing_Moment_Retrieval_and_Highlight_Detection_via_Description-Based_Similarity_Features.md)

    - [翻译: GPTSee 利用描述性相似性特征提升关键时刻检索与精彩片段检测能力](2024年03月03日/GPTSee_Enhancing_Moment_Retrieval_and_Highlight_Detection_via_Description-Based_Similarity_Features.md)

- [Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge](2024年03月03日/Fine_Tuning_vs._Retrieval_Augmented_Generation_for_Less_Popular_Knowledge.md)

    - [翻译: 面对较少为人所知的知识领域，我们探究微调和检索增强生成两种方法的优劣。](2024年03月03日/Fine_Tuning_vs._Retrieval_Augmented_Generation_for_Less_Popular_Knowledge.md)

- [Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval](2024年03月03日/Image2Sentence_based_Asymmetrical_Zero-shot_Composed_Image_Retrieval.md)

    - [翻译: Image2Sentence 技术驱动的非对称零样本图像组合检索方法，旨在实现仅通过文本描述即可检索未见过的组合图像。](2024年03月03日/Image2Sentence_based_Asymmetrical_Zero-shot_Composed_Image_Retrieval.md)

- [The Implicit Bias of Heterogeneity towards Invariance and Causality](2024年03月03日/The_Implicit_Bias_of_Heterogeneity_towards_Invariance_and_Causality.md)

    - [翻译: 异质性中蕴含着对不变性和因果性的内在倾向，本文探讨这一隐含偏置的实质及其影响。](2024年03月03日/The_Implicit_Bias_of_Heterogeneity_towards_Invariance_and_Causality.md)

- [OVEL: Large Language Model as Memory Manager for Online Video Entity Linking](2024年03月03日/OVEL_Large_Language_Model_as_Memory_Manager_for_Online_Video_Entity_Linking.md)

    - [翻译: OVEL 利用大型语言模型充当在线视频实体链接的记忆管家，提升链接效能。](2024年03月03日/OVEL_Large_Language_Model_as_Memory_Manager_for_Online_Video_Entity_Linking.md)

- [In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation](2024年03月03日/In-Context_Sharpness_as_Alerts_An_Inner_Representation_Perspective_for_Hallucination_Mitigation.md)

    - [翻译: 将“情境尖锐度”视为预警信号，我们从内在表征的视角探讨其在缓解大型语言模型生成幻觉问题上的作用。](2024年03月03日/In-Context_Sharpness_as_Alerts_An_Inner_Representation_Perspective_for_Hallucination_Mitigation.md)

- [Revisiting Dynamic Evaluation: Online Adaptation for Large Language Models](2024年03月03日/Revisiting_Dynamic_Evaluation_Online_Adaptation_for_Large_Language_Models.md)

    - [翻译: 我们重新审视“动态评估”这一概念，探讨其在大型语言模型中的应用——即在线适应策略，以实现模型性能的即时优化与更新。](2024年03月03日/Revisiting_Dynamic_Evaluation_Online_Adaptation_for_Large_Language_Models.md)

- [Fantastic Semantics and Where to Find Them: Investigating Which Layers of Generative LLMs Reflect Lexical Semantics](2024年03月03日/Fantastic_Semantics_and_Where_to_Find_Them_Investigating_Which_Layers_of_Generative_LLMs_Reflect_Lexical_Semantics.md)

    - [翻译: 《寻找奇幻的语义世界：研究生成型LLM中各层对词汇语义的体现》](2024年03月03日/Fantastic_Semantics_and_Where_to_Find_Them_Investigating_Which_Layers_of_Generative_LLMs_Reflect_Lexical_Semantics.md)

- [InfiMM-HD: A Leap Forward in High-Resolution Multimodal Understanding](2024年03月03日/InfiMM-HD_A_Leap_Forward_in_High-Resolution_Multimodal_Understanding.md)

    - [翻译: InfiMM-HD——在高清多模态理解领域实现了一次显著的跃进](2024年03月03日/InfiMM-HD_A_Leap_Forward_in_High-Resolution_Multimodal_Understanding.md)

- [Infusing Knowledge into Large Language Models with Contextual Prompts](2024年03月03日/Infusing_Knowledge_into_Large_Language_Models_with_Contextual_Prompts.md)

    - [翻译: 本研究探讨如何巧妙利用上下文提示，将知识有效地融入大型语言模型中。](2024年03月03日/Infusing_Knowledge_into_Large_Language_Models_with_Contextual_Prompts.md)

- [Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation](2024年03月03日/Align-to-Distill_Trainable_Attention_Alignment_for_Knowledge_Distillation_in_Neural_Machine_Translation.md)

    - [翻译: 在神经机器翻译中，我们提出了一种名为“Align-to-Distill”的方法，它通过可训练的注意力对齐机制实现知识的有效蒸馏。这一创新技术旨在提升模型在知识转移过程中的性能和效率，特别是在神经机器翻译任务上。](2024年03月03日/Align-to-Distill_Trainable_Attention_Alignment_for_Knowledge_Distillation_in_Neural_Machine_Translation.md)

- [KorMedMCQA: Multi-Choice Question Answering Benchmark for Korean Healthcare Professional Licensing Examinations](2024年03月03日/KorMedMCQA_Multi-Choice_Question_Answering_Benchmark_for_Korean_Healthcare_Professional_Licensing_Examinations.md)

    - [翻译: KorMedMCQA 是专为韩国医疗专业执照考试打造的多选题答题基准测试，旨在衡量和评估考生在该领域内的专业知识水平。](2024年03月03日/KorMedMCQA_Multi-Choice_Question_Answering_Benchmark_for_Korean_Healthcare_Professional_Licensing_Examinations.md)

- [Logic Rules as Explanations for Legal Case Retrieval](2024年03月03日/Logic_Rules_as_Explanations_for_Legal_Case_Retrieval.md)

    - [翻译: 在法律案例检索领域，逻辑规则被用作一种解释手段。进一步优化，逻辑规则在挖掘和理解相关判例中扮演着解释性工具的角色，助力提升案例检索效率与准确性。](2024年03月03日/Logic_Rules_as_Explanations_for_Legal_Case_Retrieval.md)

- [Can LLMs Generate Architectural Design Decisions? -An Exploratory Empirical study](2024年03月03日/Can_LLMs_Generate_Architectural_Design_Decisions_-An_Exploratory_Empirical_study.md)

    - [翻译: 探究 LLMS 是否具备生成建筑设计决策的能力：一项实证研究之旅](2024年03月03日/Can_LLMs_Generate_Architectural_Design_Decisions_-An_Exploratory_Empirical_study.md)

- [Improving LLM Code Generation with Grammar Augmentation](2024年03月03日/Improving_LLM_Code_Generation_with_Grammar_Augmentation.md)

    - [翻译: LLMM代码生成能力的提升，我们借助了语法增强技术。本研究致力于探究如何通过针对性地增加和调整语法结构，优化大型语言模型在代码生成任务上的表现。](2024年03月03日/Improving_LLM_Code_Generation_with_Grammar_Augmentation.md)

- [Relational to RDF Data Migration by Query Co-Evaluation](2024年03月03日/Relational_to_RDF_Data_Migration_by_Query_Co-Evaluation.md)

    - [翻译: 借助查询协同求值技术，实现从关系型数据向 RDF 数据的迁移步骤 1 直译：关系型数据到 RDF 数据迁移通过查询协同求值实现步骤 2 简洁优雅翻译：本研究探讨了一种基于查询协同求值的方法，用于实现关系型数据库与 RDF 数据间的高效迁移。](2024年03月03日/Relational_to_RDF_Data_Migration_by_Query_Co-Evaluation.md)

- [Using LLMs for Tabletop Exercises within the Security Domain](2024年03月03日/Using_LLMs_for_Tabletop_Exercises_within_the_Security_Domain.md)

    - [翻译: 针对安全领域，本研究探讨运用LLMs进行桌面模拟训练的可能性与效果。](2024年03月03日/Using_LLMs_for_Tabletop_Exercises_within_the_Security_Domain.md)

- [Towards Comprehensive Vietnamese Retrieval-Augmented Generation and Large Language Models](2024年03月03日/Towards_Comprehensive_Vietnamese_Retrieval-Augmented_Generation_and_Large_Language_Models.md)

    - [翻译: 致力于打造全方位的越南语检索增强生成方案，并探索大型语言模型在此领域的应用潜力。](2024年03月03日/Towards_Comprehensive_Vietnamese_Retrieval-Augmented_Generation_and_Large_Language_Models.md)

- [SCHEMA: State CHangEs MAtter for Procedure Planning in Instructional Videos](2024年03月03日/SCHEMA_State_CHangEs_MAtter_for_Procedure_Planning_in_Instructional_Videos.md)

    - [翻译: SCHEMA 研究表明，在解析教学视频中的程序规划时，状态变化起到关键作用。](2024年03月03日/SCHEMA_State_CHangEs_MAtter_for_Procedure_Planning_in_Instructional_Videos.md)

- [IoT Device Labeling Using Large Language Models](2024年03月03日/IoT_Device_Labeling_Using_Large_Language_Models.md)

    - [翻译: 借助大型语言模型实现物联网设备智能标注](2024年03月03日/IoT_Device_Labeling_Using_Large_Language_Models.md)

- [SARD: A Human-AI Collaborative Story Generation](2024年03月03日/SARD_A_Human-AI_Collaborative_Story_Generation.md)

    - [翻译: SARD：携手人类与AI共创故事新篇章](2024年03月03日/SARD_A_Human-AI_Collaborative_Story_Generation.md)

- [SERVAL: Synergy Learning between Vertical Models and LLMs towards Oracle-Level Zero-shot Medical Prediction](2024年03月03日/SERVAL_Synergy_Learning_between_Vertical_Models_and_LLMs_towards_Oracle-Level_Zero-shot_Medical_Prediction.md)

    - [翻译: SERVAL 研究通过构建垂直模型与大型语言模型（LLMs）间的协同效应，致力于在零样本条件下达到“Oracle级别”的医疗预测精度。](2024年03月03日/SERVAL_Synergy_Learning_between_Vertical_Models_and_LLMs_towards_Oracle-Level_Zero-shot_Medical_Prediction.md)

- [ReMatch: Retrieval Enhanced Schema Matching with LLMs](2024年03月03日/ReMatch_Retrieval_Enhanced_Schema_Matching_with_LLMs.md)

    - [翻译: ReMatch技术利用LLMs的力量，实现了检索增强型模式匹配，让数据结构间的对应关系更加精准高效。](2024年03月03日/ReMatch_Retrieval_Enhanced_Schema_Matching_with_LLMs.md)

- [Transformers for Supervised Online Continual Learning](2024年03月03日/Transformers_for_Supervised_Online_Continual_Learning.md)

    - [翻译: 面向监督在线连续学习的 Transformer 模型研究](2024年03月03日/Transformers_for_Supervised_Online_Continual_Learning.md)

- [Citation-Enhanced Generation for LLM-based Chatbots](2024年03月03日/Citation-Enhanced_Generation_for_LLM-based_Chatbots.md)

    - [翻译: 为基于大型语言模型（LLM）的聊天机器人引入引文增强生成技术，旨在提升其对话内容的准确性和可信度。](2024年03月03日/Citation-Enhanced_Generation_for_LLM-based_Chatbots.md)

- [Query Augmentation by Decoding Semantics from Brain Signals](2024年03月03日/Query_Augmentation_by_Decoding_Semantics_from_Brain_Signals.md)

    - [翻译: 本研究探讨了一种创新方法，通过解读大脑信号中的语义信息来丰富和增强查询，实现与用户思维更深层次的交互。](2024年03月03日/Query_Augmentation_by_Decoding_Semantics_from_Brain_Signals.md)

- [Automated Generation of Multiple-Choice Cloze Questions for Assessing English Vocabulary Using GPT-turbo 3.5](2024年03月04日/Automated_Generation_of_Multiple-Choice_Cloze_Questions_for_Assessing_English_Vocabulary_Using_GPT-turbo_3.5.md)

    - [翻译: 本研究运用 GPT-turbo 3.5 技术，自动创建适合评估英语词汇掌握程度的多选填空题。](2024年03月04日/Automated_Generation_of_Multiple-Choice_Cloze_Questions_for_Assessing_English_Vocabulary_Using_GPT-turbo_3.5.md)

- [Large Language Model-Based Evolutionary Optimizer: Reasoning with elitism](2024年03月04日/Large_Language_Model-Based_Evolutionary_Optimizer_Reasoning_with_elitism.md)

    - [翻译: 这款基于大型语言模型的进化优化器，通过精英主义原理进行智能推理。它巧妙地运用了大型语言模型的优势，在不断优化过程中甄选并借鉴最优解决方案进行迭代升级。](2024年03月04日/Large_Language_Model-Based_Evolutionary_Optimizer_Reasoning_with_elitism.md)

- [Unveiling Hidden Links Between Unseen Security Entities](2024年03月04日/Unveiling_Hidden_Links_Between_Unseen_Security_Entities.md)

    - [翻译: 本研究致力于揭开未知安全实体间的潜在关联，探寻那些未曾显现的隐性联系。](2024年03月04日/Unveiling_Hidden_Links_Between_Unseen_Security_Entities.md)

- [LLM-Oriented Retrieval Tuner](2024年03月04日/LLM-Oriented_Retrieval_Tuner.md)

    - [翻译: 针对 LLM 的检索优化器，旨在对大型语言模型进行精准高效的检索调优。](2024年03月04日/LLM-Oriented_Retrieval_Tuner.md)

- [FakeNewsGPT4: Advancing Multimodal Fake News Detection through Knowledge-Augmented LVLMs](2024年03月04日/FakeNewsGPT4_Advancing_Multimodal_Fake_News_Detection_through_Knowledge-Augmented_LVLMs.md)

    - [翻译: FakeNewsGPT4 是一项创新研究，利用了知识增强的多模态大型语言模型，旨在提升假新闻检测能力。](2024年03月04日/FakeNewsGPT4_Advancing_Multimodal_Fake_News_Detection_through_Knowledge-Augmented_LVLMs.md)

- [Evaluating the Explainability of Neural Rankers](2024年03月04日/Evaluating_the_Explainability_of_Neural_Rankers.md)

    - [翻译: 本研究旨在深入探讨和评估神经网络排序模型的可解释性，以揭示其内部决策机制及优化依据。](2024年03月04日/Evaluating_the_Explainability_of_Neural_Rankers.md)

- [SciAssess: Benchmarking LLM Proficiency in Scientific Literature Analysis](2024年03月04日/SciAssess_Benchmarking_LLM_Proficiency_in_Scientific_Literature_Analysis.md)

    - [翻译: SciAssess 是一个针对大型语言模型（LLM）在科学文献分析能力上的基准测试工具，旨在衡量和评估 LLM 在理解和解析科学文献方面的专业水准。](2024年03月04日/SciAssess_Benchmarking_LLM_Proficiency_in_Scientific_Literature_Analysis.md)

- [Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models](2024年03月04日/Multi-perspective_Improvement_of_Knowledge_Graph_Completion_with_Large_Language_Models.md)

    - [翻译: 本研究探讨如何借助大型语言模型从多个视角提升知识图谱补全任务的效果。](2024年03月04日/Multi-perspective_Improvement_of_Knowledge_Graph_Completion_with_Large_Language_Models.md)

- [ContrastRepair: Enhancing Conversation-Based Automated Program Repair via Contrastive Test Case Pairs](2024年03月04日/ContrastRepair_Enhancing_Conversation-Based_Automated_Program_Repair_via_Contrastive_Test_Case_Pairs.md)

    - [翻译: ContrastRepair 是一种创新方法，通过构建并利用对比测试用例对，有效提升基于对话模式的自动化程序修复能力。](2024年03月04日/ContrastRepair_Enhancing_Conversation-Based_Automated_Program_Repair_via_Contrastive_Test_Case_Pairs.md)

- [AS-ES Learning: Towards Efficient CoT Learning in Small Models](2024年03月04日/AS-ES_Learning_Towards_Efficient_CoT_Learning_in_Small_Models.md)

    - [翻译: AS-ES 学习致力于在小型模型中实现高效的概念到文本（CoT）学习，旨在提升模型理解和应用复杂概念的能力。](2024年03月04日/AS-ES_Learning_Towards_Efficient_CoT_Learning_in_Small_Models.md)

- [Analyzing and Adapting Large Language Models for Few-Shot Multilingual NLU: Are We There Yet?](2024年03月04日/Analyzing_and_Adapting_Large_Language_Models_for_Few-Shot_Multilingual_NLU_Are_We_There_Yet.md)

    - [翻译: 针对少量样本多语言 NLU 任务，对大型语言模型进行分析与适应的研究：我们是否已达成目标？](2024年03月04日/Analyzing_and_Adapting_Large_Language_Models_for_Few-Shot_Multilingual_NLU_Are_We_There_Yet.md)

- [To Generate or to Retrieve? On the Effectiveness of Artificial Contexts for Medical Open-Domain Question Answering](2024年03月04日/To_Generate_or_to_Retrieve_On_the_Effectiveness_of_Artificial_Contexts_for_Medical_Open-Domain_Question_Answering.md)

    - [翻译: 探究“生成”与“检索”的抉择——人工构建的上下文对医学开放领域问答效果的影响](2024年03月04日/To_Generate_or_to_Retrieve_On_the_Effectiveness_of_Artificial_Contexts_for_Medical_Open-Domain_Question_Answering.md)

- [Arabic Text Sentiment Analysis: Reinforcing Human-Performed Surveys with Wider Topic Analysis](2024年03月04日/Arabic_Text_Sentiment_Analysis_Reinforcing_Human-Performed_Surveys_with_Wider_Topic_Analysis.md)

    - [翻译: 本研究聚焦于阿拉伯语文本情感分析，通过融合更广泛的主题分析以增强基于人类调查的结果，旨在提升对调查数据的洞察力和准确性。](2024年03月04日/Arabic_Text_Sentiment_Analysis_Reinforcing_Human-Performed_Surveys_with_Wider_Topic_Analysis.md)

- [xT: Nested Tokenization for Larger Context in Large Images](2024年03月04日/xT_Nested_Tokenization_for_Larger_Context_in_Large_Images.md)

    - [翻译: xT 技术提出了一种针对大型图像的嵌套分词方法，旨在捕获并处理更大范围的上下文信息。](2024年03月04日/xT_Nested_Tokenization_for_Larger_Context_in_Large_Images.md)

- [Fostering the Ecosystem of Open Neural Encoders for Portuguese with Albertina PT* Family](2024年03月04日/Fostering_the_Ecosystem_of_Open_Neural_Encoders_for_Portuguese_with_Albertina_PT_Family.md)

    - [翻译: Albertina PT* 系列旨在促进葡萄牙语开放神经编码器生态系统的构建与发展](2024年03月04日/Fostering_the_Ecosystem_of_Open_Neural_Encoders_for_Portuguese_with_Albertina_PT_Family.md)

- [An Improved Traditional Chinese Evaluation Suite for Foundation Model](2024年03月04日/An_Improved_Traditional_Chinese_Evaluation_Suite_for_Foundation_Model.md)

    - [翻译: 为了更好地评测基础模型在处理汉字任务时的性能，我们推出了一个优化的传统中文评估套件。这个改进版套件旨在深入考察和精确衡量各类基础模型在处理汉字文本及理解传统中国文化情境中的表现。](2024年03月04日/An_Improved_Traditional_Chinese_Evaluation_Suite_for_Foundation_Model.md)

- [Rethinking LLM Language Adaptation: A Case Study on Chinese Mixtral](2024年03月04日/Rethinking_LLM_Language_Adaptation_A_Case_Study_on_Chinese_Mixtral.md)

    - [翻译: 对LLM的语言适应性进行再思考——以“Chinese Mixtral”为例的深度探究](2024年03月04日/Rethinking_LLM_Language_Adaptation_A_Case_Study_on_Chinese_Mixtral.md)

- [One Prompt Word is Enough to Boost Adversarial Robustness for Pre-trained Vision-Language Models](2024年03月04日/One_Prompt_Word_is_Enough_to_Boost_Adversarial_Robustness_for_Pre-trained_Vision-Language_Models.md)

    - [翻译: 惊人发现，只需单个提示词即可显著增强预训练视觉-语言模型在对抗性环境中的稳健性。](2024年03月04日/One_Prompt_Word_is_Enough_to_Boost_Adversarial_Robustness_for_Pre-trained_Vision-Language_Models.md)

- [CatCode: A Comprehensive Evaluation Framework for LLMs On the Mixture of Code and Text](2024年03月04日/CatCode_A_Comprehensive_Evaluation_Framework_for_LLMs_On_the_Mixture_of_Code_and_Text.md)

    - [翻译: CatCode 是一个综合性的评估框架，专为在混合代码与文本环境中的大型语言模型（LLMs）设计，旨在全方位测评其性能表现。](2024年03月04日/CatCode_A_Comprehensive_Evaluation_Framework_for_LLMs_On_the_Mixture_of_Code_and_Text.md)

- [NPHardEval4V: A Dynamic Reasoning Benchmark of Multimodal Large Language Models](2024年03月04日/NPHardEval4V_A_Dynamic_Reasoning_Benchmark_of_Multimodal_Large_Language_Models.md)

    - [翻译: NPHardEval4V 是针对多模态大型语言模型设计的一套动态推理性能评估基准，旨在全面检验此类模型在复杂场景下的理解与推理能力。](2024年03月04日/NPHardEval4V_A_Dynamic_Reasoning_Benchmark_of_Multimodal_Large_Language_Models.md)

- [WebCiteS: Attributed Query-Focused Summarization on Chinese Web Search Results with Citations](2024年03月04日/WebCiteS_Attributed_Query-Focused_Summarization_on_Chinese_Web_Search_Results_with_Citations.md)

    - [翻译: WebCiteS 是一种创新技术，专注于对中文网页搜索结果进行带引文的查询焦点摘要。该技术旨在通过考虑引用信息，提升搜索结果摘要的质量和针对性。](2024年03月04日/WebCiteS_Attributed_Query-Focused_Summarization_on_Chinese_Web_Search_Results_with_Citations.md)

- [How Multimodal Integration Boost the Performance of LLM for Optimization: Case Study on Capacitated Vehicle Routing Problems](2024年03月04日/How_Multimodal_Integration_Boost_the_Performance_of_LLM_for_Optimization_Case_Study_on_Capacitated_Vehicle_Routing_Problems.md)

    - [翻译: 通过研究载量受限车辆路径问题，本文探讨了多模态集成如何显著增强大型语言模型（LLM）在优化任务中的表现。](2024年03月04日/How_Multimodal_Integration_Boost_the_Performance_of_LLM_for_Optimization_Case_Study_on_Capacitated_Vehicle_Routing_Problems.md)

- [AI Language Models Could Both Help and Harm Equity in Marine Policymaking: The Case Study of the BBNJ Question-Answering Bot](2024年03月04日/AI_Language_Models_Could_Both_Help_and_Harm_Equity_in_Marine_Policymaking_The_Case_Study_of_the_BBNJ_Question-Answering_Bot.md)

    - [翻译: AI语言模型在海洋政策制定领域的应用，如BBNJ问答机器人案例所示，既能促进公平性也可能带来潜在的不平等问题。本研究通过该案例探讨了这一双刃剑效应。](2024年03月04日/AI_Language_Models_Could_Both_Help_and_Harm_Equity_in_Marine_Policymaking_The_Case_Study_of_the_BBNJ_Question-Answering_Bot.md)

- [Derivative-Free Optimization for Low-Rank Adaptation in Large Language Models](2024年03月04日/Derivative-Free_Optimization_for_Low-Rank_Adaptation_in_Large_Language_Models.md)

    - [翻译: 针对大型语言模型中的低秩适应问题，本研究探讨了无需依赖梯度信息的优化方法。](2024年03月04日/Derivative-Free_Optimization_for_Low-Rank_Adaptation_in_Large_Language_Models.md)

- [Differentially Private Synthetic Data via Foundation Model APIs 2: Text](2024年03月04日/Differentially_Private_Synthetic_Data_via_Foundation_Model_APIs_2_Text.md)

    - [翻译: 借助基础模型API，我们推出了针对文本的第二版差分隐私合成数据技术。这项技术利用基础模型能力，在保证数据隐私性的同时生成高质量的合成文本数据。](2024年03月04日/Differentially_Private_Synthetic_Data_via_Foundation_Model_APIs_2_Text.md)

- [Decode Neural signal as Speech](2024年03月04日/Decode_Neural_signal_as_Speech.md)

    - [翻译: 本研究致力于将神经信号转化为可识别的语音，探索从大脑活动直接解读言语信息的可能性。](2024年03月04日/Decode_Neural_signal_as_Speech.md)

- [NoteLLM: A Retrievable Large Language Model for Note Recommendation](2024年03月04日/NoteLLM_A_Retrievable_Large_Language_Model_for_Note_Recommendation.md)

    - [翻译: NoteLLM，一款专为笔记推荐打造的可检索型大型语言模型。](2024年03月04日/NoteLLM_A_Retrievable_Large_Language_Model_for_Note_Recommendation.md)

- [Key-Point-Driven Data Synthesis with its Enhancement on Mathematical Reasoning](2024年03月04日/Key-Point-Driven_Data_Synthesis_with_its_Enhancement_on_Mathematical_Reasoning.md)

    - [翻译: 通过关键点驱动的数据合成技术，并对其进行优化，以提升数学推理性能。这项研究聚焦于利用关键点引导的数据合成方法，有效增强模型在数学推理任务上的表现。](2024年03月04日/Key-Point-Driven_Data_Synthesis_with_its_Enhancement_on_Mathematical_Reasoning.md)

- [RegionGPT: Towards Region Understanding Vision Language Model](2024年03月04日/RegionGPT_Towards_Region_Understanding_Vision_Language_Model.md)

    - [翻译: RegionGPT——迈向理解视觉区域的新型语言模型，旨在提升视觉与语言融合模型在区域理解层面的表现。](2024年03月04日/RegionGPT_Towards_Region_Understanding_Vision_Language_Model.md)

- [Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures](2024年03月04日/Vision-RWKV_Efficient_and_Scalable_Visual_Perception_with_RWKV-Like_Architectures.md)

    - [翻译: Vision-RWKV 是一种采用类RWKV架构设计，有效实现了视觉感知的高效性和可扩展性的方法。](2024年03月04日/Vision-RWKV_Efficient_and_Scalable_Visual_Perception_with_RWKV-Like_Architectures.md)

- [Beyond Specialization: Assessing the Capabilities of MLLMs in Age and Gender Estimation](2024年03月04日/Beyond_Specialization_Assessing_the_Capabilities_of_MLLMs_in_Age_and_Gender_Estimation.md)

    - [翻译: 本研究超越了单一领域的专业性，致力于评估多语言大型模型（MLLMs）在年龄与性别估算任务中的能力。](2024年03月04日/Beyond_Specialization_Assessing_the_Capabilities_of_MLLMs_in_Age_and_Gender_Estimation.md)

- [FENICE: Factuality Evaluation of summarization based on Natural language Inference and Claim Extraction](2024年03月04日/FENICE_Factuality_Evaluation_of_summarization_based_on_Natural_language_Inference_and_Claim_Extraction.md)

    - [翻译: FENICE 是一种利用自然语言推理和论断抽取技术对摘要进行事实性评估的方法。](2024年03月04日/FENICE_Factuality_Evaluation_of_summarization_based_on_Natural_language_Inference_and_Claim_Extraction.md)

- [KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection](2024年03月04日/KnowPhish_Large_Language_Models_Meet_Multimodal_Knowledge_Graphs_for_Enhancing_Reference-Based_Phishing_Detection.md)

    - [翻译: KnowPhish项目将大型语言模型与多模态知识图谱相结合，旨在强化基于参照的钓鱼检测技术，实现更高效的网络欺诈识别。](2024年03月04日/KnowPhish_Large_Language_Models_Meet_Multimodal_Knowledge_Graphs_for_Enhancing_Reference-Based_Phishing_Detection.md)

- [PHAnToM: Personality Has An Effect on Theory-of-Mind Reasoning in Large Language Models](2024年03月04日/PHAnToM_Personality_Has_An_Effect_on_Theory-of-Mind_Reasoning_in_Large_Language_Models.md)

    - [翻译: PHAnToM研究表明，大型语言模型的心智理论推理会受到模型所具备的个性特征的影响。](2024年03月04日/PHAnToM_Personality_Has_An_Effect_on_Theory-of-Mind_Reasoning_in_Large_Language_Models.md)

- [Towards Intent-Based Network Management: Large Language Models for Intent Extraction in 5G Core Networks](2024年03月04日/Towards_Intent-Based_Network_Management_Large_Language_Models_for_Intent_Extraction_in_5G_Core_Networks.md)

    - [翻译: 致力于打造基于意图的网络管理模式，我们探索了在5G核心网络环境下运用大型语言模型抽取用户意图的可能性。](2024年03月04日/Towards_Intent-Based_Network_Management_Large_Language_Models_for_Intent_Extraction_in_5G_Core_Networks.md)

- [3DTopia: Large Text-to-3D Generation Model with Hybrid Diffusion Priors](2024年03月04日/3DTopia_Large_Text-to-3D_Generation_Model_with_Hybrid_Diffusion_Priors.md)

    - [翻译: 3DTopia是一款创新的大型文本转三维生成模型，巧妙融合了混合扩散先验技术，实现从文本信息高效构建高质量三维模型。](2024年03月04日/3DTopia_Large_Text-to-3D_Generation_Model_with_Hybrid_Diffusion_Priors.md)

- [TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language Models](2024年03月04日/TPLLM_A_Traffic_Prediction_Framework_Based_on_Pretrained_Large_Language_Models.md)

    - [翻译: TPLLM 是一种基于预训练大型语言模型的交通预测方案，该框架利用大规模语言模型的强大泛化和学习能力，对交通流量进行精准预测。](2024年03月04日/TPLLM_A_Traffic_Prediction_Framework_Based_on_Pretrained_Large_Language_Models.md)

- [Not all Layers of LLMs are Necessary during Inference](2024年03月04日/Not_all_Layers_of_LLMs_are_Necessary_during_Inference.md)

    - [翻译: 对于LLM的推理阶段，并非所有层级都不可或缺。](2024年03月04日/Not_all_Layers_of_LLMs_are_Necessary_during_Inference.md)

- [Masked Thought: Simply Masking Partial Reasoning Steps Can Improve Mathematical Reasoning Learning of Language Models](2024年03月04日/Masked_Thought_Simply_Masking_Partial_Reasoning_Steps_Can_Improve_Mathematical_Reasoning_Learning_of_Language_Models.md)

    - [翻译: Masked Thought 研究表明，简单地对部分推理步骤进行遮蔽处理，就能有效增强语言模型在数学推理学习上的表现。](2024年03月04日/Masked_Thought_Simply_Masking_Partial_Reasoning_Steps_Can_Improve_Mathematical_Reasoning_Learning_of_Language_Models.md)

- [Cognition is All You Need - The Next Layer of AI Above Large Language Models](2024年03月04日/Cognition_is_All_You_Need_-_The_Next_Layer_of_AI_Above_Large_Language_Models.md)

    - [翻译: 在大型语言模型基础上，认知力量被视为推动AI发展的下一关键层次 ——“认知即一切”。](2024年03月04日/Cognition_is_All_You_Need_-_The_Next_Layer_of_AI_Above_Large_Language_Models.md)

- [Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation](2024年03月04日/Memoro_Using_Large_Language_Models_to_Realize_a_Concise_Interface_for_Real-Time_Memory_Augmentation.md)

    - [翻译: Memoro项目通过运用大型语言模型，打造出一个能够实现实时记忆增强的精炼界面。](2024年03月04日/Memoro_Using_Large_Language_Models_to_Realize_a_Concise_Interface_for_Real-Time_Memory_Augmentation.md)

- [Using LLMs for the Extraction and Normalization of Product Attribute Values](2024年03月04日/Using_LLMs_for_the_Extraction_and_Normalization_of_Product_Attribute_Values.md)

    - [翻译: 运用 LLM 技术抽取并规范产品属性值，本研究旨在探索这一方法在处理产品信息时的高效性和准确性。](2024年03月04日/Using_LLMs_for_the_Extraction_and_Normalization_of_Product_Attribute_Values.md)

- [Leveraging Weakly Annotated Data for Hate Speech Detection in Code-Mixed Hinglish: A Feasibility-Driven Transfer Learning Approach with Large Language Models](2024年03月04日/Leveraging_Weakly_Annotated_Data_for_Hate_Speech_Detection_in_Code-Mixed_Hinglish_A_Feasibility-Driven_Transfer_Learning_Approach_with_Large_Language_Models.md)

    - [翻译: 针对混合语种 Hinglish 中的仇恨言论检测问题，我们提出了一种以可行性为导向的迁移学习策略，充分利用弱标注数据，并结合大型语言模型的力量。](2024年03月04日/Leveraging_Weakly_Annotated_Data_for_Hate_Speech_Detection_in_Code-Mixed_Hinglish_A_Feasibility-Driven_Transfer_Learning_Approach_with_Large_Language_Models.md)

- [Found in the Middle: How Language Models Use Long Contexts Better via Plug-and-Play Positional Encoding](2024年03月04日/Found_in_the_Middle_How_Language_Models_Use_Long_Contexts_Better_via_Plug-and-Play_Positional_Encoding.md)

    - [翻译: 研究揭示，借助“即插即用”位置编码，语言模型能够更有效地利用长篇幅的上下文信息。](2024年03月04日/Found_in_the_Middle_How_Language_Models_Use_Long_Contexts_Better_via_Plug-and-Play_Positional_Encoding.md)

- [Large Language Models in Fire Engineering: An Examination of Technical Questions Against Domain Knowledge](2024年03月04日/Large_Language_Models_in_Fire_Engineering_An_Examination_of_Technical_Questions_Against_Domain_Knowledge.md)

    - [翻译: 探究大型语言模型如何应用于火灾工程领域，通过对比领域专业知识来审视其解决技术问题的能力。](2024年03月04日/Large_Language_Models_in_Fire_Engineering_An_Examination_of_Technical_Questions_Against_Domain_Knowledge.md)

- [Online Training of Large Language Models: Learn while chatting](2024年03月04日/Online_Training_of_Large_Language_Models_Learn_while_chatting.md)

    - [翻译: 大型语言模型的在线训练技术，让模型在互动聊天中实时学习与成长。](2024年03月04日/Online_Training_of_Large_Language_Models_Learn_while_chatting.md)

- [Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents](2024年03月04日/Trial_and_Error_Exploration-Based_Trajectory_Optimization_for_LLM_Agents.md)

    - [翻译: 通过“试错”方式，研究针对LLM智能体的探索式轨迹优化策略。](2024年03月04日/Trial_and_Error_Exploration-Based_Trajectory_Optimization_for_LLM_Agents.md)

- [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](2024年03月05日/The_WMDP_Benchmark_Measuring_and_Reducing_Malicious_Use_With_Unlearning.md)

    - [翻译: WMDP基准计划旨在衡量并有效减少恶意使用，其方法是采用“消除学习”技术。这个测试标准聚焦于评估及降低利用机器学习模型进行恶意行为的可能性，并探索通过“遗忘学习”机制来达成这一目标的途径。](2024年03月05日/The_WMDP_Benchmark_Measuring_and_Reducing_Malicious_Use_With_Unlearning.md)

- [CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments](2024年03月05日/CLEVR-POC_Reasoning-Intensive_Visual_Question_Answering_in_Partially_Observable_Environments.md)

    - [翻译: CLEVR-POC 是一个专注于在局部可观察环境下的高强度视觉推理问答研究，旨在探究在不完全信息条件下进行复杂视觉推理的能力。](2024年03月05日/CLEVR-POC_Reasoning-Intensive_Visual_Question_Answering_in_Partially_Observable_Environments.md)

- [MAGID: An Automated Pipeline for Generating Synthetic Multi-modal Datasets](2024年03月05日/MAGID_An_Automated_Pipeline_for_Generating_Synthetic_Multi-modal_Datasets.md)

    - [翻译: MAGID 是一款自动化的流水线工具，专注于创建合成型多模态数据集。](2024年03月05日/MAGID_An_Automated_Pipeline_for_Generating_Synthetic_Multi-modal_Datasets.md)

- [Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement](2024年03月05日/Towards_Democratized_Flood_Risk_Management_An_Advanced_AI_Assistant_Enabled_by_GPT-4_for_Enhanced_Interpretability_and_Public_Engagement.md)

    - [翻译: 为实现洪水风险管理的大众化，我们引入了一款基于 GPT-4 技术的先进 AI 助手。这款智能助手致力于增强模型解释力和促进公众积极参与洪水风险管理工作。](2024年03月05日/Towards_Democratized_Flood_Risk_Management_An_Advanced_AI_Assistant_Enabled_by_GPT-4_for_Enhanced_Interpretability_and_Public_Engagement.md)

- [Reliable, Adaptable, and Attributable Language Models with Retrieval](2024年03月05日/Reliable,_Adaptable,_and_Attributable_Language_Models_with_Retrieval.md)

    - [翻译: 致力于构建可靠、灵活且具有明确来源的检索型语言模型，以提升其性能和可信度。](2024年03月05日/Reliable,_Adaptable,_and_Attributable_Language_Models_with_Retrieval.md)

- [SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection](2024年03月05日/SNIFFER_Multimodal_Large_Language_Model_for_Explainable_Out-of-Context_Misinformation_Detection.md)

    - [翻译: SNIFFER是一款专注于可解释性离群信息检测的多模态大型语言模型，能够有效识别和解析上下文缺失情况下的错误信息。](2024年03月05日/SNIFFER_Multimodal_Large_Language_Model_for_Explainable_Out-of-Context_Misinformation_Detection.md)

- [PARADISE: Evaluating Implicit Planning Skills of Language Models with Procedural Warnings and Tips Dataset](2024年03月05日/PARADISE_Evaluating_Implicit_Planning_Skills_of_Language_Models_with_Procedural_Warnings_and_Tips_Dataset.md)

    - [翻译: PARADISE 是一项研究，它借助程序性警告和提示数据集来评估语言模型在隐式规划任务上的表现能力。](2024年03月05日/PARADISE_Evaluating_Implicit_Planning_Skills_of_Language_Models_with_Procedural_Warnings_and_Tips_Dataset.md)

- [Quantum Many-Body Physics Calculations with Large Language Models](2024年03月05日/Quantum_Many-Body_Physics_Calculations_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型探索量子多体物理问题的计算解决之道](2024年03月05日/Quantum_Many-Body_Physics_Calculations_with_Large_Language_Models.md)

- [Language Guided Exploration for RL Agents in Text Environments](2024年03月05日/Language_Guided_Exploration_for_RL_Agents_in_Text_Environments.md)

    - [翻译: 针对文本环境中的强化学习（RL）智能体，我们提出语言指导的探索策略，利用自然语言引导智能体在复杂环境中高效探索和学习。](2024年03月05日/Language_Guided_Exploration_for_RL_Agents_in_Text_Environments.md)

- [CoGenesis: A Framework Collaborating Large and Small Language Models for Secure Context-Aware Instruction Following](2024年03月05日/CoGenesis_A_Framework_Collaborating_Large_and_Small_Language_Models_for_Secure_Context-Aware_Instruction_Following.md)

    - [翻译: CoGenesis 是一种创新框架，它巧妙地整合了大型和小型语言模型的力量，旨在实现安全且具备情境感知能力的指令执行。](2024年03月05日/CoGenesis_A_Framework_Collaborating_Large_and_Small_Language_Models_for_Secure_Context-Aware_Instruction_Following.md)

- [Angry Men, Sad Women: Large Language Models Reflect Gendered Stereotypes in Emotion Attribution](2024年03月05日/Angry_Men,_Sad_Women_Large_Language_Models_Reflect_Gendered_Stereotypes_in_Emotion_Attribution.md)

    - [翻译: 大型语言模型揭示了在情绪认知上存在的性别刻板印象，即“愤怒的男人”与“悲伤的女人”。本研究针对这一现象，深入探讨了大型语言模型如何在情感属性分配中体现性别偏见。](2024年03月05日/Angry_Men,_Sad_Women_Large_Language_Models_Reflect_Gendered_Stereotypes_in_Emotion_Attribution.md)

- ["In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning](2024年03月05日/In_Dialogues_We_Learn_Towards_Personalized_Dialogue_Without_Pre-defined_Profiles_through_In-Dialogue_Learning.md)

    - [翻译: “对话即学习”：探索无预设用户画像的个性化对话，借助于对话过程中的实时学习技术](2024年03月05日/In_Dialogues_We_Learn_Towards_Personalized_Dialogue_Without_Pre-defined_Profiles_through_In-Dialogue_Learning.md)

- [KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](2024年03月05日/KnowAgent_Knowledge-Augmented_Planning_for_LLM-Based_Agents.md)

    - [翻译: KnowAgent是一种为基于大型语言模型（LLM）的智能体设计的知识增强规划方案，旨在通过融合知识与LLM能力来提升其决策与规划效能。](2024年03月05日/KnowAgent_Knowledge-Augmented_Planning_for_LLM-Based_Agents.md)

- [MiKASA: Multi-Key-Anchor & Scene-Aware Transformer for 3D Visual Grounding](2024年03月05日/MiKASA_Multi-Key-Anchor_&_Scene-Aware_Transformer_for_3D_Visual_Grounding.md)

    - [翻译: MiKASA——这款创新的三维视觉定位模型，巧妙融合了多键锚点与场景感知技术，以Transformer架构为核心，旨在提升三维空间中的目标定位精准度。](2024年03月05日/MiKASA_Multi-Key-Anchor_&_Scene-Aware_Transformer_for_3D_Visual_Grounding.md)

- [Learning to Use Tools via Cooperative and Interactive Agents](2024年03月05日/Learning_to_Use_Tools_via_Cooperative_and_Interactive_Agents.md)

    - [翻译: 在合作与互动智能体的引导下掌握工具使用技能](2024年03月05日/Learning_to_Use_Tools_via_Cooperative_and_Interactive_Agents.md)

- [Socratic Reasoning Improves Positive Text Rewriting](2024年03月05日/Socratic_Reasoning_Improves_Positive_Text_Rewriting.md)

    - [翻译: 运用苏格拉底式推理能够显著优化正面文本的重写过程，使其更具说服力和深度。](2024年03月05日/Socratic_Reasoning_Improves_Positive_Text_Rewriting.md)

- [Word Importance Explains How Prompts Affect Language Model Outputs](2024年03月05日/Word_Importance_Explains_How_Prompts_Affect_Language_Model_Outputs.md)

    - [翻译: 探究词语权重：揭示提示如何驱动语言模型的输出变化](2024年03月05日/Word_Importance_Explains_How_Prompts_Affect_Language_Model_Outputs.md)

- [OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following](2024年03月05日/OPEx_A_Component-Wise_Analysis_of_LLM-Centric_Agents_in_Embodied_Instruction_Following.md)

    - [翻译: OPEx研究针对具身指令跟随任务中以大型语言模型（LLM）为核心的智能体，对其进行深入的组件级分析。](2024年03月05日/OPEx_A_Component-Wise_Analysis_of_LLM-Centric_Agents_in_Embodied_Instruction_Following.md)

- [Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations](2024年03月05日/Knowledge_Graphs_as_Context_Sources_for_LLM-Based_Explanations_of_Learning_Recommendations.md)

    - [翻译: 在基于LLM的学习推荐解释中，知识图谱可作为重要的上下文信息源。](2024年03月05日/Knowledge_Graphs_as_Context_Sources_for_LLM-Based_Explanations_of_Learning_Recommendations.md)

- [Feast Your Eyes: Mixture-of-Resolution Adaptation for Multimodal Large Language Models](2024年03月05日/Feast_Your_Eyes_Mixture-of-Resolution_Adaptation_for_Multimodal_Large_Language_Models.md)

    - [翻译: 标题生动翻译：“饱览盛宴”：探究多模态大型语言模型中的混合分辨率自适应技术](2024年03月05日/Feast_Your_Eyes_Mixture-of-Resolution_Adaptation_for_Multimodal_Large_Language_Models.md)

- [Localized Zeroth-Order Prompt Optimization](2024年03月05日/Localized_Zeroth-Order_Prompt_Optimization.md)

    - [翻译: 针对局部化的零阶提示优化技术，该方法利用零阶优化策略对模型的提示进行微调，特别是在特定任务或领域中，以提升模型的表现和适应性。](2024年03月05日/Localized_Zeroth-Order_Prompt_Optimization.md)

- [MADTP: Multimodal Alignment-Guided Dynamic Token Pruning for Accelerating Vision-Language Transformer](2024年03月05日/MADTP_Multimodal_Alignment-Guided_Dynamic_Token_Pruning_for_Accelerating_Vision-Language_Transformer.md)

    - [翻译: MADTP是一种创新方法，通过多模态对齐指导下的动态令牌剪枝策略，有效提升视觉-语言Transformer模型的运算效率。](2024年03月05日/MADTP_Multimodal_Alignment-Guided_Dynamic_Token_Pruning_for_Accelerating_Vision-Language_Transformer.md)

- [Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges](2024年03月05日/Data_Augmentation_using_LLMs_Data_Perspectives,_Learning_Paradigms_and_Challenges.md)

    - [翻译: LLM 数据增强技术探究：从数据角度出发，探讨其背后的新型学习范式及其面临的挑战](2024年03月05日/Data_Augmentation_using_LLMs_Data_Perspectives,_Learning_Paradigms_and_Challenges.md)

- [Multi-modal Instruction Tuned LLMs with Fine-grained Visual Perception](2024年03月05日/Multi-modal_Instruction_Tuned_LLMs_with_Fine-grained_Visual_Perception.md)

    - [翻译: 通过细粒度视觉感知优化的多模态指令训练LLM技术，使模型能够更好地理解并融合多种模态信息，特别是在处理包含丰富视觉元素的任务时。](2024年03月05日/Multi-modal_Instruction_Tuned_LLMs_with_Fine-grained_Visual_Perception.md)

- [Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering](2024年03月05日/Evidence-Focused_Fact_Summarization_for_Knowledge-Augmented_Zero-Shot_Question_Answering.md)

    - [翻译: 为了解决知识增强型零样本问题回答的挑战，我们提出了一种聚焦于证据的事实摘要方法，旨在提炼关键事实信息以辅助解答未曾见过的问题。](2024年03月05日/Evidence-Focused_Fact_Summarization_for_Knowledge-Augmented_Zero-Shot_Question_Answering.md)

- [ChatGPT and biometrics: an assessment of face recognition, gender detection, and age estimation capabilities](2024年03月05日/ChatGPT_and_biometrics_an_assessment_of_face_recognition,_gender_detection,_and_age_estimation_capabilities.md)

    - [翻译: ChatGPT 结合生物识别技术实测：针对人脸识别、性别辨别及年龄估算功能进行综合评估](2024年03月05日/ChatGPT_and_biometrics_an_assessment_of_face_recognition,_gender_detection,_and_age_estimation_capabilities.md)

- [WikiTableEdit: A Benchmark for Table Editing by Natural Language Instruction](2024年03月05日/WikiTableEdit_A_Benchmark_for_Table_Editing_by_Natural_Language_Instruction.md)

    - [翻译: WikiTableEdit 是一个专门针对通过自然语言指令进行表格编辑任务的基准测试工具，旨在评估和衡量模型在理解并执行基于文本的表格修改指令方面的性能。](2024年03月05日/WikiTableEdit_A_Benchmark_for_Table_Editing_by_Natural_Language_Instruction.md)

- [SimuCourt: Building Judicial Decision-Making Agents with Real-world Judgement Documents](2024年03月05日/SimuCourt_Building_Judicial_Decision-Making_Agents_with_Real-world_Judgement_Documents.md)

    - [翻译: SimuCourt项目致力于通过真实世界司法判决文档，打造能够进行司法决策制定的智能代理。](2024年03月05日/SimuCourt_Building_Judicial_Decision-Making_Agents_with_Real-world_Judgement_Documents.md)

- [Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation](2024年03月05日/Benchmarking_the_Text-to-SQL_Capability_of_Large_Language_Models_A_Comprehensive_Evaluation.md)

    - [翻译: 针对大型语言模型（LLM）的Text-to-SQL转换能力，本研究进行了深入且全面的基准评测。](2024年03月05日/Benchmarking_the_Text-to-SQL_Capability_of_Large_Language_Models_A_Comprehensive_Evaluation.md)

- [PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers](2024年03月05日/PaperWeaver_Enriching_Topical_Paper_Alerts_by_Contextualizing_Recommended_Papers_with_User-collected_Papers.md)

    - [翻译: PaperWeaver，一款智能工具，能够将用户自行收藏的论文作为上下文，以此强化推荐论文的相关性，从而提升主题论文提醒的质量。](2024年03月05日/PaperWeaver_Enriching_Topical_Paper_Alerts_by_Contextualizing_Recommended_Papers_with_User-collected_Papers.md)

- [ImgTrojan: Jailbreaking Vision-Language Models with ONE Image](2024年03月05日/ImgTrojan_Jailbreaking_Vision-Language_Models_with_ONE_Image.md)

    - [翻译: ImgTrojan：仅凭一张图像即可实现对视觉-语言模型的“越狱”攻击](2024年03月05日/ImgTrojan_Jailbreaking_Vision-Language_Models_with_ONE_Image.md)

- [A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods](2024年03月05日/A_Comprehensive_Survey_on_Process-Oriented_Automatic_Text_Summarization_with_Exploration_of_LLM-Based_Methods.md)

    - [翻译: 本研究对过程导向自动文本摘要进行全面综述，并深度探索基于大型语言模型（LLM）的方法在该领域中的应用。](2024年03月05日/A_Comprehensive_Survey_on_Process-Oriented_Automatic_Text_Summarization_with_Exploration_of_LLM-Based_Methods.md)

- [Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation](2024年03月05日/Domain-Agnostic_Mutual_Prompting_for_Unsupervised_Domain_Adaptation.md)

    - [翻译: 为解决无监督领域适应问题，我们提出“领域无关的相互提示”方法，该方法能够在不同领域间进行有效知识迁移，无需任何领域标注数据。](2024年03月05日/Domain-Agnostic_Mutual_Prompting_for_Unsupervised_Domain_Adaptation.md)

- [In Search of Truth: An Interrogation Approach to Hallucination Detection](2024年03月05日/In_Search_of_Truth_An_Interrogation_Approach_to_Hallucination_Detection.md)

    - [翻译: 为揭示真相，我们提出了一种通过质询法来探测幻觉的新途径。](2024年03月05日/In_Search_of_Truth_An_Interrogation_Approach_to_Hallucination_Detection.md)

- [MathScale: Scaling Instruction Tuning for Mathematical Reasoning](2024年03月05日/MathScale_Scaling_Instruction_Tuning_for_Mathematical_Reasoning.md)

    - [翻译: MathScale 是一种专门针对数学推理能力提升而设计的指令调优扩展方案。](2024年03月05日/MathScale_Scaling_Instruction_Tuning_for_Mathematical_Reasoning.md)

- [An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Models are Task-specific Classifiers](2024年03月05日/An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation_Fine-tuned_Judge_Models_are_Task-specific_Classifiers.md)

    - [翻译: 本研究通过实证方法探究了将大型语言模型（LLM）作为评价工具的应用，其中经过微调的Judge模型实质上成为了针对特定任务的分类器。](2024年03月05日/An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation_Fine-tuned_Judge_Models_are_Task-specific_Classifiers.md)

- [DPPA: Pruning Method for Large Language Model to Model Merging](2024年03月05日/DPPA_Pruning_Method_for_Large_Language_Model_to_Model_Merging.md)

    - [翻译: DPPA：一种针对大型语言模型整合的高效剪枝技术，旨在优化模型合并过程。](2024年03月05日/DPPA_Pruning_Method_for_Large_Language_Model_to_Model_Merging.md)

- [Evaluating and Optimizing Educational Content with Large Language Model Judgments](2024年03月05日/Evaluating_and_Optimizing_Educational_Content_with_Large_Language_Model_Judgments.md)

    - [翻译: 利用大型语言模型评判来评估与优化教育内容，以提升教学质量及效果。](2024年03月05日/Evaluating_and_Optimizing_Educational_Content_with_Large_Language_Model_Judgments.md)

- [PromptKD: Unsupervised Prompt Distillation for Vision-Language Models](2024年03月05日/PromptKD_Unsupervised_Prompt_Distillation_for_Vision-Language_Models.md)

    - [翻译: PromptKD 是一种针对视觉-语言模型的创新方法，通过无监督的方式进行提示蒸馏，以提升此类模型的表现和泛化能力。](2024年03月05日/PromptKD_Unsupervised_Prompt_Distillation_for_Vision-Language_Models.md)

- [EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs](2024年03月05日/EasyQuant_An_Efficient_Data-free_Quantization_Algorithm_for_LLMs.md)

    - [翻译: EasyQuant：针对LLMs设计的高效无数据量化方案](2024年03月05日/EasyQuant_An_Efficient_Data-free_Quantization_Algorithm_for_LLMs.md)

- [Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations](2024年03月05日/Emerging_Synergies_Between_Large_Language_Models_and_Machine_Learning_in_Ecommerce_Recommendations.md)

    - [翻译: 在电商推荐领域，大型语言模型与机器学习技术正展现出日益增强的协同潜力。](2024年03月05日/Emerging_Synergies_Between_Large_Language_Models_and_Machine_Learning_in_Ecommerce_Recommendations.md)

- [In-Memory Learning: A Declarative Learning Framework for Large Language Models](2024年03月05日/In-Memory_Learning_A_Declarative_Learning_Framework_for_Large_Language_Models.md)

    - [翻译: 内存学习：一种针对大型语言模型设计的声明式学习方案，它提供了一种新颖高效的方法来训练和优化大规模模型。](2024年03月05日/In-Memory_Learning_A_Declarative_Learning_Framework_for_Large_Language_Models.md)

- [Role Prompting Guided Domain Adaptation with General Capability Preserve for Large Language Models](2024年03月05日/Role_Prompting_Guided_Domain_Adaptation_with_General_Capability_Preserve_for_Large_Language_Models.md)

    - [翻译: 在保持LLM广泛能力的前提下，我们提出了一种通过角色提示驱动的领域适应技术。](2024年03月05日/Role_Prompting_Guided_Domain_Adaptation_with_General_Capability_Preserve_for_Large_Language_Models.md)

- [HINTs: Sensemaking on large collections of documents with Hypergraph visualization and INTelligent agents](2024年03月05日/HINTs_Sensemaking_on_large_collections_of_documents_with_Hypergraph_visualization_and_INTelligent_agents.md)

    - [翻译: HINTs 技术利用超图可视化和智能代理，在大规模文档集合中实现高效的意义挖掘和理解。](2024年03月05日/HINTs_Sensemaking_on_large_collections_of_documents_with_Hypergraph_visualization_and_INTelligent_agents.md)

- [CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models](2024年03月05日/CURATRON_Complete_Robust_Preference_Data_for_Robust_Alignment_of_Large_Language_Models.md)

    - [翻译: CURATRON 提供了一套完整的、针对大型语言模型进行稳健对齐所必需的高质量偏好数据，以实现其在各类任务中的可靠和稳健表现。](2024年03月05日/CURATRON_Complete_Robust_Preference_Data_for_Robust_Alignment_of_Large_Language_Models.md)

- [Towards Training A Chinese Large Language Model for Anesthesiology](2024年03月05日/Towards_Training_A_Chinese_Large_Language_Model_for_Anesthesiology.md)

    - [翻译: 致力于训练适用于麻醉学领域的大型中文语言模型](2024年03月05日/Towards_Training_A_Chinese_Large_Language_Model_for_Anesthesiology.md)

- [Causal Prompting: Debiasing Large Language Model Prompting based on Front-Door Adjustment](2024年03月05日/Causal_Prompting_Debiasing_Large_Language_Model_Prompting_based_on_Front-Door_Adjustment.md)

    - [翻译: 因果提示法：运用前门调整策略校正大型语言模型的提示偏差](2024年03月05日/Causal_Prompting_Debiasing_Large_Language_Model_Prompting_based_on_Front-Door_Adjustment.md)

- [HARGPT: Are LLMs Zero-Shot Human Activity Recognizers?](2024年03月05日/HARGPT_Are_LLMs_Zero-Shot_Human_Activity_Recognizers.md)

    - [翻译: HARGPT 探究：LLMs 在零样本情况下能否胜任人类活动识别任务？](2024年03月05日/HARGPT_Are_LLMs_Zero-Shot_Human_Activity_Recognizers.md)

- [Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models](2024年03月05日/Crossing_Linguistic_Horizons_Finetuning_and_Comprehensive_Evaluation_of_Vietnamese_Large_Language_Models.md)

    - [翻译: 跨语言界限探索，对越南大型语言模型进行细致调整与综合评测](2024年03月05日/Crossing_Linguistic_Horizons_Finetuning_and_Comprehensive_Evaluation_of_Vietnamese_Large_Language_Models.md)

- [Android in the Zoo: Chain-of-Action-Thought for GUI Agents](2024年03月05日/Android_in_the_Zoo_Chain-of-Action-Thought_for_GUI_Agents.md)

    - [翻译: 在“Android in the Zoo”研究中，我们提出了 GUI 代理的“行动思维链”概念，旨在通过模拟人类在面对界面操作时的逻辑思考过程，提升 Android 系统中 GUI 代理的智能决策与执行能力。](2024年03月05日/Android_in_the_Zoo_Chain-of-Action-Thought_for_GUI_Agents.md)

- [Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models](2024年03月05日/Mixture-of-LoRAs_An_Efficient_Multitask_Tuning_for_Large_Language_Models.md)

    - [翻译: Mixture-of-LoRAs 是一项创新技术，专为大型语言模型设计的高效多任务调优方案。](2024年03月05日/Mixture-of-LoRAs_An_Efficient_Multitask_Tuning_for_Large_Language_Models.md)

- [Generative Explanations for Program Synthesizers](2024年03月05日/Generative_Explanations_for_Program_Synthesizers.md)

    - [翻译: 面向程序合成器的生成性解释技术](2024年03月05日/Generative_Explanations_for_Program_Synthesizers.md)

- [Generative News Recommendation](2024年03月05日/Generative_News_Recommendation.md)

    - [翻译: 创新性生成新闻推荐技术步骤 1 翻译：Generative News Recommendation 直译为“生成式新闻推荐”。步骤 2 翻译：为了更生动活泼、简洁优雅地表达，可以将“生成式新闻推荐”进一步诠释为“创新性生成新闻推荐技术”，既体现了该技术的前沿性和智能性，也突出了其在新闻推荐领域的独特应用。](2024年03月05日/Generative_News_Recommendation.md)

- [Negating Negatives: Alignment without Human Positive Samples via Distributional Dispreference Optimization](2024年03月05日/Negating_Negatives_Alignment_without_Human_Positive_Samples_via_Distributional_Dispreference_Optimization.md)

    - [翻译: 本研究提出了一种新颖方法，利用分布性逆偏优化技术，在没有人工标注的正样本情况下也能实现对齐效果。这种方法巧妙地“消除负例”，突破了以往依赖正样本的局限。](2024年03月05日/Negating_Negatives_Alignment_without_Human_Positive_Samples_via_Distributional_Dispreference_Optimization.md)

- [Human vs. Machine: Language Models and Wargames](2024年03月05日/Human_vs._Machine_Language_Models_and_Wargames.md)

    - [翻译: 人类与机器的较量：探究语言模型在战争模拟游戏中的表现与应用](2024年03月05日/Human_vs._Machine_Language_Models_and_Wargames.md)

- [Explaining Genetic Programming Trees using Large Language Models](2024年03月05日/Explaining_Genetic_Programming_Trees_using_Large_Language_Models.md)

    - [翻译: 本研究探讨如何运用大型语言模型来解析遗传编程树的内在逻辑，以实现对复杂模型结构的深入理解与解读。](2024年03月05日/Explaining_Genetic_Programming_Trees_using_Large_Language_Models.md)

- [Japanese-English Sentence Translation Exercises Dataset for Automatic Grading](2024年03月05日/Japanese-English_Sentence_Translation_Exercises_Dataset_for_Automatic_Grading.md)

    - [翻译: 该数据集包含日语-英语句子翻译练习题目，专为实现自动化评分而设计。](2024年03月05日/Japanese-English_Sentence_Translation_Exercises_Dataset_for_Automatic_Grading.md)

- [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](2024年03月05日/Learning_to_Maximize_Mutual_Information_for_Chain-of-Thought_Distillation.md)

    - [翻译: 本研究致力于学习如何优化互信息，以应用于链式思考蒸馏技术中，旨在提升模型对复杂问题的推理能力。](2024年03月05日/Learning_to_Maximize_Mutual_Information_for_Chain-of-Thought_Distillation.md)

- [Enhancing Vision-Language Pre-training with Rich Supervisions](2024年03月05日/Enhancing_Vision-Language_Pre-training_with_Rich_Supervisions.md)

    - [翻译: 在视觉-语言预训练中，我们致力于借助丰富的监督信息以增强模型性能。](2024年03月05日/Enhancing_Vision-Language_Pre-training_with_Rich_Supervisions.md)

- [Learn to Code Sustainably: An Empirical Study on LLM-based Green Code Generation](2024年03月05日/Learn_to_Code_Sustainably_An_Empirical_Study_on_LLM-based_Green_Code_Generation.md)

    - [翻译: 探究如何实现可持续编程，本研究通过实证方法考察了基于大型语言模型（LLM）的绿色代码生成技术。](2024年03月05日/Learn_to_Code_Sustainably_An_Empirical_Study_on_LLM-based_Green_Code_Generation.md)

- [Scope of Large Language Models for Mining Emerging Opinions in Online Health Discourse](2024年03月05日/Scope_of_Large_Language_Models_for_Mining_Emerging_Opinions_in_Online_Health_Discourse.md)

    - [翻译: 探究大型语言模型在揭示在线健康讨论中新兴观点方面的潜力及应用范围](2024年03月05日/Scope_of_Large_Language_Models_for_Mining_Emerging_Opinions_in_Online_Health_Discourse.md)

- [DIVERSE: Deciphering Internet Views on the U.S. Military Through Video Comment Stance Analysis, A Novel Benchmark Dataset for Stance Classification](2024年03月05日/DIVERSE_Deciphering_Internet_Views_on_the_U.S._Military_Through_Video_Comment_Stance_Analysis,_A_Novel_Benchmark_Dataset_for_Stance_Classification.md)

    - [翻译: DIVERSE 是一个创新的基准数据集，它专注于通过分析视频评论中的立场来解读网络舆论中关于美国军事的不同观点，为 stance 分类任务提供了有力支持。](2024年03月05日/DIVERSE_Deciphering_Internet_Views_on_the_U.S._Military_Through_Video_Comment_Stance_Analysis,_A_Novel_Benchmark_Dataset_for_Stance_Classification.md)

- [Guardrail Baselines for Unlearning in LLMs](2024年03月05日/Guardrail_Baselines_for_Unlearning_in_LLMs.md)

    - [翻译: 针对LLMs的遗忘问题，我们提出“防护栏基线”，旨在为模型提供一种有效去除有害信息或实现数据遗忘的基准方法。](2024年03月05日/Guardrail_Baselines_for_Unlearning_in_LLMs.md)

- [Book2Dial: Generating Teacher-Student Interactions from Textbooks for Cost-Effective Development of Educational Chatbots](2024年03月05日/Book2Dial_Generating_Teacher-Student_Interactions_from_Textbooks_for_Cost-Effective_Development_of_Educational_Chatbots.md)

    - [翻译: Book2Dial 是一项创新方法，通过将教科书内容转化为教师与学生的互动对话，为高效开发教育聊天机器人降低成本。这项技术能够自动生成源于教科书的对话场景，助力构建更具教学价值的教育聊天机器人。](2024年03月05日/Book2Dial_Generating_Teacher-Student_Interactions_from_Textbooks_for_Cost-Effective_Development_of_Educational_Chatbots.md)

- ["It's the only thing I can trust": Envisioning Large Language Model Use by Autistic Workers for Communication Assistance](2024年03月05日/It's_the_only_thing_I_can_trust_Envisioning_Large_Language_Model_Use_by_Autistic_Workers_for_Communication_Assistance.md)

    - [翻译: 在协助沟通方面，大型语言模型成为自闭症工作者表达与交流的可靠工具。“这是我唯一信赖之物”，让我们展望这一技术如何助力自闭症群体实现有效沟通。](2024年03月05日/It's_the_only_thing_I_can_trust_Envisioning_Large_Language_Model_Use_by_Autistic_Workers_for_Communication_Assistance.md)

- [InjecAgent: Benchmarking Indirect Prompt Injections in Tool-Integrated Large Language Model Agents](2024年03月05日/InjecAgent_Benchmarking_Indirect_Prompt_Injections_in_Tool-Integrated_Large_Language_Model_Agents.md)

    - [翻译: InjecAgent 是一个针对工具整合型大型语言模型代理的基准测试项目，专注于探究间接提示注入技术的效果。](2024年03月05日/InjecAgent_Benchmarking_Indirect_Prompt_Injections_in_Tool-Integrated_Large_Language_Model_Agents.md)

- [Prospect Personalized Recommendation on Large Language Model-based Agent Platform](2024年03月05日/Prospect_Personalized_Recommendation_on_Large_Language_Model-based_Agent_Platform.md)

    - [翻译: 面向未来，我们探讨在大型语言模型驱动的智能代理平台上实现个性化推荐的可能性与前景。](2024年03月05日/Prospect_Personalized_Recommendation_on_Large_Language_Model-based_Agent_Platform.md)

- [Human Simulacra: A Step toward the Personification of Large Language Models](2024年03月05日/Human_Simulacra_A_Step_toward_the_Personification_of_Large_Language_Models.md)

    - [翻译: 探索“人类模拟”，我们正朝着赋予大型语言模型更多人格特征的方向迈进，使其更接近真实人类的交互体验。](2024年03月05日/Human_Simulacra_A_Step_toward_the_Personification_of_Large_Language_Models.md)

- [Bridging Language and Items for Retrieval and Recommendation](2024年03月06日/Bridging_Language_and_Items_for_Retrieval_and_Recommendation.md)

    - [翻译: 为实现检索与推荐，构建语言与物品之间的桥梁](2024年03月06日/Bridging_Language_and_Items_for_Retrieval_and_Recommendation.md)

- [Did Translation Models Get More Robust Without Anyone Even Noticing?](2024年03月06日/Did_Translation_Models_Get_More_Robust_Without_Anyone_Even_Noticing.md)

    - [翻译: 翻译模型是否悄无声息地增强了稳健性？](2024年03月06日/Did_Translation_Models_Get_More_Robust_Without_Anyone_Even_Noticing.md)

- [Fuzzing BusyBox: Leveraging LLM and Crash Reuse for Embedded Bug Unearthing](2024年03月06日/Fuzzing_BusyBox_Leveraging_LLM_and_Crash_Reuse_for_Embedded_Bug_Unearthing.md)

    - [翻译: 通过结合 LLM 技术与崩溃重用策略，我们致力于对 BusyBox 进行高效模糊测试，以揭示隐藏的嵌入式软件漏洞。](2024年03月06日/Fuzzing_BusyBox_Leveraging_LLM_and_Crash_Reuse_for_Embedded_Bug_Unearthing.md)

- [SaulLM-7B: A pioneering Large Language Model for Law](2024年03月06日/SaulLM-7B_A_pioneering_Large_Language_Model_for_Law.md)

    - [翻译: SaulLM-7B，作为一款开路先锋般的大型语言模型，专为法律应用场景打造。](2024年03月06日/SaulLM-7B_A_pioneering_Large_Language_Model_for_Law.md)

- [Learning to Decode Collaboratively with Multiple Language Models](2024年03月06日/Learning_to_Decode_Collaboratively_with_Multiple_Language_Models.md)

    - [翻译: 本研究探讨如何训练多个语言模型协同解码，以提升整体的解码效果和性能。](2024年03月06日/Learning_to_Decode_Collaboratively_with_Multiple_Language_Models.md)

- [On the Origins of Linear Representations in Large Language Models](2024年03月06日/On_the_Origins_of_Linear_Representations_in_Large_Language_Models.md)

    - [翻译: 本文深入探讨大型语言模型内部线性表示的起源，揭示其内在机理与构建过程。](2024年03月06日/On_the_Origins_of_Linear_Representations_in_Large_Language_Models.md)

- [KIWI: A Dataset of Knowledge-Intensive Writing Instructions for Answering Research Questions](2024年03月06日/KIWI_A_Dataset_of_Knowledge-Intensive_Writing_Instructions_for_Answering_Research_Questions.md)

    - [翻译: KIWI 数据集，专为解答研究问题而设计，提供了丰富的知识密集型写作指导。](2024年03月06日/KIWI_A_Dataset_of_Knowledge-Intensive_Writing_Instructions_for_Answering_Research_Questions.md)

- [Are Language Models Puzzle Prodigies? Algorithmic Puzzles Unveil Serious Challenges in Multimodal Reasoning](2024年03月06日/Are_Language_Models_Puzzle_Prodigies_Algorithmic_Puzzles_Unveil_Serious_Challenges_in_Multimodal_Reasoning.md)

    - [翻译: 语言模型堪称解谜高手吗？通过算法谜题，我们发现它们在解决多模态推理问题时面临重大挑战。](2024年03月06日/Are_Language_Models_Puzzle_Prodigies_Algorithmic_Puzzles_Unveil_Serious_Challenges_in_Multimodal_Reasoning.md)

- [X-Shot: A Unified System to Handle Frequent, Few-shot and Zero-shot Learning Simultaneously in Classification](2024年03月06日/X-Shot_A_Unified_System_to_Handle_Frequent,_Few-shot_and_Zero-shot_Learning_Simultaneously_in_Classification.md)

    - [翻译: X-Shot 系统集大成，一举囊括了分类任务中频繁出现、少量样本及零样本的学习场景，实现了一体化解决方案。](2024年03月06日/X-Shot_A_Unified_System_to_Handle_Frequent,_Few-shot_and_Zero-shot_Learning_Simultaneously_in_Classification.md)

- [Designing Informative Metrics for Few-Shot Example Selection](2024年03月06日/Designing_Informative_Metrics_for_Few-Shot_Example_Selection.md)

    - [翻译: 本研究致力于设计针对少量示例选择的有效度量标准，以期提升模型在有限数据下的学习与泛化能力。](2024年03月06日/Designing_Informative_Metrics_for_Few-Shot_Example_Selection.md)

- [Emojinize : Enriching Any Text with Emoji Translations](2024年03月06日/Emojinize__Enriching_Any_Text_with_Emoji_Translations.md)

    - [翻译: Emojinize项目致力于为任意文本增添生动有趣的Emoji表达，实现文本内容的emoji化增强。](2024年03月06日/Emojinize__Enriching_Any_Text_with_Emoji_Translations.md)

- [ShortGPT: Layers in Large Language Models are More Redundant Than You Expect](2024年03月06日/ShortGPT_Layers_in_Large_Language_Models_are_More_Redundant_Than_You_Expect.md)

    - [翻译: ShortGPT 揭示，大型语言模型内部的层级存在超乎预期的冗余现象。](2024年03月06日/ShortGPT_Layers_in_Large_Language_Models_are_More_Redundant_Than_You_Expect.md)

- [Evaluating the Elementary Multilingual Capabilities of Large Language Models with MultiQ](2024年03月06日/Evaluating_the_Elementary_Multilingual_Capabilities_of_Large_Language_Models_with_MultiQ.md)

    - [翻译: 我们运用 MultiQ 工具，对大型语言模型在处理基础多语言任务时的能力进行深入评估。](2024年03月06日/Evaluating_the_Elementary_Multilingual_Capabilities_of_Large_Language_Models_with_MultiQ.md)

- [Popeye: A Unified Visual-Language Model for Multi-Source Ship Detection from Remote Sensing Imagery](2024年03月06日/Popeye_A_Unified_Visual-Language_Model_for_Multi-Source_Ship_Detection_from_Remote_Sensing_Imagery.md)

    - [翻译: Popeye 是一款集成了视觉与语言处理能力的统一模型，专为在遥感图像中实现多源船舶检测而设计。](2024年03月06日/Popeye_A_Unified_Visual-Language_Model_for_Multi-Source_Ship_Detection_from_Remote_Sensing_Imagery.md)

- [PPTC-R benchmark: Towards Evaluating the Robustness of Large Language Models for PowerPoint Task Completion](2024年03月06日/PPTC-R_benchmark_Towards_Evaluating_the_Robustness_of_Large_Language_Models_for_PowerPoint_Task_Completion.md)

    - [翻译: PPTC-R基准测试旨在深入探究大型语言模型在应对PowerPoint任务挑战时的稳健性表现。](2024年03月06日/PPTC-R_benchmark_Towards_Evaluating_the_Robustness_of_Large_Language_Models_for_PowerPoint_Task_Completion.md)

- [German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset](2024年03月06日/German_also_Hallucinates!_Inconsistency_Detection_in_News_Summaries_with_the_Absinth_Dataset.md)

    - [翻译: 德语文本亦会“幻想”！利用Absinth数据集揭示新闻摘要中的不一致性问题](2024年03月06日/German_also_Hallucinates!_Inconsistency_Detection_in_News_Summaries_with_the_Absinth_Dataset.md)

- [Towards Safe and Aligned Large Language Models for Medicine](2024年03月06日/Towards_Safe_and_Aligned_Large_Language_Models_for_Medicine.md)

    - [翻译: 本研究致力于研发适用于医学领域的安全且高度兼容的大型语言模型，旨在提升其在医疗场景下的表现和可靠性。](2024年03月06日/Towards_Safe_and_Aligned_Large_Language_Models_for_Medicine.md)

- [Multimodal Transformer for Comics Text-Cloze](2024年03月06日/Multimodal_Transformer_for_Comics_Text-Cloze.md)

    - [翻译: 针对漫画文本完形填空任务，我们采用多模态 Transformer 技术，旨在整合图像与文本信息，以提升模型在理解漫画情境并准确完成文本完形填空方面的性能。](2024年03月06日/Multimodal_Transformer_for_Comics_Text-Cloze.md)

- [Rapidly Developing High-quality Instruction Data and Evaluation Benchmark for Large Language Models with Minimal Human Effort: A Case Study on Japanese](2024年03月06日/Rapidly_Developing_High-quality_Instruction_Data_and_Evaluation_Benchmark_for_Large_Language_Models_with_Minimal_Human_Effort_A_Case_Study_on_Japanese.md)

    - [翻译: 针对大型语言模型，本研究案例展示了如何高效地以最小化人工投入的方式快速构建高质量的指令数据集及评估基准，此方法特别适用于日语场景。](2024年03月06日/Rapidly_Developing_High-quality_Instruction_Data_and_Evaluation_Benchmark_for_Large_Language_Models_with_Minimal_Human_Effort_A_Case_Study_on_Japanese.md)

- [General2Specialized LLMs Translation for E-commerce](2024年03月06日/General2Specialized_LLMs_Translation_for_E-commerce.md)

    - [翻译: 面向电商领域的 General2Specialized LLMs 翻译技术](2024年03月06日/General2Specialized_LLMs_Translation_for_E-commerce.md)

- [Automatic Bi-modal Question Title Generation for Stack Overflow with Prompt Learning](2024年03月06日/Automatic_Bi-modal_Question_Title_Generation_for_Stack_Overflow_with_Prompt_Learning.md)

    - [翻译: 本研究借助提示学习技术，针对 Stack Overflow 平台开发了一种自动为编程问题生成融合两种模态信息的标题方法。](2024年03月06日/Automatic_Bi-modal_Question_Title_Generation_for_Stack_Overflow_with_Prompt_Learning.md)

- [K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data](2024年03月06日/K-Link_Knowledge-Link_Graph_from_LLMs_for_Enhanced_Representation_Learning_in_Multivariate_Time-Series_Data.md)

    - [翻译: K-Link 方法通过从大型语言模型（LLMs）中提炼出知识链接图，旨在提升多元时间序列数据的表征学习效果。](2024年03月06日/K-Link_Knowledge-Link_Graph_from_LLMs_for_Enhanced_Representation_Learning_in_Multivariate_Time-Series_Data.md)

- [SheetAgent: A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models](2024年03月06日/SheetAgent_A_Generalist_Agent_for_Spreadsheet_Reasoning_and_Manipulation_via_Large_Language_Models.md)

    - [翻译: SheetAgent 是一款借助大型语言模型，实现对电子表格进行高效推理与灵活操控的全能型智能助手。](2024年03月06日/SheetAgent_A_Generalist_Agent_for_Spreadsheet_Reasoning_and_Manipulation_via_Large_Language_Models.md)

- [GPTopic: Dynamic and Interactive Topic Representations](2024年03月06日/GPTopic_Dynamic_and_Interactive_Topic_Representations.md)

    - [翻译: GPTopic：探索动态且互动的主题表达方式](2024年03月06日/GPTopic_Dynamic_and_Interactive_Topic_Representations.md)

- [Multimodal Large Language Models to Support Real-World Fact-Checking](2024年03月06日/Multimodal_Large_Language_Models_to_Support_Real-World_Fact-Checking.md)

    - [翻译: 为助力现实世界中的事实核查，我们引入了多模态大型语言模型。这类模型能够整合多种信息源，以提升对复杂情境中事实信息的精准判断能力。](2024年03月06日/Multimodal_Large_Language_Models_to_Support_Real-World_Fact-Checking.md)

- [Assessing the Aesthetic Evaluation Capabilities of GPT-4 with Vision: Insights from Group and Individual Assessments](2024年03月06日/Assessing_the_Aesthetic_Evaluation_Capabilities_of_GPT-4_with_Vision_Insights_from_Group_and_Individual_Assessments.md)

    - [翻译: 通过对 GPT-4 进行群体及个体评估，本研究探索其结合视觉进行审美评价的能力，并揭示相关深刻见解。](2024年03月06日/Assessing_the_Aesthetic_Evaluation_Capabilities_of_GPT-4_with_Vision_Insights_from_Group_and_Individual_Assessments.md)

- [RouteExplainer: An Explanation Framework for Vehicle Routing Problem](2024年03月06日/RouteExplainer_An_Explanation_Framework_for_Vehicle_Routing_Problem.md)

    - [翻译: RouteExplainer 是一个专为解决车辆路径规划问题而设计的解释性框架，旨在深入解析并清晰展现路径决策背后的逻辑与依据。](2024年03月06日/RouteExplainer_An_Explanation_Framework_for_Vehicle_Routing_Problem.md)

- [Benchmarking Hallucination in Large Language Models based on Unanswerable Math Word Problem](2024年03月06日/Benchmarking_Hallucination_in_Large_Language_Models_based_on_Unanswerable_Math_Word_Problem.md)

    - [翻译: 本研究通过利用无解数学题，对大型语言模型中出现的“幻想”现象进行基准评估，旨在深入理解并量化其在面对这类问题时的错误生成表现。](2024年03月06日/Benchmarking_Hallucination_in_Large_Language_Models_based_on_Unanswerable_Math_Word_Problem.md)

- [Emotional Manipulation Through Prompt Engineering Amplifies Disinformation Generation in AI Large Language Models](2024年03月06日/Emotional_Manipulation_Through_Prompt_Engineering_Amplifies_Disinformation_Generation_in_AI_Large_Language_Models.md)

    - [翻译: 运用提示工程技术进行情感操纵，能够加剧 AI 大型语言模型制造虚假信息的问题。](2024年03月06日/Emotional_Manipulation_Through_Prompt_Engineering_Amplifies_Disinformation_Generation_in_AI_Large_Language_Models.md)

- [Prompt Mining for Language-based Human Mobility Forecasting](2024年03月06日/Prompt_Mining_for_Language-based_Human_Mobility_Forecasting.md)

    - [翻译: 在语言驱动的人类行动轨迹预测中，我们探索了提示挖掘技术的应用，旨在通过有效提取和利用提示信息来提升预测准确性与模型效能。](2024年03月06日/Prompt_Mining_for_Language-based_Human_Mobility_Forecasting.md)

- [Towards Efficient and Effective Unlearning of Large Language Models for Recommendation](2024年03月06日/Towards_Efficient_and_Effective_Unlearning_of_Large_Language_Models_for_Recommendation.md)

    - [翻译: 本研究致力于探索如何让大型语言模型在推荐场景中实现高效且有效的遗忘学习，即针对已学习内容进行有效“反学习”。（注：此处将“unlearning”翻译为“遗忘学习”或“反学习”，是因为在AI领域中，“unlearning”通常指的是对模型已经学到的内容进行去除或更新的过程。）](2024年03月06日/Towards_Efficient_and_Effective_Unlearning_of_Large_Language_Models_for_Recommendation.md)

- [Non-verbal information in spontaneous speech - towards a new framework of analysis](2024年03月06日/Non-verbal_information_in_spontaneous_speech_-_towards_a_new_framework_of_analysis.md)

    - [翻译: 在探索自发性言语的奥秘时，我们正迈向一个全新的分析框架，聚焦于其中蕴含的非言语信息。](2024年03月06日/Non-verbal_information_in_spontaneous_speech_-_towards_a_new_framework_of_analysis.md)

- [CLongEval: A Chinese Benchmark for Evaluating Long-Context Large Language Models](2024年03月06日/CLongEval_A_Chinese_Benchmark_for_Evaluating_Long-Context_Large_Language_Models.md)

    - [翻译: CLongEval —— 专为评估大型语言模型在处理长文本情境能力而设的中文评测基准](2024年03月06日/CLongEval_A_Chinese_Benchmark_for_Evaluating_Long-Context_Large_Language_Models.md)

- [GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection](2024年03月06日/GaLore_Memory-Efficient_LLM_Training_by_Gradient_Low-Rank_Projection.md)

    - [翻译: GaLore——一种通过梯度低秩投影技术提升大语言模型（LLM）训练内存效率的新方案。](2024年03月06日/GaLore_Memory-Efficient_LLM_Training_by_Gradient_Low-Rank_Projection.md)

- [A Knowledge Plug-and-Play Test Bed for Open-domain Dialogue Generation](2024年03月06日/A_Knowledge_Plug-and-Play_Test_Bed_for_Open-domain_Dialogue_Generation.md)

    - [翻译: 我们构建了一个针对开放领域对话生成的“知识即插即用”测试平台，旨在便捷地探究和验证各类知识在对话生成任务中的应用效果。](2024年03月06日/A_Knowledge_Plug-and-Play_Test_Bed_for_Open-domain_Dialogue_Generation.md)

- [Aligners: Decoupling LLMs and Alignment](2024年03月06日/Aligners_Decoupling_LLMs_and_Alignment.md)

    - [翻译: 本文探讨“对齐器”，旨在将大型语言模型（LLM）与其对齐机制分离。通过这种方法，我们深入研究如何独立优化LLM的性能与对其行为和输出的可控性，以实现更好的对齐效果。](2024年03月06日/Aligners_Decoupling_LLMs_and_Alignment.md)

- [Self-Evaluation of Large Language Model based on Glass-box Features](2024年03月06日/Self-Evaluation_of_Large_Language_Model_based_on_Glass-box_Features.md)

    - [翻译: 针对大型语言模型，本研究采用 Glass-box 特征进行自我评估，旨在通过解析模型内部透明可见的特征来评价其性能表现。](2024年03月06日/Self-Evaluation_of_Large_Language_Model_based_on_Glass-box_Features.md)

- [Large Language Models are In-Context Molecule Learners](2024年03月06日/Large_Language_Models_are_In-Context_Molecule_Learners.md)

    - [翻译: 大型语言模型擅长于在上下文中学习分子知识（注：由于原文标题简洁且具有一定的专业性，从准确性和生动性角度考虑，在翻译时保留了“上下文”这一术语，并将“learner”译为更符合中文表达习惯的“学习者”，同时也强调了其在分子领域的学习能力。）](2024年03月06日/Large_Language_Models_are_In-Context_Molecule_Learners.md)

- [Generative AI for Synthetic Data Generation: Methods, Challenges and the Future](2024年03月06日/Generative_AI_for_Synthetic_Data_Generation_Methods,_Challenges_and_the_Future.md)

    - [翻译: 探究生成式AI在合成数据创造中的方法论、面临的挑战及其未来趋势](2024年03月06日/Generative_AI_for_Synthetic_Data_Generation_Methods,_Challenges_and_the_Future.md)

- [Metric-aware LLM inference](2024年03月06日/Metric-aware_LLM_inference.md)

    - [翻译: 面向指标的 LLM 推理技术](2024年03月06日/Metric-aware_LLM_inference.md)

- [Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy](2024年03月06日/Improving_Retrieval_in_Theme-specific_Applications_using_a_Corpus_Topical_Taxonomy.md)

    - [翻译: 通过构建和运用基于语料库的主题分类体系，本研究致力于提升各类特定主题应用中的检索效果。](2024年03月06日/Improving_Retrieval_in_Theme-specific_Applications_using_a_Corpus_Topical_Taxonomy.md)

- [Chatbot Arena: An Open Platform for Evaluating LLMs by Human Preference](2024年03月06日/Chatbot_Arena_An_Open_Platform_for_Evaluating_LLMs_by_Human_Preference.md)

    - [翻译: Chatbot Arena——一个通过人类偏好评判LLMs表现的公开平台，旨在为各类大型语言模型提供公正、直观的人性化评估环境。](2024年03月06日/Chatbot_Arena_An_Open_Platform_for_Evaluating_LLMs_by_Human_Preference.md)

- [Privacy-preserving Fine-tuning of Large Language Models through Flatness](2024年03月06日/Privacy-preserving_Fine-tuning_of_Large_Language_Models_through_Flatness.md)

    - [翻译: 针对大型语言模型，我们提出了一种基于“平坦性”的隐私保护微调方法。该方法旨在在保持模型性能的同时，有效保障用户数据隐私，特别是在对大型语言模型进行针对性优化时。](2024年03月06日/Privacy-preserving_Fine-tuning_of_Large_Language_Models_through_Flatness.md)

- [Exploring LLM-based Agents for Root Cause Analysis](2024年03月06日/Exploring_LLM-based_Agents_for_Root_Cause_Analysis.md)

    - [翻译: 本研究致力于探究基于大型语言模型（LLM）的智能体在根因分析任务中的应用与潜力。](2024年03月06日/Exploring_LLM-based_Agents_for_Root_Cause_Analysis.md)

- [Can Large Language Models Reason and Plan?](2024年03月06日/Can_Large_Language_Models_Reason_and_Plan.md)

    - [翻译: 探究大型语言模型能否进行推理与规划步骤解释：](2024年03月06日/Can_Large_Language_Models_Reason_and_Plan.md)

- [Artificial Intelligence Exploring the Patent Field](2024年03月06日/Artificial_Intelligence_Exploring_the_Patent_Field.md)

    - [翻译: 人工智能涉足专利界，正不断探寻其中的创新疆域。](2024年03月06日/Artificial_Intelligence_Exploring_the_Patent_Field.md)

- [Can Large Language Models do Analytical Reasoning?](2024年03月06日/Can_Large_Language_Models_do_Analytical_Reasoning.md)

    - [翻译: 大型语言模型是否具备进行分析推理的能力呢？](2024年03月06日/Can_Large_Language_Models_do_Analytical_Reasoning.md)

- [Enhancing chest X-ray datasets with privacy-preserving large language models and multi-type annotations: a data-driven approach for improved classification](2024年03月06日/Enhancing_chest_X-ray_datasets_with_privacy-preserving_large_language_models_and_multi-type_annotations_a_data-driven_approach_for_improved_classification.md)

    - [翻译: 我们提出了一种数据驱动的方案，利用隐私保护的大规模语言模型及多元注解技术来提升胸部X射线数据集的质量，从而实现更精确的分类效果。](2024年03月06日/Enhancing_chest_X-ray_datasets_with_privacy-preserving_large_language_models_and_multi-type_annotations_a_data-driven_approach_for_improved_classification.md)

- [FaaF: Facts as a Function for the evaluation of RAG systems](2024年03月06日/FaaF_Facts_as_a_Function_for_the_evaluation_of_RAG_systems.md)

    - [翻译: FaaF：提出“事实即函数”方法，用于评估 RAG 系统的表现。](2024年03月06日/FaaF_Facts_as_a_Function_for_the_evaluation_of_RAG_systems.md)

- [Neural Exec: Learning (and Learning from) Execution Triggers for Prompt Injection Attacks](2024年03月06日/Neural_Exec_Learning_(and_Learning_from)_Execution_Triggers_for_Prompt_Injection_Attacks.md)

    - [翻译: Neural Exec：针对提示注入攻击，研究并借鉴执行触发器的学习机制](2024年03月06日/Neural_Exec_Learning_(and_Learning_from)_Execution_Triggers_for_Prompt_Injection_Attacks.md)

- [MeaCap: Memory-Augmented Zero-shot Image Captioning](2024年03月06日/MeaCap_Memory-Augmented_Zero-shot_Image_Captioning.md)

    - [翻译: MeaCap 是一种“记忆增强型零样本图像描述”技术，它利用记忆机制提升在未见过的图像上进行自动描述的能力。](2024年03月06日/MeaCap_Memory-Augmented_Zero-shot_Image_Captioning.md)

- [Quantifying Contamination in Evaluating Code Generation Capabilities of Language Models](2024年03月06日/Quantifying_Contamination_in_Evaluating_Code_Generation_Capabilities_of_Language_Models.md)

    - [翻译: 在衡量语言模型代码生成能力的过程中，本研究致力于量化评估中的“污染”问题，以更准确地了解模型的真实效能。](2024年03月06日/Quantifying_Contamination_in_Evaluating_Code_Generation_Capabilities_of_Language_Models.md)

- [WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off](2024年03月06日/WaterMax_breaking_the_LLM_watermark_detectability-robustness-quality_trade-off.md)

    - [翻译: WaterMax 技术突破了 LLM 水印在可检测性、鲁棒性和生成文本质量间的固有折衷，实现了三者的兼顾优化。](2024年03月06日/WaterMax_breaking_the_LLM_watermark_detectability-robustness-quality_trade-off.md)

- [Human I/O: Towards a Unified Approach to Detecting Situational Impairments](2024年03月06日/Human_IO_Towards_a_Unified_Approach_to_Detecting_Situational_Impairments.md)

    - [翻译: Human I/O：致力于构建一种用于识别情境性功能障碍的综合方法](2024年03月06日/Human_IO_Towards_a_Unified_Approach_to_Detecting_Situational_Impairments.md)

- [KnowledgeVIS: Interpreting Language Models by Comparing Fill-in-the-Blank Prompts](2024年03月07日/KnowledgeVIS_Interpreting_Language_Models_by_Comparing_Fill-in-the-Blank_Prompts.md)

    - [翻译: 知识可视化（KnowledgeVIS）：一种通过对比填空式提示，深入解读语言模型的新方法。](2024年03月07日/KnowledgeVIS_Interpreting_Language_Models_by_Comparing_Fill-in-the-Blank_Prompts.md)

- [LLMs in the Imaginarium: Tool Learning through Simulated Trial and Error](2024年03月07日/LLMs_in_the_Imaginarium_Tool_Learning_through_Simulated_Trial_and_Error.md)

    - [翻译: 在“想象工坊”场景下，LLMs 通过模拟试验与错误的方式习得工具使用技巧。](2024年03月07日/LLMs_in_the_Imaginarium_Tool_Learning_through_Simulated_Trial_and_Error.md)

- [Common 7B Language Models Already Possess Strong Math Capabilities](2024年03月07日/Common_7B_Language_Models_Already_Possess_Strong_Math_Capabilities.md)

    - [翻译: 现今的主流70亿参数语言模型普遍展现出强劲的数学处理能力。](2024年03月07日/Common_7B_Language_Models_Already_Possess_Strong_Math_Capabilities.md)

- [ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes](2024年03月07日/ObjectCompose_Evaluating_Resilience_of_Vision-Based_Models_on_Object-to-Background_Compositional_Changes.md)

    - [翻译: ObjectCompose 项目旨在评测视觉模型在面临对象与背景组合变化时的抗干扰能力。](2024年03月07日/ObjectCompose_Evaluating_Resilience_of_Vision-Based_Models_on_Object-to-Background_Compositional_Changes.md)

- [Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification](2024年03月07日/Fact-Checking_the_Output_of_Large_Language_Models_via_Token-Level_Uncertainty_Quantification.md)

    - [翻译: 针对大型语言模型的输出，我们采用Token级别不确定性量化方法进行深度事实核查。](2024年03月07日/Fact-Checking_the_Output_of_Large_Language_Models_via_Token-Level_Uncertainty_Quantification.md)

- [Telecom Language Models: Must They Be Large?](2024年03月07日/Telecom_Language_Models_Must_They_Be_Large.md)

    - [翻译: 电信领域的语言模型是否必须具备大模型特性？](2024年03月07日/Telecom_Language_Models_Must_They_Be_Large.md)

- [Teaching Large Language Models to Reason with Reinforcement Learning](2024年03月07日/Teaching_Large_Language_Models_to_Reason_with_Reinforcement_Learning.md)

    - [翻译: 运用强化学习策略，训练大型语言模型掌握推理技能](2024年03月07日/Teaching_Large_Language_Models_to_Reason_with_Reinforcement_Learning.md)

- [CAT: Enhancing Multimodal Large Language Model to Answer Questions in Dynamic Audio-Visual Scenarios](2024年03月07日/CAT_Enhancing_Multimodal_Large_Language_Model_to_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios.md)

    - [翻译: CAT研究致力于提升大型多模态语言模型，在充满变化的音视频场景下解答问题的能力。](2024年03月07日/CAT_Enhancing_Multimodal_Large_Language_Model_to_Answer_Questions_in_Dynamic_Audio-Visual_Scenarios.md)

- [Strong Priority and Determinacy in Timed CCS](2024年03月07日/Strong_Priority_and_Determinacy_in_Timed_CCS.md)

    - [翻译: 针对定时进程演算（Timed CCS）中体现的强优先级与确定性进行深入探讨，揭示其内在机制与影响。步骤 1 翻译：Strong Priority and Determinacy in Timed Calculus of Communicating Systems (CCS)步骤 2 翻译：在通信系统计时演算（Timed CCS）中，强优先级与确定性的概念具有重要价值。本研究致力于阐述并剖析这两个特性在处理实时交互过程中的作用及其对系统行为的深刻影响。](2024年03月07日/Strong_Priority_and_Determinacy_in_Timed_CCS.md)

- [A Detailed Audio-Text Data Simulation Pipeline using Single-Event Sounds](2024年03月07日/A_Detailed_Audio-Text_Data_Simulation_Pipeline_using_Single-Event_Sounds.md)

    - [翻译: 我们构建了一种基于单个事件声音的精细音频文本数据仿真流程，旨在高效生成高质量的模拟数据。](2024年03月07日/A_Detailed_Audio-Text_Data_Simulation_Pipeline_using_Single-Event_Sounds.md)

- [Embodied Understanding of Driving Scenarios](2024年03月07日/Embodied_Understanding_of_Driving_Scenarios.md)

    - [翻译: 深入探究驾驶场景中的具身认知](2024年03月07日/Embodied_Understanding_of_Driving_Scenarios.md)

- [Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition](2024年03月07日/Wiki-TabNERAdvancing_Table_Interpretation_Through_Named_Entity_Recognition.md)

    - [翻译: Wiki-TabNER项目致力于借助命名实体识别技术提升表格理解能力，从而推动表格信息的有效解读。](2024年03月07日/Wiki-TabNERAdvancing_Table_Interpretation_Through_Named_Entity_Recognition.md)

- [Where does In-context Translation Happen in Large Language Models](2024年03月07日/Where_does_In-context_Translation_Happen_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型内部，上下文翻译究竟如何运作呢？](2024年03月07日/Where_does_In-context_Translation_Happen_in_Large_Language_Models.md)

- [GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability](2024年03月07日/GraphInstruct_Empowering_Large_Language_Models_with_Graph_Understanding_and_Reasoning_Capability.md)

    - [翻译: GraphInstruct 是一项技术，它赋予大型语言模型强大的图理解和推理能力。](2024年03月07日/GraphInstruct_Empowering_Large_Language_Models_with_Graph_Understanding_and_Reasoning_Capability.md)

- [Do Large Language Model Understand Multi-Intent Spoken Language ?](2024年03月07日/Do_Large_Language_Model_Understand_Multi-Intent_Spoken_Language_.md)

    - [翻译: 大型语言模型是否能洞悉多意图口语？](2024年03月07日/Do_Large_Language_Model_Understand_Multi-Intent_Spoken_Language_.md)

- [Pearl: A Review-driven Persona-Knowledge Grounded Conversational Recommendation Dataset](2024年03月07日/Pearl_A_Review-driven_Persona-Knowledge_Grounded_Conversational_Recommendation_Dataset.md)

    - [翻译: Pearl 是一个独特的对话式推荐数据集，它以评论为驱动，并紧密结合了人格知识。该数据集致力于提供更加情境化和个性化的对话推荐服务。](2024年03月07日/Pearl_A_Review-driven_Persona-Knowledge_Grounded_Conversational_Recommendation_Dataset.md)

- [Low-Resource Court Judgment Summarization for Common Law Systems](2024年03月07日/Low-Resource_Court_Judgment_Summarization_for_Common_Law_Systems.md)

    - [翻译: 致力于普通法系环境下的低资源法院判决摘要生成，本研究关注在有限数据条件下，如何高效地为法院判决文档创建精炼、准确的摘要。](2024年03月07日/Low-Resource_Court_Judgment_Summarization_for_Common_Law_Systems.md)

- [Membership Inference Attacks and Privacy in Topic Modeling](2024年03月07日/Membership_Inference_Attacks_and_Privacy_in_Topic_Modeling.md)

    - [翻译: 针对主题模型的成员身份推断攻击及其对隐私保护的影响](2024年03月07日/Membership_Inference_Attacks_and_Privacy_in_Topic_Modeling.md)

- [Feedback-Generation for Programming Exercises With GPT-4](2024年03月07日/Feedback-Generation_for_Programming_Exercises_With_GPT-4.md)

    - [翻译: GPT-4 在编程练习中助力生成针对性反馈](2024年03月07日/Feedback-Generation_for_Programming_Exercises_With_GPT-4.md)

- [Sentiment-driven prediction of financial returns: a Bayesian-enhanced FinBERT approach](2024年03月07日/Sentiment-driven_prediction_of_financial_returns_a_Bayesian-enhanced_FinBERT_approach.md)

    - [翻译: 运用贝叶斯增强技术优化的FinBERT模型，针对情感驱动的金融收益预测展开研究。](2024年03月07日/Sentiment-driven_prediction_of_financial_returns_a_Bayesian-enhanced_FinBERT_approach.md)

- [SGNet: Folding Symmetrical Protein Complex with Deep Learning](2024年03月07日/SGNet_Folding_Symmetrical_Protein_Complex_with_Deep_Learning.md)

    - [翻译: SGNet 是一个运用深度学习技术来高效折叠对称蛋白质复合体的方法。](2024年03月07日/SGNet_Folding_Symmetrical_Protein_Complex_with_Deep_Learning.md)

- [Acceleron: A Tool to Accelerate Research Ideation](2024年03月07日/Acceleron_A_Tool_to_Accelerate_Research_Ideation.md)

    - [翻译: Acceleron，一款致力于提升研究构思速度的有效工具](2024年03月07日/Acceleron_A_Tool_to_Accelerate_Research_Ideation.md)

- [ProMoAI: Process Modeling with Generative AI](2024年03月07日/ProMoAI_Process_Modeling_with_Generative_AI.md)

    - [翻译: ProMoAI——利用生成式人工智能技术进行流程模型构建](2024年03月07日/ProMoAI_Process_Modeling_with_Generative_AI.md)

- [Measuring Meaning Composition in the Human Brain with Composition Scores from Large Language Models](2024年03月07日/Measuring_Meaning_Composition_in_the_Human_Brain_with_Composition_Scores_from_Large_Language_Models.md)

    - [翻译: 本研究借助大型语言模型计算出的意义组合得分，探索人类大脑中意义组合的量化衡量方法。](2024年03月07日/Measuring_Meaning_Composition_in_the_Human_Brain_with_Composition_Scores_from_Large_Language_Models.md)

- [Discriminative Probing and Tuning for Text-to-Image Generation](2024年03月07日/Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation.md)

    - [翻译: 针对文本到图像生成任务，我们采用鉴别性探查和调整技术，以深入探究模型内部机制，并优化其生成效果。](2024年03月07日/Discriminative_Probing_and_Tuning_for_Text-to-Image_Generation.md)

- [Online Adaptation of Language Models with a Memory of Amortized Contexts](2024年03月07日/Online_Adaptation_of_Language_Models_with_a_Memory_of_Amortized_Contexts.md)

    - [翻译: 通过运用对上下文进行平均化的记忆技术，在线优化语言模型以适应不同场景。](2024年03月07日/Online_Adaptation_of_Language_Models_with_a_Memory_of_Amortized_Contexts.md)

- [Can Your Model Tell a Negation from an Implicature? Unravelling Challenges With Intent Encoders](2024年03月07日/Can_Your_Model_Tell_a_Negation_from_an_Implicature_Unravelling_Challenges_With_Intent_Encoders.md)

    - [翻译: 探究模型是否能够有效区分否定表达与蕴含含义，同时揭示在构建意图编码器过程中所遇到的难题。](2024年03月07日/Can_Your_Model_Tell_a_Negation_from_an_Implicature_Unravelling_Challenges_With_Intent_Encoders.md)

- [HaluEval-Wild: Evaluating Hallucinations of Language Models in the Wild](2024年03月07日/HaluEval-Wild_Evaluating_Hallucinations_of_Language_Models_in_the_Wild.md)

    - [翻译: HaluEval-Wild 是一项针对真实环境中的语言模型所生成的幻觉内容进行评估的研究项目。](2024年03月07日/HaluEval-Wild_Evaluating_Hallucinations_of_Language_Models_in_the_Wild.md)

- [Effectiveness Assessment of Recent Large Vision-Language Models](2024年03月07日/Effectiveness_Assessment_of_Recent_Large_Vision-Language_Models.md)

    - [翻译: 本研究致力于评估最新大型视觉-语言模型的实际效果，探究其在各类跨模态任务中的表现与价值。](2024年03月07日/Effectiveness_Assessment_of_Recent_Large_Vision-Language_Models.md)

- [Proxy-RLHF: Decoupling Generation and Alignment in Large Language Model with Proxy](2024年03月07日/Proxy-RLHF_Decoupling_Generation_and_Alignment_in_Large_Language_Model_with_Proxy.md)

    - [翻译: Proxy-RLHF 是一种创新方法，它在大型语言模型中巧妙地运用“代理”手段，成功实现了生成能力与对齐目标的解耦合，尤其适用于提升语言模型在保持高质量文本生成的同时，更好地满足预设规范和要求。](2024年03月07日/Proxy-RLHF_Decoupling_Generation_and_Alignment_in_Large_Language_Model_with_Proxy.md)

- [Advancing Biomedical Text Mining with Community Challenges](2024年03月07日/Advancing_Biomedical_Text_Mining_with_Community_Challenges.md)

    - [翻译: 社区挑战驱动生物医学文本挖掘的进步与突破](2024年03月07日/Advancing_Biomedical_Text_Mining_with_Community_Challenges.md)

- [Can Small Language Models be Good Reasoners for Sequential Recommendation?](2024年03月07日/Can_Small_Language_Models_be_Good_Reasoners_for_Sequential_Recommendation.md)

    - [翻译: 小型语言模型能否在序列推荐任务上展现出色的推理能力呢？](2024年03月07日/Can_Small_Language_Models_be_Good_Reasoners_for_Sequential_Recommendation.md)

- [Towards Robustness Analysis of E-Commerce Ranking System](2024年03月07日/Towards_Robustness_Analysis_of_E-Commerce_Ranking_System.md)

    - [翻译: 本研究致力于深入探究电子商务排名系统的鲁棒性，旨在全面分析和提升该系统在复杂环境下的稳定性和可靠性。](2024年03月07日/Towards_Robustness_Analysis_of_E-Commerce_Ranking_System.md)

- [Federated Recommendation via Hybrid Retrieval Augmented Generation](2024年03月07日/Federated_Recommendation_via_Hybrid_Retrieval_Augmented_Generation.md)

    - [翻译: 我们提出了一种混合检索增强生成方法，以实现联邦推荐系统。该方法巧妙结合了检索和生成技术，在保护用户数据隐私的同时，有效提升了推荐系统的性能和准确性。步骤 1：联邦推荐是通过混合检索增强生成技术实现的。步骤 2：在保证用户数据隐私的前提下，一种名为“混合检索增强生成”的创新技术被应用于联邦推荐场景中，旨在融合检索与生成策略，以优化推荐效果并保障数据安全性。](2024年03月07日/Federated_Recommendation_via_Hybrid_Retrieval_Augmented_Generation.md)

- [UltraWiki: Ultra-fine-grained Entity Set Expansion with Negative Seed Entities](2024年03月07日/UltraWiki_Ultra-fine-grained_Entity_Set_Expansion_with_Negative_Seed_Entities.md)

    - [翻译: UltraWiki项目致力于通过引入负向种子实体，实现对实体集进行超精细的扩展探索。](2024年03月07日/UltraWiki_Ultra-fine-grained_Entity_Set_Expansion_with_Negative_Seed_Entities.md)

- [DEEP-ICL: Definition-Enriched Experts for Language Model In-Context Learning](2024年03月07日/DEEP-ICL_Definition-Enriched_Experts_for_Language_Model_In-Context_Learning.md)

    - [翻译: DEEP-ICL：致力于为语言模型的上下文学习注入更多定义性知识的专家系统](2024年03月07日/DEEP-ICL_Definition-Enriched_Experts_for_Language_Model_In-Context_Learning.md)

- [iScore: Visual Analytics for Interpreting How Language Models Automatically Score Summaries](2024年03月07日/iScore_Visual_Analytics_for_Interpreting_How_Language_Models_Automatically_Score_Summaries.md)

    - [翻译: iScore 是一款可视化分析工具，它帮助我们理解语言模型如何自动评估和打分摘要内容。](2024年03月07日/iScore_Visual_Analytics_for_Interpreting_How_Language_Models_Automatically_Score_Summaries.md)

- [XPSR: Cross-modal Priors for Diffusion-based Image Super-Resolution](2024年03月07日/XPSR_Cross-modal_Priors_for_Diffusion-based_Image_Super-Resolution.md)

    - [翻译: XPSR：探索扩散式图像超分辨率技术中的跨模态先验知识，旨在提升图像处理性能和质量。](2024年03月07日/XPSR_Cross-modal_Priors_for_Diffusion-based_Image_Super-Resolution.md)

- [Are Human Conversations Special? A Large Language Model Perspective](2024年03月07日/Are_Human_Conversations_Special_A_Large_Language_Model_Perspective.md)

    - [翻译: 从大型语言模型的角度出发，我们是否能断言人类对话具有某种特殊性呢？](2024年03月07日/Are_Human_Conversations_Special_A_Large_Language_Model_Perspective.md)

- [Is this the real life? Is this just fantasy? The Misleading Success of Simulating Social Interactions With LLMs](2024年03月07日/Is_this_the_real_life_Is_this_just_fantasy_The_Misleading_Success_of_Simulating_Social_Interactions_With_LLMs.md)

    - [翻译: 现实抑或幻象？LLMs在模拟社交互动中取得的成功，其真实性是否存在误导性呢？](2024年03月07日/Is_this_the_real_life_Is_this_just_fantasy_The_Misleading_Success_of_Simulating_Social_Interactions_With_LLMs.md)

- [Can't Remember Details in Long Documents? You Need Some R&R](2024年03月07日/Can't_Remember_Details_in_Long_Documents_You_Need_Some_R&R.md)

    - [翻译: 面对长篇文档，细节总记不住？或许你需要来点“R&R”魔法。 （注：这里的“R&R”在原文中未明确指出含义，可能是“Rest and Relaxation（休息与放松）”或某种解决方法的缩写，在翻译时可根据上下文进行适当推测和解释。）](2024年03月07日/Can't_Remember_Details_in_Long_Documents_You_Need_Some_R&R.md)

- [DiffChat: Learning to Chat with Text-to-Image Synthesis Models for Interactive Image Creation](2024年03月07日/DiffChat_Learning_to_Chat_with_Text-to-Image_Synthesis_Models_for_Interactive_Image_Creation.md)

    - [翻译: DiffChat 让我们能够通过学习与文本转图像合成模型进行对话，从而实现图像的互动式创作。](2024年03月07日/DiffChat_Learning_to_Chat_with_Text-to-Image_Synthesis_Models_for_Interactive_Image_Creation.md)

- [Embracing Large Language and Multimodal Models for Prosthetic Technologies](2024年03月07日/Embracing_Large_Language_and_Multimodal_Models_for_Prosthetic_Technologies.md)

    - [翻译: 积极采用大型语言及多模态模型赋能假体技术发展](2024年03月07日/Embracing_Large_Language_and_Multimodal_Models_for_Prosthetic_Technologies.md)

- [Tell me the truth: A system to measure the trustworthiness of Large Language Models](2024年03月07日/Tell_me_the_truth_A_system_to_measure_the_trustworthiness_of_Large_Language_Models.md)

    - [翻译: 揭示真相：该系统旨在评测大型语言模型的信任度，以准确衡量其可靠程度。](2024年03月07日/Tell_me_the_truth_A_system_to_measure_the_trustworthiness_of_Large_Language_Models.md)

- [An In-depth Evaluation of GPT-4 in Sentence Simplification with Error-based Human Assessment](2024年03月07日/An_In-depth_Evaluation_of_GPT-4_in_Sentence_Simplification_with_Error-based_Human_Assessment.md)

    - [翻译: 通过细致的错误导向人工评估，我们对GPT-4在句子简化任务中的表现进行了深度剖析。](2024年03月07日/An_In-depth_Evaluation_of_GPT-4_in_Sentence_Simplification_with_Error-based_Human_Assessment.md)

- [SecGPT: An Execution Isolation Architecture for LLM-Based Systems](2024年03月07日/SecGPT_An_Execution_Isolation_Architecture_for_LLM-Based_Systems.md)

    - [翻译: SecGPT是一种专为基于大型语言模型（LLM）的系统设计的执行隔离架构，旨在确保其安全性和稳定性。](2024年03月07日/SecGPT_An_Execution_Isolation_Architecture_for_LLM-Based_Systems.md)

- [Automatic and Universal Prompt Injection Attacks against Large Language Models](2024年03月07日/Automatic_and_Universal_Prompt_Injection_Attacks_against_Large_Language_Models.md)

    - [翻译: 自动且普遍性的提示注入攻击，对大型语言模型构成了威胁。这项研究探讨了如何针对大型语言模型实施自动化、普适性的提示注入攻击，揭示其潜在安全风险。](2024年03月07日/Automatic_and_Universal_Prompt_Injection_Attacks_against_Large_Language_Models.md)

- [A Survey on Human-AI Teaming with Large Pre-Trained Models](2024年03月07日/A_Survey_on_Human-AI_Teaming_with_Large_Pre-Trained_Models.md)

    - [翻译: 本篇调研聚焦于大型预训练模型在人机协作中的应用，详尽探讨了这一领域的最新进展与实践。](2024年03月07日/A_Survey_on_Human-AI_Teaming_with_Large_Pre-Trained_Models.md)

- [Self-Adapting Large Visual-Language Models to Edge Devices across Visual Modalities](2024年03月07日/Self-Adapting_Large_Visual-Language_Models_to_Edge_Devices_across_Visual_Modalities.md)

    - [翻译: 该研究致力于将自适应的大型视觉-语言模型推广至不同视觉模态下的边缘设备，实现模型在各类终端上的高效运行。](2024年03月07日/Self-Adapting_Large_Visual-Language_Models_to_Edge_Devices_across_Visual_Modalities.md)

- [ConstitutionalExperts: Training a Mixture of Principle-based Prompts](2024年03月07日/ConstitutionalExperts_Training_a_Mixture_of_Principle-based_Prompts.md)

    - [翻译: 「宪法专家」模型：通过融合原则性提示进行训练，旨在提升模型在处理宪法相关问题时的专业性和准确性。](2024年03月07日/ConstitutionalExperts_Training_a_Mixture_of_Principle-based_Prompts.md)

- [Few shot chain-of-thought driven reasoning to prompt LLMs for open ended medical question answering](2024年03月07日/Few_shot_chain-of-thought_driven_reasoning_to_prompt_LLMs_for_open_ended_medical_question_answering.md)

    - [翻译: 针对开放式医疗问题解答，我们采用少量示例的链式思考驱动方式来激活LLM的强大推理能力。](2024年03月07日/Few_shot_chain-of-thought_driven_reasoning_to_prompt_LLMs_for_open_ended_medical_question_answering.md)

- [Evaluating Biases in Context-Dependent Health Questions](2024年03月07日/Evaluating_Biases_in_Context-Dependent_Health_Questions.md)

    - [翻译: 本研究专注于探究上下文相关健康问题中潜在的偏见，并对其进行深入评估。](2024年03月07日/Evaluating_Biases_in_Context-Dependent_Health_Questions.md)

- [Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks](2024年03月07日/Evaluation_of_LLMs_on_Syntax-Aware_Code_Fill-in-the-Middle_Tasks.md)

    - [翻译: 本研究专注于评估LLMs在处理具有语法感知能力的代码中间填充任务时的表现。](2024年03月07日/Evaluation_of_LLMs_on_Syntax-Aware_Code_Fill-in-the-Middle_Tasks.md)

- [Ducho 2.0: Towards a More Up-to-Date Feature Extraction and Processing Framework for Multimodal Recommendation](2024年03月07日/Ducho_2.0_Towards_a_More_Up-to-Date_Feature_Extraction_and_Processing_Framework_for_Multimodal_Recommendation.md)

    - [翻译: Ducho 2.0，旨在构建一个面向最新技术的多模态推荐特征抽取与处理框架，力求在该领域实现更先进、更实时的性能提升。](2024年03月07日/Ducho_2.0_Towards_a_More_Up-to-Date_Feature_Extraction_and_Processing_Framework_for_Multimodal_Recommendation.md)

- [TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document](2024年03月07日/TextMonkey_An_OCR-Free_Large_Multimodal_Model_for_Understanding_Document.md)

    - [翻译: TextMonkey——一款突破性 OCR 限制的大型多模态模型，致力于深入理解和解析各类文档内容。](2024年03月07日/TextMonkey_An_OCR-Free_Large_Multimodal_Model_for_Understanding_Document.md)

- [CoTBal: Comprehensive Task Balancing for Multi-Task Visual Instruction Tuning](2024年03月07日/CoTBal_Comprehensive_Task_Balancing_for_Multi-Task_Visual_Instruction_Tuning.md)

    - [翻译: CoTBal 是一种针对多任务视觉指令调优的全新方法，致力于实现全面的任务平衡，以优化模型在不同视觉指令任务中的综合表现。](2024年03月07日/CoTBal_Comprehensive_Task_Balancing_for_Multi-Task_Visual_Instruction_Tuning.md)

- [Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study](2024年03月07日/Towards_General_Computer_Control_A_Multimodal_Agent_for_Red_Dead_Redemption_II_as_a_Case_Study.md)

    - [翻译: 为了探索通用计算机控制的可能性，我们以《荒野大镖客2》为例，设计并研发了一个多模态智能体进行深度探究。通过该游戏作为案例研究，旨在揭示多模态智能体在复杂环境下的控制能力与适应性。](2024年03月07日/Towards_General_Computer_Control_A_Multimodal_Agent_for_Red_Dead_Redemption_II_as_a_Case_Study.md)

- [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](2024年03月08日/Gemini_1.5_Unlocking_multimodal_understanding_across_millions_of_tokens_of_context.md)

    - [翻译: Gemini 1.5 开启新篇章，跨过数百万个上下文标记，释放强大的多模态理解潜力](2024年03月08日/Gemini_1.5_Unlocking_multimodal_understanding_across_millions_of_tokens_of_context.md)

- [GEAR: An Efficient KV Cache Compression Recipefor Near-Lossless Generative Inference of LLM](2024年03月08日/GEAR_An_Efficient_KV_Cache_Compression_Recipefor_Near-Lossless_Generative_Inference_of_LLM.md)

    - [翻译: GEAR是专为LLM设计的一种有效KV缓存压缩策略，旨在实现近无损的生成推理性能。这款新颖的压缩方案助力LLM在进行生成推理时，既能保持高效性又能实现近乎无损的质量保证。](2024年03月08日/GEAR_An_Efficient_KV_Cache_Compression_Recipefor_Near-Lossless_Generative_Inference_of_LLM.md)

- [Beyond Finite Data: Towards Data-free Out-of-distribution Generalization via Extrapola](2024年03月08日/Beyond_Finite_Data_Towards_Data-free_Out-of-distribution_Generalization_via_Extrapola.md)

    - [翻译: 迈向无限可能：利用外推法突破数据局限，实现对未见过数据分布的泛化能力](2024年03月08日/Beyond_Finite_Data_Towards_Data-free_Out-of-distribution_Generalization_via_Extrapola.md)

- [To Err Is Human, but Llamas Can Learn It Too](2024年03月08日/To_Err_Is_Human,_but_Llamas_Can_Learn_It_Too.md)

    - [翻译: 犯错误是人类的天性，然而羊驼也同样具有学习犯错的能力。](2024年03月08日/To_Err_Is_Human,_but_Llamas_Can_Learn_It_Too.md)

- [Will GPT-4 Run DOOM?](2024年03月08日/Will_GPT-4_Run_DOOM.md)

    - [翻译: GPT-4 是否具备运行经典游戏 DOOM 的能力？](2024年03月08日/Will_GPT-4_Run_DOOM.md)

- [Cost-Performance Optimization for Processing Low-Resource Language Tasks Using Commercial LLMs](2024年03月08日/Cost-Performance_Optimization_for_Processing_Low-Resource_Language_Tasks_Using_Commercial_LLMs.md)

    - [翻译: 针对低资源语言任务，本研究探讨如何运用商业大型语言模型进行成本与性能的优化，以期在保证任务完成质量的同时，有效控制处理此类任务的成本。](2024年03月08日/Cost-Performance_Optimization_for_Processing_Low-Resource_Language_Tasks_Using_Commercial_LLMs.md)

- [HistGen: Histopathology Report Generation via Local-Global Feature Encoding and Cross-modal Context Interaction](2024年03月08日/HistGen_Histopathology_Report_Generation_via_Local-Global_Feature_Encoding_and_Cross-modal_Context_Interaction.md)

    - [翻译: HistGen 是一种创新方法，利用局部-全局特征编码及跨模态上下文互动技术，专为自动生成组织病理学报告而设计。](2024年03月08日/HistGen_Histopathology_Report_Generation_via_Local-Global_Feature_Encoding_and_Cross-modal_Context_Interaction.md)

- [Exploring Robust Features for Few-Shot Object Detection in Satellite Imagery](2024年03月08日/Exploring_Robust_Features_for_Few-Shot_Object_Detection_in_Satellite_Imagery.md)

    - [翻译: 本研究致力于挖掘卫星图像中能够有效应用于少量样本目标检测任务的稳健特征，旨在提升该领域的检测性能和泛化能力。](2024年03月08日/Exploring_Robust_Features_for_Few-Shot_Object_Detection_in_Satellite_Imagery.md)

- [Explaining Pre-Trained Language Models with Attribution Scores: An Analysis in Low-Resource Settings](2024年03月08日/Explaining_Pre-Trained_Language_Models_with_Attribution_Scores_An_Analysis_in_Low-Resource_Settings.md)

    - [翻译: 针对低资源场景，本研究通过归因分数深入剖析预训练语言模型的工作原理。](2024年03月08日/Explaining_Pre-Trained_Language_Models_with_Attribution_Scores_An_Analysis_in_Low-Resource_Settings.md)

- [ChatASU: Evoking LLM's Reflexion to Truly Understand Aspect Sentiment in Dialogues](2024年03月08日/ChatASU_Evoking_LLM's_Reflexion_to_Truly_Understand_Aspect_Sentiment_in_Dialogues.md)

    - [翻译: ChatASU 研究通过触发 LLM 在对话情境中的深度反思，旨在真实捕捉和理解方面的具体情感倾向。](2024年03月08日/ChatASU_Evoking_LLM's_Reflexion_to_Truly_Understand_Aspect_Sentiment_in_Dialogues.md)

- [RAT: Retrieval Augmented Thoughts Elicit Context-Aware Reasoning in Long-Horizon Generation](2024年03月08日/RAT_Retrieval_Augmented_Thoughts_Elicit_Context-Aware_Reasoning_in_Long-Horizon_Generation.md)

    - [翻译: RAT技术通过引入检索增强思维，在长时段生成任务中有效激发了情境感知的推理能力。](2024年03月08日/RAT_Retrieval_Augmented_Thoughts_Elicit_Context-Aware_Reasoning_in_Long-Horizon_Generation.md)

- [Tapilot-Crossing: Benchmarking and Evolving LLMs Towards Interactive Data Analysis Agents](2024年03月08日/Tapilot-Crossing_Benchmarking_and_Evolving_LLMs_Towards_Interactive_Data_Analysis_Agents.md)

    - [翻译: Tapilot-Crossing 是一个专注于推动大型语言模型（LLMs）向交互式数据分析代理演进的基准测试项目，旨在评测并提升 LLMS 在此领域的能力。](2024年03月08日/Tapilot-Crossing_Benchmarking_and_Evolving_LLMs_Towards_Interactive_Data_Analysis_Agents.md)

- [ACLSum: A New Dataset for Aspect-based Summarization of Scientific Publications](2024年03月08日/ACLSum_A_New_Dataset_for_Aspect-based_Summarization_of_Scientific_Publications.md)

    - [翻译: ACLSum —— 专为科研论文打造的全新方面式摘要数据集](2024年03月08日/ACLSum_A_New_Dataset_for_Aspect-based_Summarization_of_Scientific_Publications.md)

- [LLM4Decompile: Decompiling Binary Code with Large Language Models](2024年03月08日/LLM4Decompile_Decompiling_Binary_Code_with_Large_Language_Models.md)

    - [翻译: LLM4Decompile 是一项利用大型语言模型来实现二进制代码反编译的技术。](2024年03月08日/LLM4Decompile_Decompiling_Binary_Code_with_Large_Language_Models.md)

- [ERBench: An Entity-Relationship based Automatically Verifiable Hallucination Benchmark for Large Language Models](2024年03月08日/ERBench_An_Entity-Relationship_based_Automatically_Verifiable_Hallucination_Benchmark_for_Large_Language_Models.md)

    - [翻译: ERBench 是专为大型语言模型设计的、基于实体关系的自动化验证幻觉基准测试，旨在精确衡量和评估模型在处理复杂实体关系时出现的幻觉现象。](2024年03月08日/ERBench_An_Entity-Relationship_based_Automatically_Verifiable_Hallucination_Benchmark_for_Large_Language_Models.md)

- [Debiasing Large Visual Language Models](2024年03月08日/Debiasing_Large_Visual_Language_Models.md)

    - [翻译: 本研究致力于探讨如何有效去偏大型视觉语言模型，以提升其准确性和公正性。](2024年03月08日/Debiasing_Large_Visual_Language_Models.md)

- [Cross-lingual Transfer or Machine Translation? On Data Augmentation for Monolingual Semantic Textual Similarity](2024年03月08日/Cross-lingual_Transfer_or_Machine_Translation_On_Data_Augmentation_for_Monolingual_Semantic_Textual_Similarity.md)

    - [翻译: 在探讨单语种语义文本相似度的数据增强方法时，究竟是采用跨语言迁移技术还是机器翻译策略呢？本研究旨在深入探究这一问题。](2024年03月08日/Cross-lingual_Transfer_or_Machine_Translation_On_Data_Augmentation_for_Monolingual_Semantic_Textual_Similarity.md)

- [Tracking Meets LoRA: Faster Training, Larger Model, Stronger Performance](2024年03月08日/Tracking_Meets_LoRA_Faster_Training,_Larger_Model,_Stronger_Performance.md)

    - [翻译: 在本次研究中，我们将追踪技术与LoRA相结合，带来更快的训练速度、支持更大规模的模型，并实现了更出色的整体性能。](2024年03月08日/Tracking_Meets_LoRA_Faster_Training,_Larger_Model,_Stronger_Performance.md)

- [Harnessing Multi-Role Capabilities of Large Language Models for Open-Domain Question Answering](2024年03月08日/Harnessing_Multi-Role_Capabilities_of_Large_Language_Models_for_Open-Domain_Question_Answering.md)

    - [翻译: 为解决开放领域问题回答任务，本研究探讨如何有效地利用大型语言模型所具备的多元角色功能。](2024年03月08日/Harnessing_Multi-Role_Capabilities_of_Large_Language_Models_for_Open-Domain_Question_Answering.md)

- [Overcoming Reward Overoptimization via Adversarial Policy Optimization with Lightweight Uncertainty Estimation](2024年03月08日/Overcoming_Reward_Overoptimization_via_Adversarial_Policy_Optimization_with_Lightweight_Uncertainty_Estimation.md)

    - [翻译: 借助轻量级不确定性估计的对抗性策略优化方法，有效解决奖励函数过度优化难题。](2024年03月08日/Overcoming_Reward_Overoptimization_via_Adversarial_Policy_Optimization_with_Lightweight_Uncertainty_Estimation.md)

- [On Protecting the Data Privacy of Large Language Models (LLMs): A Survey](2024年03月08日/On_Protecting_the_Data_Privacy_of_Large_Language_Models_(LLMs)_A_Survey.md)

    - [翻译: 本文对保护LLMs数据隐私的策略进行了一次全面的调查，旨在深入探讨和总结当前针对大型语言模型的数据安全防护措施。](2024年03月08日/On_Protecting_the_Data_Privacy_of_Large_Language_Models_(LLMs)_A_Survey.md)

- [Towards a Psychology of Machines: Large Language Models Predict Human Memory](2024年03月08日/Towards_a_Psychology_of_Machines_Large_Language_Models_Predict_Human_Memory.md)

    - [翻译: 致力于探索机器的心理学层面，大型语言模型已展现出预测人类记忆的能力。](2024年03月08日/Towards_a_Psychology_of_Machines_Large_Language_Models_Predict_Human_Memory.md)

- [Inverse Design of Photonic Crystal Surface Emitting Lasers is a Sequence Modeling Problem](2024年03月08日/Inverse_Design_of_Photonic_Crystal_Surface_Emitting_Lasers_is_a_Sequence_Modeling_Problem.md)

    - [翻译: 设计光子晶体表面发射激光器的逆向工程实质上可视为一个序列模型构建问题。](2024年03月08日/Inverse_Design_of_Photonic_Crystal_Surface_Emitting_Lasers_is_a_Sequence_Modeling_Problem.md)

- [Med3DInsight: Enhancing 3D Medical Image Understanding with 2D Multi-Modal Large Language Models](2024年03月08日/Med3DInsight_Enhancing_3D_Medical_Image_Understanding_with_2D_Multi-Modal_Large_Language_Models.md)

    - [翻译: Med3DInsight项目利用2D多模态大型语言模型的力量，提升三维医学图像的深入理解和分析能力。](2024年03月08日/Med3DInsight_Enhancing_3D_Medical_Image_Understanding_with_2D_Multi-Modal_Large_Language_Models.md)

- [ELLA: Equip Diffusion Models with LLM for Enhanced Semantic Alignment](2024年03月08日/ELLA_Equip_Diffusion_Models_with_LLM_for_Enhanced_Semantic_Alignment.md)

    - [翻译: ELLA项目通过将LLM与扩散模型相结合，旨在提升模型的语义对齐性能。](2024年03月08日/ELLA_Equip_Diffusion_Models_with_LLM_for_Enhanced_Semantic_Alignment.md)

- [ChatUIE: Exploring Chat-based Unified Information Extraction using Large Language Models](2024年03月08日/ChatUIE_Exploring_Chat-based_Unified_Information_Extraction_using_Large_Language_Models.md)

    - [翻译: ChatUIE 是一项研究，借助大型语言模型的力量，致力于探究和实现基于聊天模式的统一信息抽取技术。](2024年03月08日/ChatUIE_Exploring_Chat-based_Unified_Information_Extraction_using_Large_Language_Models.md)

- [Benchmarking Large Language Models for Molecule Prediction Tasks](2024年03月08日/Benchmarking_Large_Language_Models_for_Molecule_Prediction_Tasks.md)

    - [翻译: 本研究致力于为分子预测任务设定基准，对大型语言模型的表现进行全面评估和对比。](2024年03月08日/Benchmarking_Large_Language_Models_for_Molecule_Prediction_Tasks.md)

- [Can we obtain significant success in RST discourse parsing by using Large Language Models?](2024年03月08日/Can_we_obtain_significant_success_in_RST_discourse_parsing_by_using_Large_Language_Models.md)

    - [翻译: 在 RST 对话解析任务上，大型语言模型能否助力我们实现显著突破？](2024年03月08日/Can_we_obtain_significant_success_in_RST_discourse_parsing_by_using_Large_Language_Models.md)

- [Aligning Large Language Models for Controllable Recommendations](2024年03月08日/Aligning_Large_Language_Models_for_Controllable_Recommendations.md)

    - [翻译: 本研究致力于将大型语言模型与可控推荐相结合，通过调整和优化模型以实现更为精准且可控的推荐效果。](2024年03月08日/Aligning_Large_Language_Models_for_Controllable_Recommendations.md)

- [Multimodal Infusion Tuning for Large Models](2024年03月08日/Multimodal_Infusion_Tuning_for_Large_Models.md)

    - [翻译: 针对大型模型的多模态融合优化技术，旨在通过深度融合不同模态的信息来提升模型性能。](2024年03月08日/Multimodal_Infusion_Tuning_for_Large_Models.md)

- [ClinicalMamba: A Generative Clinical Language Model on Longitudinal Clinical Notes](2024年03月08日/ClinicalMamba_A_Generative_Clinical_Language_Model_on_Longitudinal_Clinical_Notes.md)

    - [翻译: ClinicalMamba——一款在连续性临床笔记上训练出的生成式临床语言模型，专门针对纵向临床记录进行设计和构建。](2024年03月08日/ClinicalMamba_A_Generative_Clinical_Language_Model_on_Longitudinal_Clinical_Notes.md)

- [ItD: Large Language Models Can Teach Themselves Induction through Deduction](2024年03月08日/ItD_Large_Language_Models_Can_Teach_Themselves_Induction_through_Deduction.md)

    - [翻译: ItD 研究表明，大型语言模型能够通过演绎推理过程来自我发现和掌握归纳能力。](2024年03月08日/ItD_Large_Language_Models_Can_Teach_Themselves_Induction_through_Deduction.md)

- [Extending Activation Steering to Broad Skills and Multiple Behaviours](2024年03月08日/Extending_Activation_Steering_to_Broad_Skills_and_Multiple_Behaviours.md)

    - [翻译: 我们将 Activation Steering 技术推广到更广泛的技能领域和多元行为表现，旨在探究其在不同能力和情境下的应用效果。](2024年03月08日/Extending_Activation_Steering_to_Broad_Skills_and_Multiple_Behaviours.md)

- [Decoding the AI Pen: Techniques and Challenges in Detecting AI-Generated Text](2024年03月08日/Decoding_the_AI_Pen_Techniques_and_Challenges_in_Detecting_AI-Generated_Text.md)

    - [翻译: 揭秘 AI 生成文本：探究检测技术及面临的挑战](2024年03月08日/Decoding_the_AI_Pen_Techniques_and_Challenges_in_Detecting_AI-Generated_Text.md)

- [A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries](2024年03月08日/A_Benchmark_of_Domain-Adapted_Large_Language_Models_for_Generating_Brief_Hospital_Course_Summaries.md)

    - [翻译: 本研究提出了一项针对生成简要住院病程总结的大型语言模型领域适应能力的基准测试，旨在评估和比较各类经过特定医疗领域调整后的大型语言模型的表现。](2024年03月08日/A_Benchmark_of_Domain-Adapted_Large_Language_Models_for_Generating_Brief_Hospital_Course_Summaries.md)

- [Are Large Language Models Aligned with People's Social Intuitions for Human-Robot Interactions?](2024年03月08日/Are_Large_Language_Models_Aligned_with_People's_Social_Intuitions_for_Human-Robot_Interactions.md)

    - [翻译: 对于人机交互，大型语言模型是否能够贴合人们的社交直觉？](2024年03月08日/Are_Large_Language_Models_Aligned_with_People's_Social_Intuitions_for_Human-Robot_Interactions.md)

- [SeeGULL Multilingual: a Dataset of Geo-Culturally Situated Stereotypes](2024年03月08日/SeeGULL_Multilingual_a_Dataset_of_Geo-Culturally_Situated_Stereotypes.md)

    - [翻译: SeeGULL Multilingual 数据集，专门收录了具有地理文化情境的刻板印象实例。](2024年03月08日/SeeGULL_Multilingual_a_Dataset_of_Geo-Culturally_Situated_Stereotypes.md)

- [DP-TabICL: In-Context Learning with Differentially Private Tabular Data](2024年03月08日/DP-TabICL_In-Context_Learning_with_Differentially_Private_Tabular_Data.md)

    - [翻译: DP-TabICL：探索在带有差分隐私保护的表格数据环境中进行上下文学习的能力](2024年03月08日/DP-TabICL_In-Context_Learning_with_Differentially_Private_Tabular_Data.md)

- [Decomposing Vision-based LLM Predictions for Auto-Evaluation with GPT-4](2024年03月08日/Decomposing_Vision-based_LLM_Predictions_for_Auto-Evaluation_with_GPT-4.md)

    - [翻译: 利用GPT-4对基于视觉的LLM预测进行拆解，实现自动评估目标](2024年03月08日/Decomposing_Vision-based_LLM_Predictions_for_Auto-Evaluation_with_GPT-4.md)

- [PipeRAG: Fast Retrieval-Augmented Generation via Algorithm-System Co-design](2024年03月08日/PipeRAG_Fast_Retrieval-Augmented_Generation_via_Algorithm-System_Co-design.md)

    - [翻译: PipeRAG 是一种创新方法，借助算法与系统协同设计的策略，高效实现了检索增强生成。这一技术旨在显著提升文本生成的速度，并在保持高质量的同时，充分融合检索与生成的优势。](2024年03月08日/PipeRAG_Fast_Retrieval-Augmented_Generation_via_Algorithm-System_Co-design.md)

- [CFaiRLLM: Consumer Fairness Evaluation in Large-Language Model Recommender System](2024年03月08日/CFaiRLLM_Consumer_Fairness_Evaluation_in_Large-Language_Model_Recommender_System.md)

    - [翻译: CFaiRLLM 是针对大型语言模型推荐系统的消费者公平性评测方案，旨在深入探究和评估该类系统中对消费者公平性的保障程度。](2024年03月08日/CFaiRLLM_Consumer_Fairness_Evaluation_in_Large-Language_Model_Recommender_System.md)

- [Tuning-Free Accountable Intervention for LLM Deployment -- A Metacognitive Approach](2024年03月08日/Tuning-Free_Accountable_Intervention_for_LLM_Deployment_--_A_Metacognitive_Approach.md)

    - [翻译: 面对LLM部署，我们提出了一种无需额外调优且具备可解释性的干预方案，该方案采用元认知方法，旨在提升模型在实际应用中的可靠性和可控性。](2024年03月08日/Tuning-Free_Accountable_Intervention_for_LLM_Deployment_--_A_Metacognitive_Approach.md)

- [Can Large Language Models Play Games? A Case Study of A Self-Play Approach](2024年03月08日/Can_Large_Language_Models_Play_Games_A_Case_Study_of_A_Self-Play_Approach.md)

    - [翻译: 大型语言模型能否涉足游戏领域？我们通过一项以自我对弈法为切入点的案例研究，探索这一可能性。](2024年03月08日/Can_Large_Language_Models_Play_Games_A_Case_Study_of_A_Self-Play_Approach.md)

- [Context-Based Multimodal Fusion](2024年03月08日/Context-Based_Multimodal_Fusion.md)

    - [翻译: 情境化多模态融合技术，是指将不同模态的信息在特定语境下进行有效整合的过程。](2024年03月08日/Context-Based_Multimodal_Fusion.md)

- [FrameQuant: Flexible Low-Bit Quantization for Transformers](2024年03月09日/FrameQuant_Flexible_Low-Bit_Quantization_for_Transformers.md)

    - [翻译: FrameQuant是一种针对Transformer设计的弹性低比特量化方案。](2024年03月09日/FrameQuant_Flexible_Low-Bit_Quantization_for_Transformers.md)

- [Reframe Anything: LLM Agent for Open World Video Reframing](2024年03月09日/Reframe_Anything_LLM_Agent_for_Open_World_Video_Reframing.md)

    - [翻译: 【重塑万物】推出 LLM 视频重构智能代理，针对开放世界场景下的视频重构任务。步骤详解：](2024年03月09日/Reframe_Anything_LLM_Agent_for_Open_World_Video_Reframing.md)

- [Test-time Distribution Learning Adapter for Cross-modal Visual Reasoning](2024年03月09日/Test-time_Distribution_Learning_Adapter_for_Cross-modal_Visual_Reasoning.md)

    - [翻译: 为解决跨模态视觉推理中的适应性问题，我们提出了一种测试阶段分布学习适配器，它能在实际推理过程中动态调整模型对不同分布数据的理解和处理能力。（由于原句较短，从准确翻译到简洁优雅的中文转换时，已尽量保持原意并增加了一些上下文信息以使句子更完整生动。）](2024年03月09日/Test-time_Distribution_Learning_Adapter_for_Cross-modal_Visual_Reasoning.md)

- [Explaining Code with a Purpose: An Integrated Approach for Developing Code Comprehension and Prompting Skills](2024年03月09日/Explaining_Code_with_a_Purpose_An_Integrated_Approach_for_Developing_Code_Comprehension_and_Prompting_Skills.md)

    - [翻译: 面向目标的代码解析：一体化方案助力提升代码理解和指令引导能力](2024年03月09日/Explaining_Code_with_a_Purpose_An_Integrated_Approach_for_Developing_Code_Comprehension_and_Prompting_Skills.md)

- [A Preliminary Exploration of YouTubers' Use of Generative-AI in Content Creation](2024年03月09日/A_Preliminary_Exploration_of_YouTubers'_Use_of_Generative-AI_in_Content_Creation.md)

    - [翻译: 本研究初步探究了YouTubers在制作视频内容时运用生成式AI技术的情况](2024年03月09日/A_Preliminary_Exploration_of_YouTubers'_Use_of_Generative-AI_in_Content_Creation.md)

- [Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in Low-Resource Languages](2024年03月09日/Few-Shot_Cross-Lingual_Transfer_for_Prompting_Large_Language_Models_in_Low-Resource_Languages.md)

    - [翻译: 针对低资源语言，我们探索了少量样本下的跨语言迁移技术，以实现对大型语言模型的有效提示。这项研究旨在通过少量示例，在资源匮乏的语言环境下提升大型语言模型的性能表现。](2024年03月09日/Few-Shot_Cross-Lingual_Transfer_for_Prompting_Large_Language_Models_in_Low-Resource_Languages.md)

- [Detectors for Safe and Reliable LLMs: Implementations, Uses, and Limitations](2024年03月09日/Detectors_for_Safe_and_Reliable_LLMs_Implementations,_Uses,_and_Limitations.md)

    - [翻译: 为确保LLMs的安全与可靠性，本文探讨了相关探测器的实现方法、应用场景及其局限性。](2024年03月09日/Detectors_for_Safe_and_Reliable_LLMs_Implementations,_Uses,_and_Limitations.md)

- [Calibrating Large Language Models Using Their Generations Only](2024年03月09日/Calibrating_Large_Language_Models_Using_Their_Generations_Only.md)

    - [翻译: 本研究专注于仅通过大型语言模型自身生成的内容对其进行校准，探讨无需额外数据辅助即可提升其准确性和可信度的方法。](2024年03月09日/Calibrating_Large_Language_Models_Using_Their_Generations_Only.md)

- [Thread Detection and Response Generation using Transformers with Prompt Optimisation](2024年03月09日/Thread_Detection_and_Response_Generation_using_Transformers_with_Prompt_Optimisation.md)

    - [翻译: 通过优化提示的Transformer模型实现对线程的精准检测与智能响应生成](2024年03月09日/Thread_Detection_and_Response_Generation_using_Transformers_with_Prompt_Optimisation.md)

- [High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models](2024年03月09日/High_Throughput_Phenotyping_of_Physician_Notes_with_Large_Language_and_Hybrid_NLP_Models.md)

    - [翻译: 我们运用大型语言模型与混合NLP技术，高效解析医师笔记中的丰富信息，实现高通量表型特征提取。](2024年03月09日/High_Throughput_Phenotyping_of_Physician_Notes_with_Large_Language_and_Hybrid_NLP_Models.md)

- [Aligning Speech to Languages to Enhance Code-switching Speech Recognition](2024年03月09日/Aligning_Speech_to_Languages_to_Enhance_Code-switching_Speech_Recognition.md)

    - [翻译: 为优化代码切换语音识别，本研究致力于通过将语音与多种语言进行精准对齐，从而增强此类混合语种识别效果。](2024年03月09日/Aligning_Speech_to_Languages_to_Enhance_Code-switching_Speech_Recognition.md)

- [KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge Graphs and Ranking Techniques](2024年03月09日/KG-Rank_Enhancing_Large_Language_Models_for_Medical_QA_with_Knowledge_Graphs_and_Ranking_Techniques.md)

    - [翻译: KG-Rank 是一项研究，通过融合知识图谱与排序技术，提升大型语言模型在处理医学问答任务时的表现力。](2024年03月09日/KG-Rank_Enhancing_Large_Language_Models_for_Medical_QA_with_Knowledge_Graphs_and_Ranking_Techniques.md)

- [LTGC: Long-tail Recognition via Leveraging LLMs-driven Generated Content](2024年03月09日/LTGC_Long-tail_Recognition_via_Leveraging_LLMs-driven_Generated_Content.md)

    - [翻译: LTGC 方法借助LLMs驱动生成的内容，有效应对长尾识别问题。](2024年03月09日/LTGC_Long-tail_Recognition_via_Leveraging_LLMs-driven_Generated_Content.md)

- [Reverse That Number! Decoding Order Matters in Arithmetic Learning](2024年03月09日/Reverse_That_Number!_Decoding_Order_Matters_in_Arithmetic_Learning.md)

    - [翻译: 反转数字有玄机！在数学运算学习过程中，解码顺序确实至关重要。](2024年03月09日/Reverse_That_Number!_Decoding_Order_Matters_in_Arithmetic_Learning.md)

- [Cached Model-as-a-Resource: Provisioning Large Language Model Agents for Edge Intelligence in Space-air-ground Integrated Networks](2024年03月09日/Cached_Model-as-a-Resource_Provisioning_Large_Language_Model_Agents_for_Edge_Intelligence_in_Space-air-ground_Integrated_Networks.md)

    - [翻译: 针对天地一体化网络中的边缘智能场景，我们提出“缓存模型即服务”方案，用于高效部署和供给大型语言模型代理。](2024年03月09日/Cached_Model-as-a-Resource_Provisioning_Large_Language_Model_Agents_for_Edge_Intelligence_in_Space-air-ground_Integrated_Networks.md)

- [Optimizing LLM Queries in Relational Workloads](2024年03月09日/Optimizing_LLM_Queries_in_Relational_Workloads.md)

    - [翻译: 针对关系型工作负载，本研究致力于提升对大型语言模型（LLM）查询的优化效果。](2024年03月09日/Optimizing_LLM_Queries_in_Relational_Workloads.md)

- [LEVA: Using Large Language Models to Enhance Visual Analytics](2024年03月09日/LEVA_Using_Large_Language_Models_to_Enhance_Visual_Analytics.md)

    - [翻译: LEVA项目致力于将大型语言模型应用于视觉分析领域，以增强其性能和洞察力。](2024年03月09日/LEVA_Using_Large_Language_Models_to_Enhance_Visual_Analytics.md)

- [MP2D: An Automated Topic Shift Dialogue Generation Framework Leveraging Knowledge Graphs](2024年03月09日/MP2D_An_Automated_Topic_Shift_Dialogue_Generation_Framework_Leveraging_Knowledge_Graphs.md)

    - [翻译: MP2D 是一种创新的自动化对话生成框架，它巧妙运用知识图谱技术来驱动话题的流畅转换，在对话内容生成中展现出强大的智能引导能力。](2024年03月09日/MP2D_An_Automated_Topic_Shift_Dialogue_Generation_Framework_Leveraging_Knowledge_Graphs.md)

- [$\textbf{S}^2$IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting](2024年03月09日/$\textbf{S}^2$IP-LLM_Semantic_Space_Informed_Prompt_Learning_with_LLM_for_Time_Series_Forecasting.md)

    - [翻译: $\textbf{S}^2$IP-LLM 是一种结合了大型语言模型（LLM）的时间序列预测方法，它运用了基于语义空间的提示学习技术，旨在提升对未来时间序列数据的预测能力。](2024年03月09日/$\textbf{S}^2$IP-LLM_Semantic_Space_Informed_Prompt_Learning_with_LLM_for_Time_Series_Forecasting.md)

- [ArgMed-Agents: Explainable Clinical Decision Reasoning with Large Language Models via Argumentation Schemes](2024年03月10日/ArgMed-Agents_Explainable_Clinical_Decision_Reasoning_with_Large_Language_Models_via_Argumentation_Schemes.md)

    - [翻译: ArgMed-Agents 是一种运用大型语言模型与论证方案相结合的方法，旨在为临床决策推理提供清晰、可解释的依据。](2024年03月10日/ArgMed-Agents_Explainable_Clinical_Decision_Reasoning_with_Large_Language_Models_via_Argumentation_Schemes.md)

- [Unpacking Tokenization: Evaluating Text Compression and its Correlation with Model Performance](2024年03月10日/Unpacking_Tokenization_Evaluating_Text_Compression_and_its_Correlation_with_Model_Performance.md)

    - [翻译: 本文旨在深入剖析分词技术，通过评估其在文本压缩上的表现，并探究这一过程与模型整体性能之间的内在关联。](2024年03月10日/Unpacking_Tokenization_Evaluating_Text_Compression_and_its_Correlation_with_Model_Performance.md)

- [Editing Conceptual Knowledge for Large Language Models](2024年03月10日/Editing_Conceptual_Knowledge_for_Large_Language_Models.md)

    - [翻译: 优化大型语言模型内部的概念理解能力步骤 1 翻译：编辑大型语言模型 (LLM) 中的概念知识。步骤 2 优化翻译：本研究探讨如何编辑和优化大型语言模型所承载的概念性知识结构，以提升其内在认知能力和表达精准度。](2024年03月10日/Editing_Conceptual_Knowledge_for_Large_Language_Models.md)

- [LLMs Still Can't Avoid Instanceof: An Investigation Into GPT-3.5, GPT-4 and Bard's Capacity to Handle Object-Oriented Programming Assignments](2024年03月10日/LLMs_Still_Can't_Avoid_Instanceof_An_Investigation_Into_GPT-3.5,_GPT-4_and_Bard's_Capacity_to_Handle_Object-Oriented_Programming_Assignments.md)

    - [翻译: 探究GPT-3.5、GPT-4与Bard对面向对象编程任务的处理能力，发现即便强大如LLMs，在涉及“instanceof”问题上仍存在局限性。](2024年03月10日/LLMs_Still_Can't_Avoid_Instanceof_An_Investigation_Into_GPT-3.5,_GPT-4_and_Bard's_Capacity_to_Handle_Object-Oriented_Programming_Assignments.md)

- [No Language is an Island: Unifying Chinese and English in Financial Large Language Models, Instruction Data, and Benchmarks](2024年03月10日/No_Language_is_an_Island_Unifying_Chinese_and_English_in_Financial_Large_Language_Models,_Instruction_Data,_and_Benchmarks.md)

    - [翻译: 无论是金融领域的大型语言模型，还是指令数据集，抑或是基准测试，“没有一种语言是孤立的”。本研究旨在打破壁垒，将中文与英文在这些领域中实现深度融合与统一。](2024年03月10日/No_Language_is_an_Island_Unifying_Chinese_and_English_in_Financial_Large_Language_Models,_Instruction_Data,_and_Benchmarks.md)

- [TRAD: Enhancing LLM Agents with Step-Wise Thought Retrieval and Aligned Decision](2024年03月10日/TRAD_Enhancing_LLM_Agents_with_Step-Wise_Thought_Retrieval_and_Aligned_Decision.md)

    - [翻译: TRAD 研究通过逐步骤检索思维及决策对齐策略，提升LLM智能体的表现。](2024年03月10日/TRAD_Enhancing_LLM_Agents_with_Step-Wise_Thought_Retrieval_and_Aligned_Decision.md)

- [Are You Being Tracked? Discover the Power of Zero-Shot Trajectory Tracing with LLMs!](2024年03月10日/Are_You_Being_Tracked_Discover_the_Power_of_Zero-Shot_Trajectory_Tracing_with_LLMs!.md)

    - [翻译: 想知道自己是否正被追踪？来领略一下LLMs在零样本轨迹追踪上的神奇力量吧！](2024年03月10日/Are_You_Being_Tracked_Discover_the_Power_of_Zero-Shot_Trajectory_Tracing_with_LLMs!.md)

- [A Comprehensive Overhaul of Multimodal Assistant with Small Language Models](2024年03月10日/A_Comprehensive_Overhaul_of_Multimodal_Assistant_with_Small_Language_Models.md)

    - [翻译: 对基于小型语言模型的多模态助手进行一次深入彻底的重构与升级](2024年03月10日/A_Comprehensive_Overhaul_of_Multimodal_Assistant_with_Small_Language_Models.md)

- [Speeding up 6-DoF Grasp Sampling with Quality-Diversity](2024年03月10日/Speeding_up_6-DoF_Grasp_Sampling_with_Quality-Diversity.md)

    - [翻译: 通过质量多样性提升 6 自由度抓取采样的效率](2024年03月10日/Speeding_up_6-DoF_Grasp_Sampling_with_Quality-Diversity.md)

- [Are LLMs ready for Visualization?](2024年03月10日/Are_LLMs_ready_for_Visualization.md)

    - [翻译: LLMs 在可视化领域是否已整装待发？](2024年03月10日/Are_LLMs_ready_for_Visualization.md)

- [Can Large Language Models Automatically Score Proficiency of Written Essays?](2024年03月10日/Can_Large_Language_Models_Automatically_Score_Proficiency_of_Written_Essays.md)

    - [翻译: 大型语言模型是否具备自动评分书面作文的能力？](2024年03月10日/Can_Large_Language_Models_Automatically_Score_Proficiency_of_Written_Essays.md)

- [Simulating Family Conversations using LLMs: Demonstration of Parenting Styles](2024年03月10日/Simulating_Family_Conversations_using_LLMs_Demonstration_of_Parenting_Styles.md)

    - [翻译: 本研究运用大型语言模型（LLMs）模拟家庭对话，生动展现不同育儿风格。通过这项演示，我们期望揭示 LLMS 如何捕捉并重现真实世界中多样化的育儿方式。](2024年03月10日/Simulating_Family_Conversations_using_LLMs_Demonstration_of_Parenting_Styles.md)

- [Fine-grainedly Synthesize Streaming Data Based On Large Language Models With Graph Structure Understanding For Data Sparsity](2024年03月10日/Fine-grainedly_Synthesize_Streaming_Data_Based_On_Large_Language_Models_With_Graph_Structure_Understanding_For_Data_Sparsity.md)

    - [翻译: 为了应对数据稀疏性挑战，本研究提出利用具备图结构理解能力的大型语言模型，对流式数据进行精细化合成。](2024年03月10日/Fine-grainedly_Synthesize_Streaming_Data_Based_On_Large_Language_Models_With_Graph_Structure_Understanding_For_Data_Sparsity.md)

- [FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning](2024年03月10日/FedPIT_Towards_Privacy-preserving_and_Few-shot_Federated_Instruction_Tuning.md)

    - [翻译: FedPIT 是一种致力于在保障隐私的同时实现少量样本的联邦指令微调的技术方案。](2024年03月10日/FedPIT_Towards_Privacy-preserving_and_Few-shot_Federated_Instruction_Tuning.md)

- [Low-dose CT Denoising with Language-engaged Dual-space Alignment](2024年03月10日/Low-dose_CT_Denoising_with_Language-engaged_Dual-space_Alignment.md)

    - [翻译: 通过运用语言引导的双空间对齐技术，本研究致力于实现低剂量 CT 图像的有效降噪。](2024年03月10日/Low-dose_CT_Denoising_with_Language-engaged_Dual-space_Alignment.md)

- [FMPAF: How Do Fed Chairs Affect the Financial Market? A Fine-grained Monetary Policy Analysis Framework on Their Language](2024年03月10日/FMPAF_How_Do_Fed_Chairs_Affect_the_Financial_Market_A_Fine-grained_Monetary_Policy_Analysis_Framework_on_Their_Language.md)

    - [翻译: FMPAF：探究美联储主席如何运用语言这一工具对金融市场施加影响，我们提出了一种针对货币政策的精细化分析框架。](2024年03月10日/FMPAF_How_Do_Fed_Chairs_Affect_the_Financial_Market_A_Fine-grained_Monetary_Policy_Analysis_Framework_on_Their_Language.md)

- [Large Language Models on Fine-grained Emotion Detection Dataset with Data Augmentation and Transfer Learning](2024年03月10日/Large_Language_Models_on_Fine-grained_Emotion_Detection_Dataset_with_Data_Augmentation_and_Transfer_Learning.md)

    - [翻译: 通过运用数据增强和迁移学习技术，大型语言模型在细粒度情感检测数据集上展现出了强大的性能。本研究聚焦于此类模型如何在丰富且精细的情感识别任务中，通过增强数据集和借用预训练知识实现更优表现。](2024年03月10日/Large_Language_Models_on_Fine-grained_Emotion_Detection_Dataset_with_Data_Augmentation_and_Transfer_Learning.md)

- [RepoHyper: Better Context Retrieval Is All You Need for Repository-Level Code Completion](2024年03月10日/RepoHyper_Better_Context_Retrieval_Is_All_You_Need_for_Repository-Level_Code_Completion.md)

    - [翻译: RepoHyper 提出，在仓库级别实现高效的代码补全，关键在于提升上下文检索能力，仅此一项改进就能满足需求。](2024年03月10日/RepoHyper_Better_Context_Retrieval_Is_All_You_Need_for_Repository-Level_Code_Completion.md)

- [Can LLMs' Tuning Methods Work in Medical Multimodal Domain?](2024年03月10日/Can_LLMs'_Tuning_Methods_Work_in_Medical_Multimodal_Domain.md)

    - [翻译: LLMs 的微调技术是否能在医学多模态领域奏效呢？](2024年03月10日/Can_LLMs'_Tuning_Methods_Work_in_Medical_Multimodal_Domain.md)

- [Amharic LLaMA and LLaVA: Multimodal LLMs for Low Resource Languages](2024年03月10日/Amharic_LLaMA_and_LLaVA_Multimodal_LLMs_for_Low_Resource_Languages.md)

    - [翻译: 针对低资源语言，我们推出了 Amharic LLaMA 和 LLaVA 多模态大型语言模型。这两个模型旨在为资源匮乏的语言提供强大的自然语言理解和生成能力，通过整合多种模态信息以提升性能表现。](2024年03月10日/Amharic_LLaMA_and_LLaVA_Multimodal_LLMs_for_Low_Resource_Languages.md)

- [Development of a Reliable and Accessible Caregiving Language Model (CaLM)](2024年03月11日/Development_of_a_Reliable_and_Accessible_Caregiving_Language_Model_(CaLM).md)

    - [翻译: 致力于构建一款既可靠又便于使用的照护语言模型（CaLM），旨在提升照护服务领域的沟通与智能化水平。](2024年03月11日/Development_of_a_Reliable_and_Accessible_Caregiving_Language_Model_(CaLM).md)

- [RA-ISF: Learning to Answer and Understand from Retrieval Augmentation via Iterative Self-Feedback](2024年03月11日/RA-ISF_Learning_to_Answer_and_Understand_from_Retrieval_Augmentation_via_Iterative_Self-Feedback.md)

    - [翻译: RA-ISF 模型致力于借助迭代自反馈机制，从检索增强中学习并掌握回答与理解的能力。](2024年03月11日/RA-ISF_Learning_to_Answer_and_Understand_from_Retrieval_Augmentation_via_Iterative_Self-Feedback.md)

- [Hybrid Human-LLM Corpus Construction and LLM Evaluation for Rare Linguistic Phenomena](2024年03月11日/Hybrid_Human-LLM_Corpus_Construction_and_LLM_Evaluation_for_Rare_Linguistic_Phenomena.md)

    - [翻译: 针对罕见语言现象，我们进行混合人类专家与大型语言模型（LLM）协同构建语料库，并通过此方法对LLM进行深入评估。](2024年03月11日/Hybrid_Human-LLM_Corpus_Construction_and_LLM_Evaluation_for_Rare_Linguistic_Phenomena.md)

- [Materials science in the era of large language models: a perspective](2024年03月11日/Materials_science_in_the_era_of_large_language_models_a_perspective.md)

    - [翻译: 在大型语言模型盛行的时代，本文提供了一种关于材料科学的独特视角。](2024年03月11日/Materials_science_in_the_era_of_large_language_models_a_perspective.md)

- [Split to Merge: Unifying Separated Modalities for Unsupervised Domain Adaptation](2024年03月11日/Split_to_Merge_Unifying_Separated_Modalities_for_Unsupervised_Domain_Adaptation.md)

    - [翻译: 通过“分裂至合并”策略，我们旨在将分离的模态融合以实现无监督领域适应的统一。这一方法旨在解决不同模态在无标签数据上进行领域适应时的问题，从而提升模型性能和泛化能力。](2024年03月11日/Split_to_Merge_Unifying_Separated_Modalities_for_Unsupervised_Domain_Adaptation.md)

- [Naming, Describing, and Quantifying Visual Objects in Humans and LLMs](2024年03月11日/Naming,_Describing,_and_Quantifying_Visual_Objects_in_Humans_and_LLMs.md)

    - [翻译: 本研究探讨人类和大型语言模型（LLMs）如何对视觉对象进行命名、细致描述以及量化处理。](2024年03月11日/Naming,_Describing,_and_Quantifying_Visual_Objects_in_Humans_and_LLMs.md)

- [ERA-CoT: Improving Chain-of-Thought through Entity Relationship Analysis](2024年03月11日/ERA-CoT_Improving_Chain-of-Thought_through_Entity_Relationship_Analysis.md)

    - [翻译: ERA-CoT 是一种创新方法，它借助实体关系分析技术来提升思维链（Chain-of-Thought）的表现。该方法旨在深入理解并优化大型语言模型在解决复杂问题时的内在逻辑推理过程。](2024年03月11日/ERA-CoT_Improving_Chain-of-Thought_through_Entity_Relationship_Analysis.md)

- [MEND: Meta dEmonstratioN Distillation for Efficient and Effective In-Context Learning](2024年03月11日/MEND_Meta_dEmonstratioN_Distillation_for_Efficient_and_Effective_In-Context_Learning.md)

    - [翻译: MEND 是一种“元演示蒸馏”方法，专注于提升上下文学习的效率和效果。](2024年03月11日/MEND_Meta_dEmonstratioN_Distillation_for_Efficient_and_Effective_In-Context_Learning.md)

- [Application of Quantum Tensor Networks for Protein Classification](2024年03月11日/Application_of_Quantum_Tensor_Networks_for_Protein_Classification.md)

    - [翻译: 本研究探讨了将量子张量网络应用于蛋白质分类任务的可能性，借助这一前沿技术揭示蛋白质内在结构与功能之间的深层次联系。](2024年03月11日/Application_of_Quantum_Tensor_Networks_for_Protein_Classification.md)

- [Exploring Large Language Models and Hierarchical Frameworks for Classification of Large Unstructured Legal Documents](2024年03月11日/Exploring_Large_Language_Models_and_Hierarchical_Frameworks_for_Classification_of_Large_Unstructured_Legal_Documents.md)

    - [翻译: 本研究致力于探究如何利用大型语言模型与层次化框架携手处理大规模非结构化法律文档的分类问题。](2024年03月11日/Exploring_Large_Language_Models_and_Hierarchical_Frameworks_for_Classification_of_Large_Unstructured_Legal_Documents.md)

- [Learning with Noisy Foundation Models](2024年03月11日/Learning_with_Noisy_Foundation_Models.md)

    - [翻译: 探究噪声底层模型下的学习机制](2024年03月11日/Learning_with_Noisy_Foundation_Models.md)

- [DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation](2024年03月11日/DriveDreamer-2_LLM-Enhanced_World_Models_for_Diverse_Driving_Video_Generation.md)

    - [翻译: DriveDreamer-2 是一款基于 LLM 强化的世界模型，专门用于创新且多样的驾驶视频生成任务。](2024年03月11日/DriveDreamer-2_LLM-Enhanced_World_Models_for_Diverse_Driving_Video_Generation.md)

- [ACFIX: Guiding LLMs with Mined Common RBAC Practices for Context-Aware Repair of Access Control Vulnerabilities in Smart Contracts](2024年03月11日/ACFIX_Guiding_LLMs_with_Mined_Common_RBAC_Practices_for_Context-Aware_Repair_of_Access_Control_Vulnerabilities_in_Smart_Contracts.md)

    - [翻译: ACFIX方案，旨在借助挖掘出的常见RBAC实践引导大型语言模型，针对智能合约中的上下文敏感访问控制漏洞进行精准修复。](2024年03月11日/ACFIX_Guiding_LLMs_with_Mined_Common_RBAC_Practices_for_Context-Aware_Repair_of_Access_Control_Vulnerabilities_in_Smart_Contracts.md)

- [Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?](2024年03月11日/Can_LLMs_Separate_Instructions_From_Data_And_What_Do_We_Even_Mean_By_That.md)

    - [翻译: LLMs 是否具备区分指令与数据的能力？而这个说法背后又蕴含着怎样的深意呢？](2024年03月11日/Can_LLMs_Separate_Instructions_From_Data_And_What_Do_We_Even_Mean_By_That.md)

- [The Power of Noise: Toward a Unified Multi-modal Knowledge Graph Representation Framework](2024年03月11日/The_Power_of_Noise_Toward_a_Unified_Multi-modal_Knowledge_Graph_Representation_Framework.md)

    - [翻译: 噪声之力：致力于构建一个融合多模态信息的知识图谱表示统一框架](2024年03月11日/The_Power_of_Noise_Toward_a_Unified_Multi-modal_Knowledge_Graph_Representation_Framework.md)

- [Boosting Image Restoration via Priors from Pre-trained Models](2024年03月11日/Boosting_Image_Restoration_via_Priors_from_Pre-trained_Models.md)

    - [翻译: 借助预训练模型中蕴含的先验信息，本研究旨在增强图像恢复技术的效果。](2024年03月11日/Boosting_Image_Restoration_via_Priors_from_Pre-trained_Models.md)

- [ConspEmoLLM: Conspiracy Theory Detection Using an Emotion-Based Large Language Model](2024年03月11日/ConspEmoLLM_Conspiracy_Theory_Detection_Using_an_Emotion-Based_Large_Language_Model.md)

    - [翻译: ConspEmoLLM是一种运用情感导向的大规模语言模型进行阴谋论检测的技术，它利用深度学习和自然语言处理技术来识别文本中的潜在阴谋论信息。](2024年03月11日/ConspEmoLLM_Conspiracy_Theory_Detection_Using_an_Emotion-Based_Large_Language_Model.md)

- [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](2024年03月11日/An_Image_is_Worth_12_Tokens_After_Layer_2_Plug-and-Play_Inference_Acceleration_for_Large_Vision-Language_Models.md)

    - [翻译: 经过第二层处理后，图像信息可有效压缩为半个标记量级，为此我们提出一种针对大型视觉-语言模型的便捷式推理加速方案。](2024年03月11日/An_Image_is_Worth_12_Tokens_After_Layer_2_Plug-and-Play_Inference_Acceleration_for_Large_Vision-Language_Models.md)

- [ALaRM: Align Language Models via Hierarchical Rewards Modeling](2024年03月11日/ALaRM_Align_Language_Models_via_Hierarchical_Rewards_Modeling.md)

    - [翻译: ALaRM 是一种创新方法，它利用层次化奖励建模技术来对齐和优化语言模型的性能。该策略旨在通过模拟不同层级的奖励机制，更好地指导和调整语言模型的行为表现。步骤 1 翻译：ALaRM: 通过层级奖励建模实现语言模型的对齐步骤 2 翻译：ALaRM 是一项研究提出的技术，通过构建层级化的奖励模型，致力于有效对齐和提升语言模型的表现力，其原理在于运用多层级的激励机制来精细化指导和校准语言模型在各类任务中的行为反应。](2024年03月11日/ALaRM_Align_Language_Models_via_Hierarchical_Rewards_Modeling.md)

- [Evaluating Large Language Models in Process Mining: Capabilities, Benchmarks, Evaluation Strategies, and Future Challenges](2024年03月11日/Evaluating_Large_Language_Models_in_Process_Mining_Capabilities,_Benchmarks,_Evaluation_Strategies,_and_Future_Challenges.md)

    - [翻译: 本研究探讨了大型语言模型在流程挖掘领域的表现，内容涵盖其功能特性、基准测试、评估策略以及未来所面临的挑战。](2024年03月11日/Evaluating_Large_Language_Models_in_Process_Mining_Capabilities,_Benchmarks,_Evaluation_Strategies,_and_Future_Challenges.md)

- [ACT-MNMT Auto-Constriction Turning for Multilingual Neural Machine Translation](2024年03月11日/ACT-MNMT_Auto-Constriction_Turning_for_Multilingual_Neural_Machine_Translation.md)

    - [翻译: ACT-MNMT 技术应用于多语言神经机器翻译，通过自动约束转换优化翻译效果。](2024年03月11日/ACT-MNMT_Auto-Constriction_Turning_for_Multilingual_Neural_Machine_Translation.md)

- [Real-Time Multimodal Cognitive Assistant for Emergency Medical Services](2024年03月11日/Real-Time_Multimodal_Cognitive_Assistant_for_Emergency_Medical_Services.md)

    - [翻译: 这款实时多模态认知助手专为急救医疗服务设计，可在紧急医疗场景下提供高效辅助。](2024年03月11日/Real-Time_Multimodal_Cognitive_Assistant_for_Emergency_Medical_Services.md)

- [Large Model driven Radiology Report Generation with Clinical Quality Reinforcement Learning](2024年03月11日/Large_Model_driven_Radiology_Report_Generation_with_Clinical_Quality_Reinforcement_Learning.md)

    - [翻译: 通过运用大型模型及临床质量强化学习驱动的策略，我们致力于实现高质量放射学报告自动生成。](2024年03月11日/Large_Model_driven_Radiology_Report_Generation_with_Clinical_Quality_Reinforcement_Learning.md)

- [Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning](2024年03月11日/Improving_Low-Resource_Knowledge_Tracing_Tasks_by_Supervised_Pre-training_and_Importance_Mechanism_Fine-tuning.md)

    - [翻译: 为解决低资源知识追踪难题，我们提出采用监督预训练结合重要性机制微调的方法以提升任务效果。这项研究旨在探索在有限数据环境下，利用预训练模型与针对性的权重调整策略优化知识追踪任务性能的可能性。](2024年03月11日/Improving_Low-Resource_Knowledge_Tracing_Tasks_by_Supervised_Pre-training_and_Importance_Mechanism_Fine-tuning.md)

- [HILL: A Hallucination Identifier for Large Language Models](2024年03月11日/HILL_A_Hallucination_Identifier_for_Large_Language_Models.md)

    - [翻译: HILL，一款专为大型语言模型设计的幻觉检测工具。](2024年03月11日/HILL_A_Hallucination_Identifier_for_Large_Language_Models.md)

- [Poisoning Programs by Un-Repairing Code: Security Concerns of AI-generated Code](2024年03月11日/Poisoning_Programs_by_Un-Repairing_Code_Security_Concerns_of_AI-generated_Code.md)

    - [翻译: 借助无法修复的代码“下毒”程序：探究 AI 生成代码所带来的安全隐忧](2024年03月11日/Poisoning_Programs_by_Un-Repairing_Code_Security_Concerns_of_AI-generated_Code.md)

- [Smart-Infinity: Fast Large Language Model Training using Near-Storage Processing on a Real System](2024年03月11日/Smart-Infinity_Fast_Large_Language_Model_Training_using_Near-Storage_Processing_on_a_Real_System.md)

    - [翻译: Smart-Infinity：通过在真实系统中应用近存储处理技术，实现大型语言模型的高效快速训练](2024年03月11日/Smart-Infinity_Fast_Large_Language_Model_Training_using_Near-Storage_Processing_on_a_Real_System.md)

- [FashionReGen: LLM-Empowered Fashion Report Generation](2024年03月11日/FashionReGen_LLM-Empowered_Fashion_Report_Generation.md)

    - [翻译: FashionReGen：借助LLM力量，革新时尚报告自动生成领域](2024年03月11日/FashionReGen_LLM-Empowered_Fashion_Report_Generation.md)

- [Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement](2024年03月11日/Zero-Shot_ECG_Classification_with_Multimodal_Learning_and_Test-time_Clinical_Knowledge_Enhancement.md)

    - [翻译: 运用多模态学习与测试阶段临床知识升级技术，我们实现了无需预先训练的心电图分类。这一研究聚焦于在零样本场景下，通过融合多种模态信息并实时提升临床相关知识，以实现对心电图的有效分类。](2024年03月11日/Zero-Shot_ECG_Classification_with_Multimodal_Learning_and_Test-time_Clinical_Knowledge_Enhancement.md)

- [Elephants Never Forget: Testing Language Models for Memorization of Tabular Data](2024年03月11日/Elephants_Never_Forget_Testing_Language_Models_for_Memorization_of_Tabular_Data.md)

    - [翻译: 标题生动翻译：“象群记忆无遗漏：检验语言模型对表格数据的存储能力”进一步优化：](2024年03月11日/Elephants_Never_Forget_Testing_Language_Models_for_Memorization_of_Tabular_Data.md)

- [KELLMRec: Knowledge-Enhanced Large Language Models for Recommendation](2024年03月11日/KELLMRec_Knowledge-Enhanced_Large_Language_Models_for_Recommendation.md)

    - [翻译: KELLMRec 是一种将知识增强技术融入大型语言模型以提升推荐系统性能的方法。](2024年03月11日/KELLMRec_Knowledge-Enhanced_Large_Language_Models_for_Recommendation.md)

- [MedKP: Medical Dialogue with Knowledge Enhancement and Clinical Pathway Encoding](2024年03月11日/MedKP_Medical_Dialogue_with_Knowledge_Enhancement_and_Clinical_Pathway_Encoding.md)

    - [翻译: MedKP 是一个通过知识增强和临床路径编码提升性能的医疗对话系统，它旨在借助这些技术改进医疗服务中的对话质量和决策支持。](2024年03月11日/MedKP_Medical_Dialogue_with_Knowledge_Enhancement_and_Clinical_Pathway_Encoding.md)

- [Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds](2024年03月11日/Guiding_Clinical_Reasoning_with_Large_Language_Models_via_Knowledge_Seeds.md)

    - [翻译: 借助“知识种子”，我们探索如何有效利用大型语言模型来指导临床推理过程。](2024年03月11日/Guiding_Clinical_Reasoning_with_Large_Language_Models_via_Knowledge_Seeds.md)

- [Decoding Complexity: Exploring Human-AI Concordance in Qualitative Coding](2024年03月11日/Decoding_Complexity_Exploring_Human-AI_Concordance_in_Qualitative_Coding.md)

    - [翻译: 探究定性编码领域中人类与AI的协同一致性，深入剖析解码复杂性问题。](2024年03月11日/Decoding_Complexity_Exploring_Human-AI_Concordance_in_Qualitative_Coding.md)

- [Authorship and the Politics and Ethics of LLM Watermarks](2024年03月11日/Authorship_and_the_Politics_and_Ethics_of_LLM_Watermarks.md)

    - [翻译: 探讨 LLM 水印背后的作者权问题及其在政治和伦理层面的影响](2024年03月11日/Authorship_and_the_Politics_and_Ethics_of_LLM_Watermarks.md)

- [Academically intelligent LLMs are not necessarily socially intelligent](2024年03月11日/Academically_intelligent_LLMs_are_not_necessarily_socially_intelligent.md)

    - [翻译: LLMs 即便在学术智能上表现出色，却未必具有社交智能。](2024年03月11日/Academically_intelligent_LLMs_are_not_necessarily_socially_intelligent.md)

- [ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models](2024年03月11日/ContextGPT_Infusing_LLMs_Knowledge_into_Neuro-Symbolic_Activity_Recognition_Models.md)

    - [翻译: ContextGPT：巧妙融合LLMs知识至神经符号活动识别模型中，提升模型性能与智能性](2024年03月11日/ContextGPT_Infusing_LLMs_Knowledge_into_Neuro-Symbolic_Activity_Recognition_Models.md)

- [AC-EVAL: Evaluating Ancient Chinese Language Understanding in Large Language Models](2024年03月11日/AC-EVAL_Evaluating_Ancient_Chinese_Language_Understanding_in_Large_Language_Models.md)

    - [翻译: AC-EVAL：针对大型语言模型，我们提出一种评估方法，用于衡量其对古代汉语的理解程度。](2024年03月11日/AC-EVAL_Evaluating_Ancient_Chinese_Language_Understanding_in_Large_Language_Models.md)

- [Unraveling the Mystery of Scaling Laws: Part I](2024年03月11日/Unraveling_the_Mystery_of_Scaling_Laws_Part_I.md)

    - [翻译: 揭秘规模定律的奥秘：第一篇章](2024年03月11日/Unraveling_the_Mystery_of_Scaling_Laws_Part_I.md)

- [ToolRerank: Adaptive and Hierarchy-Aware Reranking for Tool Retrieval](2024年03月11日/ToolRerank_Adaptive_and_Hierarchy-Aware_Reranking_for_Tool_Retrieval.md)

    - [翻译: ToolRerank：针对工具检索问题，提出了一种能够自适应调整并具备层次感知能力的重新排序方法，旨在提升检索效果。](2024年03月11日/ToolRerank_Adaptive_and_Hierarchy-Aware_Reranking_for_Tool_Retrieval.md)

- [Adding NVMe SSDs to Enable and Accelerate 100B Model Fine-tuning on a Single GPU](2024年03月11日/Adding_NVMe_SSDs_to_Enable_and_Accelerate_100B_Model_Fine-tuning_on_a_Single_GPU.md)

    - [翻译: 为了在单个GPU上有效且高效地进行百亿模型的微调，我们引入了NVMe SSD技术。这一举措旨在助力并大幅提升大型模型在单一GPU环境下的微调速度。](2024年03月11日/Adding_NVMe_SSDs_to_Enable_and_Accelerate_100B_Model_Fine-tuning_on_a_Single_GPU.md)

- [Automatic Generation of Python Programs Using Context-Free Grammars](2024年03月11日/Automatic_Generation_of_Python_Programs_Using_Context-Free_Grammars.md)

    - [翻译: 本研究探讨运用无上下文文法实现Python程序的自动化生成技术，旨在通过规则解析和程序结构自动生成，提高代码开发效率与灵活性。](2024年03月11日/Automatic_Generation_of_Python_Programs_Using_Context-Free_Grammars.md)

- [Toward Generalist Anomaly Detection via In-context Residual Learning with Few-shot Sample Prompts](2024年03月11日/Toward_Generalist_Anomaly_Detection_via_In-context_Residual_Learning_with_Few-shot_Sample_Prompts.md)

    - [翻译: 借助少量样例提示的上下文残差学习方法，我们正逐步迈向实现能应对各类异常检测任务的通才模型。](2024年03月11日/Toward_Generalist_Anomaly_Detection_via_In-context_Residual_Learning_with_Few-shot_Sample_Prompts.md)

- [Knowledge-aware Alert Aggregation in Large-scale Cloud Systems: a Hybrid Approach](2024年03月11日/Knowledge-aware_Alert_Aggregation_in_Large-scale_Cloud_Systems_a_Hybrid_Approach.md)

    - [翻译: 针对大规模云系统的警报管理，我们提出了一种融合了知识感知能力的混合警报聚合方法。这一创新方案旨在高效整合各类警报信息，在复杂的云环境中提升问题定位和决策效率。](2024年03月11日/Knowledge-aware_Alert_Aggregation_in_Large-scale_Cloud_Systems_a_Hybrid_Approach.md)

- [RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems](2024年03月11日/RecAI_Leveraging_Large_Language_Models_for_Next-Generation_Recommender_Systems.md)

    - [翻译: RecAI项目通过巧妙运用大型语言模型，为下一代推荐系统的开发注入活力。](2024年03月11日/RecAI_Leveraging_Large_Language_Models_for_Next-Generation_Recommender_Systems.md)

- [FontCLIP: A Semantic Typography Visual-Language Model for Multilingual Font Applications](2024年03月11日/FontCLIP_A_Semantic_Typography_Visual-Language_Model_for_Multilingual_Font_Applications.md)

    - [翻译: FontCLIP，一款创新的多语言字体应用场景下的语义排版视觉-语言模型，旨在通过深度学习技术探索和理解字体设计与自然语言间的语义关联。](2024年03月11日/FontCLIP_A_Semantic_Typography_Visual-Language_Model_for_Multilingual_Font_Applications.md)

- [Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models](2024年03月11日/Unsupervised_Real-Time_Hallucination_Detection_based_on_the_Internal_States_of_Large_Language_Models.md)

    - [翻译: 本研究提出了一种新颖的方法，利用大型语言模型（LLM）的内部状态进行无监督实时幻觉检测。这项技术无需人工标注，在运行过程中直接根据LLM的状态识别出可能的“幻觉”输出，特别适用于对自然语言处理系统的实时监控与优化。](2024年03月11日/Unsupervised_Real-Time_Hallucination_Detection_based_on_the_Internal_States_of_Large_Language_Models.md)

- [CoRAL: Collaborative Retrieval-Augmented Large Language Models Improve Long-tail Recommendation](2024年03月11日/CoRAL_Collaborative_Retrieval-Augmented_Large_Language_Models_Improve_Long-tail_Recommendation.md)

    - [翻译: CoRAL 是一种创新的方法，它通过协同检索增强大型语言模型，有效改善了对长尾项目的推荐效果，尤其针对那些稀有和冷启动情境。](2024年03月11日/CoRAL_Collaborative_Retrieval-Augmented_Large_Language_Models_Improve_Long-tail_Recommendation.md)

- [BoostER: Leveraging Large Language Models for Enhancing Entity Resolution](2024年03月11日/BoostER_Leveraging_Large_Language_Models_for_Enhancing_Entity_Resolution.md)

    - [翻译: BoostER 技术巧妙运用大型语言模型，以强化实体解析效能。](2024年03月11日/BoostER_Leveraging_Large_Language_Models_for_Enhancing_Entity_Resolution.md)

- [RLingua: Improving Reinforcement Learning Sample Efficiency in Robotic Manipulations With Large Language Models](2024年03月11日/RLingua_Improving_Reinforcement_Learning_Sample_Efficiency_in_Robotic_Manipulations_With_Large_Language_Models.md)

    - [翻译: RLingua 是一项研究，借助大型语言模型提升机器人操作领域强化学习的样本效率，从而改进了机器人的操控性能。](2024年03月11日/RLingua_Improving_Reinforcement_Learning_Sample_Efficiency_in_Robotic_Manipulations_With_Large_Language_Models.md)

- [A Framework for Cost-Effective and Self-Adaptive LLM Shaking and Recovery Mechanism](2024年03月11日/A_Framework_for_Cost-Effective_and_Self-Adaptive_LLM_Shaking_and_Recovery_Mechanism.md)

    - [翻译: 我们提出了一种兼顾成本效益和自我适应性的 LLM 振荡与恢复机制框架，旨在有效解决大型语言模型在运行过程中可能产生的不稳定性和性能波动问题，并实现模型自我修复与优化。](2024年03月11日/A_Framework_for_Cost-Effective_and_Self-Adaptive_LLM_Shaking_and_Recovery_Mechanism.md)

- [CKERC : Joint Large Language Models with Commonsense Knowledge for Emotion Recognition in Conversation](2024年03月11日/CKERC__Joint_Large_Language_Models_with_Commonsense_Knowledge_for_Emotion_Recognition_in_Conversation.md)

    - [翻译: CKERC项目通过将大型语言模型与常识知识库相结合，旨在提升对话情境中情绪识别的能力。](2024年03月11日/CKERC__Joint_Large_Language_Models_with_Commonsense_Knowledge_for_Emotion_Recognition_in_Conversation.md)

- [Calibrating Multi-modal Representations: A Pursuit of Group Robustness without Annotations](2024年03月11日/Calibrating_Multi-modal_Representations_A_Pursuit_of_Group_Robustness_without_Annotations.md)

    - [翻译: 为实现无需标注的群体鲁棒性，我们致力于校准多模态表示的研究。本研究探讨如何在缺乏人工注释的前提下提升多模态模型对不同群体数据的适应性和稳定性。](2024年03月11日/Calibrating_Multi-modal_Representations_A_Pursuit_of_Group_Robustness_without_Annotations.md)

- [LookupFFN: Making Transformers Compute-lite for CPU inference](2024年03月11日/LookupFFN_Making_Transformers_Compute-lite_for_CPU_inference.md)

    - [翻译: LookupFFN：为CPU推理打造更轻巧的Transformer计算结构](2024年03月11日/LookupFFN_Making_Transformers_Compute-lite_for_CPU_inference.md)

- [Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews](2024年03月11日/Monitoring_AI-Modified_Content_at_Scale_A_Case_Study_on_the_Impact_of_ChatGPT_on_AI_Conference_Peer_Reviews.md)

    - [翻译: 在大规模层面上探究 AI 内容修改，以ChatGPT对AI学术会议同行评审影响为切入点进行深入案例分析。](2024年03月11日/Monitoring_AI-Modified_Content_at_Scale_A_Case_Study_on_the_Impact_of_ChatGPT_on_AI_Conference_Peer_Reviews.md)

- [3M-Diffusion: Latent Multi-Modal Diffusion for Text-Guided Generation of Molecular Graphs](2024年03月11日/3M-Diffusion_Latent_Multi-Modal_Diffusion_for_Text-Guided_Generation_of_Molecular_Graphs.md)

    - [翻译: 3M-Diffusion 是一种创新方法，利用潜在多模态扩散技术，针对文本指导下的分子图生成任务。该模型能够巧妙地结合文本信息与分子结构特征，实现高效、精准的新型分子设计生成。](2024年03月11日/3M-Diffusion_Latent_Multi-Modal_Diffusion_for_Text-Guided_Generation_of_Molecular_Graphs.md)

- [Rebuilding ROME : Resolving Model Collapse during Sequential Model Editing](2024年03月11日/Rebuilding_ROME__Resolving_Model_Collapse_during_Sequential_Model_Editing.md)

    - [翻译: 本研究致力于“重建 ROME”，旨在解决在对模型进行连续编辑时出现的模型坍塌问题。](2024年03月11日/Rebuilding_ROME__Resolving_Model_Collapse_during_Sequential_Model_Editing.md)

- [Mapping High-level Semantic Regions in Indoor Environments without Object Recognition](2024年03月11日/Mapping_High-level_Semantic_Regions_in_Indoor_Environments_without_Object_Recognition.md)

    - [翻译: 本研究致力于在不依赖物体识别的前提下，精准描绘室内环境中的高层语义区域分布。](2024年03月11日/Mapping_High-level_Semantic_Regions_in_Indoor_Environments_without_Object_Recognition.md)

- [The Dawn of AI-Native EDA: Promises and Challenges of Large Circuit Models](2024年03月11日/The_Dawn_of_AI-Native_EDA_Promises_and_Challenges_of_Large_Circuit_Models.md)

    - [翻译: 随着AI原生EDA时代的来临，大型电路模型展现出了诱人前景和艰巨挑战。本研究探讨这一新兴领域中大型电路模型带来的承诺以及所面临的难题。](2024年03月11日/The_Dawn_of_AI-Native_EDA_Promises_and_Challenges_of_Large_Circuit_Models.md)

- [GuideGen: A Text-guided Framework for Joint CT Volume and Anatomical structure Generation](2024年03月11日/GuideGen_A_Text-guided_Framework_for_Joint_CT_Volume_and_Anatomical_structure_Generation.md)

    - [翻译: GuideGen，一款创新的文本导向框架，专为协同生成CT体积数据与解剖结构而设计。](2024年03月11日/GuideGen_A_Text-guided_Framework_for_Joint_CT_Volume_and_Anatomical_structure_Generation.md)

- [Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations](2024年03月12日/Transforming_Competition_into_Collaboration_The_Revolutionary_Role_of_Multi-Agent_Systems_and_Language_Models_in_Modern_Organizations.md)

    - [翻译: 在现代组织中，多智能体系统与语言模型正发挥着革命性的作用，它们能够巧妙地将竞争关系转变为协作模式。](2024年03月12日/Transforming_Competition_into_Collaboration_The_Revolutionary_Role_of_Multi-Agent_Systems_and_Language_Models_in_Modern_Organizations.md)

- [Synth$^2$: Boosting Visual-Language Models with Synthetic Captions and Image Embeddings](2024年03月12日/Synth$^2$_Boosting_Visual-Language_Models_with_Synthetic_Captions_and_Image_Embeddings.md)

    - [翻译: Synth$^2$：借助于合成的图片说明和图像嵌入技术，有力地增强了视觉-语言模型的功能与性能。](2024年03月12日/Synth$^2$_Boosting_Visual-Language_Models_with_Synthetic_Captions_and_Image_Embeddings.md)

- [FineMath: A Fine-Grained Mathematical Evaluation Benchmark for Chinese Large Language Models](2024年03月12日/FineMath_A_Fine-Grained_Mathematical_Evaluation_Benchmark_for_Chinese_Large_Language_Models.md)

    - [翻译: FineMath 是专为评测中文大型语言模型而设计的精细数学评估基准，旨在从更细致的角度衡量和检验模型在数学相关任务上的表现。](2024年03月12日/FineMath_A_Fine-Grained_Mathematical_Evaluation_Benchmark_for_Chinese_Large_Language_Models.md)

- [Multi-modal Auto-regressive Modeling via Visual Words](2024年03月12日/Multi-modal_Auto-regressive_Modeling_via_Visual_Words.md)

    - [翻译: 借助“视觉词汇”，我们探索多模态自回归模型的构建，旨在整合图像与文本信息，实现跨模态的联合建模与预测。](2024年03月12日/Multi-modal_Auto-regressive_Modeling_via_Visual_Words.md)

- [WorkArena: How Capable Are Web Agents at Solving Common Knowledge Work Tasks?](2024年03月12日/WorkArena_How_Capable_Are_Web_Agents_at_Solving_Common_Knowledge_Work_Tasks.md)

    - [翻译: WorkArena 探究：Web 代理在处理日常知识工作任务时，其能力表现究竟如何？](2024年03月12日/WorkArena_How_Capable_Are_Web_Agents_at_Solving_Common_Knowledge_Work_Tasks.md)

- [StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models](2024年03月12日/StableToolBench_Towards_Stable_Large-Scale_Benchmarking_on_Tool_Learning_of_Large_Language_Models.md)

    - [翻译: StableToolBench项目旨在为大型语言模型的工具学习提供一个稳定且具备大规模基准测试能力的平台。](2024年03月12日/StableToolBench_Towards_Stable_Large-Scale_Benchmarking_on_Tool_Learning_of_Large_Language_Models.md)

- [Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards](2024年03月12日/Improving_Reinforcement_Learning_from_Human_Feedback_Using_Contrastive_Rewards.md)

    - [翻译: 利用对比性奖励优化基于人类反馈的强化学习方法，以提升其效果。](2024年03月12日/Improving_Reinforcement_Learning_from_Human_Feedback_Using_Contrastive_Rewards.md)

- [Large, Small or Both: A Novel Data Augmentation Framework Based on Language Models for Debiasing Opinion Summarization](2024年03月12日/Large,_Small_or_Both_A_Novel_Data_Augmentation_Framework_Based_on_Language_Models_for_Debiasing_Opinion_Summarization.md)

    - [翻译: 创新提出了一种新的数据增强框架，它结合了大、小规模语言模型的力量，旨在有效消除意见摘要中的偏见问题。](2024年03月12日/Large,_Small_or_Both_A_Novel_Data_Augmentation_Framework_Based_on_Language_Models_for_Debiasing_Opinion_Summarization.md)

- [Annotations on a Budget: Leveraging Geo-Data Similarity to Balance Model Performance and Annotation Cost](2024年03月12日/Annotations_on_a_Budget_Leveraging_Geo-Data_Similarity_to_Balance_Model_Performance_and_Annotation_Cost.md)

    - [翻译: 面对预算限制，我们提出一种创新的注释策略，巧妙运用地理数据相似性原理，在保证模型性能的同时有效控制标注成本。](2024年03月12日/Annotations_on_a_Budget_Leveraging_Geo-Data_Similarity_to_Balance_Model_Performance_and_Annotation_Cost.md)

- [Enabling self-identification in intelligent agent: insights from computational psychoanalysis](2024年03月12日/Enabling_self-identification_in_intelligent_agent_insights_from_computational_psychoanalysis.md)

    - [翻译: 探究智能体自我识别能力，通过汲取计算精神分析学领域的洞见，本研究旨在揭示如何在智能代理中实现这一特性。](2024年03月12日/Enabling_self-identification_in_intelligent_agent_insights_from_computational_psychoanalysis.md)

- [Characterization of Large Language Model Development in the Datacenter](2024年03月12日/Characterization_of_Large_Language_Model_Development_in_the_Datacenter.md)

    - [翻译: 探究数据中心中大型语言模型开发过程的特点与特征分析](2024年03月12日/Characterization_of_Large_Language_Model_Development_in_the_Datacenter.md)

- [Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Matching Framework](2024年03月12日/Decomposing_Disease_Descriptions_for_Enhanced_Pathology_Detection_A_Multi-Aspect_Vision-Language_Matching_Framework.md)

    - [翻译: 为了提升病理检测的准确性，我们提出了一种分解疾病描述的方法，并构建了一个结合多方面视觉信息与语言描述匹配的框架。该框架旨在通过深度理解和匹配病灶特征与医学文本描述的不同方面，从而强化病理检测效能。](2024年03月12日/Decomposing_Disease_Descriptions_for_Enhanced_Pathology_Detection_A_Multi-Aspect_Vision-Language_Matching_Framework.md)

- [generAItor: Tree-in-the-Loop Text Generation for Language Model Explainability and Adaptation](2024年03月12日/generAItor_Tree-in-the-Loop_Text_Generation_for_Language_Model_Explainability_and_Adaptation.md)

    - [翻译: Generator：一种“循环中树”文本生成技术，旨在提升语言模型的可解释性及适应能力](2024年03月12日/generAItor_Tree-in-the-Loop_Text_Generation_for_Language_Model_Explainability_and_Adaptation.md)

- [Couler: Unified Machine Learning Workflow Optimization in Cloud](2024年03月12日/Couler_Unified_Machine_Learning_Workflow_Optimization_in_Cloud.md)

    - [翻译: Couler——致力于在云端实现机器学习工作流程的一体化优化，提升效率与性能。](2024年03月12日/Couler_Unified_Machine_Learning_Workflow_Optimization_in_Cloud.md)

- [LLMvsSmall Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model](2024年03月12日/LLMvsSmall_Model_Large_Language_Model_Based_Text_Augmentation_Enhanced_Personality_Detection_Model.md)

    - [翻译: 在个性化检测模型领域，采用大型语言模型（LLM）进行文本增强显著提升了性能。本文探讨了以LLM为核心的文本增强技术如何相较于小型模型，在这一任务上展现更优效果。](2024年03月12日/LLMvsSmall_Model_Large_Language_Model_Based_Text_Augmentation_Enhanced_Personality_Detection_Model.md)

- [Triples-to-isiXhosa (T2X): Addressing the Challenges of Low-Resource Agglutinative Data-to-Text Generation](2024年03月12日/Triples-to-isiXhosa_(T2X)_Addressing_the_Challenges_of_Low-Resource_Agglutinative_Data-to-Text_Generation.md)

    - [翻译: T2X项目专注于解决低资源环境下将三元组数据转化为isiXhosa文本这一难题，特别是在处理粘着语特性时所面临的挑战。](2024年03月12日/Triples-to-isiXhosa_(T2X)_Addressing_the_Challenges_of_Low-Resource_Agglutinative_Data-to-Text_Generation.md)

- [SIFiD: Reassess Summary Factual Inconsistency Detection with LLM](2024年03月12日/SIFiD_Reassess_Summary_Factual_Inconsistency_Detection_with_LLM.md)

    - [翻译: SIFiD：借助LLM技术，我们对摘要中事实不一致性检测进行重新审视和评估。](2024年03月12日/SIFiD_Reassess_Summary_Factual_Inconsistency_Detection_with_LLM.md)

- [Truth-Aware Context Selection: Mitigating the Hallucinations of Large Language Models Being Misled by Untruthful Contexts](2024年03月12日/Truth-Aware_Context_Selection_Mitigating_the_Hallucinations_of_Large_Language_Models_Being_Misled_by_Untruthful_Contexts.md)

    - [翻译: 为了解决大型语言模型在虚假上下文中易产生误导性内容的问题，我们提出“真实意识上下文选择”策略，旨在有效抑制其受不实背景影响而生成的幻觉式输出。](2024年03月12日/Truth-Aware_Context_Selection_Mitigating_the_Hallucinations_of_Large_Language_Models_Being_Misled_by_Untruthful_Contexts.md)

- [The future of document indexing: GPT and Donut revolutionize table of content processing](2024年03月12日/The_future_of_document_indexing_GPT_and_Donut_revolutionize_table_of_content_processing.md)

    - [翻译: GPT 和 Donut 引领未来，革新了文档索引领域，以崭新的方式重塑目录处理技术。](2024年03月12日/The_future_of_document_indexing_GPT_and_Donut_revolutionize_table_of_content_processing.md)

- [MAMMOTH: Massively Multilingual Modular Open Translation @ Helsinki](2024年03月12日/MAMMOTH_Massively_Multilingual_Modular_Open_Translation_@_Helsinki.md)

    - [翻译: MAMMOTH 是赫尔辛基研发的一款大规模、多语言且模块化的开源翻译工具，致力于推动翻译技术的创新与发展。](2024年03月12日/MAMMOTH_Massively_Multilingual_Modular_Open_Translation_@_Helsinki.md)

- [Process Modeling With Large Language Models](2024年03月12日/Process_Modeling_With_Large_Language_Models.md)

    - [翻译: 探索大型语言模型在过程建模中的应用](2024年03月12日/Process_Modeling_With_Large_Language_Models.md)

- [MoAI: Mixture of All Intelligence for Large Language and Vision Models](2024年03月12日/MoAI_Mixture_of_All_Intelligence_for_Large_Language_and_Vision_Models.md)

    - [翻译: MoAI——集多种智能于一体的解决方案，专为大型语言和视觉模型设计，融合了多元化的智能技术。](2024年03月12日/MoAI_Mixture_of_All_Intelligence_for_Large_Language_and_Vision_Models.md)

- [Robustness, Security, Privacy, Explainability, Efficiency, and Usability of Large Language Models for Code](2024年03月12日/Robustness,_Security,_Privacy,_Explainability,_Efficiency,_and_Usability_of_Large_Language_Models_for_Code.md)

    - [翻译: 针对大型语言模型应用于代码场景时，其稳健性、安全防护、隐私保护、可解释性、效能及易用性等方面的探讨与研究](2024年03月12日/Robustness,_Security,_Privacy,_Explainability,_Efficiency,_and_Usability_of_Large_Language_Models_for_Code.md)

- [Towards Graph Foundation Models for Personalization](2024年03月12日/Towards_Graph_Foundation_Models_for_Personalization.md)

    - [翻译: 本研究致力于探索用于个性化的图基础模型，旨在构建能够适应个性化需求的图神经网络模型，以挖掘和利用大规模图数据中的深层次关系与模式。](2024年03月12日/Towards_Graph_Foundation_Models_for_Personalization.md)

- [DrPlanner: Diagnosis and Repair of Motion Planners Using Large Language Models](2024年03月12日/DrPlanner_Diagnosis_and_Repair_of_Motion_Planners_Using_Large_Language_Models.md)

    - [翻译: DrPlanner 是一款利用大型语言模型，针对运动规划器进行高效诊断并实施修复的工具。](2024年03月12日/DrPlanner_Diagnosis_and_Repair_of_Motion_Planners_Using_Large_Language_Models.md)

- [Matrix-Transformation Based Low-Rank Adaptation (MTLoRA): A Brain-Inspired Method for Parameter-Efficient Fine-Tuning](2024年03月12日/Matrix-Transformation_Based_Low-Rank_Adaptation_(MTLoRA)_A_Brain-Inspired_Method_for_Parameter-Efficient_Fine-Tuning.md)

    - [翻译: MTLoRA，一种借鉴脑科学原理的创新方法，采用矩阵变换实现低秩适应，在保持参数高效的同时完成精准微调任务。](2024年03月12日/Matrix-Transformation_Based_Low-Rank_Adaptation_(MTLoRA)_A_Brain-Inspired_Method_for_Parameter-Efficient_Fine-Tuning.md)

- [In-context learning enables multimodal large language models to classify cancer pathology images](2024年03月12日/In-context_learning_enables_multimodal_large_language_models_to_classify_cancer_pathology_images.md)

    - [翻译: ICL 技术赋能多模态 LLM，使其能够对癌症病理图片进行精准分类](2024年03月12日/In-context_learning_enables_multimodal_large_language_models_to_classify_cancer_pathology_images.md)

- [Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs](2024年03月12日/Complex_Reasoning_over_Logical_Queries_on_Commonsense_Knowledge_Graphs.md)

    - [翻译: 在本研究中，我们专注于在常识知识图谱上对逻辑查询进行深入复杂的推理探索。](2024年03月12日/Complex_Reasoning_over_Logical_Queries_on_Commonsense_Knowledge_Graphs.md)

- [SmallToLarge (S2L): Scalable Data Selection for Fine-tuning Large Language Models by Summarizing Training Trajectories of Small Models](2024年03月12日/SmallToLarge_(S2L)_Scalable_Data_Selection_for_Fine-tuning_Large_Language_Models_by_Summarizing_Training_Trajectories_of_Small_Models.md)

    - [翻译: S2L 方法通过提炼小型模型训练历程，为大型语言模型的精细化微调提供可扩展的数据筛选方案。](2024年03月12日/SmallToLarge_(S2L)_Scalable_Data_Selection_for_Fine-tuning_Large_Language_Models_by_Summarizing_Training_Trajectories_of_Small_Models.md)

- [Hallmarks of Optimization Trajectories in Neural Networks and LLMs: The Lengths, Bends, and Dead Ends](2024年03月12日/Hallmarks_of_Optimization_Trajectories_in_Neural_Networks_and_LLMs_The_Lengths,_Bends,_and_Dead_Ends.md)

    - [翻译: 在神经网络及大型语言模型内部，优化路径具有显著特征，表现为路径长度、曲率变化以及无解的死胡同。本研究聚焦于揭示这些路径特性在深度学习训练过程中的规律及其对LLMs的影响。](2024年03月12日/Hallmarks_of_Optimization_Trajectories_in_Neural_Networks_and_LLMs_The_Lengths,_Bends,_and_Dead_Ends.md)

- [SVD-LLM: Truncation-aware Singular Value Decomposition for Large Language Model Compression](2024年03月12日/SVD-LLM_Truncation-aware_Singular_Value_Decomposition_for_Large_Language_Model_Compression.md)

    - [翻译: SVD-LLM 是一种考虑截断影响的奇异值分解方法，专门用于大型语言模型的高效压缩。](2024年03月12日/SVD-LLM_Truncation-aware_Singular_Value_Decomposition_for_Large_Language_Model_Compression.md)

- [NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning](2024年03月12日/NavCoT_Boosting_LLM-Based_Vision-and-Language_Navigation_via_Learning_Disentangled_Reasoning.md)

    - [翻译: NavCoT 项目致力于增强大型语言模型（LLM）在视觉与语言导航任务中的表现，其策略是通过学习分离式的推理机制实现这一目标。](2024年03月12日/NavCoT_Boosting_LLM-Based_Vision-and-Language_Navigation_via_Learning_Disentangled_Reasoning.md)

- [Textual Knowledge Matters: Cross-Modality Co-Teaching for Generalized Visual Class Discovery](2024年03月12日/Textual_Knowledge_Matters_Cross-Modality_Co-Teaching_for_Generalized_Visual_Class_Discovery.md)

    - [翻译: 文本信息在其中起着关键作用，我们提出了一种名为“跨模态协同教学”的方法，旨在助力广泛而有效的视觉类别发现。这种方法充分利用了文本与视觉信息之间的相互作用，以实现对各类视觉概念的泛化发现能力。](2024年03月12日/Textual_Knowledge_Matters_Cross-Modality_Co-Teaching_for_Generalized_Visual_Class_Discovery.md)

- [Premonition: Using Generative Models to Preempt Future Data Changes in Continual Learning](2024年03月12日/Premonition_Using_Generative_Models_to_Preempt_Future_Data_Changes_in_Continual_Learning.md)

    - [翻译: 预见未来：本文探讨如何在连续学习场景下运用生成模型预判未来数据变化，以应对持续学习中的挑战。](2024年03月12日/Premonition_Using_Generative_Models_to_Preempt_Future_Data_Changes_in_Continual_Learning.md)

- [KEBench: A Benchmark on Knowledge Editing for Large Vision-Language Models](2024年03月12日/KEBench_A_Benchmark_on_Knowledge_Editing_for_Large_Vision-Language_Models.md)

    - [翻译: KEBench——专为评估大型视觉-语言模型在知识编辑任务上的表现而设立的权威基准](2024年03月12日/KEBench_A_Benchmark_on_Knowledge_Editing_for_Large_Vision-Language_Models.md)

- [Rethinking ASTE: A Minimalist Tagging Scheme Alongside Contrastive Learning](2024年03月12日/Rethinking_ASTE_A_Minimalist_Tagging_Scheme_Alongside_Contrastive_Learning.md)

    - [翻译: 我们对 ASTE 进行重新审视，提出了一种与对比学习并行运作的简约标签方案。](2024年03月12日/Rethinking_ASTE_A_Minimalist_Tagging_Scheme_Alongside_Contrastive_Learning.md)

- [Multi-task Manipulation Policy Modeling with Visuomotor Latent Diffusion](2024年03月12日/Multi-task_Manipulation_Policy_Modeling_with_Visuomotor_Latent_Diffusion.md)

    - [翻译: 运用视觉运动潜在扩散技术进行多任务操控策略模型构建，旨在探索在不同任务中灵活高效地实现操作策略的方法。](2024年03月12日/Multi-task_Manipulation_Policy_Modeling_with_Visuomotor_Latent_Diffusion.md)

- [Knowledge Graph Large Language Model (KG-LLM) for Link Prediction](2024年03月12日/Knowledge_Graph_Large_Language_Model_(KG-LLM)_for_Link_Prediction.md)

    - [翻译: 面向链接预测的KG-LLM，即知识图谱与大型语言模型结合的新颖框架，专注于通过大型语言模型对知识图谱中的实体间关系进行精准预测。](2024年03月12日/Knowledge_Graph_Large_Language_Model_(KG-LLM)_for_Link_Prediction.md)

- [Lumen: Unleashing Versatile Vision-Centric Capabilities of Large Multimodal Models](2024年03月12日/Lumen_Unleashing_Versatile_Vision-Centric_Capabilities_of_Large_Multimodal_Models.md)

    - [翻译: Lumen：致力于解锁大型多模态模型中蕴含的强大且多样的视觉核心功能](2024年03月12日/Lumen_Unleashing_Versatile_Vision-Centric_Capabilities_of_Large_Multimodal_Models.md)

- [Taming Pre-trained LLMs for Generalised Time Series Forecasting via Cross-modal Knowledge Distillation](2024年03月12日/Taming_Pre-trained_LLMs_for_Generalised_Time_Series_Forecasting_via_Cross-modal_Knowledge_Distillation.md)

    - [翻译: 运用跨模态知识蒸馏技术，让预训练的大型语言模型（LLM）更好地服务于通用时间序列预测任务，实现对此类预测的有效驾驭和提升。](2024年03月12日/Taming_Pre-trained_LLMs_for_Generalised_Time_Series_Forecasting_via_Cross-modal_Knowledge_Distillation.md)

- [Beyond Text: Frozen Large Language Models in Visual Signal Comprehension](2024年03月12日/Beyond_Text_Frozen_Large_Language_Models_in_Visual_Signal_Comprehension.md)

    - [翻译: 进一步探索，我们发现大型语言模型（LLM）在解析视觉信号方面也展现出潜力。本文探讨了“Frozen Large Language Models”在非文本领域——视觉信号理解上的应用，揭示其在图像、视频等多模态信息处理中的新可能。](2024年03月12日/Beyond_Text_Frozen_Large_Language_Models_in_Visual_Signal_Comprehension.md)

- [Rethinking Generative Large Language Model Evaluation for Semantic Comprehension](2024年03月12日/Rethinking_Generative_Large_Language_Model_Evaluation_for_Semantic_Comprehension.md)

    - [翻译: 为深入探究语义理解能力，本研究对大型语言模型生成评估方法进行重新审视与思考。](2024年03月12日/Rethinking_Generative_Large_Language_Model_Evaluation_for_Semantic_Comprehension.md)

- [Exploring Safety Generalization Challenges of Large Language Models via Code](2024年03月12日/Exploring_Safety_Generalization_Challenges_of_Large_Language_Models_via_Code.md)

    - [翻译: 我们通过编码实践深入探究大型语言模型在安全性泛化方面所面临的挑战。](2024年03月12日/Exploring_Safety_Generalization_Challenges_of_Large_Language_Models_via_Code.md)

- [MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric](2024年03月12日/MoPE-CLIP_Structured_Pruning_for_Efficient_Vision-Language_Models_with_Module-wise_Pruning_Error_Metric.md)

    - [翻译: MoPE-CLIP 是一种创新方法，它通过模块化剪枝误差度量实现了对高效视觉-语言模型的结构化剪枝优化。这一技术针对视觉-语言模型进行精细化处理，采用模块化剪枝策略并引入特定的误差评估指标，旨在提升模型性能的同时减少计算资源消耗。](2024年03月12日/MoPE-CLIP_Structured_Pruning_for_Efficient_Vision-Language_Models_with_Module-wise_Pruning_Error_Metric.md)

- [DeliGrasp: Inferring Object Mass, Friction, and Compliance with LLMs for Adaptive and Minimally Deforming Grasp Policies](2024年03月12日/DeliGrasp_Inferring_Object_Mass,_Friction,_and_Compliance_with_LLMs_for_Adaptive_and_Minimally_Deforming_Grasp_Policies.md)

    - [翻译: DeliGrasp 是一项技术，通过大型语言模型（LLMs）推算物体的质量、摩擦系数及顺应性，从而制定出能适应不同物体且抓取时变形极小的智能抓取策略。](2024年03月12日/DeliGrasp_Inferring_Object_Mass,_Friction,_and_Compliance_with_LLMs_for_Adaptive_and_Minimally_Deforming_Grasp_Policies.md)

- [The Missing Piece in Model Editing: A Deep Dive into the Hidden Damage Brought By Model Editing](2024年03月12日/The_Missing_Piece_in_Model_Editing_A_Deep_Dive_into_the_Hidden_Damage_Brought_By_Model_Editing.md)

    - [翻译: 在模型编辑领域，尚有一片待深挖的盲区——即由编辑操作所带来的隐藏损害。本研究将对此进行深度剖析，揭示模型编辑过程中可能产生的无形伤害。](2024年03月12日/The_Missing_Piece_in_Model_Editing_A_Deep_Dive_into_the_Hidden_Damage_Brought_By_Model_Editing.md)

- [Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM](2024年03月12日/Branch-Train-MiX_Mixing_Expert_LLMs_into_a_Mixture-of-Experts_LLM.md)

    - [翻译: Branch-Train-MiX 技术，旨在将多个专家级大型语言模型融合为一个混合型专家 LLM，通过该方法，各专家模型的优势得以有机结合，共同提升整体性能。](2024年03月12日/Branch-Train-MiX_Mixing_Expert_LLMs_into_a_Mixture-of-Experts_LLM.md)

- [Chronos: Learning the Language of Time Series](2024年03月12日/Chronos_Learning_the_Language_of_Time_Series.md)

    - [翻译: Chronos项目致力于探索和掌握时间序列背后的“语言”，揭示其内在规律与模式。](2024年03月12日/Chronos_Learning_the_Language_of_Time_Series.md)

- [Fine-tuning Large Language Models with Sequential Instructions](2024年03月12日/Fine-tuning_Large_Language_Models_with_Sequential_Instructions.md)

    - [翻译: 针对大型语言模型，我们采用连续指令进行微调，旨在探究这种微调方式如何提升模型性能和适应性。](2024年03月12日/Fine-tuning_Large_Language_Models_with_Sequential_Instructions.md)

- [Data Interpreter: An LLM Agent For Data Science](2024年03月12日/Data_Interpreter_An_LLM_Agent_For_Data_Science.md)

    - [翻译: 数据解释员：一款专为数据科学打造的 LLM 智能助手](2024年03月12日/Data_Interpreter_An_LLM_Agent_For_Data_Science.md)

- [Can Large Language Models Identify Authorship?](2024年03月12日/Can_Large_Language_Models_Identify_Authorship.md)

    - [翻译: 大型语言模型是否具备鉴别文本作者的能力？](2024年03月12日/Can_Large_Language_Models_Identify_Authorship.md)

- [Large Language Models are Contrastive Reasoners](2024年03月12日/Large_Language_Models_are_Contrastive_Reasoners.md)

    - [翻译: 大型语言模型展现出了显著的对比推理能力](2024年03月12日/Large_Language_Models_are_Contrastive_Reasoners.md)

- [MoleculeQA: A Dataset to Evaluate Factual Accuracy in Molecular Comprehension](2024年03月12日/MoleculeQA_A_Dataset_to_Evaluate_Factual_Accuracy_in_Molecular_Comprehension.md)

    - [翻译: MoleculeQA 是专为检验分子理解领域中事实准确性而设计的数据集，旨在助力科研人员评测模型在解析分子信息时的精准度。](2024年03月12日/MoleculeQA_A_Dataset_to_Evaluate_Factual_Accuracy_in_Molecular_Comprehension.md)

- [Embedded Translations for Low-resource Automated Glossing](2024年03月12日/Embedded_Translations_for_Low-resource_Automated_Glossing.md)

    - [翻译: 为解决低资源环境下自动术语注解问题，我们提出嵌入式翻译方法。该方法旨在利用嵌入技术，高效实现对稀有语言或词汇的精准翻译和注解。](2024年03月12日/Embedded_Translations_for_Low-resource_Automated_Glossing.md)

- [VANP: Learning Where to See for Navigation with Self-Supervised Vision-Action Pre-Training](2024年03月12日/VANP_Learning_Where_to_See_for_Navigation_with_Self-Supervised_Vision-Action_Pre-Training.md)

    - [翻译: VANP 方法利用自我监督的视觉-动作预训练技术，教导模型在进行导航时学会自主发现关键观察点，从而提升导航能力。](2024年03月12日/VANP_Learning_Where_to_See_for_Navigation_with_Self-Supervised_Vision-Action_Pre-Training.md)

- [Generating Clarification Questions for Disambiguating Contracts](2024年03月12日/Generating_Clarification_Questions_for_Disambiguating_Contracts.md)

    - [翻译: 为解决合同中的歧义，我们致力于生成有针对性的澄清问题。](2024年03月12日/Generating_Clarification_Questions_for_Disambiguating_Contracts.md)

- [Training Small Multimodal Models to Bridge Biomedical Competency Gap: A Case Study in Radiology Imaging](2024年03月12日/Training_Small_Multimodal_Models_to_Bridge_Biomedical_Competency_Gap_A_Case_Study_in_Radiology_Imaging.md)

    - [翻译: 为缩小生物医学领域的能力差距，我们进行了一项针对放射影像学的案例研究，通过训练小巧而强大的多模态模型来实现这一目标。](2024年03月12日/Training_Small_Multimodal_Models_to_Bridge_Biomedical_Competency_Gap_A_Case_Study_in_Radiology_Imaging.md)

- [Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems](2024年03月12日/Investigating_the_performance_of_Retrieval-Augmented_Generation_and_fine-tuning_for_the_development_of_AI-driven_knowledge-based_systems.md)

    - [翻译: 本研究探讨了检索增强生成与微调技术在构建AI驱动的知识系统中的性能表现，旨在深入理解并提升相关系统的效能。](2024年03月12日/Investigating_the_performance_of_Retrieval-Augmented_Generation_and_fine-tuning_for_the_development_of_AI-driven_knowledge-based_systems.md)

- [Simple and Scalable Strategies to Continually Pre-train Large Language Models](2024年03月13日/Simple_and_Scalable_Strategies_to_Continually_Pre-train_Large_Language_Models.md)

    - [翻译: 本研究提出了一种简洁且易于扩展的方法，用于持续预训练大型语言模型，旨在提升模型在不断变化的数据环境中的适应性和性能。](2024年03月13日/Simple_and_Scalable_Strategies_to_Continually_Pre-train_Large_Language_Models.md)

- [DAM: Dynamic Adapter Merging for Continual Video QA Learning](2024年03月13日/DAM_Dynamic_Adapter_Merging_for_Continual_Video_QA_Learning.md)

    - [翻译: DAM 技术，即动态适配器融合，旨在解决连续视频问答学习场景下的问题，通过整合并适时调整适配器模块以适应不断变化的学习需求。](2024年03月13日/DAM_Dynamic_Adapter_Merging_for_Continual_Video_QA_Learning.md)

- [Steering LLMs Towards Unbiased Responses: A Causality-Guided Debiasing Framework](2024年03月13日/Steering_LLMs_Towards_Unbiased_Responses_A_Causality-Guided_Debiasing_Framework.md)

    - [翻译: 为了引导 LLM 输出公正无偏的答案，我们提出了一种基于因果关系指导的去偏见框架。](2024年03月13日/Steering_LLMs_Towards_Unbiased_Responses_A_Causality-Guided_Debiasing_Framework.md)

- [The Garden of Forking Paths: Observing Dynamic Parameters Distribution in Large Language Models](2024年03月13日/The_Garden_of_Forking_Paths_Observing_Dynamic_Parameters_Distribution_in_Large_Language_Models.md)

    - [翻译: 在“分叉路径的花园”中，我们深入探究大型语言模型内部的动态参数分布，揭示其内在变化规律与特性。](2024年03月13日/The_Garden_of_Forking_Paths_Observing_Dynamic_Parameters_Distribution_in_Large_Language_Models.md)

- [Strengthening Multimodal Large Language Model with Bootstrapped Preference Optimization](2024年03月13日/Strengthening_Multimodal_Large_Language_Model_with_Bootstrapped_Preference_Optimization.md)

    - [翻译: 运用引导式偏好优化策略，提升多模态大型语言模型的表现力和效能。](2024年03月13日/Strengthening_Multimodal_Large_Language_Model_with_Bootstrapped_Preference_Optimization.md)

- [SOTOPIA-$π$: Interactive Learning of Socially Intelligent Language Agents](2024年03月13日/SOTOPIA-$π$_Interactive_Learning_of_Socially_Intelligent_Language_Agents.md)

    - [翻译: SOTOPIA-$π$项目致力于研究如何通过交互式学习培养具备社交智能的语言代理。](2024年03月13日/SOTOPIA-$π$_Interactive_Learning_of_Socially_Intelligent_Language_Agents.md)

- [Review of Generative AI Methods in Cybersecurity](2024年03月13日/Review_of_Generative_AI_Methods_in_Cybersecurity.md)

    - [翻译: 本文将对应用于网络安全领域的生成式人工智能方法进行全面探讨和评析。](2024年03月13日/Review_of_Generative_AI_Methods_in_Cybersecurity.md)

- [TeaMs-RL: Teaching LLMs to Teach Themselves Better Instructions via Reinforcement Learning](2024年03月13日/TeaMs-RL_Teaching_LLMs_to_Teach_Themselves_Better_Instructions_via_Reinforcement_Learning.md)

    - [翻译: TeaMs-RL项目利用强化学习，让大型语言模型（LLMs）学会自我优化和改进指令。这项研究旨在通过RL机制使LLMs能够更有效地进行自我教学，不断提升其理解与生成高质量指令的能力。](2024年03月13日/TeaMs-RL_Teaching_LLMs_to_Teach_Themselves_Better_Instructions_via_Reinforcement_Learning.md)

- [Do Language Models Care About Text Quality? Evaluating Web-Crawled Corpora Across 11 Languages](2024年03月13日/Do_Language_Models_Care_About_Text_Quality_Evaluating_Web-Crawled_Corpora_Across_11_Languages.md)

    - [翻译: 语言模型对文本质量有多在意？我们针对 11 种语言的网络抓取语料库进行评估，以探究其对文本质量的关注程度。](2024年03月13日/Do_Language_Models_Care_About_Text_Quality_Evaluating_Web-Crawled_Corpora_Across_11_Languages.md)

- [Zero-shot and Few-shot Generation Strategies for Artificial Clinical Records](2024年03月13日/Zero-shot_and_Few-shot_Generation_Strategies_for_Artificial_Clinical_Records.md)

    - [翻译: 针对人工临床记录，我们探讨了零样本与少量样本生成策略，旨在实现更高效、精准的模拟数据生成。](2024年03月13日/Zero-shot_and_Few-shot_Generation_Strategies_for_Artificial_Clinical_Records.md)

- [An Efficient End-to-End Approach to Noise Invariant Speech Features via Multi-Task Learning](2024年03月13日/An_Efficient_End-to-End_Approach_to_Noise_Invariant_Speech_Features_via_Multi-Task_Learning.md)

    - [翻译: 本研究提出了一种新颖高效的端到端解决方案，利用多任务学习技术来提取对噪声具有鲁棒性的语音特征。](2024年03月13日/An_Efficient_End-to-End_Approach_to_Noise_Invariant_Speech_Features_via_Multi-Task_Learning.md)

- [Human Alignment of Large Language Models through Online Preference Optimisation](2024年03月13日/Human_Alignment_of_Large_Language_Models_through_Online_Preference_Optimisation.md)

    - [翻译: 借助在线偏好优化技术，本研究探讨如何实现大型语言模型与人类需求的精准对齐。](2024年03月13日/Human_Alignment_of_Large_Language_Models_through_Online_Preference_Optimisation.md)

- [MedInsight: A Multi-Source Context Augmentation Framework for Generating Patient-Centric Medical Responses using Large Language Models](2024年03月13日/MedInsight_A_Multi-Source_Context_Augmentation_Framework_for_Generating_Patient-Centric_Medical_Responses_using_Large_Language_Models.md)

    - [翻译: MedInsight：针对大型语言模型，我们提出了一种创新的多源上下文增强框架，旨在借助该框架为生成个性化、以患者为中心的医疗回复提供有力支持。](2024年03月13日/MedInsight_A_Multi-Source_Context_Augmentation_Framework_for_Generating_Patient-Centric_Medical_Responses_using_Large_Language_Models.md)

- [Language-Grounded Dynamic Scene Graphs for Interactive Object Search with Mobile Manipulation](2024年03月13日/Language-Grounded_Dynamic_Scene_Graphs_for_Interactive_Object_Search_with_Mobile_Manipulation.md)

    - [翻译: 为实现结合移动操作的交互式物体搜索，我们提出了一种基于语言引导的动态场景图方法。该方法利用语言信息构建动态场景图，以高效指导机器人在复杂环境中进行目标物体搜索和交互。](2024年03月13日/Language-Grounded_Dynamic_Scene_Graphs_for_Interactive_Object_Search_with_Mobile_Manipulation.md)

- [DevBench: A Comprehensive Benchmark for Software Development](2024年03月13日/DevBench_A_Comprehensive_Benchmark_for_Software_Development.md)

    - [翻译: DevBench 是一款综合全面的软件开发基准测试平台，旨在为开发者提供衡量和比较不同开发环境、工具及实践效果的标准参照。](2024年03月13日/DevBench_A_Comprehensive_Benchmark_for_Software_Development.md)

- [Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments](2024年03月13日/Call_Me_When_Necessary_LLMs_can_Efficiently_and_Faithfully_Reason_over_Structured_Environments.md)

    - [翻译: 无论是处理结构化环境还是应对复杂需求，LLMs 都能以高效而精准的方式进行推理。不妨视其为“必要时随时呼叫”的可靠智能工具。](2024年03月13日/Call_Me_When_Necessary_LLMs_can_Efficiently_and_Faithfully_Reason_over_Structured_Environments.md)

- [Non-discrimination Criteria for Generative Language Models](2024年03月13日/Non-discrimination_Criteria_for_Generative_Language_Models.md)

    - [翻译: 针对生成式语言模型，探究其应遵循的非歧视性准则。](2024年03月13日/Non-discrimination_Criteria_for_Generative_Language_Models.md)

- [AIGCs Confuse AI Too: Investigating and Explaining Synthetic Image-induced Hallucinations in Large Vision-Language Models](2024年03月13日/AIGCs_Confuse_AI_Too_Investigating_and_Explaining_Synthetic_Image-induced_Hallucinations_in_Large_Vision-Language_Models.md)

    - [翻译: AIGC 生成的内容同样能迷惑 AI，我们正致力于探究大型视觉-语言模型在面对合成图像时产生的幻觉现象，并对其进行深入解析。](2024年03月13日/AIGCs_Confuse_AI_Too_Investigating_and_Explaining_Synthetic_Image-induced_Hallucinations_in_Large_Vision-Language_Models.md)

- [Masked Generative Story Transformer with Character Guidance and Caption Augmentation](2024年03月13日/Masked_Generative_Story_Transformer_with_Character_Guidance_and_Caption_Augmentation.md)

    - [翻译: 通过采用字符引导与标题增强技术，我们提出了一种掩码生成故事Transformer模型。该模型在生成连贯故事的同时，能够借助字符级别的指引以及标题信息的补充，以提升文本生成质量和叙事逻辑性。](2024年03月13日/Masked_Generative_Story_Transformer_with_Character_Guidance_and_Caption_Augmentation.md)

- [Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator](2024年03月13日/Automatic_Interactive_Evaluation_for_Large_Language_Models_with_State_Aware_Patient_Simulator.md)

    - [翻译: 针对大型语言模型，我们提出了一种结合了状态感知病人模拟器的自动交互评估方法。这种方法能够模拟真实世界中病人的复杂状态变化，从而对大型语言模型进行深入细致的互动性评估。](2024年03月13日/Automatic_Interactive_Evaluation_for_Large_Language_Models_with_State_Aware_Patient_Simulator.md)

- [Rich Semantic Knowledge Enhanced Large Language Models for Few-shot Chinese Spell Checking](2024年03月13日/Rich_Semantic_Knowledge_Enhanced_Large_Language_Models_for_Few-shot_Chinese_Spell_Checking.md)

    - [翻译: 通过融入丰富语义知识以提升大型语言模型能力，我们致力于实现针对少量样本的高效中文拼写纠错。](2024年03月13日/Rich_Semantic_Knowledge_Enhanced_Large_Language_Models_for_Few-shot_Chinese_Spell_Checking.md)

- [Data-oriented Dynamic Fine-tuning Parameter Selection Strategy for FISH Mask based Efficient Fine-tuning](2024年03月13日/Data-oriented_Dynamic_Fine-tuning_Parameter_Selection_Strategy_for_FISH_Mask_based_Efficient_Fine-tuning.md)

    - [翻译: 本研究提出一种面向数据的动态微调参数选取策略，专为FISH Mask高效微调设计。该策略旨在针对不同的数据集特性，智能地选取并调整FISH Mask模型的微调参数，以实现更高效、精准的模型优化。](2024年03月13日/Data-oriented_Dynamic_Fine-tuning_Parameter_Selection_Strategy_for_FISH_Mask_based_Efficient_Fine-tuning.md)

- [SoK: Reducing the Vulnerability of Fine-tuned Language Models to Membership Inference Attacks](2024年03月13日/SoK_Reducing_the_Vulnerability_of_Fine-tuned_Language_Models_to_Membership_Inference_Attacks.md)

    - [翻译: SoK（系统化知识）：致力于降低微调语言模型遭受成员推断攻击的风险步骤 1 翻译：SoK（Systematization of Knowledge）探究了如何减少微调语言模型在面对成员推断攻击时所表现出的脆弱性问题。步骤 2 翻译优化：本文为 SoK（系统化知识）研究，专注于解决微调语言模型对成员推断攻击的易感性问题，旨在提出有效方法以降低此类模型在此类安全威胁下的风险。](2024年03月13日/SoK_Reducing_the_Vulnerability_of_Fine-tuned_Language_Models_to_Membership_Inference_Attacks.md)

- [Authorship Verification based on the Likelihood Ratio of Grammar Models](2024年03月13日/Authorship_Verification_based_on_the_Likelihood_Ratio_of_Grammar_Models.md)

    - [翻译: 通过对语法模型的似然比分析进行作者身份验证的研究](2024年03月13日/Authorship_Verification_based_on_the_Likelihood_Ratio_of_Grammar_Models.md)

- [Search-based Optimisation of LLM Learning Shots for Story Point Estimation](2024年03月13日/Search-based_Optimisation_of_LLM_Learning_Shots_for_Story_Point_Estimation.md)

    - [翻译: 针对故事点估算任务，我们提出了一种通过搜索策略优化大型语言模型（LLM）学习次数的方法，旨在提升其估算效能。](2024年03月13日/Search-based_Optimisation_of_LLM_Learning_Shots_for_Story_Point_Estimation.md)

- [Software Vulnerability and Functionality Assessment using LLMs](2024年03月13日/Software_Vulnerability_and_Functionality_Assessment_using_LLMs.md)

    - [翻译: 运用大型语言模型（LLMs）对软件的脆弱性及功能进行全面评估](2024年03月13日/Software_Vulnerability_and_Functionality_Assessment_using_LLMs.md)

- [Tastle: Distract Large Language Models for Automatic Jailbreak Attack](2024年03月13日/Tastle_Distract_Large_Language_Models_for_Automatic_Jailbreak_Attack.md)

    - [翻译: Tastle 是一种技术，通过干扰大型语言模型以实现针对目标系统的自动越狱攻击。](2024年03月13日/Tastle_Distract_Large_Language_Models_for_Automatic_Jailbreak_Attack.md)

- [System for systematic literature review using multiple AI agents: Concept and an empirical evaluation](2024年03月13日/System_for_systematic_literature_review_using_multiple_AI_agents_Concept_and_an_empirical_evaluation.md)

    - [翻译: 本研究提出了一种采用多个AI代理进行系统性文献综述的创新系统，并对其进行了深入的概念阐述和严谨的实证评估。](2024年03月13日/System_for_systematic_literature_review_using_multiple_AI_agents_Concept_and_an_empirical_evaluation.md)

- [A Picture Is Worth a Thousand Words: Exploring Diagram and Video-Based OOP Exercises to Counter LLM Over-Reliance](2024年03月13日/A_Picture_Is_Worth_a_Thousand_Words_Exploring_Diagram_and_Video-Based_OOP_Exercises_to_Counter_LLM_Over-Reliance.md)

    - [翻译: 在对抗大型语言模型过度依赖的过程中，我们发现“一图胜千言”。为此，我们探索了利用图表和视频进行面向对象编程练习的新途径，以减轻LLM过度依赖现象。](2024年03月13日/A_Picture_Is_Worth_a_Thousand_Words_Exploring_Diagram_and_Video-Based_OOP_Exercises_to_Counter_LLM_Over-Reliance.md)

- [CoIN: A Benchmark of Continual Instruction tuNing for Multimodel Large Language Model](2024年03月13日/CoIN_A_Benchmark_of_Continual_Instruction_tuNing_for_Multimodel_Large_Language_Model.md)

    - [翻译: CoIN 是一个针对多模态大型语言模型的连续指令优化基准，旨在衡量和推进此类模型在不断学习和适应新指令任务中的性能。](2024年03月13日/CoIN_A_Benchmark_of_Continual_Instruction_tuNing_for_Multimodel_Large_Language_Model.md)

- [From human experts to machines: An LLM supported approach to ontology and knowledge graph construction](2024年03月13日/From_human_experts_to_machines_An_LLM_supported_approach_to_ontology_and_knowledge_graph_construction.md)

    - [翻译: 跃迁至机器智能：运用大型语言模型助力本体与知识图谱构建之旅](2024年03月13日/From_human_experts_to_machines_An_LLM_supported_approach_to_ontology_and_knowledge_graph_construction.md)

- [LLM-Assisted Light: Leveraging Large Language Model Capabilities for Human-Mimetic Traffic Signal Control in Complex Urban Environments](2024年03月13日/LLM-Assisted_Light_Leveraging_Large_Language_Model_Capabilities_for_Human-Mimetic_Traffic_Signal_Control_in_Complex_Urban_Environments.md)

    - [翻译: 在复杂的城市环境中，我们提出了一项利用大型语言模型（LLM）能力来实现仿真人智能的交通信号控制系统——LLM辅助式智慧信号灯，以应对复杂的交通环境挑战。](2024年03月13日/LLM-Assisted_Light_Leveraging_Large_Language_Model_Capabilities_for_Human-Mimetic_Traffic_Signal_Control_in_Complex_Urban_Environments.md)

- [Positive Lynden-Bell derivative as a ticket to the bar trap?](2024年03月13日/Positive_Lynden-Bell_derivative_as_a_ticket_to_the_bar_trap.md)

    - [翻译: 正值的Lynden-Bell导数，是否意味着通往“粒子陷阱”酒吧的入场券？](2024年03月13日/Positive_Lynden-Bell_derivative_as_a_ticket_to_the_bar_trap.md)

- [Knowledge Conflicts for LLMs: A Survey](2024年03月13日/Knowledge_Conflicts_for_LLMs_A_Survey.md)

    - [翻译: 针对 LLMs 的知识冲突研究概述](2024年03月13日/Knowledge_Conflicts_for_LLMs_A_Survey.md)

- [Is Context Helpful for Chat Translation Evaluation?](2024年03月13日/Is_Context_Helpful_for_Chat_Translation_Evaluation.md)

    - [翻译: 在聊天翻译评估中，引入上下文真的能起到积极作用吗？](2024年03月13日/Is_Context_Helpful_for_Chat_Translation_Evaluation.md)

- [StreamingDialogue: Prolonged Dialogue Learning via Long Context Compression with Minimal Losses](2024年03月13日/StreamingDialogue_Prolonged_Dialogue_Learning_via_Long_Context_Compression_with_Minimal_Losses.md)

    - [翻译: StreamingDialogue 方法借助于最小损失的长上下文高效压缩技术，实现了对话模型对长时间、连续对话的深入学习。](2024年03月13日/StreamingDialogue_Prolonged_Dialogue_Learning_via_Long_Context_Compression_with_Minimal_Losses.md)

- [HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback](2024年03月13日/HRLAIF_Improvements_in_Helpfulness_and_Harmlessness_in_Open-domain_Reinforcement_Learning_From_AI_Feedback.md)

    - [翻译: HRLAIF 是一种创新方法，它利用 AI 反馈，在开放域强化学习中显著提升了模型的有用性和减少潜在危害。该研究致力于优化人工智能在复杂环境下的决策行为，确保其更加有益且无害。](2024年03月13日/HRLAIF_Improvements_in_Helpfulness_and_Harmlessness_in_Open-domain_Reinforcement_Learning_From_AI_Feedback.md)

- [Towards Personalized Evaluation of Large Language Models with An Anonymous Crowd-Sourcing Platform](2024年03月13日/Towards_Personalized_Evaluation_of_Large_Language_Models_with_An_Anonymous_Crowd-Sourcing_Platform.md)

    - [翻译: 本研究利用匿名众包平台，旨在探索针对大型语言模型的个性化评估方法。](2024年03月13日/Towards_Personalized_Evaluation_of_Large_Language_Models_with_An_Anonymous_Crowd-Sourcing_Platform.md)

- [CleanAgent: Automating Data Standardization with LLM-based Agents](2024年03月13日/CleanAgent_Automating_Data_Standardization_with_LLM-based_Agents.md)

    - [翻译: CleanAgent是一款利用大型语言模型（LLM）构建的数据标准化自动化工具，它借助LLM智能代理技术，实现高效、自动化的数据清洗与标准化。](2024年03月13日/CleanAgent_Automating_Data_Standardization_with_LLM-based_Agents.md)

- [Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models](2024年03月13日/Mastering_Text,_Code_and_Math_Simultaneously_via_Fusing_Highly_Specialized_Language_Models.md)

    - [翻译: 通过深度融合各领域的高度专业化语言模型，实现对文本、代码与数学的同时精通](2024年03月13日/Mastering_Text,_Code_and_Math_Simultaneously_via_Fusing_Highly_Specialized_Language_Models.md)

- [Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification](2024年03月13日/Efficient_Prompt_Tuning_of_Large_Vision-Language_Model_for_Fine-Grained_Ship_Classification.md)

    - [翻译: 在细粒度船舶分类任务上，我们提出了一种高效的方法来对大型视觉-语言模型进行提示调优，以提升其性能表现。](2024年03月13日/Efficient_Prompt_Tuning_of_Large_Vision-Language_Model_for_Fine-Grained_Ship_Classification.md)

- [Emergence of Social Norms in Large Language Model-based Agent Societies](2024年03月13日/Emergence_of_Social_Norms_in_Large_Language_Model-based_Agent_Societies.md)

    - [翻译: 探究大型语言模型驱动的智能体社会中社会规范如何自然形成与发展](2024年03月13日/Emergence_of_Social_Norms_in_Large_Language_Model-based_Agent_Societies.md)

- [Continuous Object State Recognition for Cooking Robots Using Pre-Trained Vision-Language Models and Black-box Optimization](2024年03月13日/Continuous_Object_State_Recognition_for_Cooking_Robots_Using_Pre-Trained_Vision-Language_Models_and_Black-box_Optimization.md)

    - [翻译: 本研究运用预训练的视觉-语言模型与黑盒优化方法，助力烹饪机器人实现对连续物体状态的精准识别。](2024年03月13日/Continuous_Object_State_Recognition_for_Cooking_Robots_Using_Pre-Trained_Vision-Language_Models_and_Black-box_Optimization.md)

- [Boosting Disfluency Detection with Large Language Model as Disfluency Generator](2024年03月13日/Boosting_Disfluency_Detection_with_Large_Language_Model_as_Disfluency_Generator.md)

    - [翻译: 通过将大型语言模型用作不流畅生成器，我们能够显著提升对不流畅性的检测效果。这项研究旨在借助LLM的力量，探索其在模拟和识别语言表达中的不流畅性方面的潜力，从而改进不流畅检测技术。](2024年03月13日/Boosting_Disfluency_Detection_with_Large_Language_Model_as_Disfluency_Generator.md)

- [Empowering Robotics with Large Language Models: osmAG Map Comprehension with LLMs](2024年03月13日/Empowering_Robotics_with_Large_Language_Models_osmAG_Map_Comprehension_with_LLMs.md)

    - [翻译: 借助大型语言模型的力量，我们正在革新机器人技术领域，特别是在运用LLMs实现对osmAG地图的深度理解方面。](2024年03月13日/Empowering_Robotics_with_Large_Language_Models_osmAG_Map_Comprehension_with_LLMs.md)

- [Large Language Models are Parallel Multilingual Learners](2024年03月13日/Large_Language_Models_are_Parallel_Multilingual_Learners.md)

    - [翻译: 大型语言模型能够实现并行多语言学习，揭示了其在多种语言环境中同步掌握知识的能力。](2024年03月13日/Large_Language_Models_are_Parallel_Multilingual_Learners.md)

- [UniCode: Learning a Unified Codebook for Multimodal Large Language Models](2024年03月13日/UniCode_Learning_a_Unified_Codebook_for_Multimodal_Large_Language_Models.md)

    - [翻译: UniCode项目致力于为多模态大型语言模型打造一个统一的码本，旨在整合和优化不同模态数据在模型中的表示与处理。](2024年03月13日/UniCode_Learning_a_Unified_Codebook_for_Multimodal_Large_Language_Models.md)

- [Query Rewriting via Large Language Models](2024年03月13日/Query_Rewriting_via_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现查询改写技术](2024年03月13日/Query_Rewriting_via_Large_Language_Models.md)

- [RAGGED: Towards Informed Design of Retrieval Augmented Generation Systems](2024年03月13日/RAGGED_Towards_Informed_Design_of_Retrieval_Augmented_Generation_Systems.md)

    - [翻译: RAGGED：致力于实现知情设计的检索增强生成系统研究，旨在深入理解并改进此类系统的构建方式。](2024年03月13日/RAGGED_Towards_Informed_Design_of_Retrieval_Augmented_Generation_Systems.md)

- [Detecting Hallucination and Coverage Errors in Retrieval Augmented Generation for Controversial Topics](2024年03月13日/Detecting_Hallucination_and_Coverage_Errors_in_Retrieval_Augmented_Generation_for_Controversial_Topics.md)

    - [翻译: 针对争议性话题的检索增强生成技术，本研究致力于揭示其中的幻觉现象与覆盖错误，并对其进行有效检测。](2024年03月13日/Detecting_Hallucination_and_Coverage_Errors_in_Retrieval_Augmented_Generation_for_Controversial_Topics.md)

- [VisionGPT: Vision-Language Understanding Agent Using Generalized Multimodal Framework](2024年03月13日/VisionGPT_Vision-Language_Understanding_Agent_Using_Generalized_Multimodal_Framework.md)

    - [翻译: VisionGPT 是一款基于通用多模态框架构建的视觉-语言理解利器，旨在高效融合视觉与语言信息，实现深度理解。](2024年03月13日/VisionGPT_Vision-Language_Understanding_Agent_Using_Generalized_Multimodal_Framework.md)

- [AutoGuide: Automated Generation and Selection of State-Aware Guidelines for Large Language Model Agents](2024年03月13日/AutoGuide_Automated_Generation_and_Selection_of_State-Aware_Guidelines_for_Large_Language_Model_Agents.md)

    - [翻译: AutoGuide 是一项技术，它能自动为大型语言模型智能体生成并优选具备状态感知能力的操作指南。](2024年03月13日/AutoGuide_Automated_Generation_and_Selection_of_State-Aware_Guidelines_for_Large_Language_Model_Agents.md)

- [Cultural evolution in populations of Large Language Models](2024年03月13日/Cultural_evolution_in_populations_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型群体中文化演进的现象](2024年03月13日/Cultural_evolution_in_populations_of_Large_Language_Models.md)

- [TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation](2024年03月13日/TINA_Think,_Interaction,_and_Action_Framework_for_Zero-Shot_Vision_Language_Navigation.md)

    - [翻译: TINA 是一个专为零样本视觉语言导航设计的框架，涵盖了思考（Think）、交互（Interaction）和行动（Action）三个关键维度。](2024年03月13日/TINA_Think,_Interaction,_and_Action_Framework_for_Zero-Shot_Vision_Language_Navigation.md)

- [Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors](2024年03月13日/Re-Search_for_The_Truth_Multi-round_Retrieval-augmented_Large_Language_Models_are_Strong_Fake_News_Detectors.md)

    - [翻译: 《重新搜索真相：通过多次检索增强的大规模语言模型在假新闻识别中展现强大实力》注：由于原句标题简短且具有一定的修辞特点，从准确性和生动性角度出发，在第一步直译的基础上，第二步仅做了微调以符合中文标题通常的行文习惯，保持了原有的紧凑与有力的表达风格。](2024年03月13日/Re-Search_for_The_Truth_Multi-round_Retrieval-augmented_Large_Language_Models_are_Strong_Fake_News_Detectors.md)

- [OverleafCopilot: Empowering Academic Writing in Overleaf with Large Language Models](2024年03月13日/OverleafCopilot_Empowering_Academic_Writing_in_Overleaf_with_Large_Language_Models.md)

    - [翻译: OverleafCopilot：借助大型语言模型的力量，让 Overleaf 上的学术写作如虎添翼步骤详解：](2024年03月13日/OverleafCopilot_Empowering_Academic_Writing_in_Overleaf_with_Large_Language_Models.md)

- [GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping](2024年03月14日/GaussianGrasper_3D_Language_Gaussian_Splatting_for_Open-vocabulary_Robotic_Grasping.md)

    - [翻译: GaussianGrasper 是一项创新技术，通过三维语言高斯扩散方法赋予机器人以开放式词汇理解能力，从而实现更灵活精准的物体抓取。](2024年03月14日/GaussianGrasper_3D_Language_Gaussian_Splatting_for_Open-vocabulary_Robotic_Grasping.md)

- [Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference](2024年03月14日/Dynamic_Memory_Compression_Retrofitting_LLMs_for_Accelerated_Inference.md)

    - [翻译: 动态内存压缩技术应用于LLMs，旨在实现快速推理优化。这项技术是对大型语言模型进行改造升级，以适应更高效的推理需求。](2024年03月14日/Dynamic_Memory_Compression_Retrofitting_LLMs_for_Accelerated_Inference.md)

- [3D-VLA: A 3D Vision-Language-Action Generative World Model](2024年03月14日/3D-VLA_A_3D_Vision-Language-Action_Generative_World_Model.md)

    - [翻译: 3D-VLA，一款创新的三维视觉-语言-动作生成世界模型，它将三维视觉信息、自然语言理解和执行动作的能力整合于一体。](2024年03月14日/3D-VLA_A_3D_Vision-Language-Action_Generative_World_Model.md)

- [PosSAM: Panoptic Open-vocabulary Segment Anything](2024年03月14日/PosSAM_Panoptic_Open-vocabulary_Segment_Anything.md)

    - [翻译: PosSAM：一款能够对任意目标进行泛视觉、开词汇表的全方位分割技术](2024年03月14日/PosSAM_Panoptic_Open-vocabulary_Segment_Anything.md)

- [MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](2024年03月14日/MM1_Methods,_Analysis_&_Insights_from_Multimodal_LLM_Pre-training.md)

    - [翻译: MM1 探究了多模态 LLM 预训练中的方法策略、深度分析及其带来的独到见解。](2024年03月14日/MM1_Methods,_Analysis_&_Insights_from_Multimodal_LLM_Pre-training.md)

- [Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey](2024年03月14日/Large_Language_Models_and_Causal_Inference_in_Collaboration_A_Comprehensive_Survey.md)

    - [翻译: 针对大型语言模型在协作场景下的因果推断应用，本研究提供了一份详尽的综述。](2024年03月14日/Large_Language_Models_and_Causal_Inference_in_Collaboration_A_Comprehensive_Survey.md)

- [Logical Discrete Graphical Models Must Supplement Large Language Models for Information Synthesis](2024年03月14日/Logical_Discrete_Graphical_Models_Must_Supplement_Large_Language_Models_for_Information_Synthesis.md)

    - [翻译: 为了实现有效信息综合，在处理大型语言模型时，逻辑离散图形模型不可或缺。它们能够辅助和增强LLM在整合信息方面的表现。](2024年03月14日/Logical_Discrete_Graphical_Models_Must_Supplement_Large_Language_Models_for_Information_Synthesis.md)

- [ExploRLLM: Guiding Exploration in Reinforcement Learning with Large Language Models](2024年03月14日/ExploRLLM_Guiding_Exploration_in_Reinforcement_Learning_with_Large_Language_Models.md)

    - [翻译: ExploRLLM 是一项研究，旨在利用大型语言模型（LLMs）来引导强化学习过程中的有效探索。](2024年03月14日/ExploRLLM_Guiding_Exploration_in_Reinforcement_Learning_with_Large_Language_Models.md)

- [Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation](2024年03月14日/Eyes_Closed,_Safety_On_Protecting_Multimodal_LLMs_via_Image-to-Text_Transformation.md)

    - [翻译: 在“闭眼”状态下保障安全：探索利用图像转文本技术来保护多模态大型语言模型（LLMs）的方案](2024年03月14日/Eyes_Closed,_Safety_On_Protecting_Multimodal_LLMs_via_Image-to-Text_Transformation.md)

- [Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models](2024年03月14日/Enhancing_Trust_in_Autonomous_Agents_An_Architecture_for_Accountability_and_Explainability_through_Blockchain_and_Large_Language_Models.md)

    - [翻译: 为提升对自主智能体的信任，我们提出了一种结合区块链技术和大型语言模型的新型架构，旨在实现自主智能体的责任追溯与可解释性。](2024年03月14日/Enhancing_Trust_in_Autonomous_Agents_An_Architecture_for_Accountability_and_Explainability_through_Blockchain_and_Large_Language_Models.md)

- [Welcome Your New AI Teammate: On Safety Analysis by Leashing Large Language Models](2024年03月14日/Welcome_Your_New_AI_Teammate_On_Safety_Analysis_by_Leashing_Large_Language_Models.md)

    - [翻译: 向您介绍您的新晋AI队友，它将通过约束大型语言模型的方式助力安全分析工作。](2024年03月14日/Welcome_Your_New_AI_Teammate_On_Safety_Analysis_by_Leashing_Large_Language_Models.md)

- [Less is More: Data Value Estimation for Visual Instruction Tuning](2024年03月14日/Less_is_More_Data_Value_Estimation_for_Visual_Instruction_Tuning.md)

    - [翻译: 在视觉指令微调中，我们提出“少即是多”的理念，专注于对数据价值的精准估算。这项研究旨在探讨和挖掘少量高质量数据在优化视觉指令模型性能方面的重要作用。](2024年03月14日/Less_is_More_Data_Value_Estimation_for_Visual_Instruction_Tuning.md)

- [Logits of API-Protected LLMs Leak Proprietary Information](2024年03月14日/Logits_of_API-Protected_LLMs_Leak_Proprietary_Information.md)

    - [翻译: 研究表明，受 API 保护的大规模语言模型（LLMs）的 logits 输出可能泄露其内部所包含的专有信息。](2024年03月14日/Logits_of_API-Protected_LLMs_Leak_Proprietary_Information.md)

- [VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding](2024年03月14日/VisionGPT-3D_A_Generalized_Multimodal_Agent_for_Enhanced_3D_Vision_Understanding.md)

    - [翻译: VisionGPT-3D：一款强大而全面的多模态智能体，旨在提升三维视觉理解能力](2024年03月14日/VisionGPT-3D_A_Generalized_Multimodal_Agent_for_Enhanced_3D_Vision_Understanding.md)

- [WavCraft: Audio Editing and Generation with Natural Language Prompts](2024年03月14日/WavCraft_Audio_Editing_and_Generation_with_Natural_Language_Prompts.md)

    - [翻译: WavCraft——通过自然语言指令实现音频编辑与生成](2024年03月14日/WavCraft_Audio_Editing_and_Generation_with_Natural_Language_Prompts.md)

- [MT-PATCHER: Selective and Extendable Knowledge Distillation from Large Language Models for Machine Translation](2024年03月14日/MT-PATCHER_Selective_and_Extendable_Knowledge_Distillation_from_Large_Language_Models_for_Machine_Translation.md)

    - [翻译: MT-PATCHER：针对机器翻译任务，该技术实现了从大型语言模型中进行选择性且可扩展的知识蒸馏，旨在提炼和有效利用大规模模型中的宝贵知识。](2024年03月14日/MT-PATCHER_Selective_and_Extendable_Knowledge_Distillation_from_Large_Language_Models_for_Machine_Translation.md)

- [AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting](2024年03月14日/AdaShield_Safeguarding_Multimodal_Large_Language_Models_from_Structure-based_Attack_via_Adaptive_Shield_Prompting.md)

    - [翻译: AdaShield方案：针对多模态大型语言模型，利用自适应防护提示技术有效抵御基于结构的攻击威胁。](2024年03月14日/AdaShield_Safeguarding_Multimodal_Large_Language_Models_from_Structure-based_Attack_via_Adaptive_Shield_Prompting.md)

- [From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News](2024年03月14日/From_Skepticism_to_Acceptance_Simulating_the_Attitude_Dynamics_Toward_Fake_News.md)

    - [翻译: 本研究模拟了人们对假新闻从怀疑到接受这一态度转变的动态过程。](2024年03月14日/From_Skepticism_to_Acceptance_Simulating_the_Attitude_Dynamics_Toward_Fake_News.md)

- [Anomaly Detection by Adapting a pre-trained Vision Language Model](2024年03月14日/Anomaly_Detection_by_Adapting_a_pre-trained_Vision_Language_Model.md)

    - [翻译: 我们采用预训练的视觉语言模型并对其进行适应性调整，以实现对异常的有效检测。](2024年03月14日/Anomaly_Detection_by_Adapting_a_pre-trained_Vision_Language_Model.md)

- [Rectifying Demonstration Shortcut in In-Context Learning](2024年03月14日/Rectifying_Demonstration_Shortcut_in_In-Context_Learning.md)

    - [翻译: 本研究致力于纠正ICL中的“演示捷径”问题，探讨如何改进上下文学习方法，以消除对示例的过度依赖，并提升其在各类任务中的泛化性能。](2024年03月14日/Rectifying_Demonstration_Shortcut_in_In-Context_Learning.md)

- [LLM-based agents for automating the enhancement of user story quality: An early report](2024年03月14日/LLM-based_agents_for_automating_the_enhancement_of_user_story_quality_An_early_report.md)

    - [翻译: 一份早期报告显示，利用 LLM 技术开发的智能代理能够实现用户故事质量的自动化优化。](2024年03月14日/LLM-based_agents_for_automating_the_enhancement_of_user_story_quality_An_early_report.md)

- [GPT on a Quantum Computer](2024年03月14日/GPT_on_a_Quantum_Computer.md)

    - [翻译: GPT 与量子计算的邂逅：探究 GPT 在量子计算机环境下的表现与应用](2024年03月14日/GPT_on_a_Quantum_Computer.md)

- [OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments](2024年03月14日/OpenGraph_Open-Vocabulary_Hierarchical_3D_Graph_Representation_in_Large-Scale_Outdoor_Environments.md)

    - [翻译: OpenGraph是一种在大规模户外环境中实现开放词汇、分层三维图形表达的方法。](2024年03月14日/OpenGraph_Open-Vocabulary_Hierarchical_3D_Graph_Representation_in_Large-Scale_Outdoor_Environments.md)

- [XCoOp: Explainable Prompt Learning for Computer-Aided Diagnosis via Concept-guided Context Optimization](2024年03月14日/XCoOp_Explainable_Prompt_Learning_for_Computer-Aided_Diagnosis_via_Concept-guided_Context_Optimization.md)

    - [翻译: XCoOp：借助于概念指导下的上下文优化技术，实现对计算机辅助诊断任务具有可解释性的提示学习。](2024年03月14日/XCoOp_Explainable_Prompt_Learning_for_Computer-Aided_Diagnosis_via_Concept-guided_Context_Optimization.md)

- ["Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students using Large Language Models](2024年03月14日/Like_a_Nesting_Doll_Analyzing_Recursion_Analogies_Generated_by_CS_Students_using_Large_Language_Models.md)

    - [翻译: 本研究以“套娃”为喻，借助大型语言模型，深入剖析了计算机科学学生在运用大型语言模型时所创造出的递归类比实例。](2024年03月14日/Like_a_Nesting_Doll_Analyzing_Recursion_Analogies_Generated_by_CS_Students_using_Large_Language_Models.md)

- [An Extensible Framework for Architecture-Based Data Flow Analysis for Information Security](2024年03月14日/An_Extensible_Framework_for_Architecture-Based_Data_Flow_Analysis_for_Information_Security.md)

    - [翻译: 为探究信息安全中的数据流动规律，我们提出了一种灵活可扩展的架构导向数据流分析框架。](2024年03月14日/An_Extensible_Framework_for_Architecture-Based_Data_Flow_Analysis_for_Information_Security.md)

- [GiT: Towards Generalist Vision Transformer through Universal Language Interface](2024年03月14日/GiT_Towards_Generalist_Vision_Transformer_through_Universal_Language_Interface.md)

    - [翻译: GiT项目致力于打造一款全能型视觉Transformer，借助统一语言接口实现这一目标。](2024年03月14日/GiT_Towards_Generalist_Vision_Transformer_through_Universal_Language_Interface.md)

- [Introducing Routing Functions to Vision-Language Parameter-Efficient Fine-Tuning with Low-Rank Bottlenecks](2024年03月14日/Introducing_Routing_Functions_to_Vision-Language_Parameter-Efficient_Fine-Tuning_with_Low-Rank_Bottlenecks.md)

    - [翻译: 为了提升视觉-语言模型的参数效率与微调性能，我们提出在具有低秩瓶颈的视觉-语言模型微调过程中引入路由函数技术。](2024年03月14日/Introducing_Routing_Functions_to_Vision-Language_Parameter-Efficient_Fine-Tuning_with_Low-Rank_Bottlenecks.md)

- [Komodo: A Linguistic Expedition into Indonesia's Regional Languages](2024年03月14日/Komodo_A_Linguistic_Expedition_into_Indonesia's_Regional_Languages.md)

    - [翻译: Komodo项目：一场探索印尼区域语言的深度语言学之旅](2024年03月14日/Komodo_A_Linguistic_Expedition_into_Indonesia's_Regional_Languages.md)

- [BurstAttention: An Efficient Distributed Attention Framework for Extremely Long Sequences](2024年03月14日/BurstAttention_An_Efficient_Distributed_Attention_Framework_for_Extremely_Long_Sequences.md)

    - [翻译: BurstAttention 是专为处理超长序列而设计的一种高效分布式注意力机制架构。](2024年03月14日/BurstAttention_An_Efficient_Distributed_Attention_Framework_for_Extremely_Long_Sequences.md)

- [AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions](2024年03月14日/AVIBench_Towards_Evaluating_the_Robustness_of_Large_Vision-Language_Model_on_Adversarial_Visual-Instructions.md)

    - [翻译: AVIBench 是一个专注于评估大型视觉-语言模型在面对对抗性视觉指令时的稳健性的研究项目，旨在揭示模型在此挑战性场景下的表现和适应能力。](2024年03月14日/AVIBench_Towards_Evaluating_the_Robustness_of_Large_Vision-Language_Model_on_Adversarial_Visual-Instructions.md)

- [Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring](2024年03月14日/Griffon_v2_Advancing_Multimodal_Perception_with_High-Resolution_Scaling_and_Visual-Language_Co-Referring.md)

    - [翻译: Griffon v2 引领进步，利用高分辨率缩放与视觉-语言共指技术提升多模态感知能力](2024年03月14日/Griffon_v2_Advancing_Multimodal_Perception_with_High-Resolution_Scaling_and_Visual-Language_Co-Referring.md)

- [Enabling Waypoint Generation for Collaborative Robots using LLMs and Mixed Reality](2024年03月14日/Enabling_Waypoint_Generation_for_Collaborative_Robots_using_LLMs_and_Mixed_Reality.md)

    - [翻译: 借助 LLM 和混合现实技术，我们能够为协作机器人赋予路径点自动生成能力，让其在协同工作中更加智能化和灵活。](2024年03月14日/Enabling_Waypoint_Generation_for_Collaborative_Robots_using_LLMs_and_Mixed_Reality.md)

- [Annotation Free Semantic Segmentation with Vision Foundation Models](2024年03月14日/Annotation_Free_Semantic_Segmentation_with_Vision_Foundation_Models.md)

    - [翻译: 利用视觉基础模型实现无需标注的语义分割技术](2024年03月14日/Annotation_Free_Semantic_Segmentation_with_Vision_Foundation_Models.md)

- [Select and Distill: Selective Dual-Teacher Knowledge Transfer for Continual Learning on Vision-Language Models](2024年03月14日/Select_and_Distill_Selective_Dual-Teacher_Knowledge_Transfer_for_Continual_Learning_on_Vision-Language_Models.md)

    - [翻译: 为了解决视觉-语言模型在连续学习中的挑战，我们提出了一种名为“选择并提炼”的方法，通过精心设计的双教师机制进行知识转移。这种方法旨在有选择性地从先前任务中萃取关键知识，并将其高效融入后续任务的学习过程中，从而促进视觉-语言模型在不断学习新任务时保持和提升旧任务的表现。](2024年03月14日/Select_and_Distill_Selective_Dual-Teacher_Knowledge_Transfer_for_Continual_Learning_on_Vision-Language_Models.md)

- [VIVID: Human-AI Collaborative Authoring of Vicarious Dialogues from Lecture Videos](2024年03月14日/VIVID_Human-AI_Collaborative_Authoring_of_Vicarious_Dialogues_from_Lecture_Videos.md)

    - [翻译: VIVID项目致力于实现人机协作，共同从讲座视频中创作生动的、身临其境的对话内容。](2024年03月14日/VIVID_Human-AI_Collaborative_Authoring_of_Vicarious_Dialogues_from_Lecture_Videos.md)

- [Dial-insight: Fine-tuning Large Language Models with High-Quality Domain-Specific Data Preventing Capability Collapse](2024年03月14日/Dial-insight_Fine-tuning_Large_Language_Models_with_High-Quality_Domain-Specific_Data_Preventing_Capability_Collapse.md)

    - [翻译: Dial-insight 方法，通过采用高质量的特定领域数据对大型语言模型进行微调，有效防止模型能力退化。](2024年03月14日/Dial-insight_Fine-tuning_Large_Language_Models_with_High-Quality_Domain-Specific_Data_Preventing_Capability_Collapse.md)

- [Exploring the Comprehension of ChatGPT in Traditional Chinese Medicine Knowledge](2024年03月14日/Exploring_the_Comprehension_of_ChatGPT_in_Traditional_Chinese_Medicine_Knowledge.md)

    - [翻译: 本研究致力于探究ChatGPT在理解中医知识方面的表现，深入探索其对于传统中医药学领域知识的掌握和应用能力。](2024年03月14日/Exploring_the_Comprehension_of_ChatGPT_in_Traditional_Chinese_Medicine_Knowledge.md)

- [Caveat Lector: Large Language Models in Legal Practice](2024年03月14日/Caveat_Lector_Large_Language_Models_in_Legal_Practice.md)

    - [翻译: 审慎阅读：大型语言模型在法律实务领域的探索与应用](2024年03月14日/Caveat_Lector_Large_Language_Models_in_Legal_Practice.md)

- [Unveiling the Generalization Power of Fine-Tuned Large Language Models](2024年03月14日/Unveiling_the_Generalization_Power_of_Fine-Tuned_Large_Language_Models.md)

    - [翻译: 探究微调后大型语言模型的普遍适用性力量](2024年03月14日/Unveiling_the_Generalization_Power_of_Fine-Tuned_Large_Language_Models.md)

- [Evaluating LLMs for Gender Disparities in Notable Persons](2024年03月14日/Evaluating_LLMs_for_Gender_Disparities_in_Notable_Persons.md)

    - [翻译: 本研究旨在评估大型语言模型（LLMs）在描述著名人物时是否存在性别差异问题。](2024年03月14日/Evaluating_LLMs_for_Gender_Disparities_in_Notable_Persons.md)

- [USimAgent: Large Language Models for Simulating Search Users](2024年03月14日/USimAgent_Large_Language_Models_for_Simulating_Search_Users.md)

    - [翻译: USimAgent 是一款专门针对模拟搜索用户而设计的大规模语言模型，它利用强大的自然语言处理能力来仿真用户的搜索行为与意图。](2024年03月14日/USimAgent_Large_Language_Models_for_Simulating_Search_Users.md)

- [Towards Proactive Interactions for In-Vehicle Conversational Assistants Utilizing Large Language Models](2024年03月14日/Towards_Proactive_Interactions_for_In-Vehicle_Conversational_Assistants_Utilizing_Large_Language_Models.md)

    - [翻译: 本研究致力于借助大型语言模型，开发能够主动发起互动的车载对话助手，提升车内交互体验。](2024年03月14日/Towards_Proactive_Interactions_for_In-Vehicle_Conversational_Assistants_Utilizing_Large_Language_Models.md)

- [ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate Professional and Non-Professional Styled Text](2024年03月14日/ProSwitch_Knowledge-Guided_Language_Model_Fine-Tuning_to_Generate_Professional_and_Non-Professional_Styled_Text.md)

    - [翻译: ProSwitch 是一种创新方法，它运用知识指导对语言模型进行精细调整，旨在实现生成兼具专业和非专业写作风格的文本。](2024年03月14日/ProSwitch_Knowledge-Guided_Language_Model_Fine-Tuning_to_Generate_Professional_and_Non-Professional_Styled_Text.md)

- [Exploring the Capabilities and Limitations of Large Language Models in the Electric Energy Sector](2024年03月14日/Exploring_the_Capabilities_and_Limitations_of_Large_Language_Models_in_the_Electric_Energy_Sector.md)

    - [翻译: 本研究致力于揭示大型语言模型在电力能源行业的潜力与局限，深入探讨其在该领域的表现特征及应用场景。](2024年03月14日/Exploring_the_Capabilities_and_Limitations_of_Large_Language_Models_in_the_Electric_Energy_Sector.md)

- [AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning](2024年03月14日/AutoLoRA_Automatically_Tuning_Matrix_Ranks_in_Low-Rank_Adaptation_Based_on_Meta_Learning.md)

    - [翻译: AutoLoRA 是一种创新方法，它运用元学习技术，在低秩适应过程中自动化地优化矩阵的秩。这项研究旨在解决在模型适应时对矩阵秩高效且智能调节的问题。](2024年03月14日/AutoLoRA_Automatically_Tuning_Matrix_Ranks_in_Low-Rank_Adaptation_Based_on_Meta_Learning.md)

- [Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance](2024年03月14日/Meaningful_Learning_Advancing_Abstract_Reasoning_in_Large_Language_Models_via_Generic_Fact_Guidance.md)

    - [翻译: 借助通用事实引导，促进大型语言模型在抽象推理方面的提升——“有意义学习”崭新探索](2024年03月14日/Meaningful_Learning_Advancing_Abstract_Reasoning_in_Large_Language_Models_via_Generic_Fact_Guidance.md)

- [Retrieval augmented text-to-SQL generation for epidemiological question answering using electronic health records](2024年03月14日/Retrieval_augmented_text-to-SQL_generation_for_epidemiological_question_answering_using_electronic_health_records.md)

    - [翻译: 本研究专注于利用电子健康记录，通过增强检索技术改进文本转SQL生成方法，应用于流行病学问题解答。](2024年03月14日/Retrieval_augmented_text-to-SQL_generation_for_epidemiological_question_answering_using_electronic_health_records.md)

- [BjTT: A Large-scale Multimodal Dataset for Traffic Prediction](2024年03月14日/BjTT_A_Large-scale_Multimodal_Dataset_for_Traffic_Prediction.md)

    - [翻译: BjTT 是一个专为交通预测打造的大规模多模态数据集，通过整合多元信息助力提升预测准确性。](2024年03月14日/BjTT_A_Large-scale_Multimodal_Dataset_for_Traffic_Prediction.md)

- [Identifying Health Risks from Family History: A Survey of Natural Language Processing Techniques](2024年03月14日/Identifying_Health_Risks_from_Family_History_A_Survey_of_Natural_Language_Processing_Techniques.md)

    - [翻译: 本研究针对通过家庭史识别健康风险这一主题，对自然语言处理技术进行了全面梳理和探讨。](2024年03月14日/Identifying_Health_Risks_from_Family_History_A_Survey_of_Natural_Language_Processing_Techniques.md)

- [Trusting the Search: Unraveling Human Trust in Health Information from Google and ChatGPT](2024年03月14日/Trusting_the_Search_Unraveling_Human_Trust_in_Health_Information_from_Google_and_ChatGPT.md)

    - [翻译: 探究搜索背后的信任——深入理解人们在使用谷歌和ChatGPT获取健康信息时的信任构建机制](2024年03月14日/Trusting_the_Search_Unraveling_Human_Trust_in_Health_Information_from_Google_and_ChatGPT.md)

- [EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba](2024年03月14日/EfficientVMamba_Atrous_Selective_Scan_for_Light_Weight_Visual_Mamba.md)

    - [翻译: EfficientVMamba，一种专为轻量级视觉Mamba设计的创新技术，通过采用空洞选择性扫描机制，实现高效处理。](2024年03月14日/EfficientVMamba_Atrous_Selective_Scan_for_Light_Weight_Visual_Mamba.md)

- [Think Twice Before Assure: Confidence Estimation for Large Language Models through Reflection on Multiple Answers](2024年03月14日/Think_Twice_Before_Assure_Confidence_Estimation_for_Large_Language_Models_through_Reflection_on_Multiple_Answers.md)

    - [翻译: 面对大型语言模型，请审慎决策，我们提出了一种方法，通过对多个答案的反思实现对模型输出的信心度评估。](2024年03月14日/Think_Twice_Before_Assure_Confidence_Estimation_for_Large_Language_Models_through_Reflection_on_Multiple_Answers.md)

- [Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer](2024年03月14日/Advancing_Object_Goal_Navigation_Through_LLM-enhanced_Object_Affinities_Transfer.md)

    - [翻译: 本研究借助LLM强化的对象亲和力转移技术，推进物体目标导航的发展。](2024年03月14日/Advancing_Object_Goal_Navigation_Through_LLM-enhanced_Object_Affinities_Transfer.md)

- [ViTCN: Vision Transformer Contrastive Network For Reasoning](2024年03月14日/ViTCN_Vision_Transformer_Contrastive_Network_For_Reasoning.md)

    - [翻译: ViTCN 是一种视觉Transformer对比网络，专为推理任务设计。](2024年03月14日/ViTCN_Vision_Transformer_Contrastive_Network_For_Reasoning.md)

- [Recurrent Drafter for Fast Speculative Decoding in Large Language Models](2024年03月14日/Recurrent_Drafter_for_Fast_Speculative_Decoding_in_Large_Language_Models.md)

    - [翻译: 针对大型语言模型，一种名为“循环草稿器”的技术被应用于快速推测性解码过程。](2024年03月14日/Recurrent_Drafter_for_Fast_Speculative_Decoding_in_Large_Language_Models.md)

- [Reality Bites: Assessing the Realism of Driving Scenarios with Large Language Models](2024年03月14日/Reality_Bites_Assessing_the_Realism_of_Driving_Scenarios_with_Large_Language_Models.md)

    - [翻译: 面对现实：借助大型语言模型深入探究驾驶场景的真实程度](2024年03月14日/Reality_Bites_Assessing_the_Realism_of_Driving_Scenarios_with_Large_Language_Models.md)

- [Geographically-Informed Language Identification](2024年03月14日/Geographically-Informed_Language_Identification.md)

    - [翻译: 基于地理位置的语言识别技术](2024年03月14日/Geographically-Informed_Language_Identification.md)

- [Sabiá-2: A New Generation of Portuguese Large Language Models](2024年03月14日/Sabiá-2_A_New_Generation_of_Portuguese_Large_Language_Models.md)

    - [翻译: Sabiá-2：引领潮流的全新一代葡萄牙大型语言模型](2024年03月14日/Sabiá-2_A_New_Generation_of_Portuguese_Large_Language_Models.md)

- [Scaling Behavior of Machine Translation with Large Language Models under Prompt Injection Attacks](2024年03月14日/Scaling_Behavior_of_Machine_Translation_with_Large_Language_Models_under_Prompt_Injection_Attacks.md)

    - [翻译: 面对提示注入攻击，探究大规模语言模型应用于机器翻译任务时的性能变化规律](2024年03月14日/Scaling_Behavior_of_Machine_Translation_with_Large_Language_Models_under_Prompt_Injection_Attacks.md)

- [Comparing Rationality Between Large Language Models and Humans: Insights and Open Questions](2024年03月14日/Comparing_Rationality_Between_Large_Language_Models_and_Humans_Insights_and_Open_Questions.md)

    - [翻译: 探究大型语言模型与人类在理性层面的对比，揭示其中的深刻洞见与亟待解答的问题。](2024年03月14日/Comparing_Rationality_Between_Large_Language_Models_and_Humans_Insights_and_Open_Questions.md)

- [Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention](2024年03月14日/Helpful_or_Harmful_Exploring_the_Efficacy_of_Large_Language_Models_for_Online_Grooming_Prevention.md)

    - [翻译: 大型语言模型在防止网络诱导行为方面是利大于弊还是弊大于利？本研究深入探讨其实际效用。步骤分解：](2024年03月14日/Helpful_or_Harmful_Exploring_the_Efficacy_of_Large_Language_Models_for_Online_Grooming_Prevention.md)

- [Images are Achilles' Heel of Alignment: Exploiting Visual Vulnerabilities for Jailbreaking Multimodal Large Language Models](2024年03月14日/Images_are_Achilles'_Heel_of_Alignment_Exploiting_Visual_Vulnerabilities_for_Jailbreaking_Multimodal_Large_Language_Models.md)

    - [翻译: 在多模态大型语言模型中，图像识别环节成为了其“阿喀琉斯之踵”，本研究通过揭示并利用视觉层面的安全漏洞，旨在突破和“越狱”这类模型的既有对齐限制。](2024年03月14日/Images_are_Achilles'_Heel_of_Alignment_Exploiting_Visual_Vulnerabilities_for_Jailbreaking_Multimodal_Large_Language_Models.md)

- [VideoAgent: Long-form Video Understanding with Large Language Model as Agent](2024年03月15日/VideoAgent_Long-form_Video_Understanding_with_Large_Language_Model_as_Agent.md)

    - [翻译: VideoAgent 是一项通过运用大型语言模型作为智能代理，实现对长格式视频内容深度理解的技术方案。](2024年03月15日/VideoAgent_Long-form_Video_Understanding_with_Large_Language_Model_as_Agent.md)

- [Demystifying Faulty Code with LLM: Step-by-Step Reasoning for Explainable Fault Localization](2024年03月15日/Demystifying_Faulty_Code_with_LLM_Step-by-Step_Reasoning_for_Explainable_Fault_Localization.md)

    - [翻译: 通过 LLM 逐步揭秘错误代码，提供可理解的故障定位机制步骤 1：利用 LLM 解析错误代码：针对可解释性故障定位的逐层深入分析步骤 2：本研究借助 LLM，对错误代码进行逐行剖析和逻辑解读，致力于实现可解释的故障定位过程。](2024年03月15日/Demystifying_Faulty_Code_with_LLM_Step-by-Step_Reasoning_for_Explainable_Fault_Localization.md)

- [ATOM: Asynchronous Training of Massive Models for Deep Learning in a Decentralized Environment](2024年03月15日/ATOM_Asynchronous_Training_of_Massive_Models_for_Deep_Learning_in_a_Decentralized_Environment.md)

    - [翻译: ATOM 技术专为去中心化环境中的深度学习设计，实现了大规模模型的异步训练，赋予其高效处理能力。](2024年03月15日/ATOM_Asynchronous_Training_of_Massive_Models_for_Deep_Learning_in_a_Decentralized_Environment.md)

- [Reconfigurable Robot Identification from Motion Data](2024年03月15日/Reconfigurable_Robot_Identification_from_Motion_Data.md)

    - [翻译: 通过对运动数据的分析，本研究致力于识别和解析可重构机器人的特性。](2024年03月15日/Reconfigurable_Robot_Identification_from_Motion_Data.md)

- [Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution Analyst?](2024年03月15日/Can_a_GPT4-Powered_AI_Agent_Be_a_Good_Enough_Performance_Attribution_Analyst.md)

    - [翻译: GPT4 驱动的 AI 代理是否有能力成为卓越的绩效归因分析师？](2024年03月15日/Can_a_GPT4-Powered_AI_Agent_Be_a_Good_Enough_Performance_Attribution_Analyst.md)

- [Enhancing LLM Factual Accuracy with RAG to Counter Hallucinations: A Case Study on Domain-Specific Queries in Private Knowledge-Bases](2024年03月15日/Enhancing_LLM_Factual_Accuracy_with_RAG_to_Counter_Hallucinations_A_Case_Study_on_Domain-Specific_Queries_in_Private_Knowledge-Bases.md)

    - [翻译: 为解决LLM在处理特定领域查询时可能出现的虚构问题，本研究运用RAG技术提升其在私有知识库上的事实准确性，并进行了深入案例分析。](2024年03月15日/Enhancing_LLM_Factual_Accuracy_with_RAG_to_Counter_Hallucinations_A_Case_Study_on_Domain-Specific_Queries_in_Private_Knowledge-Bases.md)

- [Optimal Block-Level Draft Verification for Accelerating Speculative Decoding](2024年03月15日/Optimal_Block-Level_Draft_Verification_for_Accelerating_Speculative_Decoding.md)

    - [翻译: 为加快推测性解码的速度，我们提出了一种针对块级草稿的最优验证方法。](2024年03月15日/Optimal_Block-Level_Draft_Verification_for_Accelerating_Speculative_Decoding.md)

- [Using an LLM to Turn Sign Spottings into Spoken Language Sentences](2024年03月15日/Using_an_LLM_to_Turn_Sign_Spottings_into_Spoken_Language_Sentences.md)

    - [翻译: 通过运用 LLM 技术，我们可以将手语识别直接转化为流畅的口语句子。](2024年03月15日/Using_an_LLM_to_Turn_Sign_Spottings_into_Spoken_Language_Sentences.md)

- [How to train your ears: Auditory-model emulation for large-dynamic-range inputs and mild-to-severe hearing losses](2024年03月15日/How_to_train_your_ears_Auditory-model_emulation_for_large-dynamic-range_inputs_and_mild-to-severe_hearing_losses.md)

    - [翻译: 本研究探讨如何通过模拟听觉模型，有效提升对大动态范围声音输入以及应对轻度至重度听力损失情况下的听力理解能力。](2024年03月15日/How_to_train_your_ears_Auditory-model_emulation_for_large-dynamic-range_inputs_and_mild-to-severe_hearing_losses.md)

- [SocialGenPod: Privacy-Friendly Generative AI Social Web Applications with Decentralised Personal Data Stores](2024年03月15日/SocialGenPod_Privacy-Friendly_Generative_AI_Social_Web_Applications_with_Decentralised_Personal_Data_Stores.md)

    - [翻译: SocialGenPod 是一款注重隐私保护的生成式 AI 社交网络应用，它利用去中心化的个人数据存储技术。这款应用致力于在保障用户隐私的同时，提供基于 AI 的创新社交体验。](2024年03月15日/SocialGenPod_Privacy-Friendly_Generative_AI_Social_Web_Applications_with_Decentralised_Personal_Data_Stores.md)

- [A Thorough Comparison of Cross-Encoders and LLMs for Reranking SPLADE](2024年03月15日/A_Thorough_Comparison_of_Cross-Encoders_and_LLMs_for_Reranking_SPLADE.md)

    - [翻译: 为了重新排名 SPLADE 系统，我们深入对比了跨编码器与大型语言模型在该任务中的性能表现。](2024年03月15日/A_Thorough_Comparison_of_Cross-Encoders_and_LLMs_for_Reranking_SPLADE.md)

- [TriSum: Learning Summarization Ability from Large Language Models with Structured Rationale](2024年03月15日/TriSum_Learning_Summarization_Ability_from_Large_Language_Models_with_Structured_Rationale.md)

    - [翻译: TriSum 方法致力于在大型语言模型中汲取摘要能力，借助结构化的推理方式实现这一目标。进一步细化步骤2的翻译：TriSum 是一项研究，它探索如何利用大型语言模型中的结构化推理机制来培养和提升文本摘要能力。](2024年03月15日/TriSum_Learning_Summarization_Ability_from_Large_Language_Models_with_Structured_Rationale.md)

- [Uni-SMART: Universal Science Multimodal Analysis and Research Transformer](2024年03月15日/Uni-SMART_Universal_Science_Multimodal_Analysis_and_Research_Transformer.md)

    - [翻译: Uni-SMART 是一款致力于科学领域多模态数据分析与研究的通用Transformer模型。步骤解释：1. 直译：Uni-SMART 这个术语保持不变，"Universal Science Multimodal Analysis and Research Transformer" 翻译为“通用科学多模态分析与研究Transformer”，确保了专业术语的准确传达。2. 优化：在直译的基础上，简化并调整语序以符合中文表达习惯，使整体表述更加流畅、易懂，同时强调了Uni-SMART模型在科学领域多模态数据分析与研究方面的应用特点。](2024年03月15日/Uni-SMART_Universal_Science_Multimodal_Analysis_and_Research_Transformer.md)

- [Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning](2024年03月15日/Team_Trifecta_at_Factify5WQA_Setting_the_Standard_in_Fact_Verification_with_Fine-Tuning.md)

    - [翻译: Team Trifecta 在 Factify5WQA 项目中以微调技术树立了事实核查的新标杆](2024年03月15日/Team_Trifecta_at_Factify5WQA_Setting_the_Standard_in_Fact_Verification_with_Fine-Tuning.md)

- [A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption](2024年03月15日/A_Question_on_the_Explainability_of_Large_Language_Models_and_the_Word-Level_Univariate_First-Order_Plausibility_Assumption.md)

    - [翻译: 探究大型语言模型的可解释性难题，及其涉及词级别的单变量一阶合理性假设](2024年03月15日/A_Question_on_the_Explainability_of_Large_Language_Models_and_the_Word-Level_Univariate_First-Order_Plausibility_Assumption.md)

- [DSP: Dynamic Sequence Parallelism for Multi-Dimensional Transformers](2024年03月15日/DSP_Dynamic_Sequence_Parallelism_for_Multi-Dimensional_Transformers.md)

    - [翻译: DSP技术为多维变换器引入了动态序列并行机制，旨在优化处理效率和性能。](2024年03月15日/DSP_Dynamic_Sequence_Parallelism_for_Multi-Dimensional_Transformers.md)

- [Is Translation All You Need? A Study on Solving Multilingual Tasks with Large Language Models](2024年03月15日/Is_Translation_All_You_Need_A_Study_on_Solving_Multilingual_Tasks_with_Large_Language_Models.md)

    - [翻译: 是否只需运用翻译即可应对各类多语言任务？本研究探讨了通过大型语言模型解决此类任务的可能性。](2024年03月15日/Is_Translation_All_You_Need_A_Study_on_Solving_Multilingual_Tasks_with_Large_Language_Models.md)

- [A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges](2024年03月15日/A_Survey_on_Game_Playing_Agents_and_Large_Models_Methods,_Applications,_and_Challenges.md)

    - [翻译: 本研究综述了游戏智能体和大型模型的研究进展，探讨了各类方法、应用场景以及面临的挑战。](2024年03月15日/A_Survey_on_Game_Playing_Agents_and_Large_Models_Methods,_Applications,_and_Challenges.md)

- [CoLeCLIP: Open-Domain Continual Learning via Joint Task Prompt and Vocabulary Learning](2024年03月15日/CoLeCLIP_Open-Domain_Continual_Learning_via_Joint_Task_Prompt_and_Vocabulary_Learning.md)

    - [翻译: CoLeCLIP 是一种创新方法，通过结合任务提示与词汇学习技术，在开放领域内实现持续学习能力。](2024年03月15日/CoLeCLIP_Open-Domain_Continual_Learning_via_Joint_Task_Prompt_and_Vocabulary_Learning.md)

- [HawkEye: Training Video-Text LLMs for Grounding Text in Videos](2024年03月15日/HawkEye_Training_Video-Text_LLMs_for_Grounding_Text_in_Videos.md)

    - [翻译: HawkEye项目致力于训练能够将文本内容有效定位到对应视频片段的视频-文本大型语言模型。](2024年03月15日/HawkEye_Training_Video-Text_LLMs_for_Grounding_Text_in_Videos.md)

- [Read between the lines -- Functionality Extraction From READMEs](2024年03月15日/Read_between_the_lines_--_Functionality_Extraction_From_READMEs.md)

    - [翻译: 深入研读README，挖掘其中隐含的功能信息](2024年03月15日/Read_between_the_lines_--_Functionality_Extraction_From_READMEs.md)

- [Generative Region-Language Pretraining for Open-Ended Object Detection](2024年03月15日/Generative_Region-Language_Pretraining_for_Open-Ended_Object_Detection.md)

    - [翻译: 为了解决开放式物体检测的挑战，我们提出了一种“生成区域-语言预训练”方法。该技术旨在通过联合学习图像区域特征与相关描述性语言表达，以实现更强大、更具开放性的物体检测能力。](2024年03月15日/Generative_Region-Language_Pretraining_for_Open-Ended_Object_Detection.md)

- [AUTONODE: A Neuro-Graphic Self-Learnable Engine for Cognitive GUI Automation](2024年03月15日/AUTONODE_A_Neuro-Graphic_Self-Learnable_Engine_for_Cognitive_GUI_Automation.md)

    - [翻译: AUTONODE——一款面向认知GUI自动化的自我学习型神经图形引擎](2024年03月15日/AUTONODE_A_Neuro-Graphic_Self-Learnable_Engine_for_Cognitive_GUI_Automation.md)

- [Improving Medical Multi-modal Contrastive Learning with Expert Annotations](2024年03月15日/Improving_Medical_Multi-modal_Contrastive_Learning_with_Expert_Annotations.md)

    - [翻译: 借助专家标注优化医疗多模态对比学习技术，提升模型性能和准确性。](2024年03月15日/Improving_Medical_Multi-modal_Contrastive_Learning_with_Expert_Annotations.md)

- [The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation](2024年03月15日/The_Whole_is_Better_than_the_Sum_Using_Aggregated_Demonstrations_in_In-Context_Learning_for_Sequential_Recommendation.md)

    - [翻译: 整体胜于局部：本研究探讨将聚合演示应用于序列推荐任务的上下文学习，以期实现超越单个示例之和的效果。](2024年03月15日/The_Whole_is_Better_than_the_Sum_Using_Aggregated_Demonstrations_in_In-Context_Learning_for_Sequential_Recommendation.md)

- [RAFT: Adapting Language Model to Domain Specific RAG](2024年03月15日/RAFT_Adapting_Language_Model_to_Domain_Specific_RAG.md)

    - [翻译: RAFT 方法致力于让语言模型更好地适应特定领域的 RAG。](2024年03月15日/RAFT_Adapting_Language_Model_to_Domain_Specific_RAG.md)

- [Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning](2024年03月15日/Enhancing_Human-Centered_Dynamic_Scene_Understanding_via_Multiple_LLMs_Collaborated_Reasoning.md)

    - [翻译: 通过多台 LLM（大型语言模型）协同推理的方式，提升对以人类为中心的动态场景理解能力进一步优化后的](2024年03月15日/Enhancing_Human-Centered_Dynamic_Scene_Understanding_via_Multiple_LLMs_Collaborated_Reasoning.md)

- [Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties](2024年03月15日/Large_Language_Models_to_Generate_System-Level_Test_Programs_Targeting_Non-functional_Properties.md)

    - [翻译: 我们探索利用大型语言模型来创作针对非功能性属性的系统级测试程序，旨在通过智能化手段提升软件质量保障效能。](2024年03月15日/Large_Language_Models_to_Generate_System-Level_Test_Programs_Targeting_Non-functional_Properties.md)

- [CrossGLG: LLM Guides One-shot Skeleton-based 3D Action Recognition in a Cross-level Manner](2024年03月15日/CrossGLG_LLM_Guides_One-shot_Skeleton-based_3D_Action_Recognition_in_a_Cross-level_Manner.md)

    - [翻译: CrossGLG 是一种创新方法，利用大型语言模型（LLM）以跨层次的方式实现仅通过一次示例就能指导基于骨架的3D动作识别。](2024年03月15日/CrossGLG_LLM_Guides_One-shot_Skeleton-based_3D_Action_Recognition_in_a_Cross-level_Manner.md)

- [DRAGIN: Dynamic Retrieval Augmented Generation based on the Real-time Information Needs of Large Language Models](2024年03月15日/DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Real-time_Information_Needs_of_Large_Language_Models.md)

    - [翻译: DRAGIN 是一项创新技术，它依据大型语言模型的实际信息需求进行动态检索增强生成。这项技术能够实时捕捉并满足LLM在生成过程中的信息需求，从而提升其表现力和准确性。](2024年03月15日/DRAGIN_Dynamic_Retrieval_Augmented_Generation_based_on_the_Real-time_Information_Needs_of_Large_Language_Models.md)

- [Codebook Transfer with Part-of-Speech for Vector-Quantized Image Modeling](2024年03月15日/Codebook_Transfer_with_Part-of-Speech_for_Vector-Quantized_Image_Modeling.md)

    - [翻译: 在向量量化图像模型中，我们引入了一种结合词性标签进行码本迁移的方法。这一技术旨在优化码本在不同场景下的表现，特别是在向量量化图像建模任务中。](2024年03月15日/Codebook_Transfer_with_Part-of-Speech_for_Vector-Quantized_Image_Modeling.md)

- [Repoformer: Selective Retrieval for Repository-Level Code Completion](2024年03月15日/Repoformer_Selective_Retrieval_for_Repository-Level_Code_Completion.md)

    - [翻译: Repoformer，一种专为仓库级别代码补全设计的选择性检索技术，旨在提升代码补全任务的效果和精准度。](2024年03月15日/Repoformer_Selective_Retrieval_for_Repository-Level_Code_Completion.md)

- [Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning](2024年03月15日/Don't_Half-listen_Capturing_Key-part_Information_in_Continual_Instruction_Tuning.md)

    - [翻译: 切勿一知半解：在连续指令调优过程中精准捕获关键信息要素](2024年03月15日/Don't_Half-listen_Capturing_Key-part_Information_in_Continual_Instruction_Tuning.md)

- [TextBlockV2: Towards Precise-Detection-Free Scene Text Spotting with Pre-trained Language Model](2024年03月15日/TextBlockV2_Towards_Precise-Detection-Free_Scene_Text_Spotting_with_Pre-trained_Language_Model.md)

    - [翻译: TextBlockV2：迈向基于预训练语言模型、无需精细检测的精准场景文字识别技术](2024年03月15日/TextBlockV2_Towards_Precise-Detection-Free_Scene_Text_Spotting_with_Pre-trained_Language_Model.md)

- [Knowledge Condensation and Reasoning for Knowledge-based VQA](2024年03月15日/Knowledge_Condensation_and_Reasoning_for_Knowledge-based_VQA.md)

    - [翻译: 在知识驱动的视觉问答（VQA）中，知识提炼与推理技术发挥着关键作用。该研究专注于如何有效地整合和提炼相关知识，并运用高级推理方法以提升 VQA 的准确性和智能性。](2024年03月15日/Knowledge_Condensation_and_Reasoning_for_Knowledge-based_VQA.md)

- [Lost in Overlap: Exploring Watermark Collision in LLMs](2024年03月15日/Lost_in_Overlap_Exploring_Watermark_Collision_in_LLMs.md)

    - [翻译: 探究 LLMS 中的水印碰撞现象，揭示隐藏在模型重叠区域的奥秘。](2024年03月15日/Lost_in_Overlap_Exploring_Watermark_Collision_in_LLMs.md)

- [Language to Map: Topological map generation from natural language path instructions](2024年03月15日/Language_to_Map_Topological_map_generation_from_natural_language_path_instructions.md)

    - [翻译: 将语言指令转化为地图：探究如何从自然语言路径指示中生成拓扑地图](2024年03月15日/Language_to_Map_Topological_map_generation_from_natural_language_path_instructions.md)

- [Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study](2024年03月15日/Benchmarking_Zero-Shot_Robustness_of_Multimodal_Foundation_Models_A_Pilot_Study.md)

    - [翻译: 本研究作为一项先导性探索，致力于对多模态基础模型在零样本条件下的鲁棒性进行基准评估。](2024年03月15日/Benchmarking_Zero-Shot_Robustness_of_Multimodal_Foundation_Models_A_Pilot_Study.md)

- [Emotion-Aware Multimodal Fusion for Meme Emotion Detection](2024年03月15日/Emotion-Aware_Multimodal_Fusion_for_Meme_Emotion_Detection.md)

    - [翻译: 为了提升表情包情感检测的准确性，我们提出了一种情绪感知的多模态融合方法，通过深度融合图像与文本信息，精准捕捉表情包中蕴含的情感色彩。](2024年03月15日/Emotion-Aware_Multimodal_Fusion_for_Meme_Emotion_Detection.md)