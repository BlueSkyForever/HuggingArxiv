# NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试

发布时间：2024年03月18日

`LLM应用` `文本理解`

> NovelQA: A Benchmark for Long-Range Novel Question Answering

> 随着LLMs的飞速发展，自然语言处理的新纪元已开启，尤其是在理解和处理长篇幅语境信息方面。然而，受限于当前评估标准，衡量此类模型的长篇处理能力仍面临困难。为此，我们创新推出了NovelQA——一个专为检测LLMs处理长篇文本能力而设计的基准测试平台。该平台基于英文小说构建，以其独特的复杂度、篇幅及叙述连贯性相结合的特点，成为了检验LLMs深层次文本理解的理想之选。本文详述了NovelQA的设计与构造方法，着重展示了人工标注工作与多元化的题目类型。通过在NovelQA上对长篇LLMs进行评估，我们获得了深入洞见，尤其凸显了模型在多级推理、细粒度问题解答以及面对超10万字符以上的极端长输入时所面临的难题。这些发现有力证明了深化LLMs的长篇理解能力和推动计算文学研究进步的重要性。

> The rapid advancement of Large Language Models (LLMs) has introduced a new frontier in natural language processing, particularly in understanding and processing long-context information. However, the evaluation of these models' long-context abilities remains a challenge due to the limitations of current benchmarks. To address this gap, we introduce NovelQA, a benchmark specifically designed to test the capabilities of LLMs with extended texts. Constructed from English novels, NovelQA offers a unique blend of complexity, length, and narrative coherence, making it an ideal tool for assessing deep textual understanding in LLMs. This paper presents the design and construction of NovelQA, highlighting its manual annotation, and diverse question types. Our evaluation of Long-context LLMs on NovelQA reveals significant insights into the models' performance, particularly emphasizing the challenges they face with multi-hop reasoning, detail-oriented questions, and extremely long input with more than 100,000 tokens. The results underscore the necessity for further advancements in LLMs to improve their long-context comprehension and computational literary studies.

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x1.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x2.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x3.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x4.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x5.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x6.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x7.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x8.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x9.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x10.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x11.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x12.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x13.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x14.png)

![NovelQA，一项专注于长篇文本中复杂新颖问题解答能力的权威基准测试](../../../paper_images/2403.12766/x15.png)

[Arxiv](https://arxiv.org/abs/2403.12766)