# 面对大型语言模型的安全挑战，本文探讨了潜在的威胁和漏洞，并提出了实施负责任安全实践的重要性。

发布时间：2024年03月19日

`LLM理论` `安全与隐私`

> Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices

> LLMs在NLP领域掀起了一场变革，对多样化的任务产生深远影响，颠覆了我们对语言理解与生成的传统认知。但同时，它们也带来了不容忽视的安全与风险问题。为实现负责任的部署并防范潜在隐患，有必要细致探究这些问题。本文全面审视了LLMs从五个核心视角所涉及的安全与隐私议题，包括对抗攻击下的弱点、LLMs误用可能引发的危害，以及当前应对策略的局限性，并在此基础上提出改进措施。最终，本文建议未来的研究应聚焦于哪些途径，以增强LLMs的安全防护与风险管理能力。

> Large language models (LLMs) have significantly transformed the landscape of Natural Language Processing (NLP). Their impact extends across a diverse spectrum of tasks, revolutionizing how we approach language understanding and generations. Nevertheless, alongside their remarkable utility, LLMs introduce critical security and risk considerations. These challenges warrant careful examination to ensure responsible deployment and safeguard against potential vulnerabilities. This research paper thoroughly investigates security and privacy concerns related to LLMs from five thematic perspectives: security and privacy concerns, vulnerabilities against adversarial attacks, potential harms caused by misuses of LLMs, mitigation strategies to address these challenges while identifying limitations of current strategies. Lastly, the paper recommends promising avenues for future research to enhance the security and risk management of LLMs.

![面对大型语言模型的安全挑战，本文探讨了潜在的威胁和漏洞，并提出了实施负责任安全实践的重要性。](../../../paper_images/2403.12503/x1.png)

[Arxiv](https://arxiv.org/abs/2403.12503)