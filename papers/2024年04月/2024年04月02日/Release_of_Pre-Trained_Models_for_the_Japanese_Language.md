# 日语预训练模型现已发布。

发布时间：2024年04月02日

`LLM应用` `日语处理` `人工智能普及`

> Release of Pre-Trained Models for the Japanese Language

# 摘要

> 人工智能的普及目标是让每个人都能轻松使用AI技术。许多研究机构为了让研究成果惠及大众，做出了巨大努力。尤其是那些基于海量数据训练的大型预训练模型，展现了惊人的潜力，它们的推出对社会产生了深远的影响。然而，目前大多数模型都偏重于英语，导致非英语区域在AI普及上的步伐相对缓慢。为了缩小这一差距，我们推出了日语版本的GPT、CLIP、稳定扩散模型和HuBERT等预训练模型。这些模型让使用者能够与贴近日本文化、保护日本文化特色的AI无缝互动，进而推动AI在日本的普及。实验也证明，这些专为日语定制的预训练模型在日本相关任务上能够带来丰富的成果。

> AI democratization aims to create a world in which the average person can utilize AI techniques. To achieve this goal, numerous research institutes have attempted to make their results accessible to the public. In particular, large pre-trained models trained on large-scale data have shown unprecedented potential, and their release has had a significant impact. However, most of the released models specialize in the English language, and thus, AI democratization in non-English-speaking communities is lagging significantly. To reduce this gap in AI access, we released Generative Pre-trained Transformer (GPT), Contrastive Language and Image Pre-training (CLIP), Stable Diffusion, and Hidden-unit Bidirectional Encoder Representations from Transformers (HuBERT) pre-trained in Japanese. By providing these models, users can freely interface with AI that aligns with Japanese cultural values and ensures the identity of Japanese culture, thus enhancing the democratization of AI. Additionally, experiments showed that pre-trained models specialized for Japanese can efficiently achieve high performance in Japanese tasks.

![日语预训练模型现已发布。](../../../paper_images/2404.01657/x1.png)

![日语预训练模型现已发布。](../../../paper_images/2404.01657/x2.png)

![日语预训练模型现已发布。](../../../paper_images/2404.01657/x3.png)

[Arxiv](https://arxiv.org/abs/2404.01657)