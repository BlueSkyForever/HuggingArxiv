# 2024年04月

2024年04月17日

- [Single-temporal Supervised Remote Change Detection for Domain Generalization](2024年04月17日/Single-temporal_Supervised_Remote_Change_Detection_for_Domain_Generalization.md)

    - [翻译: 在领域泛化中，单时相的遥感变化检测技术得到了监督学习的应用。](2024年04月17日/Single-temporal_Supervised_Remote_Change_Detection_for_Domain_Generalization.md)

- [Exploring the Transferability of Visual Prompting for Multimodal Large Language Models](2024年04月17日/Exploring_the_Transferability_of_Visual_Prompting_for_Multimodal_Large_Language_Models.md)

    - [翻译: 本文旨在探究多模态大型语言模型中视觉提示的迁移能力。](2024年04月17日/Exploring_the_Transferability_of_Visual_Prompting_for_Multimodal_Large_Language_Models.md)

2024年04月16日

- [Construction of Domain-specified Japanese Large Language Model for Finance through Continual Pre-training](2024年04月16日/Construction_of_Domain-specified_Japanese_Large_Language_Model_for_Finance_through_Continual_Pre-training.md)

    - [翻译: 本研究旨在通过持续预训练的方法，打造一款专门针对金融领域的日语大型语言模型。](2024年04月16日/Construction_of_Domain-specified_Japanese_Large_Language_Model_for_Finance_through_Continual_Pre-training.md)

- [Unveiling the Misuse Potential of Base Large Language Models via In-Context Learning](2024年04月16日/Unveiling_the_Misuse_Potential_of_Base_Large_Language_Models_via_In-Context_Learning.md)

    - [翻译: 借助上下文学习，探究基础大型语言模型潜在的滥用风险](2024年04月16日/Unveiling_the_Misuse_Potential_of_Base_Large_Language_Models_via_In-Context_Learning.md)

- [CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity](2024年04月16日/CoTAR_Chain-of-Thought_Attribution_Reasoning_with_Multi-level_Granularity.md)

    - [翻译: CoTAR：采用多级细节的思考路径归因分析](2024年04月16日/CoTAR_Chain-of-Thought_Attribution_Reasoning_with_Multi-level_Granularity.md)

- [White Men Lead, Black Women Help: Uncovering Gender, Racial, and Intersectional Bias in Language Agency](2024年04月16日/White_Men_Lead,_Black_Women_Help_Uncovering_Gender,_Racial,_and_Intersectional_Bias_in_Language_Agency.md)

    - [翻译: 白人男性主导，黑人女性助力：揭秘语言代理中的性别、种族及交叉性偏见。](2024年04月16日/White_Men_Lead,_Black_Women_Help_Uncovering_Gender,_Racial,_and_Intersectional_Bias_in_Language_Agency.md)

- [When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical Paradigm](2024年04月16日/When_Emotional_Stimuli_meet_Prompt_Designing_An_Auto-Prompt_Graphical_Paradigm.md)

    - [翻译: 情感刺激与提示设计相遇：探索自动生成提示的图形化方法](2024年04月16日/When_Emotional_Stimuli_meet_Prompt_Designing_An_Auto-Prompt_Graphical_Paradigm.md)

- [Spiral of Silences: How is Large Language Model Killing Information Retrieval? -- A Case Study on Open Domain Question Answering](2024年04月16日/Spiral_of_Silences_How_is_Large_Language_Model_Killing_Information_Retrieval_--_A_Case_Study_on_Open_Domain_Question_Answering.md)

    - [翻译: 沉默螺旋：大型语言模型如何影响信息检索？以开放领域问答为案例进行探讨。](2024年04月16日/Spiral_of_Silences_How_is_Large_Language_Model_Killing_Information_Retrieval_--_A_Case_Study_on_Open_Domain_Question_Answering.md)

- [DESTEIN: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion](2024年04月16日/DESTEIN_Navigating_Detoxification_of_Language_Models_via_Universal_Steering_Pairs_and_Head-wise_Activation_Fusion.md)

    - [翻译: DESTEIN：利用通用指令对和逐步激活整合技术引导语言模型净化之旅](2024年04月16日/DESTEIN_Navigating_Detoxification_of_Language_Models_via_Universal_Steering_Pairs_and_Head-wise_Activation_Fusion.md)

- [MEEL: Multi-Modal Event Evolution Learning](2024年04月16日/MEEL_Multi-Modal_Event_Evolution_Learning.md)

    - [翻译: MEEL 代表多模态事件演化学习，这是一种结合多种数据形式以更好地理解和学习事件发展过程的方法。](2024年04月16日/MEEL_Multi-Modal_Event_Evolution_Learning.md)

- [VDTuner: Automated Performance Tuning for Vector Data Management Systems](2024年04月16日/VDTuner_Automated_Performance_Tuning_for_Vector_Data_Management_Systems.md)

    - [翻译: VDTuner：自动优化向量数据管理系统的性能](2024年04月16日/VDTuner_Automated_Performance_Tuning_for_Vector_Data_Management_Systems.md)

- [Reasoning on Efficient Knowledge Paths:Knowledge Graph Guides Large Language Model for Domain Question Answering](2024年04月16日/Reasoning_on_Efficient_Knowledge_PathsKnowledge_Graph_Guides_Large_Language_Model_for_Domain_Question_Answering.md)

    - [翻译: 高效知识路径推理：知识图谱助力大型语言模型解答领域问题](2024年04月16日/Reasoning_on_Efficient_Knowledge_PathsKnowledge_Graph_Guides_Large_Language_Model_for_Domain_Question_Answering.md)

- [Self-Explore to Avoid the Pit: Improving the Reasoning Capabilities of Language Models with Fine-grained Rewards](2024年04月16日/Self-Explore_to_Avoid_the_Pit_Improving_the_Reasoning_Capabilities_of_Language_Models_with_Fine-grained_Rewards.md)

    - [翻译: 探索自救，远离陷阱：利用精细奖励机制增强语言模型的推理能力](2024年04月16日/Self-Explore_to_Avoid_the_Pit_Improving_the_Reasoning_Capabilities_of_Language_Models_with_Fine-grained_Rewards.md)

- [Efficiently Adversarial Examples Generation for Visual-Language Models under Targeted Transfer Scenarios using Diffusion Models](2024年04月16日/Efficiently_Adversarial_Examples_Generation_for_Visual-Language_Models_under_Targeted_Transfer_Scenarios_using_Diffusion_Models.md)

    - [翻译: 针对特定目标转移情境，本研究利用扩散模型，探索了一种高效的生成视觉-语言模型对抗样本的方法。](2024年04月16日/Efficiently_Adversarial_Examples_Generation_for_Visual-Language_Models_under_Targeted_Transfer_Scenarios_using_Diffusion_Models.md)

- [Prescribing the Right Remedy: Mitigating Hallucinations in Large Vision-Language Models via Targeted Instruction Tuning](2024年04月16日/Prescribing_the_Right_Remedy_Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_Targeted_Instruction_Tuning.md)

    - [翻译: 对症下药：通过针对性指令调整，缓解大型视觉-语言模型中的幻觉问题](2024年04月16日/Prescribing_the_Right_Remedy_Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_Targeted_Instruction_Tuning.md)

- [Towards Complex Ontology Alignment using Large Language Models](2024年04月16日/Towards_Complex_Ontology_Alignment_using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现复杂本体的精准对齐](2024年04月16日/Towards_Complex_Ontology_Alignment_using_Large_Language_Models.md)

- [Exact and Efficient Unlearning for Large Language Model-based Recommendation](2024年04月16日/Exact_and_Efficient_Unlearning_for_Large_Language_Model-based_Recommendation.md)

    - [翻译: 在大型语言模型驱动的推荐系统中，实现精确而高效的“忘却”机制显得尤为关键。](2024年04月16日/Exact_and_Efficient_Unlearning_for_Large_Language_Model-based_Recommendation.md)

- [LLMs4OM: Matching Ontologies with Large Language Models](2024年04月16日/LLMs4OM_Matching_Ontologies_with_Large_Language_Models.md)

    - [翻译: LLMs4OM：借助大型语言模型实现本体匹配](2024年04月16日/LLMs4OM_Matching_Ontologies_with_Large_Language_Models.md)

- [Enhancing Confidence Expression in Large Language Models Through Learning from Past Experience](2024年04月16日/Enhancing_Confidence_Expression_in_Large_Language_Models_Through_Learning_from_Past_Experience.md)

    - [翻译: 本研究探讨了如何通过借鉴历史经验，增强大型语言模型在表达信心方面的能力。](2024年04月16日/Enhancing_Confidence_Expression_in_Large_Language_Models_Through_Learning_from_Past_Experience.md)

- [Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs](2024年04月16日/Hierarchical_Context_Merging_Better_Long_Context_Understanding_for_Pre-trained_LLMs.md)

    - [翻译: 通过层级上下文融合，我们能够提升预训练大型语言模型对长篇幅上下文的把握与理解能力。](2024年04月16日/Hierarchical_Context_Merging_Better_Long_Context_Understanding_for_Pre-trained_LLMs.md)

- [Balancing Speciality and Versatility: a Coarse to Fine Framework for Supervised Fine-tuning Large Language Model](2024年04月16日/Balancing_Speciality_and_Versatility_a_Coarse_to_Fine_Framework_for_Supervised_Fine-tuning_Large_Language_Model.md)

    - [翻译: 为了兼顾专业性与通用性，本文提出了一种由粗到细的监督微调框架，旨在优化大型语言模型的性能。](2024年04月16日/Balancing_Speciality_and_Versatility_a_Coarse_to_Fine_Framework_for_Supervised_Fine-tuning_Large_Language_Model.md)

- [LLM-Powered Test Case Generation for Detecting Tricky Bugs](2024年04月16日/LLM-Powered_Test_Case_Generation_for_Detecting_Tricky_Bugs.md)

    - [翻译: 借助大型语言模型（LLM）的力量，我们能够生成测试用例来捕捉那些难以发现的软件缺陷。](2024年04月16日/LLM-Powered_Test_Case_Generation_for_Detecting_Tricky_Bugs.md)

- [Nearly Optimal Algorithms for Contextual Dueling Bandits from Adversarial Feedback](2024年04月16日/Nearly_Optimal_Algorithms_for_Contextual_Dueling_Bandits_from_Adversarial_Feedback.md)

    - [翻译: 通过对抗性反馈优化的情境对决强盗算法接近最优解](2024年04月16日/Nearly_Optimal_Algorithms_for_Contextual_Dueling_Bandits_from_Adversarial_Feedback.md)

- [Deep Learning and LLM-based Methods Applied to Stellar Lightcurve Classification](2024年04月16日/Deep_Learning_and_LLM-based_Methods_Applied_to_Stellar_Lightcurve_Classification.md)

    - [翻译: 深度学习与基于大型语言模型的技术在恒星光变曲线的分类上得到了应用。](2024年04月16日/Deep_Learning_and_LLM-based_Methods_Applied_to_Stellar_Lightcurve_Classification.md)

- [Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study](2024年04月16日/Is_DPO_Superior_to_PPO_for_LLM_Alignment_A_Comprehensive_Study.md)

    - [翻译: 在大型语言模型 (LLM) 对齐方面，DPO 是否超越了 PPO？本研究进行了深入全面的比较分析。](2024年04月16日/Is_DPO_Superior_to_PPO_for_LLM_Alignment_A_Comprehensive_Study.md)

- [An empirical study on code review activity prediction in practice](2024年04月16日/An_empirical_study_on_code_review_activity_prediction_in_practice.md)

    - [翻译: 实际应用中对代码审查活动进行预测的经验性研究](2024年04月16日/An_empirical_study_on_code_review_activity_prediction_in_practice.md)

- [Automating REST API Postman Test Cases Using LLM](2024年04月16日/Automating_REST_API_Postman_Test_Cases_Using_LLM.md)

    - [翻译: 借助大型语言模型 (LLM)，我们可以实现 REST API Postman 测试用例的自动化，从而提高测试效率和准确性。](2024年04月16日/Automating_REST_API_Postman_Test_Cases_Using_LLM.md)

- [ViTextVQA: A Large-Scale Visual Question Answering Dataset for Evaluating Vietnamese Text Comprehension in Images](2024年04月16日/ViTextVQA_A_Large-Scale_Visual_Question_Answering_Dataset_for_Evaluating_Vietnamese_Text_Comprehension_in_Images.md)

    - [翻译: ViTextVQA：一套大型视觉问答数据集，旨在评估图像中的越南文理解能力。](2024年04月16日/ViTextVQA_A_Large-Scale_Visual_Question_Answering_Dataset_for_Evaluating_Vietnamese_Text_Comprehension_in_Images.md)

- [Self-playing Adversarial Language Game Enhances LLM Reasoning](2024年04月16日/Self-playing_Adversarial_Language_Game_Enhances_LLM_Reasoning.md)

    - [翻译: 通过自我对弈的对抗性语言游戏，有效提升了大型语言模型的推理水平。](2024年04月16日/Self-playing_Adversarial_Language_Game_Enhances_LLM_Reasoning.md)

- [HLAT: High-quality Large Language Model Pre-trained on AWS Trainium](2024年04月16日/HLAT_High-quality_Large_Language_Model_Pre-trained_on_AWS_Trainium.md)

    - [翻译: HLAT：依托 AWS Trainium 打造的高品质大型语言模型](2024年04月16日/HLAT_High-quality_Large_Language_Model_Pre-trained_on_AWS_Trainium.md)

- [Private Attribute Inference from Images with Vision-Language Models](2024年04月16日/Private_Attribute_Inference_from_Images_with_Vision-Language_Models.md)

    - [翻译: 通过视觉-语言模型从图像中推断个人隐私属性](2024年04月16日/Private_Attribute_Inference_from_Images_with_Vision-Language_Models.md)

- [Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases](2024年04月16日/Automated_Evaluation_of_Large_Vision-Language_Models_on_Self-driving_Corner_Cases.md)

    - [翻译: 本文探讨了如何对大型视觉-语言模型在自动驾驶领域的边缘案例中进行自动化评估。](2024年04月16日/Automated_Evaluation_of_Large_Vision-Language_Models_on_Self-driving_Corner_Cases.md)

- [MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents](2024年04月16日/MiniCheck_Efficient_Fact-Checking_of_LLMs_on_Grounding_Documents.md)

    - [翻译: MiniCheck：一种高效的事实核查工具，专为在基础文档上验证大型语言模型（LLMs）的准确性而设计。](2024年04月16日/MiniCheck_Efficient_Fact-Checking_of_LLMs_on_Grounding_Documents.md)

2024年04月15日

- [Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration](2024年04月15日/Harnessing_GPT-4V(ision)_for_Insurance_A_Preliminary_Exploration.md)

    - [翻译: 探索 GPT-4V(ision) 在保险领域的应用：一项初步研究](2024年04月15日/Harnessing_GPT-4V(ision)_for_Insurance_A_Preliminary_Exploration.md)

- [Bridging Vision and Language Spaces with Assignment Prediction](2024年04月15日/Bridging_Vision_and_Language_Spaces_with_Assignment_Prediction.md)

    - [翻译: 通过预测任务分配，架起视觉与语言之间的桥梁](2024年04月15日/Bridging_Vision_and_Language_Spaces_with_Assignment_Prediction.md)

- [AesExpert: Towards Multi-modality Foundation Model for Image Aesthetics Perception](2024年04月15日/AesExpert_Towards_Multi-modality_Foundation_Model_for_Image_Aesthetics_Perception.md)

    - [翻译: AesExpert：探索构建多模态基础模型，以提升图像美学感知能力。](2024年04月15日/AesExpert_Towards_Multi-modality_Foundation_Model_for_Image_Aesthetics_Perception.md)

- [MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems](2024年04月15日/MMCode_Evaluating_Multi-Modal_Code_Large_Language_Models_with_Visually_Rich_Programming_Problems.md)

    - [翻译: MMCode：利用视觉丰富的编程挑战，评估融合多模态信息的大型语言模型。](2024年04月15日/MMCode_Evaluating_Multi-Modal_Code_Large_Language_Models_with_Visually_Rich_Programming_Problems.md)

- [in2IN: Leveraging individual Information to Generate Human INteractions](2024年04月15日/in2IN_Leveraging_individual_Information_to_Generate_Human_INteractions.md)

    - [翻译: in2IN：借助个体信息打造真实人际互动体验](2024年04月15日/in2IN_Leveraging_individual_Information_to_Generate_Human_INteractions.md)

- [OneChart: Purify the Chart Structural Extraction via One Auxiliary Token](2024年04月15日/OneChart_Purify_the_Chart_Structural_Extraction_via_One_Auxiliary_Token.md)

    - [翻译: OneChart：利用单一辅助标记净化图表结构提取过程。](2024年04月15日/OneChart_Purify_the_Chart_Structural_Extraction_via_One_Auxiliary_Token.md)

- [Memory Sharing for Large Language Model based Agents](2024年04月15日/Memory_Sharing_for_Large_Language_Model_based_Agents.md)

    - [翻译: 在大型语言模型代理中，内存共享的策略得以运用。](2024年04月15日/Memory_Sharing_for_Large_Language_Model_based_Agents.md)

- [Context Does Matter: Implications for Crowdsourced Evaluation Labels in Task-Oriented Dialogue Systems](2024年04月15日/Context_Does_Matter_Implications_for_Crowdsourced_Evaluation_Labels_in_Task-Oriented_Dialogue_Systems.md)

    - [翻译: 上下文在任务导向对话系统的众包评估标签中具有重要意义。](2024年04月15日/Context_Does_Matter_Implications_for_Crowdsourced_Evaluation_Labels_in_Task-Oriented_Dialogue_Systems.md)

- [Constructing Benchmarks and Interventions for Combating Hallucinations in LLMs](2024年04月15日/Constructing_Benchmarks_and_Interventions_for_Combating_Hallucinations_in_LLMs.md)

    - [翻译: 为了对抗大型语言模型中的幻觉现象，我们正在构建一系列基准测试和干预策略。](2024年04月15日/Constructing_Benchmarks_and_Interventions_for_Combating_Hallucinations_in_LLMs.md)

- [Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization](2024年04月15日/Tango_2_Aligning_Diffusion-based_Text-to-Audio_Generations_through_Direct_Preference_Optimization.md)

    - [翻译: Tango 2：借助直接偏好优化技术，实现基于扩散模型的文本到音频生成精准对齐](2024年04月15日/Tango_2_Aligning_Diffusion-based_Text-to-Audio_Generations_through_Direct_Preference_Optimization.md)

- [LLMorpheus: Mutation Testing using Large Language Models](2024年04月15日/LLMorpheus_Mutation_Testing_using_Large_Language_Models.md)

    - [翻译: LLMorpheus：借助大型语言模型进行变异测试研究](2024年04月15日/LLMorpheus_Mutation_Testing_using_Large_Language_Models.md)

- [Knowledge-enhanced Visual-Language Pretraining for Computational Pathology](2024年04月15日/Knowledge-enhanced_Visual-Language_Pretraining_for_Computational_Pathology.md)

    - [翻译: 计算病理学领域中，通过知识增强的视觉-语言预训练方法，旨在提升模型的性能。](2024年04月15日/Knowledge-enhanced_Visual-Language_Pretraining_for_Computational_Pathology.md)

- [Evolving Interpretable Visual Classifiers with Large Language Models](2024年04月15日/Evolving_Interpretable_Visual_Classifiers_with_Large_Language_Models.md)

    - [翻译: 通过结合大型语言模型，我们不断优化和提升视觉分类器的可解释性。](2024年04月15日/Evolving_Interpretable_Visual_Classifiers_with_Large_Language_Models.md)

- [A Survey on Deep Learning for Theorem Proving](2024年04月15日/A_Survey_on_Deep_Learning_for_Theorem_Proving.md)

    - [翻译: 本文综述了深度学习在定理证明领域的研究进展。](2024年04月15日/A_Survey_on_Deep_Learning_for_Theorem_Proving.md)

- [Compression Represents Intelligence Linearly](2024年04月15日/Compression_Represents_Intelligence_Linearly.md)

    - [翻译: 压缩与智能之间呈现出线性的正相关性。](2024年04月15日/Compression_Represents_Intelligence_Linearly.md)

- [HOI-Ref: Hand-Object Interaction Referral in Egocentric Vision](2024年04月15日/HOI-Ref_Hand-Object_Interaction_Referral_in_Egocentric_Vision.md)

    - [翻译: HOI-Ref：自我视角视觉中的手部与物体互动参照](2024年04月15日/HOI-Ref_Hand-Object_Interaction_Referral_in_Egocentric_Vision.md)

- [Foundational Challenges in Assuring Alignment and Safety of Large Language Models](2024年04月15日/Foundational_Challenges_in_Assuring_Alignment_and_Safety_of_Large_Language_Models.md)

    - [翻译: 在确保大型语言模型的一致性和安全性方面，我们面临着根本性的挑战。](2024年04月15日/Foundational_Challenges_in_Assuring_Alignment_and_Safety_of_Large_Language_Models.md)

- [Zero-shot detection of buildings in mobile LiDAR using Language Vision Model](2024年04月15日/Zero-shot_detection_of_buildings_in_mobile_LiDAR_using_Language_Vision_Model.md)

    - [翻译: 借助语言视觉模型，实现移动激光雷达中建筑物的零次检测。](2024年04月15日/Zero-shot_detection_of_buildings_in_mobile_LiDAR_using_Language_Vision_Model.md)

- [Zero-shot Building Age Classification from Facade Image Using GPT-4](2024年04月15日/Zero-shot_Building_Age_Classification_from_Facade_Image_Using_GPT-4.md)

    - [翻译: 借助 GPT-4，我们能够直接从建筑立面图片中判断建筑的年代，无需事先了解具体建筑信息。](2024年04月15日/Zero-shot_Building_Age_Classification_from_Facade_Image_Using_GPT-4.md)

- [Glitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection](2024年04月15日/Glitch_Tokens_in_Large_Language_Models_Categorization_Taxonomy_and_Effective_Detection.md)

    - [翻译: 大型语言模型里，错误标记的分类及其检测策略。](2024年04月15日/Glitch_Tokens_in_Large_Language_Models_Categorization_Taxonomy_and_Effective_Detection.md)

- [Conditional Prototype Rectification Prompt Learning](2024年04月15日/Conditional_Prototype_Rectification_Prompt_Learning.md)

    - [翻译: 条件原型调整提示学习法](2024年04月15日/Conditional_Prototype_Rectification_Prompt_Learning.md)

- [AI-Driven Statutory Reasoning via Software Engineering Methods](2024年04月15日/AI-Driven_Statutory_Reasoning_via_Software_Engineering_Methods.md)

    - [翻译: 借助软件工程技术，实现人工智能推动的法定逻辑推理。](2024年04月15日/AI-Driven_Statutory_Reasoning_via_Software_Engineering_Methods.md)

- [Reimagining Self-Adaptation in the Age of Large Language Models](2024年04月15日/Reimagining_Self-Adaptation_in_the_Age_of_Large_Language_Models.md)

    - [翻译: 在大型语言模型时代，重新构想自我适应的概念](2024年04月15日/Reimagining_Self-Adaptation_in_the_Age_of_Large_Language_Models.md)

- [Anatomy of Industrial Scale Multilingual ASR](2024年04月15日/Anatomy_of_Industrial_Scale_Multilingual_ASR.md)

    - [翻译: 探究工业级多语言自动语音识别的内在机制](2024年04月15日/Anatomy_of_Industrial_Scale_Multilingual_ASR.md)

- [How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models](2024年04月15日/How_Far_Have_We_Gone_in_Stripped_Binary_Code_Understanding_Using_Large_Language_Models.md)

    - [翻译: 通过大型语言模型，我们在解析简化的二进制代码理解方面取得了哪些进展？](2024年04月15日/How_Far_Have_We_Gone_in_Stripped_Binary_Code_Understanding_Using_Large_Language_Models.md)

- [Benchmarking Llama2, Mistral, Gemma and GPT for Factuality, Toxicity, Bias and Propensity for Hallucinations](2024年04月15日/Benchmarking_Llama2,_Mistral,_Gemma_and_GPT_for_Factuality,_Toxicity,_Bias_and_Propensity_for_Hallucinations.md)

    - [翻译: 本研究旨在对Llama2、Mistral、Gemma以及GPT等模型进行综合评估，探究它们在事实准确性、有害内容产生、偏见表现以及产生幻觉文本的倾向上的差异性。](2024年04月15日/Benchmarking_Llama2,_Mistral,_Gemma_and_GPT_for_Factuality,_Toxicity,_Bias_and_Propensity_for_Hallucinations.md)

- [Language-Agnostic Modeling of Wikipedia Articles for Content Quality Assessment across Languages](2024年04月15日/Language-Agnostic_Modeling_of_Wikipedia_Articles_for_Content_Quality_Assessment_across_Languages.md)

    - [翻译: 本文提出了一种语言无关的方法，用于评估维基百科文章的内容质量，该方法适用于不同语言。](2024年04月15日/Language-Agnostic_Modeling_of_Wikipedia_Articles_for_Content_Quality_Assessment_across_Languages.md)

- [KG-CTG: Citation Generation through Knowledge Graph-guided Large Language Models](2024年04月15日/KG-CTG_Citation_Generation_through_Knowledge_Graph-guided_Large_Language_Models.md)

    - [翻译: KG-CTG：借助知识图谱引导的大型语言模型实现引文自动生成](2024年04月15日/KG-CTG_Citation_Generation_through_Knowledge_Graph-guided_Large_Language_Models.md)

- [Resilience of Large Language Models for Noisy Instructions](2024年04月15日/Resilience_of_Large_Language_Models_for_Noisy_Instructions.md)

    - [翻译: 大型语言模型在应对噪声指令时展现出的韧性](2024年04月15日/Resilience_of_Large_Language_Models_for_Noisy_Instructions.md)

- [Personalized Collaborative Fine-Tuning for On-Device Large Language Models](2024年04月15日/Personalized_Collaborative_Fine-Tuning_for_On-Device_Large_Language_Models.md)

    - [翻译: 针对移动设备的大型语言模型，采用个性化协同微调技术](2024年04月15日/Personalized_Collaborative_Fine-Tuning_for_On-Device_Large_Language_Models.md)

- [AMPCliff: quantitative definition and benchmarking of activity cliffs in antimicrobial peptides](2024年04月15日/AMPCliff_quantitative_definition_and_benchmarking_of_activity_cliffs_in_antimicrobial_peptides.md)

    - [翻译: AMPCliff 研究：为抗微生物肽中的活性差异设立定量标准，并进行性能基准评估](2024年04月15日/AMPCliff_quantitative_definition_and_benchmarking_of_activity_cliffs_in_antimicrobial_peptides.md)

- [Quantization of Large Language Models with an Overdetermined Basis](2024年04月15日/Quantization_of_Large_Language_Models_with_an_Overdetermined_Basis.md)

    - [翻译: 通过过定基数基实现大型语言模型的量化](2024年04月15日/Quantization_of_Large_Language_Models_with_an_Overdetermined_Basis.md)

- [Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model](2024年04月15日/Unveiling_Imitation_Learning_Exploring_the_Impact_of_Data_Falsity_to_Large_Language_Model.md)

    - [翻译: 揭秘模仿学习：探究数据不真实性如何影响大型语言模型的表现。](2024年04月15日/Unveiling_Imitation_Learning_Exploring_the_Impact_of_Data_Falsity_to_Large_Language_Model.md)

- [Enhancing Robot Explanation Capabilities through Vision-Language Models: a Preliminary Study by Interpreting Visual Inputs for Improved Human-Robot Interaction](2024年04月15日/Enhancing_Robot_Explanation_Capabilities_through_Vision-Language_Models_a_Preliminary_Study_by_Interpreting_Visual_Inputs_for_Improved_Human-Robot_Interaction.md)

    - [翻译: 本初步研究探讨了如何通过视觉-语言模型提升机器人的解释能力，通过解读视觉信息来优化人机互动体验。](2024年04月15日/Enhancing_Robot_Explanation_Capabilities_through_Vision-Language_Models_a_Preliminary_Study_by_Interpreting_Visual_Inputs_for_Improved_Human-Robot_Interaction.md)

- [Generative AI for Game Theory-based Mobile Networking](2024年04月15日/Generative_AI_for_Game_Theory-based_Mobile_Networking.md)

    - [翻译: 在移动网络领域，生成性AI运用博弈论原理，为网络通信带来创新性解决方案。](2024年04月15日/Generative_AI_for_Game_Theory-based_Mobile_Networking.md)

- [Are Large Language Models Reliable Argument Quality Annotators?](2024年04月15日/Are_Large_Language_Models_Reliable_Argument_Quality_Annotators.md)

    - [翻译: 大型语言模型能否成为值得信赖的论证质量评价者？](2024年04月15日/Are_Large_Language_Models_Reliable_Argument_Quality_Annotators.md)

- [LoRAP: Transformer Sub-Layers Deserve Differentiated Structured Compression for Large Language Models](2024年04月15日/LoRAP_Transformer_Sub-Layers_Deserve_Differentiated_Structured_Compression_for_Large_Language_Models.md)

    - [翻译: LoRAP: 针对大型语言模型，Transformer子层需差异化结构压缩技术](2024年04月15日/LoRAP_Transformer_Sub-Layers_Deserve_Differentiated_Structured_Compression_for_Large_Language_Models.md)

- [Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation](2024年04月15日/Multi-News+_Cost-efficient_Dataset_Cleansing_via_LLM-based_Data_Annotation.md)

    - [翻译: Multi-News+：利用大型语言模型实现高效数据集净化与注释](2024年04月15日/Multi-News+_Cost-efficient_Dataset_Cleansing_via_LLM-based_Data_Annotation.md)

- [Do LLMs Understand Visual Anomalies? Uncovering LLM Capabilities in Zero-shot Anomaly Detection](2024年04月15日/Do_LLMs_Understand_Visual_Anomalies_Uncovering_LLM_Capabilities_in_Zero-shot_Anomaly_Detection.md)

    - [翻译: 大型语言模型能否洞察视觉异常？探究LLM在无先验知识下的异常检测技能。](2024年04月15日/Do_LLMs_Understand_Visual_Anomalies_Uncovering_LLM_Capabilities_in_Zero-shot_Anomaly_Detection.md)

- [UNIAA: A Unified Multi-modal Image Aesthetic Assessment Baseline and Benchmark](2024年04月15日/UNIAA_A_Unified_Multi-modal_Image_Aesthetic_Assessment_Baseline_and_Benchmark.md)

    - [翻译: UNIAA：构建统一的多模态图像审美评估基准与评测标准](2024年04月15日/UNIAA_A_Unified_Multi-modal_Image_Aesthetic_Assessment_Baseline_and_Benchmark.md)

- [A Self-feedback Knowledge Elicitation Approach for Chemical Reaction Predictions](2024年04月15日/A_Self-feedback_Knowledge_Elicitation_Approach_for_Chemical_Reaction_Predictions.md)

    - [翻译: 采用自反馈知识提取方法，提升化学反应预测的准确性](2024年04月15日/A_Self-feedback_Knowledge_Elicitation_Approach_for_Chemical_Reaction_Predictions.md)

- [Improving Recall of Large Language Models: A Model Collaboration Approach for Relational Triple Extraction](2024年04月15日/Improving_Recall_of_Large_Language_Models_A_Model_Collaboration_Approach_for_Relational_Triple_Extraction.md)

    - [翻译: 为了提升大型语言模型在关系三元组提取方面的召回率，本文提出了一种模型协作方法。通过这种方法，多个模型可以协同工作，共同提高对实体间关系的识别和提取能力。](2024年04月15日/Improving_Recall_of_Large_Language_Models_A_Model_Collaboration_Approach_for_Relational_Triple_Extraction.md)

- [Modelling Language](2024年04月15日/Modelling_Language.md)

    - [翻译: 语言建模是一门研究如何根据上下文预测和生成语言数据的科学。](2024年04月15日/Modelling_Language.md)

- [Large language models and linguistic intentionality](2024年04月15日/Large_language_models_and_linguistic_intentionality.md)

    - [翻译: 在探讨大型语言模型时，我们不可忽视语言的意图性。](2024年04月15日/Large_language_models_and_linguistic_intentionality.md)

- [Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models](2024年04月15日/Prepacking_A_Simple_Method_for_Fast_Prefilling_and_Increased_Throughput_in_Large_Language_Models.md)

    - [翻译: 预打包技术：轻松实现大型语言模型的快速填充与吞吐量提升](2024年04月15日/Prepacking_A_Simple_Method_for_Fast_Prefilling_and_Increased_Throughput_in_Large_Language_Models.md)

- [LoongServe: Efficiently Serving Long-context Large Language Models with Elastic Sequence Parallelism](2024年04月15日/LoongServe_Efficiently_Serving_Long-context_Large_Language_Models_with_Elastic_Sequence_Parallelism.md)

    - [翻译: LoongServe 通过灵活的序列并行技术，高效地处理长文本的大型语言模型，以满足不同的需求。](2024年04月15日/LoongServe_Efficiently_Serving_Long-context_Large_Language_Models_with_Elastic_Sequence_Parallelism.md)

- [Bridging the Gap between Different Vocabularies for LLM Ensemble](2024年04月15日/Bridging_the_Gap_between_Different_Vocabularies_for_LLM_Ensemble.md)

    - [翻译: 搭建桥梁，实现大型语言模型集合中词汇差异的融合](2024年04月15日/Bridging_the_Gap_between_Different_Vocabularies_for_LLM_Ensemble.md)

- [Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning](2024年04月15日/Large_Language_Models_Can_Automatically_Engineer_Features_for_Few-Shot_Tabular_Learning.md)

    - [翻译: 大型语言模型能够自动设计特征，以助力少次表格学习任务。](2024年04月15日/Large_Language_Models_Can_Automatically_Engineer_Features_for_Few-Shot_Tabular_Learning.md)

- [TextCoT: Zoom In for Enhanced Multimodal Text-Rich Image Understanding](2024年04月15日/TextCoT_Zoom_In_for_Enhanced_Multimodal_Text-Rich_Image_Understanding.md)

    - [翻译: TextCoT：深入探索，提升图文融合的多模态理解](2024年04月15日/TextCoT_Zoom_In_for_Enhanced_Multimodal_Text-Rich_Image_Understanding.md)

- [Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy](2024年04月15日/Uncovering_Latent_Arguments_in_Social_Media_Messaging_by_Employing_LLMs-in-the-Loop_Strategy.md)

    - [翻译: 利用LLM参与策略，挖掘社交媒体通讯中的隐性争议。](2024年04月15日/Uncovering_Latent_Arguments_in_Social_Media_Messaging_by_Employing_LLMs-in-the-Loop_Strategy.md)

- [MoE-TinyMed: Mixture of Experts for Tiny Medical Large Vision-Language Models](2024年04月15日/MoE-TinyMed_Mixture_of_Experts_for_Tiny_Medical_Large_Vision-Language_Models.md)

    - [翻译: MoE-TinyMed：面向小型医疗领域的大型视觉-语言模型的专家融合方法](2024年04月15日/MoE-TinyMed_Mixture_of_Experts_for_Tiny_Medical_Large_Vision-Language_Models.md)

- [Generative Text Steganography with Large Language Model](2024年04月15日/Generative_Text_Steganography_with_Large_Language_Model.md)

    - [翻译: 借助大型语言模型，探索生成性文本隐写技术。](2024年04月15日/Generative_Text_Steganography_with_Large_Language_Model.md)

- [Find The Gap: Knowledge Base Reasoning For Visual Question Answering](2024年04月15日/Find_The_Gap_Knowledge_Base_Reasoning_For_Visual_Question_Answering.md)

    - [翻译: 揭秘背后：视觉问答中的知识库逻辑推理](2024年04月15日/Find_The_Gap_Knowledge_Base_Reasoning_For_Visual_Question_Answering.md)

- [Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models](2024年04月15日/Demonstration_of_DB-GPT_Next_Generation_Data_Interaction_System_Empowered_by_Large_Language_Models.md)

    - [翻译: DB-GPT 演示：下一代数据交互系统，由先进的大型语言模型赋能。](2024年04月15日/Demonstration_of_DB-GPT_Next_Generation_Data_Interaction_System_Empowered_by_Large_Language_Models.md)

- [TEL'M: Test and Evaluation of Language Models](2024年04月15日/TEL'M_Test_and_Evaluation_of_Language_Models.md)

    - [翻译: TEL'M：对语言模型进行测试与评价的研究](2024年04月15日/TEL'M_Test_and_Evaluation_of_Language_Models.md)

- [CULTURE-GEN: Revealing Global Cultural Perception in Language Models through Natural Language Prompting](2024年04月15日/CULTURE-GEN_Revealing_Global_Cultural_Perception_in_Language_Models_through_Natural_Language_Prompting.md)

    - [翻译: CULTURE-GEN：透过自然语言提示，探究语言模型中的全球文化认知](2024年04月15日/CULTURE-GEN_Revealing_Global_Cultural_Perception_in_Language_Models_through_Natural_Language_Prompting.md)

- [How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior](2024年04月15日/How_faithful_are_RAG_models_Quantifying_the_tug-of-war_between_RAG_and_LLMs'_internal_prior.md)

    - [翻译: RAG模型的准确性有多高？探究RAG与大型语言模型内在先验之间的相互制衡。](2024年04月15日/How_faithful_are_RAG_models_Quantifying_the_tug-of-war_between_RAG_and_LLMs'_internal_prior.md)

- [Numerical Attributes Learning for Cardiac Failure Diagnostic from Clinical Narratives - A LESA-CamemBERT-bio Approach](2024年04月15日/Numerical_Attributes_Learning_for_Cardiac_Failure_Diagnostic_from_Clinical_Narratives_-_A_LESA-CamemBERT-bio_Approach.md)

    - [翻译: 利用 LESA-CamemBERT-bio 方法，通过临床叙述学习数值属性以诊断心脏衰竭](2024年04月15日/Numerical_Attributes_Learning_for_Cardiac_Failure_Diagnostic_from_Clinical_Narratives_-_A_LESA-CamemBERT-bio_Approach.md)

- [Deceiving to Enlighten: Coaxing LLMs to Self-Reflection for Enhanced Bias Detection and Mitigation](2024年04月15日/Deceiving_to_Enlighten_Coaxing_LLMs_to_Self-Reflection_for_Enhanced_Bias_Detection_and_Mitigation.md)

    - [翻译: 启迪而非欺骗：引导大型语言模型（LLM）自我审视，提升偏见识别与减缓能力。](2024年04月15日/Deceiving_to_Enlighten_Coaxing_LLMs_to_Self-Reflection_for_Enhanced_Bias_Detection_and_Mitigation.md)

- [Quality Assessment of Prompts Used in Code Generation](2024年04月15日/Quality_Assessment_of_Prompts_Used_in_Code_Generation.md)

    - [翻译: 评估代码生成中提示的质量](2024年04月15日/Quality_Assessment_of_Prompts_Used_in_Code_Generation.md)

- [TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition](2024年04月15日/TabSQLify_Enhancing_Reasoning_Capabilities_of_LLMs_Through_Table_Decomposition.md)

    - [翻译: TabSQLify：通过表格解构，提升大型语言模型的推理技能](2024年04月15日/TabSQLify_Enhancing_Reasoning_Capabilities_of_LLMs_Through_Table_Decomposition.md)

- [Cross-Modal Self-Training: Aligning Images and Pointclouds to Learn Classification without Labels](2024年04月15日/Cross-Modal_Self-Training_Aligning_Images_and_Pointclouds_to_Learn_Classification_without_Labels.md)

    - [翻译: 通过跨模态自训练，我们能够将图像与点云数据对齐，从而在无需标签的情况下学习分类，这一方法为无监督学习开辟了新的可能性。](2024年04月15日/Cross-Modal_Self-Training_Aligning_Images_and_Pointclouds_to_Learn_Classification_without_Labels.md)

- [ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis](2024年04月15日/ANCHOR_LLM-driven_News_Subject_Conditioning_for_Text-to-Image_Synthesis.md)

    - [翻译: 锚定：借助大型语言模型实现文本至图像合成中的新闻主题条件设置](2024年04月15日/ANCHOR_LLM-driven_News_Subject_Conditioning_for_Text-to-Image_Synthesis.md)

- [Language Model Cascades: Token-level uncertainty and beyond](2024年04月15日/Language_Model_Cascades_Token-level_uncertainty_and_beyond.md)

    - [翻译: 语言模型级联：探究Token层级的不确定性及其更深层次的影响](2024年04月15日/Language_Model_Cascades_Token-level_uncertainty_and_beyond.md)

- [PRODIS - a speech database and a phoneme-based language model for the study of predictability effects in Polish](2024年04月15日/PRODIS_-_a_speech_database_and_a_phoneme-based_language_model_for_the_study_of_predictability_effects_in_Polish.md)

    - [翻译: PRODIS 是一个语音数据库，它配备了基于音素的语言模型，专门用于探究波兰语中的可预测性效应。](2024年04月15日/PRODIS_-_a_speech_database_and_a_phoneme-based_language_model_for_the_study_of_predictability_effects_in_Polish.md)

- [LLM-based Test-driven Interactive Code Generation: User Study and Empirical Evaluation](2024年04月15日/LLM-based_Test-driven_Interactive_Code_Generation_User_Study_and_Empirical_Evaluation.md)

    - [翻译: 基于大型语言模型的测试驱动交互式代码生成：用户研究与实证评估探究](2024年04月15日/LLM-based_Test-driven_Interactive_Code_Generation_User_Study_and_Empirical_Evaluation.md)

- [LegalPro-BERT: Classification of Legal Provisions by fine-tuning BERT Large Language Model](2024年04月15日/LegalPro-BERT_Classification_of_Legal_Provisions_by_fine-tuning_BERT_Large_Language_Model.md)

    - [翻译: LegalPro-BERT：借助 BERT 大型语言模型的微调技术，实现对法律条文的精准分类。](2024年04月15日/LegalPro-BERT_Classification_of_Legal_Provisions_by_fine-tuning_BERT_Large_Language_Model.md)

2024年04月14日

- [A Survey on Integration of Large Language Models with Intelligent Robots](2024年04月14日/A_Survey_on_Integration_of_Large_Language_Models_with_Intelligent_Robots.md)

    - [翻译: 本文综述了大型语言模型与智能机器人的融合应用，探讨了两者结合的潜力与挑战。](2024年04月14日/A_Survey_on_Integration_of_Large_Language_Models_with_Intelligent_Robots.md)

- [TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models](2024年04月14日/TextHawk_Exploring_Efficient_Fine-Grained_Perception_of_Multimodal_Large_Language_Models.md)

    - [翻译: TextHawk：高效精准感知多模态大型语言模型的新探索](2024年04月14日/TextHawk_Exploring_Efficient_Fine-Grained_Perception_of_Multimodal_Large_Language_Models.md)

- [Tri-modal Confluence with Temporal Dynamics for Scene Graph Generation in Operating Rooms](2024年04月14日/Tri-modal_Confluence_with_Temporal_Dynamics_for_Scene_Graph_Generation_in_Operating_Rooms.md)

    - [翻译: 在手术室场景中，结合时间动态的三模态交汇技术，用于生成场景图。](2024年04月14日/Tri-modal_Confluence_with_Temporal_Dynamics_for_Scene_Graph_Generation_in_Operating_Rooms.md)

- [DreamScape: 3D Scene Creation via Gaussian Splatting joint Correlation Modeling](2024年04月14日/DreamScape_3D_Scene_Creation_via_Gaussian_Splatting_joint_Correlation_Modeling.md)

    - [翻译: DreamScape：运用高斯溅射与联合相关性建模技术打造三维场景](2024年04月14日/DreamScape_3D_Scene_Creation_via_Gaussian_Splatting_joint_Correlation_Modeling.md)

- [Compass: Large Multilingual Language Model for South-east Asia](2024年04月14日/Compass_Large_Multilingual_Language_Model_for_South-east_Asia.md)

    - [翻译: 指南针：为东南亚地区量身打造的大型多语言语言模型](2024年04月14日/Compass_Large_Multilingual_Language_Model_for_South-east_Asia.md)

- [DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection](2024年04月14日/DetCLIPv3_Towards_Versatile_Generative_Open-vocabulary_Object_Detection.md)

    - [翻译: DetCLIPv3 致力于实现多样化的开放词汇目标检测，旨在提升生成式目标检测的灵活性与适应性。](2024年04月14日/DetCLIPv3_Towards_Versatile_Generative_Open-vocabulary_Object_Detection.md)

- [DKE-Research at SemEval-2024 Task 2: Incorporating Data Augmentation with Generative Models and Biomedical Knowledge to Enhance Inference Robustness](2024年04月14日/DKE-Research_at_SemEval-2024_Task_2_Incorporating_Data_Augmentation_with_Generative_Models_and_Biomedical_Knowledge_to_Enhance_Inference_Robustness.md)

    - [翻译: DKE-Research 参与 SemEval-2024 的第二项任务，通过融合生成模型与生物医学知识进行数据增强，旨在增强推理过程的稳健性。](2024年04月14日/DKE-Research_at_SemEval-2024_Task_2_Incorporating_Data_Augmentation_with_Generative_Models_and_Biomedical_Knowledge_to_Enhance_Inference_Robustness.md)

- [TransformerFAM: Feedback attention is working memory](2024年04月14日/TransformerFAM_Feedback_attention_is_working_memory.md)

    - [翻译: TransformerFAM 模型中，反馈注意力机制扮演着工作记忆的角色。](2024年04月14日/TransformerFAM_Feedback_attention_is_working_memory.md)

- [Post-Semantic-Thinking: A Robust Strategy to Distill Reasoning Capacity from Large Language Models](2024年04月14日/Post-Semantic-Thinking_A_Robust_Strategy_to_Distill_Reasoning_Capacity_from_Large_Language_Models.md)

    - [翻译: 探索后语义思维：高效提炼大型语言模型的推理能力](2024年04月14日/Post-Semantic-Thinking_A_Robust_Strategy_to_Distill_Reasoning_Capacity_from_Large_Language_Models.md)

- [GeMQuAD : Generating Multilingual Question Answering Datasets from Large Language Models using Few Shot Learning](2024年04月14日/GeMQuAD__Generating_Multilingual_Question_Answering_Datasets_from_Large_Language_Models_using_Few_Shot_Learning.md)

    - [翻译: GeMQuAD：借助少量样本学习技术，从大型语言模型中打造多语言问答数据集。](2024年04月14日/GeMQuAD__Generating_Multilingual_Question_Answering_Datasets_from_Large_Language_Models_using_Few_Shot_Learning.md)

- [From Bytes to Borsch: Fine-Tuning Gemma and Mistral for the Ukrainian Language Representation](2024年04月14日/From_Bytes_to_Borsch_Fine-Tuning_Gemma_and_Mistral_for_the_Ukrainian_Language_Representation.md)

    - [翻译: 跨越字节界限，迈向罗宋汤的风味：精心调整吉玛与米斯特拉，以提升乌克兰语的表现力。](2024年04月14日/From_Bytes_to_Borsch_Fine-Tuning_Gemma_and_Mistral_for_the_Ukrainian_Language_Representation.md)

- [Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A~Case~Study~at~HCMUT](2024年04月14日/Cross-Data_Knowledge_Graph_Construction_for_LLM-enabled_Educational_Question-Answering_System_A~Case~Study~at~HCMUT.md)

    - [翻译: 构建跨数据知识图，助力LLM驱动的教育问答系统——以HCMUT为例](2024年04月14日/Cross-Data_Knowledge_Graph_Construction_for_LLM-enabled_Educational_Question-Answering_System_A~Case~Study~at~HCMUT.md)

- [Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts](2024年04月14日/Knowledgeable_Agents_by_Offline_Reinforcement_Learning_from_Large_Language_Model_Rollouts.md)

    - [翻译: 通过大型语言模型的模拟数据进行离线强化学习，打造出见多识广的智能代理。](2024年04月14日/Knowledgeable_Agents_by_Offline_Reinforcement_Learning_from_Large_Language_Model_Rollouts.md)

- [RankCLIP: Ranking-Consistent Language-Image Pretraining](2024年04月14日/RankCLIP_Ranking-Consistent_Language-Image_Pretraining.md)

    - [翻译: RankCLIP：实现语言与图像预训练的排名一致性](2024年04月14日/RankCLIP_Ranking-Consistent_Language-Image_Pretraining.md)

- [Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches](2024年04月14日/Tasks_People_Prompt_A_Taxonomy_of_LLM_Downstream_Tasks_in_Software_Verification_and_Falsification_Approaches.md)

    - [翻译: 任务人员提示：对大型语言模型在软件验证与错误检测方法中的下游任务进行分类](2024年04月14日/Tasks_People_Prompt_A_Taxonomy_of_LLM_Downstream_Tasks_in_Software_Verification_and_Falsification_Approaches.md)

- [Can AI Understand Our Universe? Test of Fine-Tuning GPT by Astrophysical Data](2024年04月14日/Can_AI_Understand_Our_Universe_Test_of_Fine-Tuning_GPT_by_Astrophysical_Data.md)

    - [翻译: 人工智能能否洞悉宇宙之谜？本研究通过天体物理数据对GPT模型进行精细调整，以测试其理解宇宙的能力。](2024年04月14日/Can_AI_Understand_Our_Universe_Test_of_Fine-Tuning_GPT_by_Astrophysical_Data.md)

2024年04月13日

- [Unveiling LLM Evaluation Focused on Metrics: Challenges and Solutions](2024年04月13日/Unveiling_LLM_Evaluation_Focused_on_Metrics_Challenges_and_Solutions.md)

    - [翻译: 揭秘大型语言模型（LLM）评估：聚焦于度量指标的挑战与应对策略](2024年04月13日/Unveiling_LLM_Evaluation_Focused_on_Metrics_Challenges_and_Solutions.md)

- [Interactive Generative AI Agents for Satellite Networks through a Mixture of Experts Transmission](2024年04月13日/Interactive_Generative_AI_Agents_for_Satellite_Networks_through_a_Mixture_of_Experts_Transmission.md)

    - [翻译: 本研究探讨了通过专家混合传输技术实现卫星网络中的交互式生成性人工智能代理，旨在提高通信效率和性能。](2024年04月13日/Interactive_Generative_AI_Agents_for_Satellite_Networks_through_a_Mixture_of_Experts_Transmission.md)

- [When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models](2024年04月13日/When_Hindsight_is_Not_2020_Testing_Limits_on_Reflective_Thinking_in_Large_Language_Models.md)

    - [翻译: 后见之明并不总是清晰透彻：探究大型语言模型反思性思维的边界](2024年04月13日/When_Hindsight_is_Not_2020_Testing_Limits_on_Reflective_Thinking_in_Large_Language_Models.md)

- [Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation](2024年04月13日/Confidence_Calibration_and_Rationalization_for_LLMs_via_Multi-Agent_Deliberation.md)

    - [翻译: 本研究通过多智能体协商机制，对大型语言模型（LLM）的置信度进行校准与合理化，以提升模型的预测准确性和解释性。](2024年04月13日/Confidence_Calibration_and_Rationalization_for_LLMs_via_Multi-Agent_Deliberation.md)

- [CuriousLLM: Elevating Multi-Document QA with Reasoning-Infused Knowledge Graph Prompting](2024年04月13日/CuriousLLM_Elevating_Multi-Document_QA_with_Reasoning-Infused_Knowledge_Graph_Prompting.md)

    - [翻译: CuriousLLM 通过结合推理知识图谱的提示，提升了多文档问答的能力。](2024年04月13日/CuriousLLM_Elevating_Multi-Document_QA_with_Reasoning-Infused_Knowledge_Graph_Prompting.md)

- [Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model](2024年04月13日/Adapting_Mental_Health_Prediction_Tasks_for_Cross-lingual_Learning_via_Meta-Training_and_In-context_Learning_with_Large_Language_Model.md)

    - [翻译: 通过利用大型语言模型的元训练和上下文学习，我们调整心理健康预测任务，以便在跨语言学习中取得更好的效果。](2024年04月13日/Adapting_Mental_Health_Prediction_Tasks_for_Cross-lingual_Learning_via_Meta-Training_and_In-context_Learning_with_Large_Language_Model.md)

- [Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large Language Models for Behavioral Simulation](2024年04月13日/Do_LLMs_Play_Dice_Exploring_Probability_Distribution_Sampling_in_Large_Language_Models_for_Behavioral_Simulation.md)

    - [翻译: 大型语言模型是否遵循随机规则？本研究探讨了在行为模拟中，大型语言模型是如何进行概率分布采样的。](2024年04月13日/Do_LLMs_Play_Dice_Exploring_Probability_Distribution_Sampling_in_Large_Language_Models_for_Behavioral_Simulation.md)

- [Three Disclaimers for Safe Disclosure: A Cardwriter for Reporting the Use of Generative AI in Writing Process](2024年04月13日/Three_Disclaimers_for_Safe_Disclosure_A_Cardwriter_for_Reporting_the_Use_of_Generative_AI_in_Writing_Process.md)

    - [翻译: 写作过程中使用生成型AI需注意三大免责声明：这是一份为报告而生的卡片式指南。](2024年04月13日/Three_Disclaimers_for_Safe_Disclosure_A_Cardwriter_for_Reporting_the_Use_of_Generative_AI_in_Writing_Process.md)

- [MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts](2024年04月13日/MING-MOE_Enhancing_Medical_Multi-Task_Learning_in_Large_Language_Models_with_Sparse_Mixture_of_Low-Rank_Adapter_Experts.md)

    - [翻译: MING-MOE 通过引入稀疏的低秩适配器专家混合技术，旨在提升大型语言模型在医学多任务学习领域的性能。](2024年04月13日/MING-MOE_Enhancing_Medical_Multi-Task_Learning_in_Large_Language_Models_with_Sparse_Mixture_of_Low-Rank_Adapter_Experts.md)

- [Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies](2024年04月13日/Navigating_the_Landscape_of_Large_Language_Models_A_Comprehensive_Review_and_Analysis_of_Paradigms_and_Fine-Tuning_Strategies.md)

    - [翻译: 驾驭大型语言模型的疆域：一篇深入剖析各种范式与微调手法的综述文章](2024年04月13日/Navigating_the_Landscape_of_Large_Language_Models_A_Comprehensive_Review_and_Analysis_of_Paradigms_and_Fine-Tuning_Strategies.md)

- [PracticalDG: Perturbation Distillation on Vision-Language Models for Hybrid Domain Generalization](2024年04月13日/PracticalDG_Perturbation_Distillation_on_Vision-Language_Models_for_Hybrid_Domain_Generalization.md)

    - [翻译: 实用数字生成（PracticalDG）：通过在视觉-语言模型中应用扰动蒸馏技术，实现跨领域的有效泛化。](2024年04月13日/PracticalDG_Perturbation_Distillation_on_Vision-Language_Models_for_Hybrid_Domain_Generalization.md)

- [WikiSplit++: Easy Data Refinement for Split and Rephrase](2024年04月13日/WikiSplit++_Easy_Data_Refinement_for_Split_and_Rephrase.md)

    - [翻译: WikiSplit++：轻松优化数据，让分割与改述更简单](2024年04月13日/WikiSplit++_Easy_Data_Refinement_for_Split_and_Rephrase.md)

- [Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning](2024年04月13日/Intuition-aware_Mixture-of-Rank-1-Experts_for_Parameter_Efficient_Finetuning.md)

    - [翻译: 在参数高效微调中，我们引入了一种直觉感知的混合Rank-1专家模型，旨在通过熵正则化来优化模型性能。](2024年04月13日/Intuition-aware_Mixture-of-Rank-1-Experts_for_Parameter_Efficient_Finetuning.md)

- [Incremental Residual Concept Bottleneck Models](2024年04月13日/Incremental_Residual_Concept_Bottleneck_Models.md)

    - [翻译: 逐步深入的残差概念瓶颈模型](2024年04月13日/Incremental_Residual_Concept_Bottleneck_Models.md)

- [RoNID: New Intent Discovery with Generated-Reliable Labels and Cluster-friendly Representations](2024年04月13日/RoNID_New_Intent_Discovery_with_Generated-Reliable_Labels_and_Cluster-friendly_Representations.md)

    - [翻译: RoNID：探索新意图，借助生成的可靠标签与便于聚类的表示法](2024年04月13日/RoNID_New_Intent_Discovery_with_Generated-Reliable_Labels_and_Cluster-friendly_Representations.md)

- [OOVs in the Spotlight: How to Inflect them?](2024年04月13日/OOVs_in_the_Spotlight_How_to_Inflect_them.md)

    - [翻译: 词汇表之外的词汇（OOVs）备受关注：我们该如何调整它们呢？](2024年04月13日/OOVs_in_the_Spotlight_How_to_Inflect_them.md)

- [Large Language Models for Mobile GUI Text Input Generation: An Empirical Study](2024年04月13日/Large_Language_Models_for_Mobile_GUI_Text_Input_Generation_An_Empirical_Study.md)

    - [翻译: 面向移动设备图形界面文本输入的大型语言模型：实证分析](2024年04月13日/Large_Language_Models_for_Mobile_GUI_Text_Input_Generation_An_Empirical_Study.md)

- [Zero-Shot Code Representation Learning via Prompt Tuning](2024年04月13日/Zero-Shot_Code_Representation_Learning_via_Prompt_Tuning.md)

    - [翻译: 通过提示调整实现零-shot环境下的代码表示学习。](2024年04月13日/Zero-Shot_Code_Representation_Learning_via_Prompt_Tuning.md)

- [Introducing Super RAGs in Mistral 8x7B-v1](2024年04月13日/Introducing_Super_RAGs_in_Mistral_8x7B-v1.md)

    - [翻译: Mistral 8x7B-v1 版本中，我们迎来了超级 RAGs 的登场。](2024年04月13日/Introducing_Super_RAGs_in_Mistral_8x7B-v1.md)

2024年04月12日

- [Enhancing Visual Question Answering through Question-Driven Image Captions as Prompts](2024年04月12日/Enhancing_Visual_Question_Answering_through_Question-Driven_Image_Captions_as_Prompts.md)

    - [翻译: 借助问题引导的图像描述作为前置提示，提升视觉问答系统的性能。](2024年04月12日/Enhancing_Visual_Question_Answering_through_Question-Driven_Image_Captions_as_Prompts.md)

- [Enhancing Autonomous Vehicle Training with Language Model Integration and Critical Scenario Generation](2024年04月12日/Enhancing_Autonomous_Vehicle_Training_with_Language_Model_Integration_and_Critical_Scenario_Generation.md)

    - [翻译: 结合语言模型和关键情景生成技术，提升自动驾驶车辆的训练效果](2024年04月12日/Enhancing_Autonomous_Vehicle_Training_with_Language_Model_Integration_and_Critical_Scenario_Generation.md)

- [RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs](2024年04月12日/RLHF_Deciphered_A_Critical_Analysis_of_Reinforcement_Learning_from_Human_Feedback_for_LLMs.md)

    - [翻译: 深度剖析RLHF：揭秘人类反馈在大型语言模型强化学习中的作用](2024年04月12日/RLHF_Deciphered_A_Critical_Analysis_of_Reinforcement_Learning_from_Human_Feedback_for_LLMs.md)

- [Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward](2024年04月12日/Online_Safety_Analysis_for_LLMs_a_Benchmark,_an_Assessment,_and_a_Path_Forward.md)

    - [翻译: 针对大型语言模型的网络安全评估：建立行业标准，进行全面审视，并规划未来发展方向。](2024年04月12日/Online_Safety_Analysis_for_LLMs_a_Benchmark,_an_Assessment,_and_a_Path_Forward.md)

- [Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction](2024年04月12日/Efficient_Interactive_LLM_Serving_with_Proxy_Model-based_Sequence_Length_Prediction.md)

    - [翻译: 通过代理模型预测序列长度，实现大型语言模型（LLM）的高效互动服务。](2024年04月12日/Efficient_Interactive_LLM_Serving_with_Proxy_Model-based_Sequence_Length_Prediction.md)

- [LaSagnA: Language-based Segmentation Assistant for Complex Queries](2024年04月12日/LaSagnA_Language-based_Segmentation_Assistant_for_Complex_Queries.md)

    - [翻译: LaSagnA：复杂查询的语言分割助理](2024年04月12日/LaSagnA_Language-based_Segmentation_Assistant_for_Complex_Queries.md)

- [Strategic Interactions between Large Language Models-based Agents in Beauty Contests](2024年04月12日/Strategic_Interactions_between_Large_Language_Models-based_Agents_in_Beauty_Contests.md)

    - [翻译: 选美竞技中，大型语言模型驱动的智能体展开策略博弈。](2024年04月12日/Strategic_Interactions_between_Large_Language_Models-based_Agents_in_Beauty_Contests.md)

- [Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation](2024年04月12日/Mitigating_Language-Level_Performance_Disparity_in_mPLMs_via_Teacher_Language_Selection_and_Cross-lingual_Self-Distillation.md)

    - [翻译: 为了缩小多语言预训练语言模型（mPLMs）在不同语言间性能的差距，本研究采用了教师语言选择和跨语言自我蒸馏的策略。](2024年04月12日/Mitigating_Language-Level_Performance_Disparity_in_mPLMs_via_Teacher_Language_Selection_and_Cross-lingual_Self-Distillation.md)

- [Thematic Analysis with Large Language Models: does it work with languages other than English? A targeted test in Italian](2024年04月12日/Thematic_Analysis_with_Large_Language_Models_does_it_work_with_languages_other_than_English_A_targeted_test_in_Italian.md)

    - [翻译: 大型语言模型进行主题分析：非英语语言是否同样有效？一项针对意大利语的专项测试探究](2024年04月12日/Thematic_Analysis_with_Large_Language_Models_does_it_work_with_languages_other_than_English_A_targeted_test_in_Italian.md)

- [Comparing Apples to Oranges: LLM-powered Multimodal Intention Prediction in an Object Categorization Task](2024年04月12日/Comparing_Apples_to_Oranges_LLM-powered_Multimodal_Intention_Prediction_in_an_Object_Categorization_Task.md)

    - [翻译: 在对象分类任务中，利用大型语言模型进行多模态意图预测的苹果与橙子之比较。](2024年04月12日/Comparing_Apples_to_Oranges_LLM-powered_Multimodal_Intention_Prediction_in_an_Object_Categorization_Task.md)

- [AdapterSwap: Continuous Training of LLMs with Data Removal and Access-Control Guarantees](2024年04月12日/AdapterSwap_Continuous_Training_of_LLMs_with_Data_Removal_and_Access-Control_Guarantees.md)

    - [翻译: AdapterSwap 技术能够在确保数据安全删除和访问受限的前提下，对大型语言模型（LLM）实施持续的训练与优化。](2024年04月12日/AdapterSwap_Continuous_Training_of_LLMs_with_Data_Removal_and_Access-Control_Guarantees.md)

- [Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think](2024年04月12日/Look_at_the_Text_Instruction-Tuned_Language_Models_are_More_Robust_Multiple_Choice_Selectors_than_You_Think.md)

    - [翻译: 细读这篇文章：经过指令调优的语言模型，在多项选择任务上的筛选能力比你想象的要强大得多。](2024年04月12日/Look_at_the_Text_Instruction-Tuned_Language_Models_are_More_Robust_Multiple_Choice_Selectors_than_You_Think.md)

- [Gaining More Insight into Neural Semantic Parsing with Challenging Benchmarks](2024年04月12日/Gaining_More_Insight_into_Neural_Semantic_Parsing_with_Challenging_Benchmarks.md)

    - [翻译: 借助富有挑战性的基准测试，我们能够更深入地洞察神经网络在语义解析方面的表现。](2024年04月12日/Gaining_More_Insight_into_Neural_Semantic_Parsing_with_Challenging_Benchmarks.md)

- [Toward a Theory of Tokenization in LLMs](2024年04月12日/Toward_a_Theory_of_Tokenization_in_LLMs.md)

    - [翻译: 探索大型语言模型中的分词原理](2024年04月12日/Toward_a_Theory_of_Tokenization_in_LLMs.md)

- [Subtoxic Questions: Dive Into Attitude Change of LLM's Response in Jailbreak Attempts](2024年04月12日/Subtoxic_Questions_Dive_Into_Attitude_Change_of_LLM's_Response_in_Jailbreak_Attempts.md)

    - [翻译: Subtoxic Questions: 探究在越狱尝试中大型语言模型回应的态度转变](2024年04月12日/Subtoxic_Questions_Dive_Into_Attitude_Change_of_LLM's_Response_in_Jailbreak_Attempts.md)

- [Pretraining and Updating Language- and Domain-specific Large Language Model: A Case Study in Japanese Business Domain](2024年04月12日/Pretraining_and_Updating_Language-_and_Domain-specific_Large_Language_Model_A_Case_Study_in_Japanese_Business_Domain.md)

    - [翻译: 探索日本商业领域：预训练与更新特定语言和领域大型语言模型的案例分析](2024年04月12日/Pretraining_and_Updating_Language-_and_Domain-specific_Large_Language_Model_A_Case_Study_in_Japanese_Business_Domain.md)

- [Investigating Neural Machine Translation for Low-Resource Languages: Using Bavarian as a Case Study](2024年04月12日/Investigating_Neural_Machine_Translation_for_Low-Resource_Languages_Using_Bavarian_as_a_Case_Study.md)

    - [翻译: 探索低资源语言的神经机器翻译：以巴伐利亚语为案例研究](2024年04月12日/Investigating_Neural_Machine_Translation_for_Low-Resource_Languages_Using_Bavarian_as_a_Case_Study.md)

- [Pre-training Small Base LMs with Fewer Tokens](2024年04月12日/Pre-training_Small_Base_LMs_with_Fewer_Tokens.md)

    - [翻译: 在预训练小型基础语言模型时，采用更少的标记。](2024年04月12日/Pre-training_Small_Base_LMs_with_Fewer_Tokens.md)

- [Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension](2024年04月12日/Is_Next_Token_Prediction_Sufficient_for_GPT_Exploration_on_Code_Logic_Comprehension.md)

    - [翻译: GPT仅凭下一个词的预测是否足够？探究其在代码逻辑理解方面的表现](2024年04月12日/Is_Next_Token_Prediction_Sufficient_for_GPT_Exploration_on_Code_Logic_Comprehension.md)

- [Generative AI Agent for Next-Generation MIMO Design: Fundamentals, Challenges, and Vision](2024年04月12日/Generative_AI_Agent_for_Next-Generation_MIMO_Design_Fundamentals,_Challenges,_and_Vision.md)

    - [翻译: 下一代MIMO设计中的生成型AI代理：基础原理、面临挑战及未来展望](2024年04月12日/Generative_AI_Agent_for_Next-Generation_MIMO_Design_Fundamentals,_Challenges,_and_Vision.md)

- [Aligning LLMs for FL-free Program Repair](2024年04月12日/Aligning_LLMs_for_FL-free_Program_Repair.md)

    - [翻译: 在无需特征标注的情况下，对大型语言模型进行优化以实现程序修复](2024年04月12日/Aligning_LLMs_for_FL-free_Program_Repair.md)

- [LLM In-Context Recall is Prompt Dependent](2024年04月12日/LLM_In-Context_Recall_is_Prompt_Dependent.md)

    - [翻译: 在大型语言模型中，上下文记忆的召回效果与提示密切相关。](2024年04月12日/LLM_In-Context_Recall_is_Prompt_Dependent.md)

- [On Speculative Decoding for Multimodal Large Language Models](2024年04月12日/On_Speculative_Decoding_for_Multimodal_Large_Language_Models.md)

    - [翻译: 探索多模态大型语言模型的推测性解码技术](2024年04月12日/On_Speculative_Decoding_for_Multimodal_Large_Language_Models.md)

- [Assessing Economic Viability: A Comparative Analysis of Total Cost of Ownership for Domain-Adapted Large Language Models versus State-of-the-art Counterparts in Chip Design Coding Assistance](2024年04月12日/Assessing_Economic_Viability_A_Comparative_Analysis_of_Total_Cost_of_Ownership_for_Domain-Adapted_Large_Language_Models_versus_State-of-the-art_Counterparts_in_Chip_Design_Coding_Assistance.md)

    - [翻译: 探究经济价值：比较分析领域定制大型语言模型与芯片设计编码辅助领域中尖端技术的总成本拥有情况。](2024年04月12日/Assessing_Economic_Viability_A_Comparative_Analysis_of_Total_Cost_of_Ownership_for_Domain-Adapted_Large_Language_Models_versus_State-of-the-art_Counterparts_in_Chip_Design_Coding_Assistance.md)

- [Experimental Design for Active Transductive Inference in Large Language Models](2024年04月12日/Experimental_Design_for_Active_Transductive_Inference_in_Large_Language_Models.md)

    - [翻译: 本文探讨了大型语言模型中主动归纳推理的实验设计方案。](2024年04月12日/Experimental_Design_for_Active_Transductive_Inference_in_Large_Language_Models.md)

- ["Don't forget to put the milk back!" Dataset for Enabling Embodied Agents to Detect Anomalous Situations](2024年04月12日/Don't_forget_to_put_the_milk_back!_Dataset_for_Enabling_Embodied_Agents_to_Detect_Anomalous_Situations.md)

    - [翻译: "记得把牛奶归位哦！" 这个数据集旨在帮助具身智能体识别不寻常的场景。](2024年04月12日/Don't_forget_to_put_the_milk_back!_Dataset_for_Enabling_Embodied_Agents_to_Detect_Anomalous_Situations.md)

- [Inverse Kinematics for Neuro-Robotic Grasping with Humanoid Embodied Agents](2024年04月12日/Inverse_Kinematics_for_Neuro-Robotic_Grasping_with_Humanoid_Embodied_Agents.md)

    - [翻译: 本文探讨了逆运动学在人形机器人抓取任务中的应用，特别是针对具有人形体现的神经机器人代理。](2024年04月12日/Inverse_Kinematics_for_Neuro-Robotic_Grasping_with_Humanoid_Embodied_Agents.md)

- [The Illusion of State in State-Space Models](2024年04月12日/The_Illusion_of_State_in_State-Space_Models.md)

    - [翻译: 状态空间模型中的状态幻觉](2024年04月12日/The_Illusion_of_State_in_State-Space_Models.md)

- [Evaluating the Quality of Answers in Political Q&A Sessions with Large Language Models](2024年04月12日/Evaluating_the_Quality_of_Answers_in_Political_Q&A_Sessions_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，我们探讨了政治问答环节中答案的质量评估问题。](2024年04月12日/Evaluating_the_Quality_of_Answers_in_Political_Q&A_Sessions_with_Large_Language_Models.md)

- [Reducing the Barriers to Entry for Foundation Model Training](2024年04月12日/Reducing_the_Barriers_to_Entry_for_Foundation_Model_Training.md)

    - [翻译: 本文旨在探讨如何减少进入基础模型训练领域的障碍，以便更多的研究人员和开发者能够参与并推动这一领域的进步。](2024年04月12日/Reducing_the_Barriers_to_Entry_for_Foundation_Model_Training.md)

- [CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation](2024年04月12日/CreativEval_Evaluating_Creativity_of_LLM-Based_Hardware_Code_Generation.md)

    - [翻译: CreativEval：探究大型语言模型在硬件代码创造中的表现](2024年04月12日/CreativEval_Evaluating_Creativity_of_LLM-Based_Hardware_Code_Generation.md)

- [JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large Language Models](2024年04月12日/JailbreakLens_Visual_Analysis_of_Jailbreak_Attacks_Against_Large_Language_Models.md)

    - [翻译: JailbreakLens：揭秘大型语言模型面临的越狱攻击的视觉解析](2024年04月12日/JailbreakLens_Visual_Analysis_of_Jailbreak_Attacks_Against_Large_Language_Models.md)

- [LLM-Seg: Bridging Image Segmentation and Large Language Model Reasoning](2024年04月12日/LLM-Seg_Bridging_Image_Segmentation_and_Large_Language_Model_Reasoning.md)

    - [翻译: LLM-Seg：融合图像分割与大型语言模型的推理能力](2024年04月12日/LLM-Seg_Bridging_Image_Segmentation_and_Large_Language_Model_Reasoning.md)

- [CATS: Contextually-Aware Thresholding for Sparsity in Large Language Models](2024年04月12日/CATS_Contextually-Aware_Thresholding_for_Sparsity_in_Large_Language_Models.md)

    - [翻译: CATS：针对大型语言模型的稀疏性，采用情境感知的阈值策略](2024年04月12日/CATS_Contextually-Aware_Thresholding_for_Sparsity_in_Large_Language_Models.md)

- [The Generation Gap:Exploring Age Bias in Large Language Models](2024年04月12日/The_Generation_GapExploring_Age_Bias_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中的年龄偏见：揭秘生成差距](2024年04月12日/The_Generation_GapExploring_Age_Bias_in_Large_Language_Models.md)

- [Training a Vision Language Model as Smartphone Assistant](2024年04月12日/Training_a_Vision_Language_Model_as_Smartphone_Assistant.md)

    - [翻译: 将视觉语言模型打造成智能手机助理。](2024年04月12日/Training_a_Vision_Language_Model_as_Smartphone_Assistant.md)

- [VizGroup: An AI-Assisted Event-Driven System for Real-Time Collaborative Programming Learning Analytics](2024年04月12日/VizGroup_An_AI-Assisted_Event-Driven_System_for_Real-Time_Collaborative_Programming_Learning_Analytics.md)

    - [翻译: VizGroup：一款人工智能驱动的实时协作编程学习分析系统，采用事件触发机制。](2024年04月12日/VizGroup_An_AI-Assisted_Event-Driven_System_for_Real-Time_Collaborative_Programming_Learning_Analytics.md)

- [Can LLMs substitute SQL? Comparing Resource Utilization of Querying LLMs versus Traditional Relational Databases](2024年04月12日/Can_LLMs_substitute_SQL_Comparing_Resource_Utilization_of_Querying_LLMs_versus_Traditional_Relational_Databases.md)

    - [翻译: 大型语言模型能否取代SQL？探究在查询过程中，LLMs与传统关系型数据库在资源消耗方面的对比。](2024年04月12日/Can_LLMs_substitute_SQL_Comparing_Resource_Utilization_of_Querying_LLMs_versus_Traditional_Relational_Databases.md)

2024年04月11日

- [OpenBias: Open-set Bias Detection in Text-to-Image Generative Models](2024年04月11日/OpenBias_Open-set_Bias_Detection_in_Text-to-Image_Generative_Models.md)

    - [翻译: OpenBias 旨在揭示文本到图像生成模型中的开放集偏差问题，为这一领域的研究和改进提供了新的视角。](2024年04月11日/OpenBias_Open-set_Bias_Detection_in_Text-to-Image_Generative_Models.md)

- [Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding](2024年04月11日/Any2Point_Empowering_Any-modality_Large_Models_for_Efficient_3D_Understanding.md)

    - [翻译: Any2Point：激活各类大型模型，实现精准高效的三维理解](2024年04月11日/Any2Point_Empowering_Any-modality_Large_Models_for_Efficient_3D_Understanding.md)

- [Language Imbalance Can Boost Cross-lingual Generalisation](2024年04月11日/Language_Imbalance_Can_Boost_Cross-lingual_Generalisation.md)

    - [翻译: 在跨语言学习中，语言的不平衡现象有时反而能增强模型的泛化性能。](2024年04月11日/Language_Imbalance_Can_Boost_Cross-lingual_Generalisation.md)

- [Manipulating Large Language Models to Increase Product Visibility](2024年04月11日/Manipulating_Large_Language_Models_to_Increase_Product_Visibility.md)

    - [翻译: 通过调整大型语言模型，我们可以有效提升产品的曝光率。](2024年04月11日/Manipulating_Large_Language_Models_to_Increase_Product_Visibility.md)

- [LLoCO: Learning Long Contexts Offline](2024年04月11日/LLoCO_Learning_Long_Contexts_Offline.md)

    - [翻译: LLoCO：探索离线长文本学习在离线模式下，长文本环境的学习与处理仍充满挑战，有待我们进一步探索和突破。](2024年04月11日/LLoCO_Learning_Long_Contexts_Offline.md)

- [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](2024年04月11日/Ferret-v2_An_Improved_Baseline_for_Referring_and_Grounding_with_Large_Language_Models.md)

    - [翻译: Ferret-v2：提升大型语言模型指代解析与实体定位的进阶基准。](2024年04月11日/Ferret-v2_An_Improved_Baseline_for_Referring_and_Grounding_with_Large_Language_Models.md)

- [Leveraging Large Language Models (LLMs) to Support Collaborative Human-AI Online Risk Data Annotation](2024年04月11日/Leveraging_Large_Language_Models_(LLMs)_to_Support_Collaborative_Human-AI_Online_Risk_Data_Annotation.md)

    - [翻译: 本文探讨了如何运用大型语言模型（LLMs）来加强人类与AI之间的协作，以共同完成在线风险数据的标注工作。](2024年04月11日/Leveraging_Large_Language_Models_(LLMs)_to_Support_Collaborative_Human-AI_Online_Risk_Data_Annotation.md)

- [LaVy: Vietnamese Multimodal Large Language Model](2024年04月11日/LaVy_Vietnamese_Multimodal_Large_Language_Model.md)

    - [翻译: LaVy，一款融合多模态特性的越南大型语言模型。](2024年04月11日/LaVy_Vietnamese_Multimodal_Large_Language_Model.md)

- [AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs](2024年04月11日/AmpleGCG_Learning_a_Universal_and_Transferable_Generative_Model_of_Adversarial_Suffixes_for_Jailbreaking_Both_Open_and_Closed_LLMs.md)

    - [翻译: AmpleGCG 致力于开发一种普适且具备迁移能力的对抗性后缀生成模型，旨在解放开放与封闭的大型语言模型（LLM）的潜能。](2024年04月11日/AmpleGCG_Learning_a_Universal_and_Transferable_Generative_Model_of_Adversarial_Suffixes_for_Jailbreaking_Both_Open_and_Closed_LLMs.md)

- [DesignQA: A Multimodal Benchmark for Evaluating Large Language Models' Understanding of Engineering Documentation](2024年04月11日/DesignQA_A_Multimodal_Benchmark_for_Evaluating_Large_Language_Models'_Understanding_of_Engineering_Documentation.md)

    - [翻译: DesignQA：一个多模态基准，用于评测大型语言模型对工程文档的理解力。](2024年04月11日/DesignQA_A_Multimodal_Benchmark_for_Evaluating_Large_Language_Models'_Understanding_of_Engineering_Documentation.md)

- [High-Dimension Human Value Representation in Large Language Models](2024年04月11日/High-Dimension_Human_Value_Representation_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的人类价值，以高维度形式呈现。](2024年04月11日/High-Dimension_Human_Value_Representation_in_Large_Language_Models.md)

- [Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations](2024年04月11日/Guiding_Large_Language_Models_to_Post-Edit_Machine_Translation_with_Error_Annotations.md)

    - [翻译: 通过错误注释指导大型语言模型对机器翻译进行精准修正](2024年04月11日/Guiding_Large_Language_Models_to_Post-Edit_Machine_Translation_with_Error_Annotations.md)

- [Nostra Domina at EvaLatin 2024: Improving Latin Polarity Detection through Data Augmentation](2024年04月11日/Nostra_Domina_at_EvaLatin_2024_Improving_Latin_Polarity_Detection_through_Data_Augmentation.md)

    - [翻译: 在 2024 年的 EvaLatin 会议上，Nostra Domina 通过采用数据增强技术，有效提升了拉丁语极性检测的准确性。](2024年04月11日/Nostra_Domina_at_EvaLatin_2024_Improving_Latin_Polarity_Detection_through_Data_Augmentation.md)

- [Discourse-Aware In-Context Learning for Temporal Expression Normalization](2024年04月11日/Discourse-Aware_In-Context_Learning_for_Temporal_Expression_Normalization.md)

    - [翻译: 在时间表达归一化任务中，采用话语感知的上下文学习方法，以提高处理效果。](2024年04月11日/Discourse-Aware_In-Context_Learning_for_Temporal_Expression_Normalization.md)

- [AnnoCTR: A Dataset for Detecting and Linking Entities, Tactics, and Techniques in Cyber Threat Reports](2024年04月11日/AnnoCTR_A_Dataset_for_Detecting_and_Linking_Entities,_Tactics,_and_Techniques_in_Cyber_Threat_Reports.md)

    - [翻译: AnnoCTR：网络威胁报告中实体、策略与技术检测与关联的数据集](2024年04月11日/AnnoCTR_A_Dataset_for_Detecting_and_Linking_Entities,_Tactics,_and_Techniques_in_Cyber_Threat_Reports.md)

- [Generating consistent PDDL domains with Large Language Models](2024年04月11日/Generating_consistent_PDDL_domains_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，打造统一的PDDL领域](2024年04月11日/Generating_consistent_PDDL_domains_with_Large_Language_Models.md)

- [ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models](2024年04月11日/ResearchAgent_Iterative_Research_Idea_Generation_over_Scientific_Literature_with_Large_Language_Models.md)

    - [翻译: ResearchAgent：借助大型语言模型，通过科学文献实现研究创意的迭代产生](2024年04月11日/ResearchAgent_Iterative_Research_Idea_Generation_over_Scientific_Literature_with_Large_Language_Models.md)

- [Unraveling the Dilemma of AI Errors: Exploring the Effectiveness of Human and Machine Explanations for Large Language Models](2024年04月11日/Unraveling_the_Dilemma_of_AI_Errors_Exploring_the_Effectiveness_of_Human_and_Machine_Explanations_for_Large_Language_Models.md)

    - [翻译: 探究AI误差之谜：研究人类与机器解释在大型语言模型中的有效性。](2024年04月11日/Unraveling_the_Dilemma_of_AI_Errors_Exploring_the_Effectiveness_of_Human_and_Machine_Explanations_for_Large_Language_Models.md)

- [Automatic Generation and Evaluation of Reading Comprehension Test Items with Large Language Models](2024年04月11日/Automatic_Generation_and_Evaluation_of_Reading_Comprehension_Test_Items_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，实现阅读理解试题的自动生成与评估](2024年04月11日/Automatic_Generation_and_Evaluation_of_Reading_Comprehension_Test_Items_with_Large_Language_Models.md)

- [Reflectance Estimation for Proximity Sensing by Vision-Language Models: Utilizing Distributional Semantics for Low-Level Cognition in Robotics](2024年04月11日/Reflectance_Estimation_for_Proximity_Sensing_by_Vision-Language_Models_Utilizing_Distributional_Semantics_for_Low-Level_Cognition_in_Robotics.md)

    - [翻译: 视觉-语言模型用于邻近感知的反射率估算：在机器人学领域，运用分布式语义学来实现低层次认知。](2024年04月11日/Reflectance_Estimation_for_Proximity_Sensing_by_Vision-Language_Models_Utilizing_Distributional_Semantics_for_Low-Level_Cognition_in_Robotics.md)

- [ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs](2024年04月11日/ODA_Observation-Driven_Agent_for_integrating_LLMs_and_Knowledge_Graphs.md)

    - [翻译: ODA，即观察驱动代理，旨在融合大型语言模型与知识图谱，提升智能代理的性能。](2024年04月11日/ODA_Observation-Driven_Agent_for_integrating_LLMs_and_Knowledge_Graphs.md)

- [rollama: An R package for using generative large language models through Ollama](2024年04月11日/rollama_An_R_package_for_using_generative_large_language_models_through_Ollama.md)

    - [翻译: Rollama，一个借助Ollama实现的R语言包，用于调用和利用生成式大型语言模型。](2024年04月11日/rollama_An_R_package_for_using_generative_large_language_models_through_Ollama.md)

- [Why do small language models underperform? Studying Language Model Saturation via the Softmax Bottleneck](2024年04月11日/Why_do_small_language_models_underperform_Studying_Language_Model_Saturation_via_the_Softmax_Bottleneck.md)

    - [翻译: 小型语言模型为何表现不尽人意？探究 Softmax 瓶颈背后的语言模型饱和现象。](2024年04月11日/Why_do_small_language_models_underperform_Studying_Language_Model_Saturation_via_the_Softmax_Bottleneck.md)

- [Audio Dialogues: Dialogues dataset for audio and music understanding](2024年04月11日/Audio_Dialogues_Dialogues_dataset_for_audio_and_music_understanding.md)

    - [翻译: 音频对话集：为深入理解和分析音频及音乐而打造的对话数据集。](2024年04月11日/Audio_Dialogues_Dialogues_dataset_for_audio_and_music_understanding.md)

- [Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain](2024年04月11日/Medical_mT5_An_Open-Source_Multilingual_Text-to-Text_LLM_for_The_Medical_Domain.md)

    - [翻译: Medical mT5：一款面向医学领域的开源多语言文本到文本转换的大型语言模型。](2024年04月11日/Medical_mT5_An_Open-Source_Multilingual_Text-to-Text_LLM_for_The_Medical_Domain.md)

- [Measuring Geographic Diversity of Foundation Models with a Natural Language--based Geo-guessing Experiment on GPT-4](2024年04月11日/Measuring_Geographic_Diversity_of_Foundation_Models_with_a_Natural_Language--based_Geo-guessing_Experiment_on_GPT-4.md)

    - [翻译: 通过在GPT-4上开展一项自然语言地理猜测实验，我们探究了基础模型的地理多样性。](2024年04月11日/Measuring_Geographic_Diversity_of_Foundation_Models_with_a_Natural_Language--based_Geo-guessing_Experiment_on_GPT-4.md)

- [NoticIA: A Clickbait Article Summarization Dataset in Spanish](2024年04月11日/NoticIA_A_Clickbait_Article_Summarization_Dataset_in_Spanish.md)

    - [翻译: NoticIA：西班牙语点击诱饵文章的摘要数据集](2024年04月11日/NoticIA_A_Clickbait_Article_Summarization_Dataset_in_Spanish.md)

- [Implicit and Explicit Language Guidance for Diffusion-based Visual Perception](2024年04月11日/Implicit_and_Explicit_Language_Guidance_for_Diffusion-based_Visual_Perception.md)

    - [翻译: 在基于扩散模型的视觉感知任务中，隐性与显性语言引导的结合运用](2024年04月11日/Implicit_and_Explicit_Language_Guidance_for_Diffusion-based_Visual_Perception.md)

- [UltraEval: A Lightweight Platform for Flexible and Comprehensive Evaluation for LLMs](2024年04月11日/UltraEval_A_Lightweight_Platform_for_Flexible_and_Comprehensive_Evaluation_for_LLMs.md)

    - [翻译: UltraEval：为大型语言模型（LLMs）提供了一个轻巧、灵活且全面的评估平台。](2024年04月11日/UltraEval_A_Lightweight_Platform_for_Flexible_and_Comprehensive_Evaluation_for_LLMs.md)

- [Can Vehicle Motion Planning Generalize to Realistic Long-tail Scenarios?](2024年04月11日/Can_Vehicle_Motion_Planning_Generalize_to_Realistic_Long-tail_Scenarios.md)

    - [翻译: 车辆运动规划能否适应现实世界中的长尾情景？](2024年04月11日/Can_Vehicle_Motion_Planning_Generalize_to_Realistic_Long-tail_Scenarios.md)

- [Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective](2024年04月11日/Comments_as_Natural_Logic_Pivots_Improve_Code_Generation_via_Comment_Perspective.md)

    - [翻译: 将评论视作自然逻辑的转换点，以此来提升代码生成的效果。](2024年04月11日/Comments_as_Natural_Logic_Pivots_Improve_Code_Generation_via_Comment_Perspective.md)

- [Decomposing Label Space, Format and Discrimination: Rethinking How LLMs Respond and Solve Tasks via In-Context Learning](2024年04月11日/Decomposing_Label_Space,_Format_and_Discrimination_Rethinking_How_LLMs_Respond_and_Solve_Tasks_via_In-Context_Learning.md)

    - [翻译: 解构标签空间、格式与歧视现象：深入探讨大型语言模型（LLM）通过上下文学习应对与解决问题的机制。](2024年04月11日/Decomposing_Label_Space,_Format_and_Discrimination_Rethinking_How_LLMs_Respond_and_Solve_Tasks_via_In-Context_Learning.md)

- [From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples](2024年04月11日/From_Words_to_Numbers_Your_Large_Language_Model_Is_Secretly_A_Capable_Regressor_When_Given_In-Context_Examples.md)

    - [翻译: 单词变身数字：揭示大型语言模型在上下文示例辅助下的隐秘回归能力。](2024年04月11日/From_Words_to_Numbers_Your_Large_Language_Model_Is_Secretly_A_Capable_Regressor_When_Given_In-Context_Examples.md)

- [Best Practices and Lessons Learned on Synthetic Data for Language Models](2024年04月11日/Best_Practices_and_Lessons_Learned_on_Synthetic_Data_for_Language_Models.md)

    - [翻译: 在语言模型的合成数据应用中，我们总结了一些最佳实践和所汲取的教训。](2024年04月11日/Best_Practices_and_Lessons_Learned_on_Synthetic_Data_for_Language_Models.md)

- [Can Large Language Models Assess Serendipity in Recommender Systems?](2024年04月11日/Can_Large_Language_Models_Assess_Serendipity_in_Recommender_Systems.md)

    - [翻译: 大型语言模型能否对推荐系统里的惊喜元素进行评价？](2024年04月11日/Can_Large_Language_Models_Assess_Serendipity_in_Recommender_Systems.md)

- [Neural Fault Injection: Generating Software Faults from Natural Language](2024年04月11日/Neural_Fault_Injection_Generating_Software_Faults_from_Natural_Language.md)

    - [翻译: 神经故障注入技术：利用自然语言创建软件缺陷](2024年04月11日/Neural_Fault_Injection_Generating_Software_Faults_from_Natural_Language.md)

- [Multimodal Emotion Recognition by Fusing Video Semantic in MOOC Learning Scenarios](2024年04月11日/Multimodal_Emotion_Recognition_by_Fusing_Video_Semantic_in_MOOC_Learning_Scenarios.md)

    - [翻译: 在大规模在线开放课程（MOOC）的学习环境中，通过整合视频中的语义信息，实现对学习者情感的多维度识别。](2024年04月11日/Multimodal_Emotion_Recognition_by_Fusing_Video_Semantic_in_MOOC_Learning_Scenarios.md)

- [Scalable Language Model with Generalized Continual Learning](2024年04月11日/Scalable_Language_Model_with_Generalized_Continual_Learning.md)

    - [翻译: 本文介绍了一种具有泛化持续学习能力的可扩展语言模型。](2024年04月11日/Scalable_Language_Model_with_Generalized_Continual_Learning.md)

- [Improving Continuous Sign Language Recognition with Adapted Image Models](2024年04月11日/Improving_Continuous_Sign_Language_Recognition_with_Adapted_Image_Models.md)

    - [翻译: 借助调整后的图像模型，提升连续手语识别的准确性](2024年04月11日/Improving_Continuous_Sign_Language_Recognition_with_Adapted_Image_Models.md)

- [Reducing hallucination in structured outputs via Retrieval-Augmented Generation](2024年04月11日/Reducing_hallucination_in_structured_outputs_via_Retrieval-Augmented_Generation.md)

    - [翻译: 利用检索辅助生成技术，降低结构化输出中的失真现象](2024年04月11日/Reducing_hallucination_in_structured_outputs_via_Retrieval-Augmented_Generation.md)

- [Distilling Algorithmic Reasoning from LLMs via Explaining Solution Programs](2024年04月11日/Distilling_Algorithmic_Reasoning_from_LLMs_via_Explaining_Solution_Programs.md)

    - [翻译: 通过解析解题程序，从大型语言模型 (LLM) 中提取算法推理能力。](2024年04月11日/Distilling_Algorithmic_Reasoning_from_LLMs_via_Explaining_Solution_Programs.md)

- [Generative Information Retrieval Evaluation](2024年04月11日/Generative_Information_Retrieval_Evaluation.md)

    - [翻译: 在生成式信息检索领域，评估方法的创新和优化是推动技术进步的关键。通过对检索结果的生成质量、相关性和实用性进行综合评估，我们可以更好地理解和提升系统的性能。](2024年04月11日/Generative_Information_Retrieval_Evaluation.md)

- [Auctions with LLM Summaries](2024年04月11日/Auctions_with_LLM_Summaries.md)

    - [翻译: 在拍卖中，利用大型语言模型（LLM）提供的摘要可以为参与者提供更丰富、直观的信息，从而提高拍卖的透明度和效率。](2024年04月11日/Auctions_with_LLM_Summaries.md)

- [Data-Augmentation-Based Dialectal Adaptation for LLMs](2024年04月11日/Data-Augmentation-Based_Dialectal_Adaptation_for_LLMs.md)

    - [翻译: 针对大型语言模型，采用数据增强技术进行方言适配。](2024年04月11日/Data-Augmentation-Based_Dialectal_Adaptation_for_LLMs.md)

- [SQBC: Active Learning using LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions](2024年04月11日/SQBC_Active_Learning_using_LLM-Generated_Synthetic_Data_for_Stance_Detection_in_Online_Political_Discussions.md)

    - [翻译: SQBC：运用由大型语言模型生成的合成数据，主动学习以识别在线政治讨论中的立场。](2024年04月11日/SQBC_Active_Learning_using_LLM-Generated_Synthetic_Data_for_Stance_Detection_in_Online_Political_Discussions.md)

- [MSciNLI: A Diverse Benchmark for Scientific Natural Language Inference](2024年04月11日/MSciNLI_A_Diverse_Benchmark_for_Scientific_Natural_Language_Inference.md)

    - [翻译: MSciNLI：为科学领域量身打造的自然语言推理多维度评测基准](2024年04月11日/MSciNLI_A_Diverse_Benchmark_for_Scientific_Natural_Language_Inference.md)

- [Latent Guard: a Safety Framework for Text-to-image Generation](2024年04月11日/Latent_Guard_a_Safety_Framework_for_Text-to-image_Generation.md)

    - [翻译: 《潜在守卫》：为文本生成图像提供的安全框架](2024年04月11日/Latent_Guard_a_Safety_Framework_for_Text-to-image_Generation.md)

- [A Multi-Expert Large Language Model Architecture for Verilog Code Generation](2024年04月11日/A_Multi-Expert_Large_Language_Model_Architecture_for_Verilog_Code_Generation.md)

    - [翻译: 本文介绍了一种面向 Verilog 代码生成的多专家大型语言模型架构。](2024年04月11日/A_Multi-Expert_Large_Language_Model_Architecture_for_Verilog_Code_Generation.md)

- [Augmenting Knowledge Graph Hierarchies Using Neural Transformers](2024年04月11日/Augmenting_Knowledge_Graph_Hierarchies_Using_Neural_Transformers.md)

    - [翻译: 通过神经变换器技术，我们能够提升知识图谱的层级结构。](2024年04月11日/Augmenting_Knowledge_Graph_Hierarchies_Using_Neural_Transformers.md)

- [MM-PhyQA: Multimodal Physics Question-Answering With Multi-Image CoT Prompting](2024年04月11日/MM-PhyQA_Multimodal_Physics_Question-Answering_With_Multi-Image_CoT_Prompting.md)

    - [翻译: MM-PhyQA：运用多张图片的 CoT 提示技术，实现多模态物理问答功能。](2024年04月11日/MM-PhyQA_Multimodal_Physics_Question-Answering_With_Multi-Image_CoT_Prompting.md)

2024年04月10日

- [UMBRAE: Unified Multimodal Decoding of Brain Signals](2024年04月10日/UMBRAE_Unified_Multimodal_Decoding_of_Brain_Signals.md)

    - [翻译: UMBRAE：一种整合多种模式的脑信号解读技术](2024年04月10日/UMBRAE_Unified_Multimodal_Decoding_of_Brain_Signals.md)

- [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](2024年04月10日/Leave_No_Context_Behind_Efficient_Infinite_Context_Transformers_with_Infini-attention.md)

    - [翻译: 全面覆盖：搭载无限注意力机制的高效无限上下文变换器，让每个细节都得到关注。](2024年04月10日/Leave_No_Context_Behind_Efficient_Infinite_Context_Transformers_with_Infini-attention.md)

- [What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation](2024年04月10日/What_needs_to_go_right_for_an_induction_head_A_mechanistic_study_of_in-context_learning_circuits_and_their_formation.md)

    - [翻译: 要让感应头部发挥作用，需要哪些关键因素？本文通过机械性研究，深入探讨了上下文学习电路及其形成过程。](2024年04月10日/What_needs_to_go_right_for_an_induction_head_A_mechanistic_study_of_in-context_learning_circuits_and_their_formation.md)

- [Continuous Language Model Interpolation for Dynamic and Controllable Text Generation](2024年04月10日/Continuous_Language_Model_Interpolation_for_Dynamic_and_Controllable_Text_Generation.md)

    - [翻译: 通过连续性的语言模型融合技术，实现文本生成的动态调整与精准控制。](2024年04月10日/Continuous_Language_Model_Interpolation_for_Dynamic_and_Controllable_Text_Generation.md)

- [From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications](2024年04月10日/From_Model-centered_to_Human-Centered_Revision_Distance_as_a_Metric_for_Text_Evaluation_in_LLMs-based_Applications.md)

    - [翻译: 将视角从模型转向人类，修订距离被提出作为评估基于大型语言模型（LLMs）应用中文本质量的新指标。](2024年04月10日/From_Model-centered_to_Human-Centered_Revision_Distance_as_a_Metric_for_Text_Evaluation_in_LLMs-based_Applications.md)

- [Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs](2024年04月10日/Graph_Chain-of-Thought_Augmenting_Large_Language_Models_by_Reasoning_on_Graphs.md)

    - [翻译: 图链思考：借助图谱推理，提升大型语言模型的智能水平。](2024年04月10日/Graph_Chain-of-Thought_Augmenting_Large_Language_Models_by_Reasoning_on_Graphs.md)

- [Dynamic Generation of Personalities with Large Language Models](2024年04月10日/Dynamic_Generation_of_Personalities_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，实现个性化人格的动态塑造](2024年04月10日/Dynamic_Generation_of_Personalities_with_Large_Language_Models.md)

- [VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning](2024年04月10日/VLLMs_Provide_Better_Context_for_Emotion_Understanding_Through_Common_Sense_Reasoning.md)

    - [翻译: 借助常识推理，超大型语言模型（VLLMs）能够更精准地把握情感理解的脉络。](2024年04月10日/VLLMs_Provide_Better_Context_for_Emotion_Understanding_Through_Common_Sense_Reasoning.md)

- [Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?](2024年04月10日/Exploring_Concept_Depth_How_Large_Language_Models_Acquire_Knowledge_at_Different_Layers.md)

    - [翻译: 深入概念探究：大型语言模型是如何在各自的层次上吸收知识的呢？](2024年04月10日/Exploring_Concept_Depth_How_Large_Language_Models_Acquire_Knowledge_at_Different_Layers.md)

- [Groundedness in Retrieval-augmented Long-form Generation: An Empirical Study](2024年04月10日/Groundedness_in_Retrieval-augmented_Long-form_Generation_An_Empirical_Study.md)

    - [翻译: 本实证研究深入探讨了检索辅助长篇文章生成中的 Groundedness 问题。](2024年04月10日/Groundedness_in_Retrieval-augmented_Long-form_Generation_An_Empirical_Study.md)

- [ORacle: Large Vision-Language Models for Knowledge-Guided Holistic OR Domain Modeling](2024年04月10日/ORacle_Large_Vision-Language_Models_for_Knowledge-Guided_Holistic_OR_Domain_Modeling.md)

    - [翻译: ORacle：面向整体OR领域建模的知识引导型大型视觉-语言模型](2024年04月10日/ORacle_Large_Vision-Language_Models_for_Knowledge-Guided_Holistic_OR_Domain_Modeling.md)

- [A Mathematical Theory for Learning Semantic Languages by Abstract Learners](2024年04月10日/A_Mathematical_Theory_for_Learning_Semantic_Languages_by_Abstract_Learners.md)

    - [翻译: 抽象学习者学习语义语言的数学理论探究](2024年04月10日/A_Mathematical_Theory_for_Learning_Semantic_Languages_by_Abstract_Learners.md)

- [WordDecipher: Enhancing Digital Workspace Communication with Explainable AI for Non-native English Speakers](2024年04月10日/WordDecipher_Enhancing_Digital_Workspace_Communication_with_Explainable_AI_for_Non-native_English_Speakers.md)

    - [翻译: WordDecipher：借助可解释AI技术，提升非英语母语者在数字工作空间的沟通体验](2024年04月10日/WordDecipher_Enhancing_Digital_Workspace_Communication_with_Explainable_AI_for_Non-native_English_Speakers.md)

- [LM Transparency Tool: Interactive Tool for Analyzing Transformer Language Models](2024年04月10日/LM_Transparency_Tool_Interactive_Tool_for_Analyzing_Transformer_Language_Models.md)

    - [翻译: LM 透明度工具：深入剖析 Transformer 语言模型的互动利器](2024年04月10日/LM_Transparency_Tool_Interactive_Tool_for_Analyzing_Transformer_Language_Models.md)

- [Event Grounded Criminal Court View Generation withCooperative (Large) Language Models](2024年04月10日/Event_Grounded_Criminal_Court_View_Generation_withCooperative_(Large)_Language_Models.md)

    - [翻译: 刑事法庭视角生成：基于事件的合作大型语言模型应用](2024年04月10日/Event_Grounded_Criminal_Court_View_Generation_withCooperative_(Large)_Language_Models.md)

- [Hybrid Multi-stage Decoding for Few-shot NER with Entity-aware Contrastive Learning](2024年04月10日/Hybrid_Multi-stage_Decoding_for_Few-shot_NER_with_Entity-aware_Contrastive_Learning.md)

    - [翻译: 本文提出了一种结合实体感知对比学习的方法，用于少样本命名实体识别（NER）的混合多阶段解码策略。](2024年04月10日/Hybrid_Multi-stage_Decoding_for_Few-shot_NER_with_Entity-aware_Contrastive_Learning.md)

- [Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study](2024年04月10日/Advancing_Real-time_Pandemic_Forecasting_Using_Large_Language_Models_A_COVID-19_Case_Study.md)

    - [翻译: 借助大型语言模型，提升实时疫情预测的准确性：以COVID-19为例的深入分析](2024年04月10日/Advancing_Real-time_Pandemic_Forecasting_Using_Large_Language_Models_A_COVID-19_Case_Study.md)

- [Accelerating Inference in Large Language Models with a Unified Layer Skipping Strategy](2024年04月10日/Accelerating_Inference_in_Large_Language_Models_with_a_Unified_Layer_Skipping_Strategy.md)

    - [翻译: 通过统一的层跳过技巧，我们能够加快大型语言模型的推理速度。](2024年04月10日/Accelerating_Inference_in_Large_Language_Models_with_a_Unified_Layer_Skipping_Strategy.md)

- [MetaCheckGPT -- A Multi-task Hallucination Detection Using LLM Uncertainty and Meta-models](2024年04月10日/MetaCheckGPT_--_A_Multi-task_Hallucination_Detection_Using_LLM_Uncertainty_and_Meta-models.md)

    - [翻译: MetaCheckGPT —— 通过 LLM 的不确定性和元模型实现多任务幻觉检测](2024年04月10日/MetaCheckGPT_--_A_Multi-task_Hallucination_Detection_Using_LLM_Uncertainty_and_Meta-models.md)

- [GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications](2024年04月10日/GoEX_Perspectives_and_Designs_Towards_a_Runtime_for_Autonomous_LLM_Applications.md)

    - [翻译: GoEX：探索构建自主大型语言模型应用运行时的视角与设计理念](2024年04月10日/GoEX_Perspectives_and_Designs_Towards_a_Runtime_for_Autonomous_LLM_Applications.md)

- [HRVDA: High-Resolution Visual Document Assistant](2024年04月10日/HRVDA_High-Resolution_Visual_Document_Assistant.md)

    - [翻译: HRVDA：高清视觉文档辅助工具](2024年04月10日/HRVDA_High-Resolution_Visual_Document_Assistant.md)

- [Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation](2024年04月10日/Superposition_Prompting_Improving_and_Accelerating_Retrieval-Augmented_Generation.md)

    - [翻译: 超位置提示技术：提升并加快检索辅助生成的效果](2024年04月10日/Superposition_Prompting_Improving_and_Accelerating_Retrieval-Augmented_Generation.md)

- [SARA: Smart AI Reading Assistant for Reading Comprehension](2024年04月10日/SARA_Smart_AI_Reading_Assistant_for_Reading_Comprehension.md)

    - [翻译: SARA：智能AI阅读助手，助力阅读理解](2024年04月10日/SARA_Smart_AI_Reading_Assistant_for_Reading_Comprehension.md)

- [Vision-Language Model-based Physical Reasoning for Robot Liquid Perception](2024年04月10日/Vision-Language_Model-based_Physical_Reasoning_for_Robot_Liquid_Perception.md)

    - [翻译: 利用视觉-语言模型，实现机器人对液体的物理识别与推理。](2024年04月10日/Vision-Language_Model-based_Physical_Reasoning_for_Robot_Liquid_Perception.md)

- [Beyond Random Inputs: A Novel ML-Based Hardware Fuzzing](2024年04月10日/Beyond_Random_Inputs_A_Novel_ML-Based_Hardware_Fuzzing.md)

    - [翻译: 除了随机输入，我们还探索了一种基于机器学习的创新硬件模糊测试方法。](2024年04月10日/Beyond_Random_Inputs_A_Novel_ML-Based_Hardware_Fuzzing.md)

- [Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural Knowledge](2024年04月10日/Does_Mapo_Tofu_Contain_Coffee_Probing_LLMs_for_Food-related_Cultural_Knowledge.md)

    - [翻译: 麻婆豆腐是否含有咖啡成分？深挖大型语言模型对食物文化知识的掌握](2024年04月10日/Does_Mapo_Tofu_Contain_Coffee_Probing_LLMs_for_Food-related_Cultural_Knowledge.md)

- [Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation](2024年04月10日/Not_All_Contexts_Are_Equal_Teaching_LLMs_Credibility-aware_Generation.md)

    - [翻译: 上下文并非一视同仁：引导大型语言模型（LLM）进行可信度敏感的内容生成。](2024年04月10日/Not_All_Contexts_Are_Equal_Teaching_LLMs_Credibility-aware_Generation.md)

- [MedRG: Medical Report Grounding with Multi-modal Large Language Model](2024年04月10日/MedRG_Medical_Report_Grounding_with_Multi-modal_Large_Language_Model.md)

    - [翻译: MedRG：借助多模态大型语言模型实现医学报告的精准定位](2024年04月10日/MedRG_Medical_Report_Grounding_with_Multi-modal_Large_Language_Model.md)

- [Adapting LLaMA Decoder to Vision Transformer](2024年04月10日/Adapting_LLaMA_Decoder_to_Vision_Transformer.md)

    - [翻译: 适配 LLaMA 解码器至视觉变换网络](2024年04月10日/Adapting_LLaMA_Decoder_to_Vision_Transformer.md)

- [Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems](2024年04月10日/Personality-aware_Student_Simulation_for_Conversational_Intelligent_Tutoring_Systems.md)

    - [翻译: 为了会话式智能辅导系统，我们开发了一种能够感知学生个性的模拟技术。](2024年04月10日/Personality-aware_Student_Simulation_for_Conversational_Intelligent_Tutoring_Systems.md)

- [Language Generation in the Limit](2024年04月10日/Language_Generation_in_the_Limit.md)

    - [翻译: 极限下的语言生成](2024年04月10日/Language_Generation_in_the_Limit.md)

- [Frontier AI Ethics: Anticipating and Evaluating the Societal Impacts of Generative Agents](2024年04月10日/Frontier_AI_Ethics_Anticipating_and_Evaluating_the_Societal_Impacts_of_Generative_Agents.md)

    - [翻译: 探索AI伦理新境界：洞悉并评估生成性智能体对社会的深远影响](2024年04月10日/Frontier_AI_Ethics_Anticipating_and_Evaluating_the_Societal_Impacts_of_Generative_Agents.md)

- [Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking](2024年04月10日/Transferable_and_Efficient_Non-Factual_Content_Detection_via_Probe_Training_with_Offline_Consistency_Checking.md)

    - [翻译: 本研究通过探针训练结合离线一致性检查，提出了一种可迁移且高效的非事实内容检测方法。](2024年04月10日/Transferable_and_Efficient_Non-Factual_Content_Detection_via_Probe_Training_with_Offline_Consistency_Checking.md)

- [Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination](2024年04月10日/Accuracy_of_a_Large_Language_Model_in_Distinguishing_Anti-_And_Pro-vaccination_Messages_on_Social_Media_The_Case_of_Human_Papillomavirus_Vaccination.md)

    - [翻译: 社交媒体上，大型语言模型识别反疫苗与支持疫苗信息的准确度探究：以人乳头瘤病毒疫苗为案例分析。](2024年04月10日/Accuracy_of_a_Large_Language_Model_in_Distinguishing_Anti-_And_Pro-vaccination_Messages_on_Social_Media_The_Case_of_Human_Papillomavirus_Vaccination.md)

- [Towards Robustness of Text-to-Visualization Translation against Lexical and Phrasal Variability](2024年04月10日/Towards_Robustness_of_Text-to-Visualization_Translation_against_Lexical_and_Phrasal_Variability.md)

    - [翻译: 为提升文本至可视化翻译的稳定性，本研究致力于应对词汇与短语多样性所带来的挑战。](2024年04月10日/Towards_Robustness_of_Text-to-Visualization_Translation_against_Lexical_and_Phrasal_Variability.md)

- [GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models](2024年04月10日/GoodDrag_Towards_Good_Practices_for_Drag_Editing_with_Diffusion_Models.md)

    - [翻译: GoodDrag：探索扩散模型在拖拽编辑中的优良实践方法](2024年04月10日/GoodDrag_Towards_Good_Practices_for_Drag_Editing_with_Diffusion_Models.md)

- ["Confidently Nonsensical?'': A Critical Survey on the Perspectives and Challenges of 'Hallucinations' in NLP](2024年04月10日/Confidently_Nonsensical''_A_Critical_Survey_on_the_Perspectives_and_Challenges_of_'Hallucinations'_in_NLP.md)

    - [翻译: 《荒谬与否？——自然语言处理中“幻觉”现象的批判性审视与挑战探讨》](2024年04月10日/Confidently_Nonsensical''_A_Critical_Survey_on_the_Perspectives_and_Challenges_of_'Hallucinations'_in_NLP.md)

- [WESE: Weak Exploration to Strong Exploitation for LLM Agents](2024年04月10日/WESE_Weak_Exploration_to_Strong_Exploitation_for_LLM_Agents.md)

    - [翻译: WESE：为大型语言模型代理实现从浅尝辄止到深度挖掘的转变](2024年04月10日/WESE_Weak_Exploration_to_Strong_Exploitation_for_LLM_Agents.md)

- [RiskLabs: Predicting Financial Risk Using Large Language Model Based on Multi-Sources Data](2024年04月10日/RiskLabs_Predicting_Financial_Risk_Using_Large_Language_Model_Based_on_Multi-Sources_Data.md)

    - [翻译: RiskLabs 项目利用大型语言模型，结合多源数据，旨在预测金融风险。](2024年04月10日/RiskLabs_Predicting_Financial_Risk_Using_Large_Language_Model_Based_on_Multi-Sources_Data.md)

- [Learning to Localize Objects Improves Spatial Reasoning in Visual-LLMs](2024年04月10日/Learning_to_Localize_Objects_Improves_Spatial_Reasoning_in_Visual-LLMs.md)

    - [翻译: 通过学习识别物体的位置，视觉-大型语言模型在空间推理方面的表现得到了显著提升。](2024年04月10日/Learning_to_Localize_Objects_Improves_Spatial_Reasoning_in_Visual-LLMs.md)

- [Transferable and Principled Efficiency for Open-Vocabulary Segmentation](2024年04月10日/Transferable_and_Principled_Efficiency_for_Open-Vocabulary_Segmentation.md)

    - [翻译: 开放词汇分割的可迁移性和原则性高效性](2024年04月10日/Transferable_and_Principled_Efficiency_for_Open-Vocabulary_Segmentation.md)

- [Data-Driven Portfolio Management for Motion Pictures Industry: A New Data-Driven Optimization Methodology Using a Large Language Model as the Expert](2024年04月10日/Data-Driven_Portfolio_Management_for_Motion_Pictures_Industry_A_New_Data-Driven_Optimization_Methodology_Using_a_Large_Language_Model_as_the_Expert.md)

    - [翻译: 电影产业采用数据驱动策略：借助大型语言模型的专业知识，探索一种创新的数据驱动优化方法。](2024年04月10日/Data-Driven_Portfolio_Management_for_Motion_Pictures_Industry_A_New_Data-Driven_Optimization_Methodology_Using_a_Large_Language_Model_as_the_Expert.md)

- [AdaDemo: Data-Efficient Demonstration Expansion for Generalist Robotic Agent](2024年04月10日/AdaDemo_Data-Efficient_Demonstration_Expansion_for_Generalist_Robotic_Agent.md)

    - [翻译: AdaDemo 通过数据高效的方式扩展通用机器人代理的演示，助力其更好地学习和适应多样化任务。](2024年04月10日/AdaDemo_Data-Efficient_Demonstration_Expansion_for_Generalist_Robotic_Agent.md)

- [CopilotCAD: Empowering Radiologists with Report Completion Models and Quantitative Evidence from Medical Image Foundation Models](2024年04月10日/CopilotCAD_Empowering_Radiologists_with_Report_Completion_Models_and_Quantitative_Evidence_from_Medical_Image_Foundation_Models.md)

    - [翻译: CopilotCAD：借助医学影像基础模型的报告完成模型和定量证据，提升放射科医生的工作效率](2024年04月10日/CopilotCAD_Empowering_Radiologists_with_Report_Completion_Models_and_Quantitative_Evidence_from_Medical_Image_Foundation_Models.md)

- [JetMoE: Reaching Llama2 Performance with 0.1M Dollars](2024年04月10日/JetMoE_Reaching_Llama2_Performance_with_0.1M_Dollars.md)

    - [翻译: JetMoE：以百万美元级成本实现Llama2级别性能](2024年04月10日/JetMoE_Reaching_Llama2_Performance_with_0.1M_Dollars.md)

- [LLMs in Biomedicine: A study on clinical Named Entity Recognition](2024年04月10日/LLMs_in_Biomedicine_A_study_on_clinical_Named_Entity_Recognition.md)

    - [翻译: 在生物医学领域，LLMs的应用：探究临床命名实体识别的研究成果](2024年04月10日/LLMs_in_Biomedicine_A_study_on_clinical_Named_Entity_Recognition.md)

- [Analyzing the Performance of Large Language Models on Code Summarization](2024年04月10日/Analyzing_the_Performance_of_Large_Language_Models_on_Code_Summarization.md)

    - [翻译: 探究大型语言模型在代码摘要任务上的表现](2024年04月10日/Analyzing_the_Performance_of_Large_Language_Models_on_Code_Summarization.md)

- [Is Your LLM Outdated? Benchmarking LLMs & Alignment Algorithms for Time-Sensitive Knowledge](2024年04月10日/Is_Your_LLM_Outdated_Benchmarking_LLMs_&_Alignment_Algorithms_for_Time-Sensitive_Knowledge.md)

    - [翻译: 你的大型语言模型（LLM）落伍了吗？本文旨在评估适用于时效性知识的 LLM 和对齐算法的性能基准。](2024年04月10日/Is_Your_LLM_Outdated_Benchmarking_LLMs_&_Alignment_Algorithms_for_Time-Sensitive_Knowledge.md)

- [Enhancing Question Answering for Enterprise Knowledge Bases using Large Language Models](2024年04月10日/Enhancing_Question_Answering_for_Enterprise_Knowledge_Bases_using_Large_Language_Models.md)

    - [翻译: 通过运用大型语言模型，我们能够提升企业知识库中的问答体验。](2024年04月10日/Enhancing_Question_Answering_for_Enterprise_Knowledge_Bases_using_Large_Language_Models.md)

2024年04月09日

- [Text-Based Reasoning About Vector Graphics](2024年04月09日/Text-Based_Reasoning_About_Vector_Graphics.md)

    - [翻译: 通过文本解读矢量图形的逻辑推理](2024年04月09日/Text-Based_Reasoning_About_Vector_Graphics.md)

- [VISION2UI: A Real-World Dataset with Layout for Code Generation from UI Designs](2024年04月09日/VISION2UI_A_Real-World_Dataset_with_Layout_for_Code_Generation_from_UI_Designs.md)

    - [翻译: VISION2UI：一个包含布局信息的真实世界数据集，用于从UI设计生成代码。](2024年04月09日/VISION2UI_A_Real-World_Dataset_with_Layout_for_Code_Generation_from_UI_Designs.md)

- [InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD](2024年04月09日/InternLM-XComposer2-4KHD_A_Pioneering_Large_Vision-Language_Model_Handling_Resolutions_from_336_Pixels_to_4K_HD.md)

    - [翻译: InternLM-XComposer2-4KHD，作为先锋的大型视觉-语言模型，能够应对从336像素直至4K高清的多样分辨率。](2024年04月09日/InternLM-XComposer2-4KHD_A_Pioneering_Large_Vision-Language_Model_Handling_Resolutions_from_336_Pixels_to_4K_HD.md)

- [Can Feedback Enhance Semantic Grounding in Large Vision-Language Models?](2024年04月09日/Can_Feedback_Enhance_Semantic_Grounding_in_Large_Vision-Language_Models.md)

    - [翻译: 反馈是否能够提升大型视觉-语言模型的语义理解能力？](2024年04月09日/Can_Feedback_Enhance_Semantic_Grounding_in_Large_Vision-Language_Models.md)

- [Reconstructing Hand-Held Objects in 3D](2024年04月09日/Reconstructing_Hand-Held_Objects_in_3D.md)

    - [翻译: 三维空间中手持物体的重建](2024年04月09日/Reconstructing_Hand-Held_Objects_in_3D.md)

- [Pitfalls of Conversational LLMs on News Debiasing](2024年04月09日/Pitfalls_of_Conversational_LLMs_on_News_Debiasing.md)

    - [翻译: 对话型大型语言模型在新闻去偏见方面的潜在问题](2024年04月09日/Pitfalls_of_Conversational_LLMs_on_News_Debiasing.md)

- [Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks](2024年04月09日/Ada-LEval_Evaluating_long-context_LLMs_with_length-adaptable_benchmarks.md)

    - [翻译: Ada-LEval：通过可伸缩的评估标准，对长文本处理能力的大型语言模型进行评测。](2024年04月09日/Ada-LEval_Evaluating_long-context_LLMs_with_length-adaptable_benchmarks.md)

- [Automated Federated Pipeline for Parameter-Efficient Fine-Tuning of Large Language Models](2024年04月09日/Automated_Federated_Pipeline_for_Parameter-Efficient_Fine-Tuning_of_Large_Language_Models.md)

    - [翻译: 本文介绍了一种自动化联邦管道技术，旨在实现大型语言模型微调过程中的参数高效利用。](2024年04月09日/Automated_Federated_Pipeline_for_Parameter-Efficient_Fine-Tuning_of_Large_Language_Models.md)

- [Large Language Models to the Rescue: Deadlock Resolution in Multi-Robot Systems](2024年04月09日/Large_Language_Models_to_the_Rescue_Deadlock_Resolution_in_Multi-Robot_Systems.md)

    - [翻译: 大型语言模型破解僵局：多机器人系统的死锁难题](2024年04月09日/Large_Language_Models_to_the_Rescue_Deadlock_Resolution_in_Multi-Robot_Systems.md)

- [AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents](2024年04月09日/AgentQuest_A_Modular_Benchmark_Framework_to_Measure_Progress_and_Improve_LLM_Agents.md)

    - [翻译: AgentQuest：构建模块化基准，助力大型语言模型（LLM）代理的发展与优化。](2024年04月09日/AgentQuest_A_Modular_Benchmark_Framework_to_Measure_Progress_and_Improve_LLM_Agents.md)

- [Take a Look at it! Rethinking How to Evaluate Language Model Jailbreak](2024年04月09日/Take_a_Look_at_it!_Rethinking_How_to_Evaluate_Language_Model_Jailbreak.md)

    - [翻译: 来一探究竟吧！重新审视评估语言模型突破的方法。](2024年04月09日/Take_a_Look_at_it!_Rethinking_How_to_Evaluate_Language_Model_Jailbreak.md)

- [Apprentices to Research Assistants: Advancing Research with Large Language Models](2024年04月09日/Apprentices_to_Research_Assistants_Advancing_Research_with_Large_Language_Models.md)

    - [翻译: 学徒变身研究助手：借助大型语言模型助力研究进步](2024年04月09日/Apprentices_to_Research_Assistants_Advancing_Research_with_Large_Language_Models.md)

- [MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies](2024年04月09日/MiniCPM_Unveiling_the_Potential_of_Small_Language_Models_with_Scalable_Training_Strategies.md)

    - [翻译: MiniCPM：借助可扩展训练策略，挖掘小型语言模型的潜在力量](2024年04月09日/MiniCPM_Unveiling_the_Potential_of_Small_Language_Models_with_Scalable_Training_Strategies.md)

- [MuPT: A Generative Symbolic Music Pretrained Transformer](2024年04月09日/MuPT_A_Generative_Symbolic_Music_Pretrained_Transformer.md)

    - [翻译: MuPT：一款预训练的变换器，专注于生成富有象征意义的音乐作品。](2024年04月09日/MuPT_A_Generative_Symbolic_Music_Pretrained_Transformer.md)

- [Latent Distance Guided Alignment Training for Large Language Models](2024年04月09日/Latent_Distance_Guided_Alignment_Training_for_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，采用潜在距离引导的对齐训练方法。](2024年04月09日/Latent_Distance_Guided_Alignment_Training_for_Large_Language_Models.md)

- [Model Generation from Requirements with LLMs: an Exploratory Study](2024年04月09日/Model_Generation_from_Requirements_with_LLMs_an_Exploratory_Study.md)

    - [翻译: 基于需求，利用大型语言模型生成模型：探索性研究](2024年04月09日/Model_Generation_from_Requirements_with_LLMs_an_Exploratory_Study.md)

- [Enhancing Decision Analysis with a Large Language Model: pyDecision a Comprehensive Library of MCDA Methods in Python](2024年04月09日/Enhancing_Decision_Analysis_with_a_Large_Language_Model_pyDecision_a_Comprehensive_Library_of_MCDA_Methods_in_Python.md)

    - [翻译: 借助大型语言模型，pyDecision 成为一个全面的 Python 多准则决策分析（MCDA）方法库，有效提升决策分析的效率和准确性。](2024年04月09日/Enhancing_Decision_Analysis_with_a_Large_Language_Model_pyDecision_a_Comprehensive_Library_of_MCDA_Methods_in_Python.md)

- [ClinLinker: Medical Entity Linking of Clinical Concept Mentions in Spanish](2024年04月09日/ClinLinker_Medical_Entity_Linking_of_Clinical_Concept_Mentions_in_Spanish.md)

    - [翻译: ClinLinker：将西班牙语临床术语中的医疗实体进行链接](2024年04月09日/ClinLinker_Medical_Entity_Linking_of_Clinical_Concept_Mentions_in_Spanish.md)

- [CausalBench: A Comprehensive Benchmark for Causal Learning Capability of Large Language Models](2024年04月09日/CausalBench_A_Comprehensive_Benchmark_for_Causal_Learning_Capability_of_Large_Language_Models.md)

    - [翻译: CausalBench：为大型语言模型的因果学习能力提供全面评估的基准测试平台](2024年04月09日/CausalBench_A_Comprehensive_Benchmark_for_Causal_Learning_Capability_of_Large_Language_Models.md)

- [AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning](2024年04月09日/AgentsCoDriver_Large_Language_Model_Empowered_Collaborative_Driving_with_Lifelong_Learning.md)

    - [翻译: AgentsCoDriver：借助大型语言模型实现的协作驾驶，采用终身学习机制。](2024年04月09日/AgentsCoDriver_Large_Language_Model_Empowered_Collaborative_Driving_with_Lifelong_Learning.md)

- [DRE: Generating Recommendation Explanations by Aligning Large Language Models at Data-level](2024年04月09日/DRE_Generating_Recommendation_Explanations_by_Aligning_Large_Language_Models_at_Data-level.md)

    - [翻译: DRE：通过数据层面的大型语言模型对齐，打造推荐解释的生成机制](2024年04月09日/DRE_Generating_Recommendation_Explanations_by_Aligning_Large_Language_Models_at_Data-level.md)

- [Exploring the True Potential: Evaluating the Black-box Optimization Capability of Large Language Models](2024年04月09日/Exploring_the_True_Potential_Evaluating_the_Black-box_Optimization_Capability_of_Large_Language_Models.md)

    - [翻译: 挖掘深层能力：对大型语言模型进行黑盒优化性能评估](2024年04月09日/Exploring_the_True_Potential_Evaluating_the_Black-box_Optimization_Capability_of_Large_Language_Models.md)

- [LLMs' Reading Comprehension Is Affected by Parametric Knowledge and Struggles with Hypothetical Statements](2024年04月09日/LLMs'_Reading_Comprehension_Is_Affected_by_Parametric_Knowledge_and_Struggles_with_Hypothetical_Statements.md)

    - [翻译: 大型语言模型在阅读理解方面易受参数知识左右，面对假设性语句时往往力不从心。](2024年04月09日/LLMs'_Reading_Comprehension_Is_Affected_by_Parametric_Knowledge_and_Struggles_with_Hypothetical_Statements.md)

- [Understanding Cross-Lingual Alignment -- A Survey](2024年04月09日/Understanding_Cross-Lingual_Alignment_--_A_Survey.md)

    - [翻译: 探索跨语言一致性：一项全面调查](2024年04月09日/Understanding_Cross-Lingual_Alignment_--_A_Survey.md)

- [Multimodal Road Network Generation Based on Large Language Model](2024年04月09日/Multimodal_Road_Network_Generation_Based_on_Large_Language_Model.md)

    - [翻译: 利用大型语言模型实现多模态道路网络的构建](2024年04月09日/Multimodal_Road_Network_Generation_Based_on_Large_Language_Model.md)

- [Low-Cost Generation and Evaluation of Dictionary Example Sentences](2024年04月09日/Low-Cost_Generation_and_Evaluation_of_Dictionary_Example_Sentences.md)

    - [翻译: 通过低成本的方式生成和评价词典中的示例句子，旨在高效地提升语言学习资源的质量。](2024年04月09日/Low-Cost_Generation_and_Evaluation_of_Dictionary_Example_Sentences.md)

- [OmniFusion Technical Report](2024年04月09日/OmniFusion_Technical_Report.md)

    - [翻译: OmniFusion 技术报告，全面解析](2024年04月09日/OmniFusion_Technical_Report.md)

- [Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models](2024年04月09日/Elephants_Never_Forget_Memorization_and_Learning_of_Tabular_Data_in_Large_Language_Models.md)

    - [翻译: 大象记忆力惊人，这篇文章探讨了大型语言模型如何记忆和学习表格数据。](2024年04月09日/Elephants_Never_Forget_Memorization_and_Learning_of_Tabular_Data_in_Large_Language_Models.md)

- [Open-Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning](2024年04月09日/Open-Source_AI-based_SE_Tools_Opportunities_and_Challenges_of_Collaborative_Software_Learning.md)

    - [翻译: 开源AI驱动的软件工程工具：携手共进的软件学习新机遇与面临挑战](2024年04月09日/Open-Source_AI-based_SE_Tools_Opportunities_and_Challenges_of_Collaborative_Software_Learning.md)

- [Exploring the Potential of Large Foundation Models for Open-Vocabulary HOI Detection](2024年04月09日/Exploring_the_Potential_of_Large_Foundation_Models_for_Open-Vocabulary_HOI_Detection.md)

    - [翻译: 本研究旨在挖掘大型基础模型在开放词汇表人体姿态识别（HOI）检测中的应用潜力。](2024年04月09日/Exploring_the_Potential_of_Large_Foundation_Models_for_Open-Vocabulary_HOI_Detection.md)

- [Clue-Instruct: Text-Based Clue Generation for Educational Crossword Puzzles](2024年04月09日/Clue-Instruct_Text-Based_Clue_Generation_for_Educational_Crossword_Puzzles.md)

    - [翻译: Clue-Instruct：为教育性填字游戏设计的文本线索生成方法](2024年04月09日/Clue-Instruct_Text-Based_Clue_Generation_for_Educational_Crossword_Puzzles.md)

- [Characterizing Multimodal Long-form Summarization: A Case Study on Financial Reports](2024年04月09日/Characterizing_Multimodal_Long-form_Summarization_A_Case_Study_on_Financial_Reports.md)

    - [翻译: 探究多模态长文本摘要：以金融报告分析为例](2024年04月09日/Characterizing_Multimodal_Long-form_Summarization_A_Case_Study_on_Financial_Reports.md)

- [Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages](2024年04月09日/Cendol_Open_Instruction-tuned_Generative_Large_Language_Models_for_Indonesian_Languages.md)

    - [翻译: Cendol：面向印尼语言的开放指令调整生成型大型语言模型](2024年04月09日/Cendol_Open_Instruction-tuned_Generative_Large_Language_Models_for_Indonesian_Languages.md)

- [Communication-Efficient Large-Scale Distributed Deep Learning: A Comprehensive Survey](2024年04月09日/Communication-Efficient_Large-Scale_Distributed_Deep_Learning_A_Comprehensive_Survey.md)

    - [翻译: 大规模分布式深度学习中的通信效率：一篇全面综述](2024年04月09日/Communication-Efficient_Large-Scale_Distributed_Deep_Learning_A_Comprehensive_Survey.md)

- [A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs](2024年04月09日/A_RAG_Method_for_Source_Code_Inquiry_Tailored_to_Long-Context_LLMs.md)

    - [翻译: 为长文本环境下的大型语言模型（LLMs）设计了一种源代码查询的随机访问图（RAG）策略。](2024年04月09日/A_RAG_Method_for_Source_Code_Inquiry_Tailored_to_Long-Context_LLMs.md)

- [Unified Multi-modal Diagnostic Framework with Reconstruction Pre-training and Heterogeneity-combat Tuning](2024年04月09日/Unified_Multi-modal_Diagnostic_Framework_with_Reconstruction_Pre-training_and_Heterogeneity-combat_Tuning.md)

    - [翻译: 本研究提出了一种集成的多模态诊断框架，该框架通过重建预训练和针对性的异质性调整，实现了对不同数据源的高效融合与诊断。](2024年04月09日/Unified_Multi-modal_Diagnostic_Framework_with_Reconstruction_Pre-training_and_Heterogeneity-combat_Tuning.md)

- [On Evaluating the Efficiency of Source Code Generated by LLMs](2024年04月09日/On_Evaluating_the_Efficiency_of_Source_Code_Generated_by_LLMs.md)

    - [翻译: 探讨大型语言模型生成源代码的效率评估](2024年04月09日/On_Evaluating_the_Efficiency_of_Source_Code_Generated_by_LLMs.md)

- [PM4Py.LLM: a Comprehensive Module for Implementing PM on LLMs](2024年04月09日/PM4Py.LLM_a_Comprehensive_Module_for_Implementing_PM_on_LLMs.md)

    - [翻译: PM4Py.LLM：为在大型语言模型 (LLM) 中应用过程挖掘 (PM) 而设计的全方位模块。](2024年04月09日/PM4Py.LLM_a_Comprehensive_Module_for_Implementing_PM_on_LLMs.md)

- [FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models](2024年04月09日/FreeEval_A_Modular_Framework_for_Trustworthy_and_Efficient_Evaluation_of_Large_Language_Models.md)

    - [翻译: FreeEval 是一个模块化的评估框架，旨在为大型语言模型提供可靠和高效的评估方法。](2024年04月09日/FreeEval_A_Modular_Framework_for_Trustworthy_and_Efficient_Evaluation_of_Large_Language_Models.md)

- [Privacy Preserving Prompt Engineering: A Survey](2024年04月09日/Privacy_Preserving_Prompt_Engineering_A_Survey.md)

    - [翻译: 本调查研究了如何在保护隐私的前提下，通过提示工程技术提升大型语言模型的性能。](2024年04月09日/Privacy_Preserving_Prompt_Engineering_A_Survey.md)

- [RAR-b: Reasoning as Retrieval Benchmark](2024年04月09日/RAR-b_Reasoning_as_Retrieval_Benchmark.md)

    - [翻译: RAR-b：将推理视作检索的基准测试](2024年04月09日/RAR-b_Reasoning_as_Retrieval_Benchmark.md)

- [Dimensionality Reduction in Sentence Transformer Vector Databases with Fast Fourier Transform](2024年04月09日/Dimensionality_Reduction_in_Sentence_Transformer_Vector_Databases_with_Fast_Fourier_Transform.md)

    - [翻译: 通过快速傅里叶变换技术，实现句子转换器向量数据库的高效降维处理。](2024年04月09日/Dimensionality_Reduction_in_Sentence_Transformer_Vector_Databases_with_Fast_Fourier_Transform.md)

- [AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free Information Retrieval](2024年04月09日/AiSAQ_All-in-Storage_ANNS_with_Product_Quantization_for_DRAM-free_Information_Retrieval.md)

    - [翻译: AiSAQ: 采用产品量化技术的全存储式近似最近邻搜索（ANNS），为无需DRAM的信息检索提供解决方案。](2024年04月09日/AiSAQ_All-in-Storage_ANNS_with_Product_Quantization_for_DRAM-free_Information_Retrieval.md)

- [Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness](2024年04月09日/Llama-VITS_Enhancing_TTS_Synthesis_with_Semantic_Awareness.md)

    - [翻译: Llama-VITS：借助语义理解提升TTS语音合成效果](2024年04月09日/Llama-VITS_Enhancing_TTS_Synthesis_with_Semantic_Awareness.md)

- [MathVC: An LLM-Simulated Multi-Character Virtual Classroom for Mathematics Education](2024年04月09日/MathVC_An_LLM-Simulated_Multi-Character_Virtual_Classroom_for_Mathematics_Education.md)

    - [翻译: MathVC：借助大型语言模型打造的多角色虚拟教室，致力于提升数学教学效果。](2024年04月09日/MathVC_An_LLM-Simulated_Multi-Character_Virtual_Classroom_for_Mathematics_Education.md)

- [CQIL: Inference Latency Optimization with Concurrent Computation of Quasi-Independent Layers](2024年04月09日/CQIL_Inference_Latency_Optimization_with_Concurrent_Computation_of_Quasi-Independent_Layers.md)

    - [翻译: CQIL技术：通过同时处理准独立层次以减少推理过程的延迟](2024年04月09日/CQIL_Inference_Latency_Optimization_with_Concurrent_Computation_of_Quasi-Independent_Layers.md)

- [Onco-Retriever: Generative Classifier for Retrieval of EHR Records in Oncology](2024年04月09日/Onco-Retriever_Generative_Classifier_for_Retrieval_of_EHR_Records_in_Oncology.md)

    - [翻译: Onco-Retriever：一种创新的生成式分类器，专门用于在肿瘤学领域快速准确地检索电子健康记录（EHR）。](2024年04月09日/Onco-Retriever_Generative_Classifier_for_Retrieval_of_EHR_Records_in_Oncology.md)

- [Toward Cross-Layer Energy Optimizations in Machine Learning Systems](2024年04月09日/Toward_Cross-Layer_Energy_Optimizations_in_Machine_Learning_Systems.md)

    - [翻译: 探索机器学习系统中的跨层能源优化](2024年04月09日/Toward_Cross-Layer_Energy_Optimizations_in_Machine_Learning_Systems.md)

- [CulturalTeaming: AI-Assisted Interactive Red-Teaming for Challenging LLMs' (Lack of) Multicultural Knowledge](2024年04月09日/CulturalTeaming_AI-Assisted_Interactive_Red-Teaming_for_Challenging_LLMs'_(Lack_of)_Multicultural_Knowledge.md)

    - [翻译: CulturalTeaming：借助人工智能的互动红队策略，挑战大型语言模型在多元文化知识方面的不足。](2024年04月09日/CulturalTeaming_AI-Assisted_Interactive_Red-Teaming_for_Challenging_LLMs'_(Lack_of)_Multicultural_Knowledge.md)

- [RULER: What's the Real Context Size of Your Long-Context Language Models?](2024年04月09日/RULER_What's_the_Real_Context_Size_of_Your_Long-Context_Language_Models.md)

    - [翻译: RULER: 长语境语言模型的实际上下文容量究竟有多大？](2024年04月09日/RULER_What's_the_Real_Context_Size_of_Your_Long-Context_Language_Models.md)

- [GenCHiP: Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks](2024年04月09日/GenCHiP_Generating_Robot_Policy_Code_for_High-Precision_and_Contact-Rich_Manipulation_Tasks.md)

    - [翻译: GenCHiP：针对精密操作和丰富接触任务，自动编写机器人策略代码](2024年04月09日/GenCHiP_Generating_Robot_Policy_Code_for_High-Precision_and_Contact-Rich_Manipulation_Tasks.md)

- [Khayyam Challenge (PersianMMLU): Is Your LLM Truly Wise to The Persian Language?](2024年04月09日/Khayyam_Challenge_(PersianMMLU)_Is_Your_LLM_Truly_Wise_to_The_Persian_Language.md)

    - [翻译: Khayyam挑战赛（PersianMMLU）：你的LLM真的精通波斯语吗？](2024年04月09日/Khayyam_Challenge_(PersianMMLU)_Is_Your_LLM_Truly_Wise_to_The_Persian_Language.md)

- [Perplexed: Understanding When Large Language Models are Confused](2024年04月09日/Perplexed_Understanding_When_Large_Language_Models_are_Confused.md)

    - [翻译: 探究困惑：揭秘大型语言模型何时陷入迷茫](2024年04月09日/Perplexed_Understanding_When_Large_Language_Models_are_Confused.md)

- [What is Your Favorite Gender, MLM? Gender Bias Evaluation in Multilingual Masked Language Models](2024年04月09日/What_is_Your_Favorite_Gender,_MLM_Gender_Bias_Evaluation_in_Multilingual_Masked_Language_Models.md)

    - [翻译: MLM，你偏好的性别是什么？探究多语言掩码语言模型中的性别歧视问题](2024年04月09日/What_is_Your_Favorite_Gender,_MLM_Gender_Bias_Evaluation_in_Multilingual_Masked_Language_Models.md)

- [Less is More for Improving Automatic Evaluation of Factual Consistency](2024年04月09日/Less_is_More_for_Improving_Automatic_Evaluation_of_Factual_Consistency.md)

    - [翻译: 简化方法更有助于提升事实一致性的自动评估效果。](2024年04月09日/Less_is_More_for_Improving_Automatic_Evaluation_of_Factual_Consistency.md)

- [Building A Knowledge Graph to Enrich ChatGPT Responses in Manufacturing Service Discovery](2024年04月09日/Building_A_Knowledge_Graph_to_Enrich_ChatGPT_Responses_in_Manufacturing_Service_Discovery.md)

    - [翻译: 打造知识图谱，提升ChatGPT在制造服务业发现中的答复质量。](2024年04月09日/Building_A_Knowledge_Graph_to_Enrich_ChatGPT_Responses_in_Manufacturing_Service_Discovery.md)

- [Deep Generative Data Assimilation in Multimodal Setting](2024年04月09日/Deep_Generative_Data_Assimilation_in_Multimodal_Setting.md)

    - [翻译: 深度生成式数据融合技术在多模态环境下的应用](2024年04月09日/Deep_Generative_Data_Assimilation_in_Multimodal_Setting.md)

- [Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation](2024年04月09日/Training-Free_Open-Vocabulary_Segmentation_with_Offline_Diffusion-Augmented_Prototype_Generation.md)

    - [翻译: 通过离线扩散技术增强原型生成，实现无需训练的开放词汇文本分割。](2024年04月09日/Training-Free_Open-Vocabulary_Segmentation_with_Offline_Diffusion-Augmented_Prototype_Generation.md)

- [Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition](2024年04月09日/Sample-Efficient_Human_Evaluation_of_Large_Language_Models_via_Maximum_Discrepancy_Competition.md)

    - [翻译: 利用最大差异竞赛，高效地进行人类对大型语言模型的样本评估](2024年04月09日/Sample-Efficient_Human_Evaluation_of_Large_Language_Models_via_Maximum_Discrepancy_Competition.md)

- [Apollonion: Profile-centric Dialog Agent](2024年04月09日/Apollonion_Profile-centric_Dialog_Agent.md)

    - [翻译: Apollonion：以用户画像为核心的智能对话助手。](2024年04月09日/Apollonion_Profile-centric_Dialog_Agent.md)

2024年04月08日

- [A Large-Scale Exploration of $μ$-Transfer](2024年04月08日/A_Large-Scale_Exploration_of_$μ$-Transfer.md)

    - [翻译: 本研究进行了对 $μ$-转移的大规模探索，旨在深入理解其在不同情境下的应用和影响。](2024年04月08日/A_Large-Scale_Exploration_of_$μ$-Transfer.md)

- [MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding](2024年04月08日/MA-LMM_Memory-Augmented_Large_Multimodal_Model_for_Long-Term_Video_Understanding.md)

    - [翻译: MA-LMM 模型：为深入理解长时段视频内容而设计的具有记忆功能的多模态大型模型。](2024年04月08日/MA-LMM_Memory-Augmented_Large_Multimodal_Model_for_Long-Term_Video_Understanding.md)

- [Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs](2024年04月08日/Ferret-UI_Grounded_Mobile_UI_Understanding_with_Multimodal_LLMs.md)

    - [翻译: Ferret-UI 利用多模态大型语言模型，实现对移动用户界面的深入理解。](2024年04月08日/Ferret-UI_Grounded_Mobile_UI_Understanding_with_Multimodal_LLMs.md)

- [Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding](2024年04月08日/Comprehensive_Study_on_German_Language_Models_for_Clinical_and_Biomedical_Text_Understanding.md)

    - [翻译: 本研究深入探讨了德语语言模型在临床及生物医学文本理解方面的表现。](2024年04月08日/Comprehensive_Study_on_German_Language_Models_for_Clinical_and_Biomedical_Text_Understanding.md)

- [Evaluating Mathematical Reasoning Beyond Accuracy](2024年04月08日/Evaluating_Mathematical_Reasoning_Beyond_Accuracy.md)

    - [翻译: 数学推理的评估，超越了单纯的准确率](2024年04月08日/Evaluating_Mathematical_Reasoning_Beyond_Accuracy.md)

- [Retrieval-Augmented Open-Vocabulary Object Detection](2024年04月08日/Retrieval-Augmented_Open-Vocabulary_Object_Detection.md)

    - [翻译: 开放词汇表的目标检测通过检索增强技术得以实现。](2024年04月08日/Retrieval-Augmented_Open-Vocabulary_Object_Detection.md)

- [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](2024年04月08日/MoMA_Multimodal_LLM_Adapter_for_Fast_Personalized_Image_Generation.md)

    - [翻译: MoMA 是一款多模态适配器，专为大型语言模型打造，旨在实现快速且个性化的图像创作。](2024年04月08日/MoMA_Multimodal_LLM_Adapter_for_Fast_Personalized_Image_Generation.md)

- [CoReS: Orchestrating the Dance of Reasoning and Segmentation](2024年04月08日/CoReS_Orchestrating_the_Dance_of_Reasoning_and_Segmentation.md)

    - [翻译: CoReS：协同演绎推理与分割的协奏曲](2024年04月08日/CoReS_Orchestrating_the_Dance_of_Reasoning_and_Segmentation.md)

- [Fighting crime with Transformers: Empirical analysis of address parsing methods in payment data](2024年04月08日/Fighting_crime_with_Transformers_Empirical_analysis_of_address_parsing_methods_in_payment_data.md)

    - [翻译: 以变换器助力打击犯罪：对支付数据中地址解析方法的实证研究](2024年04月08日/Fighting_crime_with_Transformers_Empirical_analysis_of_address_parsing_methods_in_payment_data.md)

- [LTNER: Large Language Model Tagging for Named Entity Recognition with Contextualized Entity Marking](2024年04月08日/LTNER_Large_Language_Model_Tagging_for_Named_Entity_Recognition_with_Contextualized_Entity_Marking.md)

    - [翻译: LTNER：一种大型语言模型，通过情境化标记技术，专门用于命名实体的识别。](2024年04月08日/LTNER_Large_Language_Model_Tagging_for_Named_Entity_Recognition_with_Contextualized_Entity_Marking.md)

- [AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets](2024年04月08日/AnchorAL_Computationally_Efficient_Active_Learning_for_Large_and_Imbalanced_Datasets.md)

    - [翻译: AnchorAL 采用了一种计算高效的方法，专为处理规模庞大且不平衡的数据集而设计的主动学习技术。](2024年04月08日/AnchorAL_Computationally_Efficient_Active_Learning_for_Large_and_Imbalanced_Datasets.md)

- [MULTIFLOW: Shifting Towards Task-Agnostic Vision-Language Pruning](2024年04月08日/MULTIFLOW_Shifting_Towards_Task-Agnostic_Vision-Language_Pruning.md)

    - [翻译: MULTIFLOW：迈向与任务无关的视觉-语言模型精简方法](2024年04月08日/MULTIFLOW_Shifting_Towards_Task-Agnostic_Vision-Language_Pruning.md)

- [MedExpQA: Multilingual Benchmarking of Large Language Models for Medical Question Answering](2024年04月08日/MedExpQA_Multilingual_Benchmarking_of_Large_Language_Models_for_Medical_Question_Answering.md)

    - [翻译: MedExpQA：多语言环境下大型语言模型在医学问答任务中的评估基准](2024年04月08日/MedExpQA_Multilingual_Benchmarking_of_Large_Language_Models_for_Medical_Question_Answering.md)

- [360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System](2024年04月08日/360°REA_Towards_A_Reusable_Experience_Accumulation_with_360°_Assessment_for_Multi-Agent_System.md)

    - [翻译: 360°REA：探索多智能体系统中可复用的经验积累，通过全方位的360°评估来实现。](2024年04月08日/360°REA_Towards_A_Reusable_Experience_Accumulation_with_360°_Assessment_for_Multi-Agent_System.md)

- [Evaluating Interventional Reasoning Capabilities of Large Language Models](2024年04月08日/Evaluating_Interventional_Reasoning_Capabilities_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的干预性推理能力](2024年04月08日/Evaluating_Interventional_Reasoning_Capabilities_of_Large_Language_Models.md)

- [OPSD: an Offensive Persian Social media Dataset and its baseline evaluations](2024年04月08日/OPSD_an_Offensive_Persian_Social_media_Dataset_and_its_baseline_evaluations.md)

    - [翻译: OPSD：一个针对波斯语社交媒体的攻击性行为数据集及其基础性能评价](2024年04月08日/OPSD_an_Offensive_Persian_Social_media_Dataset_and_its_baseline_evaluations.md)

- [Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data](2024年04月08日/Best-of-Venom_Attacking_RLHF_by_Injecting_Poisoned_Preference_Data.md)

    - [翻译: 《最佳毒液：注入恶意偏好数据以攻击强化学习人类反馈》](2024年04月08日/Best-of-Venom_Attacking_RLHF_by_Injecting_Poisoned_Preference_Data.md)

- [3DMambaIPF: A State Space Model for Iterative Point Cloud Filtering via Differentiable Rendering](2024年04月08日/3DMambaIPF_A_State_Space_Model_for_Iterative_Point_Cloud_Filtering_via_Differentiable_Rendering.md)

    - [翻译: 3DMambaIPF：一种利用可微渲染技术实现迭代点云滤波的状态空间模型。](2024年04月08日/3DMambaIPF_A_State_Space_Model_for_Iterative_Point_Cloud_Filtering_via_Differentiable_Rendering.md)

- [The Fact Selection Problem in LLM-Based Program Repair](2024年04月08日/The_Fact_Selection_Problem_in_LLM-Based_Program_Repair.md)

    - [翻译: 在利用大型语言模型（LLM）进行程序修复时，事实选择问题尤为突出。](2024年04月08日/The_Fact_Selection_Problem_in_LLM-Based_Program_Repair.md)

- [Synergy of Large Language Model and Model Driven Engineering for Automated Development of Centralized Vehicular Systems](2024年04月08日/Synergy_of_Large_Language_Model_and_Model_Driven_Engineering_for_Automated_Development_of_Centralized_Vehicular_Systems.md)

    - [翻译: 大型语言模型与模型驱动工程相结合，为集中式车辆系统的自动化开发提供强大助力。](2024年04月08日/Synergy_of_Large_Language_Model_and_Model_Driven_Engineering_for_Automated_Development_of_Centralized_Vehicular_Systems.md)

- [Constraining Large Language Model for Generating Computer-Parsable Content](2024年04月08日/Constraining_Large_Language_Model_for_Generating_Computer-Parsable_Content.md)

    - [翻译: 通过对大型语言模型施加限制，我们能够生成计算机能够理解和解析的内容。](2024年04月08日/Constraining_Large_Language_Model_for_Generating_Computer-Parsable_Content.md)

- [HAMMR: HierArchical MultiModal React agents for generic VQA](2024年04月08日/HAMMR_HierArchical_MultiModal_React_agents_for_generic_VQA.md)

    - [翻译: HAMMR：构建通用视觉问答系统中的层级多模态智能反应代理](2024年04月08日/HAMMR_HierArchical_MultiModal_React_agents_for_generic_VQA.md)

- [RoT: Enhancing Large Language Models with Reflection on Search Trees](2024年04月08日/RoT_Enhancing_Large_Language_Models_with_Reflection_on_Search_Trees.md)

    - [翻译: RoT 技术：借助搜索树反思，提升大型语言模型的性能](2024年04月08日/RoT_Enhancing_Large_Language_Models_with_Reflection_on_Search_Trees.md)

- [XL$^2$Bench: A Benchmark for Extremely Long Context Understanding with Long-range Dependencies](2024年04月08日/XL$^2$Bench_A_Benchmark_for_Extremely_Long_Context_Understanding_with_Long-range_Dependencies.md)

    - [翻译: XL$^2$Bench：针对极长上下文理解及其长距离依赖性的基准测试平台。](2024年04月08日/XL$^2$Bench_A_Benchmark_for_Extremely_Long_Context_Understanding_with_Long-range_Dependencies.md)

- [Unlocking Adaptive User Experience with Generative AI](2024年04月08日/Unlocking_Adaptive_User_Experience_with_Generative_AI.md)

    - [翻译: 利用生成性 AI 打造个性化用户体验](2024年04月08日/Unlocking_Adaptive_User_Experience_with_Generative_AI.md)

- [Language Models on a Diet: Cost-Efficient Development of Encoders for Closely-Related Languages via Additional Pretraining](2024年04月08日/Language_Models_on_a_Diet_Cost-Efficient_Development_of_Encoders_for_Closely-Related_Languages_via_Additional_Pretraining.md)

    - [翻译: 节食中的语言模型：通过额外的预训练，经济高效地为近缘语言打造编码器。](2024年04月08日/Language_Models_on_a_Diet_Cost-Efficient_Development_of_Encoders_for_Closely-Related_Languages_via_Additional_Pretraining.md)

- [AutoCodeRover: Autonomous Program Improvement](2024年04月08日/AutoCodeRover_Autonomous_Program_Improvement.md)

    - [翻译: AutoCodeRover：智能程序优化专家](2024年04月08日/AutoCodeRover_Autonomous_Program_Improvement.md)

- [Test-Time Zero-Shot Temporal Action Localization](2024年04月08日/Test-Time_Zero-Shot_Temporal_Action_Localization.md)

    - [翻译: 在测试阶段实现零-shot技术的时间动作定位](2024年04月08日/Test-Time_Zero-Shot_Temporal_Action_Localization.md)

- [Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations](2024年04月08日/Relation_Extraction_Using_Large_Language_Models_A_Case_Study_on_Acupuncture_Point_Locations.md)

    - [翻译: 通过大型语言模型进行关系提取研究：以针灸穴位位置为例](2024年04月08日/Relation_Extraction_Using_Large_Language_Models_A_Case_Study_on_Acupuncture_Point_Locations.md)

- [Know When To Stop: A Study of Semantic Drift in Text Generation](2024年04月08日/Know_When_To_Stop_A_Study_of_Semantic_Drift_in_Text_Generation.md)

    - [翻译: 适时止步：探究文本创造中的语义漂移现象](2024年04月08日/Know_When_To_Stop_A_Study_of_Semantic_Drift_in_Text_Generation.md)

- [PerkwE_COQA: enhance Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models](2024年04月08日/PerkwE_COQA_enhance_Persian_Conversational_Question_Answering_by_combining_contextual_keyword_extraction_with_Large_Language_Models.md)

    - [翻译: PerkwE_COQA：融合上下文关键词抓取与大型语言模型，提升波斯语对话问答系统的性能。](2024年04月08日/PerkwE_COQA_enhance_Persian_Conversational_Question_Answering_by_combining_contextual_keyword_extraction_with_Large_Language_Models.md)

- [SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety](2024年04月08日/SafetyPrompts_a_Systematic_Review_of_Open_Datasets_for_Evaluating_and_Improving_Large_Language_Model_Safety.md)

    - [翻译: 《安全提示：大型语言模型安全性评估与提升的开放数据集系统综述》](2024年04月08日/SafetyPrompts_a_Systematic_Review_of_Open_Datasets_for_Evaluating_and_Improving_Large_Language_Model_Safety.md)

- [Towards Objectively Benchmarking Social Intelligence for Language Agents at Action Level](2024年04月08日/Towards_Objectively_Benchmarking_Social_Intelligence_for_Language_Agents_at_Action_Level.md)

    - [翻译: 旨在客观地衡量语言代理在行动层面的社会智能。](2024年04月08日/Towards_Objectively_Benchmarking_Social_Intelligence_for_Language_Agents_at_Action_Level.md)

- [Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models](2024年04月08日/Long-horizon_Locomotion_and_Manipulation_on_a_Quadrupedal_Robot_with_Large_Language_Models.md)

    - [翻译: 在四足机器人上，结合大型语言模型实现远程运动与操控](2024年04月08日/Long-horizon_Locomotion_and_Manipulation_on_a_Quadrupedal_Robot_with_Large_Language_Models.md)

- [Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security](2024年04月08日/Unbridled_Icarus_A_Survey_of_the_Potential_Perils_of_Image_Inputs_in_Multimodal_Large_Language_Model_Security.md)

    - [翻译: 伊卡洛斯之翼：探究多模态大型语言模型安全性中图像输入可能带来的风险](2024年04月08日/Unbridled_Icarus_A_Survey_of_the_Potential_Perils_of_Image_Inputs_in_Multimodal_Large_Language_Model_Security.md)

- [PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection](2024年04月08日/PromptAD_Learning_Prompts_with_only_Normal_Samples_for_Few-Shot_Anomaly_Detection.md)

    - [翻译: PromptAD 研究：仅通过正常样本进行学习，实现少样本情况下的高效异常检测。](2024年04月08日/PromptAD_Learning_Prompts_with_only_Normal_Samples_for_Few-Shot_Anomaly_Detection.md)

- [LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding](2024年04月08日/LayoutLLM_Layout_Instruction_Tuning_with_Large_Language_Models_for_Document_Understanding.md)

    - [翻译: LayoutLLM：利用大型语言模型对布局指令进行优化，提升文档理解能力](2024年04月08日/LayoutLLM_Layout_Instruction_Tuning_with_Large_Language_Models_for_Document_Understanding.md)

- [LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models](2024年04月08日/LLM_Reasoners_New_Evaluation,_Library,_and_Analysis_of_Step-by-Step_Reasoning_with_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的推理能力：构建新评估体系、推理资源库，并深入分析其逐步推理过程。](2024年04月08日/LLM_Reasoners_New_Evaluation,_Library,_and_Analysis_of_Step-by-Step_Reasoning_with_Large_Language_Models.md)

- [Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging](2024年04月08日/Have_You_Merged_My_Model_On_The_Robustness_of_Large_Language_Model_IP_Protection_Methods_Against_Model_Merging.md)

    - [翻译: 我的模型被合并了吗？探究大型语言模型知识产权防护措施在抵御模型合并攻击时的坚固程度。](2024年04月08日/Have_You_Merged_My_Model_On_The_Robustness_of_Large_Language_Model_IP_Protection_Methods_Against_Model_Merging.md)

- [Progressive Alignment with VLM-LLM Feature to Augment Defect Classification for the ASE Dataset](2024年04月08日/Progressive_Alignment_with_VLM-LLM_Feature_to_Augment_Defect_Classification_for_the_ASE_Dataset.md)

    - [翻译: 通过 VLM-LLM 特征的渐进式对齐方法，提升 ASE 数据集中缺陷识别的准确性。](2024年04月08日/Progressive_Alignment_with_VLM-LLM_Feature_to_Augment_Defect_Classification_for_the_ASE_Dataset.md)

- [DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model](2024年04月08日/DLoRA_Distributed_Parameter-Efficient_Fine-Tuning_Solution_for_Large_Language_Model.md)

    - [翻译: DLoRA 为大型语言模型提供了一种分布式的、参数高效的微调方法。](2024年04月08日/DLoRA_Distributed_Parameter-Efficient_Fine-Tuning_Solution_for_Large_Language_Model.md)

- [Enhancing Software Related Information Extraction with Generative Language Models through Single-Choice Question Answering](2024年04月08日/Enhancing_Software_Related_Information_Extraction_with_Generative_Language_Models_through_Single-Choice_Question_Answering.md)

    - [翻译: 借助生成性语言模型，我们可以通过单选题问答的方式，提升软件信息抽取的效果。](2024年04月08日/Enhancing_Software_Related_Information_Extraction_with_Generative_Language_Models_through_Single-Choice_Question_Answering.md)

- [Responsible Visual Editing](2024年04月08日/Responsible_Visual_Editing.md)

    - [翻译: 在视觉编辑领域，我们强调负责任的实践，旨在确保编辑过程不仅追求美观，而且兼顾道德和文化敏感性。](2024年04月08日/Responsible_Visual_Editing.md)

- [AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM Experts](2024年04月08日/AEGIS_Online_Adaptive_AI_Content_Safety_Moderation_with_Ensemble_of_LLM_Experts.md)

    - [翻译: AEGIS：借助众多大型语言模型专家的协同力量，实现在线内容的自适应AI安全审核。](2024年04月08日/AEGIS_Online_Adaptive_AI_Content_Safety_Moderation_with_Ensemble_of_LLM_Experts.md)

- [Automatic Authorities: Power and AI](2024年04月08日/Automatic_Authorities_Power_and_AI.md)

    - [翻译: 自动权威：探讨权力与AI的结合](2024年04月08日/Automatic_Authorities_Power_and_AI.md)

- [Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation](2024年04月08日/Optimization_Methods_for_Personalizing_Large_Language_Models_through_Retrieval_Augmentation.md)

    - [翻译: 通过检索增强技术，优化大型语言模型的个性化方法研究](2024年04月08日/Optimization_Methods_for_Personalizing_Large_Language_Models_through_Retrieval_Augmentation.md)

- [LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders](2024年04月08日/LLM2Vec_Large_Language_Models_Are_Secretly_Powerful_Text_Encoders.md)

    - [翻译: LLM2Vec：大型语言模型，悄然成为强大的文本编码利器](2024年04月08日/LLM2Vec_Large_Language_Models_Are_Secretly_Powerful_Text_Encoders.md)

- [VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?](2024年04月08日/VisualWebBench_How_Far_Have_Multimodal_LLMs_Evolved_in_Web_Page_Understanding_and_Grounding.md)

    - [翻译: VisualWebBench: 多模态LLM在网页理解和定位领域究竟取得了多大的进展？](2024年04月08日/VisualWebBench_How_Far_Have_Multimodal_LLMs_Evolved_in_Web_Page_Understanding_and_Grounding.md)

- [The Hallucinations Leaderboard -- An Open Effort to Measure Hallucinations in Large Language Models](2024年04月08日/The_Hallucinations_Leaderboard_--_An_Open_Effort_to_Measure_Hallucinations_in_Large_Language_Models.md)

    - [翻译: 《幻觉排行榜》—— 一场旨在衡量大型语言模型幻觉现象的公开行动。](2024年04月08日/The_Hallucinations_Leaderboard_--_An_Open_Effort_to_Measure_Hallucinations_in_Large_Language_Models.md)

- [WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents](2024年04月08日/WILBUR_Adaptive_In-Context_Learning_for_Robust_and_Accurate_Web_Agents.md)

    - [翻译: WILBUR：为打造强大精准的网络代理，采用自适应式上下文学习方法](2024年04月08日/WILBUR_Adaptive_In-Context_Learning_for_Robust_and_Accurate_Web_Agents.md)

- [Use of a Structured Knowledge Base Enhances Metadata Curation by Large Language Models](2024年04月08日/Use_of_a_Structured_Knowledge_Base_Enhances_Metadata_Curation_by_Large_Language_Models.md)

    - [翻译: 借助结构化知识库，大型语言模型在元数据策划方面的能力得到提升。](2024年04月08日/Use_of_a_Structured_Knowledge_Base_Enhances_Metadata_Curation_by_Large_Language_Models.md)

- [Eraser: Jailbreaking Defense in Large Language Models via Unlearning Harmful Knowledge](2024年04月08日/Eraser_Jailbreaking_Defense_in_Large_Language_Models_via_Unlearning_Harmful_Knowledge.md)

    - [翻译: Eraser：通过摒弃有害知识，打破大型语言模型的束缚](2024年04月08日/Eraser_Jailbreaking_Defense_in_Large_Language_Models_via_Unlearning_Harmful_Knowledge.md)

- [Event-enhanced Retrieval in Real-time Search](2024年04月08日/Event-enhanced_Retrieval_in_Real-time_Search.md)

    - [翻译: 实时搜索中，通过事件增强的检索技术可以有效提升搜索质量。但目前，我们对于如何充分发挥事件信息的作用，以优化检索结果的相关性和准确性，尚存诸多不明之处。本研究致力于探索事件信息在实时搜索中的应用，并分析其对提升检索效能的具体影响。](2024年04月08日/Event-enhanced_Retrieval_in_Real-time_Search.md)

- [Xiwu: A Basis Flexible and Learnable LLM for High Energy Physics](2024年04月08日/Xiwu_A_Basis_Flexible_and_Learnable_LLM_for_High_Energy_Physics.md)

    - [翻译: Xiwu：一款适应高能物理领域的基础性、灵活性强且具备学习能力的大型语言模型](2024年04月08日/Xiwu_A_Basis_Flexible_and_Learnable_LLM_for_High_Energy_Physics.md)

2024年04月07日

- [Linguistic Changes in Spontaneous Speech for Detecting Parkinsons Disease Using Large Language Models](2024年04月07日/Linguistic_Changes_in_Spontaneous_Speech_for_Detecting_Parkinsons_Disease_Using_Large_Language_Models.md)

    - [翻译: 通过分析自发口语中的语言变化，借助大型语言模型来识别帕金森病的迹象。](2024年04月07日/Linguistic_Changes_in_Spontaneous_Speech_for_Detecting_Parkinsons_Disease_Using_Large_Language_Models.md)

- [Enhancing Clinical Efficiency through LLM: Discharge Note Generation for Cardiac Patients](2024年04月07日/Enhancing_Clinical_Efficiency_through_LLM_Discharge_Note_Generation_for_Cardiac_Patients.md)

    - [翻译: 利用大型语言模型优化临床工作流程：自动撰写心脏病患者出院小结。](2024年04月07日/Enhancing_Clinical_Efficiency_through_LLM_Discharge_Note_Generation_for_Cardiac_Patients.md)

- [Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation](2024年04月07日/Plug_and_Play_with_Prompts_A_Prompt_Tuning_Approach_for_Controlling_Text_Generation.md)

    - [翻译: 玩转提示：巧用提示调整技术驾驭文本生成](2024年04月07日/Plug_and_Play_with_Prompts_A_Prompt_Tuning_Approach_for_Controlling_Text_Generation.md)

- [LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees](2024年04月07日/LLM-BT_Performing_Robotic_Adaptive_Tasks_based_on_Large_Language_Models_and_Behavior_Trees.md)

    - [翻译: 利用大型语言模型与行为树，实现机器人的自适应任务执行。](2024年04月07日/LLM-BT_Performing_Robotic_Adaptive_Tasks_based_on_Large_Language_Models_and_Behavior_Trees.md)

- [EcoVerse: An Annotated Twitter Dataset for Eco-Relevance Classification, Environmental Impact Analysis, and Stance Detection](2024年04月07日/EcoVerse_An_Annotated_Twitter_Dataset_for_Eco-Relevance_Classification,_Environmental_Impact_Analysis,_and_Stance_Detection.md)

    - [翻译: EcoVerse: 一个针对生态相关性分类、环境影响评估和立场识别的推特数据集注释项目](2024年04月07日/EcoVerse_An_Annotated_Twitter_Dataset_for_Eco-Relevance_Classification,_Environmental_Impact_Analysis,_and_Stance_Detection.md)

- [StockGPT: A GenAI Model for Stock Prediction and Trading](2024年04月07日/StockGPT_A_GenAI_Model_for_Stock_Prediction_and_Trading.md)

    - [翻译: StockGPT：一款股票预测与交易的智能AI模型](2024年04月07日/StockGPT_A_GenAI_Model_for_Stock_Prediction_and_Trading.md)

- [Advancing Geometric Problem Solving: A Comprehensive Benchmark for Multimodal Model Evaluation](2024年04月07日/Advancing_Geometric_Problem_Solving_A_Comprehensive_Benchmark_for_Multimodal_Model_Evaluation.md)

    - [翻译: 在几何问题求解领域取得新进展：构建全方位多模态模型评测的权威基准](2024年04月07日/Advancing_Geometric_Problem_Solving_A_Comprehensive_Benchmark_for_Multimodal_Model_Evaluation.md)

- [A Note on LoRA](2024年04月07日/A_Note_on_LoRA.md)

    - [翻译: LoRA浅析](2024年04月07日/A_Note_on_LoRA.md)

- [HaVTR: Improving Video-Text Retrieval Through Augmentation Using Large Foundation Models](2024年04月07日/HaVTR_Improving_Video-Text_Retrieval_Through_Augmentation_Using_Large_Foundation_Models.md)

    - [翻译: HaVTR：借助大型基础模型的增强功能，提升视频与文本的检索效能](2024年04月07日/HaVTR_Improving_Video-Text_Retrieval_Through_Augmentation_Using_Large_Foundation_Models.md)

- [RoboMP$^2$: A Robotic Multimodal Perception-Planning Framework with Multimodal Large Language Models](2024年04月07日/RoboMP$^2$_A_Robotic_Multimodal_Perception-Planning_Framework_with_Multimodal_Large_Language_Models.md)

    - [翻译: RoboMP$^2$：融合多模态大型语言模型的机器人感知与规划架构](2024年04月07日/RoboMP$^2$_A_Robotic_Multimodal_Perception-Planning_Framework_with_Multimodal_Large_Language_Models.md)

- [LLM-Based Multi-Agent Systems for Software Engineering: Vision and the Road Ahead](2024年04月07日/LLM-Based_Multi-Agent_Systems_for_Software_Engineering_Vision_and_the_Road_Ahead.md)

    - [翻译: 软件工程领域的多智能体系统基于大型语言模型（LLM），展望未来的发展蓝图。](2024年04月07日/LLM-Based_Multi-Agent_Systems_for_Software_Engineering_Vision_and_the_Road_Ahead.md)

- [X-VARS: Introducing Explainability in Football Refereeing with Multi-Modal Large Language Model](2024年04月07日/X-VARS_Introducing_Explainability_in_Football_Refereeing_with_Multi-Modal_Large_Language_Model.md)

    - [翻译: X-VARS: 融合多模态大型语言模型，为足球裁判决策带来可解释性](2024年04月07日/X-VARS_Introducing_Explainability_in_Football_Refereeing_with_Multi-Modal_Large_Language_Model.md)

- [Information Retrieval with Entity Linking](2024年04月07日/Information_Retrieval_with_Entity_Linking.md)

    - [翻译: 通过实体链接进行信息检索](2024年04月07日/Information_Retrieval_with_Entity_Linking.md)

2024年04月06日

- [Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models](2024年04月06日/Q-PEFT_Query-dependent_Parameter_Efficient_Fine-tuning_for_Text_Reranking_with_Large_Language_Models.md)

    - [翻译: Q-PEFT 技术：为大型语言模型在文本重排序任务中提供基于查询的高效参数调整方法](2024年04月06日/Q-PEFT_Query-dependent_Parameter_Efficient_Fine-tuning_for_Text_Reranking_with_Large_Language_Models.md)

- [IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials](2024年04月06日/IITK_at_SemEval-2024_Task_2_Exploring_the_Capabilities_of_LLMs_for_Safe_Biomedical_Natural_Language_Inference_for_Clinical_Trials.md)

    - [翻译: IITK 参与 SemEval-2024 的第二项任务，旨在挖掘大型语言模型在临床试验领域进行安全生物医学自然语言推理的潜力。](2024年04月06日/IITK_at_SemEval-2024_Task_2_Exploring_the_Capabilities_of_LLMs_for_Safe_Biomedical_Natural_Language_Inference_for_Clinical_Trials.md)

- [Challenges Faced by Large Language Models in Solving Multi-Agent Flocking](2024年04月06日/Challenges_Faced_by_Large_Language_Models_in_Solving_Multi-Agent_Flocking.md)

    - [翻译: 大型语言模型在处理多智能体群体行为问题时遭遇的难题](2024年04月06日/Challenges_Faced_by_Large_Language_Models_in_Solving_Multi-Agent_Flocking.md)

- [MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems](2024年04月06日/MACM_Utilizing_a_Multi-Agent_System_for_Condition_Mining_in_Solving_Complex_Mathematical_Problems.md)

    - [翻译: MACM：通过多智能体系统进行条件挖掘，以应对复杂的数学难题。](2024年04月06日/MACM_Utilizing_a_Multi-Agent_System_for_Condition_Mining_in_Solving_Complex_Mathematical_Problems.md)

- [Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology](2024年04月06日/Autonomous_Artificial_Intelligence_Agents_for_Clinical_Decision_Making_in_Oncology.md)

    - [翻译: 在肿瘤学领域，我们运用自主性人工智能代理来辅助临床决策过程。](2024年04月06日/Autonomous_Artificial_Intelligence_Agents_for_Clinical_Decision_Making_in_Oncology.md)

- [Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model](2024年04月06日/Do_We_Really_Need_a_Complex_Agent_System_Distill_Embodied_Agent_into_a_Single_Model.md)

    - [翻译: 我们真的需要构建复杂的代理系统吗？不如将具身智能体简化为一个模型。](2024年04月06日/Do_We_Really_Need_a_Complex_Agent_System_Distill_Embodied_Agent_into_a_Single_Model.md)

- [GenEARL: A Training-Free Generative Framework for Multimodal Event Argument Role Labeling](2024年04月06日/GenEARL_A_Training-Free_Generative_Framework_for_Multimodal_Event_Argument_Role_Labeling.md)

    - [翻译: GenEARL：一种无需训练的多模态事件角色标注生成框架](2024年04月06日/GenEARL_A_Training-Free_Generative_Framework_for_Multimodal_Event_Argument_Role_Labeling.md)

- [Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment](2024年04月06日/Interpretable_Multimodal_Learning_for_Cardiovascular_Hemodynamics_Assessment.md)

    - [翻译: 心血管血流动力学评估中的可解释性多模态学习](2024年04月06日/Interpretable_Multimodal_Learning_for_Cardiovascular_Hemodynamics_Assessment.md)

- [Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models](2024年04月06日/Joint_Visual_and_Text_Prompting_for_Improved_Object-Centric_Perception_with_Multimodal_Large_Language_Models.md)

    - [翻译: 通过结合视觉和文本提示，我们利用多模态大型语言模型，显著提升了对物体中心的感知能力。](2024年04月06日/Joint_Visual_and_Text_Prompting_for_Improved_Object-Centric_Perception_with_Multimodal_Large_Language_Models.md)

- [A Multi-Level Framework for Accelerating Training Transformer Models](2024年04月06日/A_Multi-Level_Framework_for_Accelerating_Training_Transformer_Models.md)

    - [翻译: 为了加快变换模型的训练速度，我们提出了一个多层次的框架。](2024年04月06日/A_Multi-Level_Framework_for_Accelerating_Training_Transformer_Models.md)

- [PMG : Personalized Multimodal Generation with Large Language Models](2024年04月06日/PMG__Personalized_Multimodal_Generation_with_Large_Language_Models.md)

    - [翻译: PMG：借助大型语言模型实现个性化的多模态创作](2024年04月06日/PMG__Personalized_Multimodal_Generation_with_Large_Language_Models.md)

2024年04月05日

- [Physical Property Understanding from Language-Embedded Feature Fields](2024年04月05日/Physical_Property_Understanding_from_Language-Embedded_Feature_Fields.md)

    - [翻译: 通过语言嵌入的特征场来掌握物理属性理解](2024年04月05日/Physical_Property_Understanding_from_Language-Embedded_Feature_Fields.md)

- [Cleared for Takeoff? Compositional & Conditional Reasoning may be the Achilles Heel to (Flight-Booking) Language Agents](2024年04月05日/Cleared_for_Takeoff_Compositional_&_Conditional_Reasoning_may_be_the_Achilles_Heel_to_(Flight-Booking)_Language_Agents.md)

    - [翻译: 起飞在即？组合与条件推理或许会成为机票预订语言助手的软肋。](2024年04月05日/Cleared_for_Takeoff_Compositional_&_Conditional_Reasoning_may_be_the_Achilles_Heel_to_(Flight-Booking)_Language_Agents.md)

- [Unlocking Parameter-Efficient Fine-Tuning for Low-Resource Language Translation](2024年04月05日/Unlocking_Parameter-Efficient_Fine-Tuning_for_Low-Resource_Language_Translation.md)

    - [翻译: 探索低资源语言翻译的高效参数微调方法](2024年04月05日/Unlocking_Parameter-Efficient_Fine-Tuning_for_Low-Resource_Language_Translation.md)

- [Social Skill Training with Large Language Models](2024年04月05日/Social_Skill_Training_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型开展社交技巧培训](2024年04月05日/Social_Skill_Training_with_Large_Language_Models.md)

- [Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model](2024年04月05日/Chinese_Tiny_LLM_Pretraining_a_Chinese-Centric_Large_Language_Model.md)

    - [翻译: 中文迷你巨模：打造一个专注于中文的超大语言预训练模型](2024年04月05日/Chinese_Tiny_LLM_Pretraining_a_Chinese-Centric_Large_Language_Model.md)

- [Large language models as oracles for instantiating ontologies with domain-specific knowledge](2024年04月05日/Large_language_models_as_oracles_for_instantiating_ontologies_with_domain-specific_knowledge.md)

    - [翻译: 大型语言模型充当领域专业知识本体的即插即用式智能顾问。](2024年04月05日/Large_language_models_as_oracles_for_instantiating_ontologies_with_domain-specific_knowledge.md)

- [Robust Preference Optimization with Provable Noise Tolerance for LLMs](2024年04月05日/Robust_Preference_Optimization_with_Provable_Noise_Tolerance_for_LLMs.md)

    - [翻译: 在大型语言模型中，我们研发了一种鲁棒偏好优化算法，它能够有效抵御噪声干扰，确保了算法的稳定性和可靠性。](2024年04月05日/Robust_Preference_Optimization_with_Provable_Noise_Tolerance_for_LLMs.md)

- [Assessing the quality of information extraction](2024年04月05日/Assessing_the_quality_of_information_extraction.md)

    - [翻译: 对信息提取品质进行评定](2024年04月05日/Assessing_the_quality_of_information_extraction.md)

- [CLUE: A Clinical Language Understanding Evaluation for LLMs](2024年04月05日/CLUE_A_Clinical_Language_Understanding_Evaluation_for_LLMs.md)

    - [翻译: CLUE：一套针对大型语言模型的临床级语言理解评估体系](2024年04月05日/CLUE_A_Clinical_Language_Understanding_Evaluation_for_LLMs.md)

- [VoicePilot: Harnessing LLMs as Speech Interfaces for Physically Assistive Robots](2024年04月05日/VoicePilot_Harnessing_LLMs_as_Speech_Interfaces_for_Physically_Assistive_Robots.md)

    - [翻译: VoicePilot：将大型语言模型 (LLM) 作为物理辅助机器人的语音交互界面](2024年04月05日/VoicePilot_Harnessing_LLMs_as_Speech_Interfaces_for_Physically_Assistive_Robots.md)

- [A Comparison of Methods for Evaluating Generative IR](2024年04月05日/A_Comparison_of_Methods_for_Evaluating_Generative_IR.md)

    - [翻译: 本研究对比了不同的生成式信息检索评估方法。](2024年04月05日/A_Comparison_of_Methods_for_Evaluating_Generative_IR.md)

- [Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer](2024年04月05日/Teaching_Llama_a_New_Language_Through_Cross-Lingual_Knowledge_Transfer.md)

    - [翻译: 借助跨语言知识迁移，教会 Llama 掌握新的语言技能。](2024年04月05日/Teaching_Llama_a_New_Language_Through_Cross-Lingual_Knowledge_Transfer.md)

- [BuDDIE: A Business Document Dataset for Multi-task Information Extraction](2024年04月05日/BuDDIE_A_Business_Document_Dataset_for_Multi-task_Information_Extraction.md)

    - [翻译: BuDDIE：专为多任务信息提取打造的商业文档数据集](2024年04月05日/BuDDIE_A_Business_Document_Dataset_for_Multi-task_Information_Extraction.md)

- [SEME at SemEval-2024 Task 2: Comparing Masked and Generative Language Models on Natural Language Inference for Clinical Trials](2024年04月05日/SEME_at_SemEval-2024_Task_2_Comparing_Masked_and_Generative_Language_Models_on_Natural_Language_Inference_for_Clinical_Trials.md)

    - [翻译: SemEval-2024 任务 2 探讨了 SEME，通过对比遮蔽式和生成式语言模型在临床试验自然语言推理任务上的效果。](2024年04月05日/SEME_at_SemEval-2024_Task_2_Comparing_Masked_and_Generative_Language_Models_on_Natural_Language_Inference_for_Clinical_Trials.md)

- [Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models](2024年04月05日/Simple_Techniques_for_Enhancing_Sentence_Embeddings_in_Generative_Language_Models.md)

    - [翻译: 生成型语言模型中，提升句子嵌入的简易技巧。](2024年04月05日/Simple_Techniques_for_Enhancing_Sentence_Embeddings_in_Generative_Language_Models.md)

- [Can only LLMs do Reasoning?: Potential of Small Language Models in Task Planning](2024年04月05日/Can_only_LLMs_do_Reasoning_Potential_of_Small_Language_Models_in_Task_Planning.md)

    - [翻译: 难道只有大型语言模型才具备推理能力吗？其实不然，小型语言模型在任务规划领域同样拥有不可忽视的潜力。](2024年04月05日/Can_only_LLMs_do_Reasoning_Potential_of_Small_Language_Models_in_Task_Planning.md)

- [SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models](2024年04月05日/SAAS_Solving_Ability_Amplification_Strategy_for_Enhanced_Mathematical_Reasoning_in_Large_Language_Models.md)

    - [翻译: SAAS：为大型语言模型注入数学推理的强化策略](2024年04月05日/SAAS_Solving_Ability_Amplification_Strategy_for_Enhanced_Mathematical_Reasoning_in_Large_Language_Models.md)

- [Assisting humans in complex comparisons: automated information comparison at scale](2024年04月05日/Assisting_humans_in_complex_comparisons_automated_information_comparison_at_scale.md)

    - [翻译: 本文探讨了如何在海量数据中，通过自动化技术辅助人类进行细致入微的比较分析。](2024年04月05日/Assisting_humans_in_complex_comparisons_automated_information_comparison_at_scale.md)

- [Exploring Autonomous Agents through the Lens of Large Language Models: A Review](2024年04月05日/Exploring_Autonomous_Agents_through_the_Lens_of_Large_Language_Models_A_Review.md)

    - [翻译: 从大型语言模型的视角探究自主智能体：一篇综述性研究](2024年04月05日/Exploring_Autonomous_Agents_through_the_Lens_of_Large_Language_Models_A_Review.md)

- [Increased LLM Vulnerabilities from Fine-tuning and Quantization](2024年04月05日/Increased_LLM_Vulnerabilities_from_Fine-tuning_and_Quantization.md)

    - [翻译: 微调和量化过程中，大型语言模型的脆弱性有所增加。](2024年04月05日/Increased_LLM_Vulnerabilities_from_Fine-tuning_and_Quantization.md)

- [Idea-2-3D: Collaborative LMM Agents Enable 3D Model Generation from Interleaved Multimodal Inputs](2024年04月05日/Idea-2-3D_Collaborative_LMM_Agents_Enable_3D_Model_Generation_from_Interleaved_Multimodal_Inputs.md)

    - [翻译: Idea-2-3D：协同工作的LMM智能代理通过混合多模态输入实现3D模型的创建。](2024年04月05日/Idea-2-3D_Collaborative_LMM_Agents_Enable_3D_Model_Generation_from_Interleaved_Multimodal_Inputs.md)

2024年04月04日

- [OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views](2024年04月04日/OpenNeRF_Open_Set_3D_Neural_Scene_Segmentation_with_Pixel-Wise_Features_and_Rendered_Novel_Views.md)

    - [翻译: OpenNeRF 通过利用像素级别的细节特征和渲染出全新的视角，实现了对3D场景的开放集神经分割，为三维场景理解提供了一种全新的方法。](2024年04月04日/OpenNeRF_Open_Set_3D_Neural_Scene_Segmentation_with_Pixel-Wise_Features_and_Rendered_Novel_Views.md)

- [AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent](2024年04月04日/AutoWebGLM_Bootstrap_And_Reinforce_A_Large_Language_Model-based_Web_Navigating_Agent.md)

    - [翻译: AutoWebGLM：利用自助法和强化策略，打造一款基于大型语言模型的智能网络浏览助手。](2024年04月04日/AutoWebGLM_Bootstrap_And_Reinforce_A_Large_Language_Model-based_Web_Navigating_Agent.md)

- [Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra](2024年04月04日/Capabilities_of_Large_Language_Models_in_Control_Engineering_A_Benchmark_Study_on_GPT-4,_Claude_3_Opus,_and_Gemini_1.0_Ultra.md)

    - [翻译: 大型语言模型在控制工程领域的能力探究：对 GPT-4、Claude 3 Opus 及 Gemini 1.0 Ultra 进行的基准比较研究。](2024年04月04日/Capabilities_of_Large_Language_Models_in_Control_Engineering_A_Benchmark_Study_on_GPT-4,_Claude_3_Opus,_and_Gemini_1.0_Ultra.md)

- [Training LLMs over Neurally Compressed Text](2024年04月04日/Training_LLMs_over_Neurally_Compressed_Text.md)

    - [翻译: 通过对神经网络压缩的文本进行训练，提升了大型语言模型（LLM）的能力。](2024年04月04日/Training_LLMs_over_Neurally_Compressed_Text.md)

- [Unveiling LLMs: The Evolution of Latent Representations in a Temporal Knowledge Graph](2024年04月04日/Unveiling_LLMs_The_Evolution_of_Latent_Representations_in_a_Temporal_Knowledge_Graph.md)

    - [翻译: 探究大型语言模型：时间知识库中潜在表达的进化之旅](2024年04月04日/Unveiling_LLMs_The_Evolution_of_Latent_Representations_in_a_Temporal_Knowledge_Graph.md)

- [Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models](2024年04月04日/Visualization-of-Thought_Elicits_Spatial_Reasoning_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，通过思维可视化能够激发空间推理能力。](2024年04月04日/Visualization-of-Thought_Elicits_Spatial_Reasoning_in_Large_Language_Models.md)

- [DeViDe: Faceted medical knowledge for improved medical vision-language pre-training](2024年04月04日/DeViDe_Faceted_medical_knowledge_for_improved_medical_vision-language_pre-training.md)

    - [翻译: DeViDe：面向医学视觉-语言预训练的全方位医学知识架构](2024年04月04日/DeViDe_Faceted_medical_knowledge_for_improved_medical_vision-language_pre-training.md)

- [Sailor: Open Language Models for South-East Asia](2024年04月04日/Sailor_Open_Language_Models_for_South-East_Asia.md)

    - [翻译: Sailor：面向东南亚地区的开放语言模型](2024年04月04日/Sailor_Open_Language_Models_for_South-East_Asia.md)

- [Evaluating LLMs at Detecting Errors in LLM Responses](2024年04月04日/Evaluating_LLMs_at_Detecting_Errors_in_LLM_Responses.md)

    - [翻译: 探究大型语言模型识别自身回应错误的能力](2024年04月04日/Evaluating_LLMs_at_Detecting_Errors_in_LLM_Responses.md)

- [Intent Detection and Entity Extraction from BioMedical Literature](2024年04月04日/Intent_Detection_and_Entity_Extraction_from_BioMedical_Literature.md)

    - [翻译: 在生物医学文献中识别意图与抽取关键信息](2024年04月04日/Intent_Detection_and_Entity_Extraction_from_BioMedical_Literature.md)

- [ReFT: Representation Finetuning for Language Models](2024年04月04日/ReFT_Representation_Finetuning_for_Language_Models.md)

    - [翻译: ReFT 代表「表示微调」，是一种针对语言模型的优化技术。](2024年04月04日/ReFT_Representation_Finetuning_for_Language_Models.md)

- [SemGrasp: Semantic Grasp Generation via Language Aligned Discretization](2024年04月04日/SemGrasp_Semantic_Grasp_Generation_via_Language_Aligned_Discretization.md)

    - [翻译: SemGrasp：利用语言对齐离散化技术实现语义抓取的生成](2024年04月04日/SemGrasp_Semantic_Grasp_Generation_via_Language_Aligned_Discretization.md)

- [Untangle the KNOT: Interweaving Conflicting Knowledge and Reasoning Skills in Large Language Models](2024年04月04日/Untangle_the_KNOT_Interweaving_Conflicting_Knowledge_and_Reasoning_Skills_in_Large_Language_Models.md)

    - [翻译: 拨乱反正：大型语言模型中融合知识冲突与推理能力的交织艺术](2024年04月04日/Untangle_the_KNOT_Interweaving_Conflicting_Knowledge_and_Reasoning_Skills_in_Large_Language_Models.md)

- [Embodied AI with Two Arms: Zero-shot Learning, Safety and Modularity](2024年04月04日/Embodied_AI_with_Two_Arms_Zero-shot_Learning,_Safety_and_Modularity.md)

    - [翻译: 双臂机器人的具身人工智能：探索零-shot 学习能力、安全性能与模块化设计。](2024年04月04日/Embodied_AI_with_Two_Arms_Zero-shot_Learning,_Safety_and_Modularity.md)

- [Personalized LLM Response Generation with Parameterized Memory Injection](2024年04月04日/Personalized_LLM_Response_Generation_with_Parameterized_Memory_Injection.md)

    - [翻译: 通过参数化记忆注入，实现大型语言模型（LLM）的个性化响应生成。](2024年04月04日/Personalized_LLM_Response_Generation_with_Parameterized_Memory_Injection.md)

- [Select and Summarize: Scene Saliency for Movie Script Summarization](2024年04月04日/Select_and_Summarize_Scene_Saliency_for_Movie_Script_Summarization.md)

    - [翻译: 精选与概述：电影剧本摘要中的场景焦点](2024年04月04日/Select_and_Summarize_Scene_Saliency_for_Movie_Script_Summarization.md)

- [How does Multi-Task Training Affect Transformer In-Context Capabilities? Investigations with Function Classes](2024年04月04日/How_does_Multi-Task_Training_Affect_Transformer_In-Context_Capabilities_Investigations_with_Function_Classes.md)

    - [翻译: 多任务训练对变换器模型的上下文理解能力有何影响？本研究通过探索不同函数类别，深入探讨了这一问题。](2024年04月04日/How_does_Multi-Task_Training_Affect_Transformer_In-Context_Capabilities_Investigations_with_Function_Classes.md)

- [CodeEditorBench: Evaluating Code Editing Capability of Large Language Models](2024年04月04日/CodeEditorBench_Evaluating_Code_Editing_Capability_of_Large_Language_Models.md)

    - [翻译: CodeEditorBench：探究大型语言模型在代码编辑方面的表现](2024年04月04日/CodeEditorBench_Evaluating_Code_Editing_Capability_of_Large_Language_Models.md)

- [Evaluating Generative Language Models in Information Extraction as Subjective Question Correction](2024年04月04日/Evaluating_Generative_Language_Models_in_Information_Extraction_as_Subjective_Question_Correction.md)

    - [翻译: 在信息提取领域，探究生成型语言模型在主观问题纠正任务中的表现。](2024年04月04日/Evaluating_Generative_Language_Models_in_Information_Extraction_as_Subjective_Question_Correction.md)

- [Learn When (not) to Trust Language Models: A Privacy-Centric Adaptive Model-Aware Approach](2024年04月04日/Learn_When_(not)_to_Trust_Language_Models_A_Privacy-Centric_Adaptive_Model-Aware_Approach.md)

    - [翻译: 探索信任与否：一种以隐私为核心，适应性的语言模型感知策略](2024年04月04日/Learn_When_(not)_to_Trust_Language_Models_A_Privacy-Centric_Adaptive_Model-Aware_Approach.md)

- [AI and the Problem of Knowledge Collapse](2024年04月04日/AI_and_the_Problem_of_Knowledge_Collapse.md)

    - [翻译: 人工智能面临的知识崩溃挑战](2024年04月04日/AI_and_the_Problem_of_Knowledge_Collapse.md)

- [Integrating Large Language Models with Multimodal Virtual Reality Interfaces to Support Collaborative Human-Robot Construction Work](2024年04月04日/Integrating_Large_Language_Models_with_Multimodal_Virtual_Reality_Interfaces_to_Support_Collaborative_Human-Robot_Construction_Work.md)

    - [翻译: 融合大型语言模型和多模态虚拟现实接口，助力人机协作建筑任务。](2024年04月04日/Integrating_Large_Language_Models_with_Multimodal_Virtual_Reality_Interfaces_to_Support_Collaborative_Human-Robot_Construction_Work.md)

- [A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded Dialogue Generation](2024年04月04日/A_Cause-Effect_Look_at_Alleviating_Hallucination_of_Knowledge-grounded_Dialogue_Generation.md)

    - [翻译: 本文通过因果分析，探讨了如何减轻知识引导对话生成中的知识幻觉问题。](2024年04月04日/A_Cause-Effect_Look_at_Alleviating_Hallucination_of_Knowledge-grounded_Dialogue_Generation.md)

- [Generative AI and Teachers - For Us or Against Us? A Case Study](2024年04月04日/Generative_AI_and_Teachers_-_For_Us_or_Against_Us_A_Case_Study.md)

    - [翻译: 生成性人工智能：助力教育还是竞争者？案例分析揭秘](2024年04月04日/Generative_AI_and_Teachers_-_For_Us_or_Against_Us_A_Case_Study.md)

- [Reevaluating Bias Detection in Language Models: The Role of Implicit Norm](2024年04月04日/Reevaluating_Bias_Detection_in_Language_Models_The_Role_of_Implicit_Norm.md)

    - [翻译: 重新审视语言模型中的偏见识别：探究隐性规范的角色](2024年04月04日/Reevaluating_Bias_Detection_in_Language_Models_The_Role_of_Implicit_Norm.md)

- [Scaffolding Language Learning via Multi-modal Tutoring Systems with Pedagogical Instructions](2024年04月04日/Scaffolding_Language_Learning_via_Multi-modal_Tutoring_Systems_with_Pedagogical_Instructions.md)

    - [翻译: 利用融入教学指导的多模态辅导系统，为语言学习提供有效支撑。](2024年04月04日/Scaffolding_Language_Learning_via_Multi-modal_Tutoring_Systems_with_Pedagogical_Instructions.md)

- [Edisum: Summarizing and Explaining Wikipedia Edits at Scale](2024年04月04日/Edisum_Summarizing_and_Explaining_Wikipedia_Edits_at_Scale.md)

    - [翻译: Edisum：面向大规模的维基百科编辑，实现内容概括与阐释。](2024年04月04日/Edisum_Summarizing_and_Explaining_Wikipedia_Edits_at_Scale.md)

- [Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](2024年04月04日/Can_Small_Language_Models_Help_Large_Language_Models_Reason_Better_LM-Guided_Chain-of-Thought.md)

    - [翻译: 小型语言模型能否助力大型语言模型提升推理能力？——通过LM引导的思维链条探究](2024年04月04日/Can_Small_Language_Models_Help_Large_Language_Models_Reason_Better_LM-Guided_Chain-of-Thought.md)

- [MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens](2024年04月04日/MiniGPT4-Video_Advancing_Multimodal_LLMs_for_Video_Understanding_with_Interleaved_Visual-Textual_Tokens.md)

    - [翻译: MiniGPT4-Video：利用交错的视觉与文本元素，推动多模态大型语言模型在视频理解方面的发展。](2024年04月04日/MiniGPT4-Video_Advancing_Multimodal_LLMs_for_Video_Understanding_with_Interleaved_Visual-Textual_Tokens.md)

- [Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?](2024年04月04日/Red_Teaming_GPT-4V_Are_GPT-4V_Safe_Against_UniMulti-Modal_Jailbreak_Attacks.md)

    - [翻译: 针对 GPT-4V 的红队测试：这款 AI 能否抵御单模态或多模态的攻击逃逸？](2024年04月04日/Red_Teaming_GPT-4V_Are_GPT-4V_Safe_Against_UniMulti-Modal_Jailbreak_Attacks.md)

- [Scaling Up Video Summarization Pretraining with Large Language Models](2024年04月04日/Scaling_Up_Video_Summarization_Pretraining_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，我们正在扩大视频摘要预训练的规模。](2024年04月04日/Scaling_Up_Video_Summarization_Pretraining_with_Large_Language_Models.md)

- [LongVLM: Efficient Long Video Understanding via Large Language Models](2024年04月04日/LongVLM_Efficient_Long_Video_Understanding_via_Large_Language_Models.md)

    - [翻译: LongVLM 通过运用大型语言模型，高效地解读长视频内容。](2024年04月04日/LongVLM_Efficient_Long_Video_Understanding_via_Large_Language_Models.md)

- [nicolay-r at SemEval-2024 Task 3: Using Flan-T5 for Reasoning Emotion Cause in Conversations with Chain-of-Thought on Emotion States](2024年04月04日/nicolay-r_at_SemEval-2024_Task_3_Using_Flan-T5_for_Reasoning_Emotion_Cause_in_Conversations_with_Chain-of-Thought_on_Emotion_States.md)

    - [翻译: 在 SemEval-2024 的第三项任务中，nicolay-r 利用 Flan-T5 模型，通过情绪状态的思维链推理对话中的情绪成因。](2024年04月04日/nicolay-r_at_SemEval-2024_Task_3_Using_Flan-T5_for_Reasoning_Emotion_Cause_in_Conversations_with_Chain-of-Thought_on_Emotion_States.md)

- [Towards Pareto Optimal Throughput in Small Language Model Serving](2024年04月04日/Towards_Pareto_Optimal_Throughput_in_Small_Language_Model_Serving.md)

    - [翻译: 追求在小型语言模型服务中的帕累托最优吞吐量](2024年04月04日/Towards_Pareto_Optimal_Throughput_in_Small_Language_Model_Serving.md)

- [How Easily do Irrelevant Inputs Skew the Responses of Large Language Models?](2024年04月04日/How_Easily_do_Irrelevant_Inputs_Skew_the_Responses_of_Large_Language_Models.md)

    - [翻译: 大型语言模型对无关输入的敏感程度如何？](2024年04月04日/How_Easily_do_Irrelevant_Inputs_Skew_the_Responses_of_Large_Language_Models.md)

- [Probing Large Language Models for Scalar Adjective Lexical Semantics and Scalar Diversity Pragmatics](2024年04月04日/Probing_Large_Language_Models_for_Scalar_Adjective_Lexical_Semantics_and_Scalar_Diversity_Pragmatics.md)

    - [翻译: 深入研究大型语言模型中的标量形容词词义和标量多样性语用现象。](2024年04月04日/Probing_Large_Language_Models_for_Scalar_Adjective_Lexical_Semantics_and_Scalar_Diversity_Pragmatics.md)

- [DELTA: Decomposed Efficient Long-Term Robot Task Planning using Large Language Models](2024年04月04日/DELTA_Decomposed_Efficient_Long-Term_Robot_Task_Planning_using_Large_Language_Models.md)

    - [翻译: DELTA：借助大型语言模型，实现高效分解的机器人长期任务规划](2024年04月04日/DELTA_Decomposed_Efficient_Long-Term_Robot_Task_Planning_using_Large_Language_Models.md)

- [RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis](2024年04月04日/RALL-E_Robust_Codec_Language_Modeling_with_Chain-of-Thought_Prompting_for_Text-to-Speech_Synthesis.md)

    - [翻译: RALL-E：采用链式思维引导的编解码器语言模型，增强文本至语音合成的鲁棒性](2024年04月04日/RALL-E_Robust_Codec_Language_Modeling_with_Chain-of-Thought_Prompting_for_Text-to-Speech_Synthesis.md)

- [Do Large Language Models Rank Fairly? An Empirical Study on the Fairness of LLMs as Rankers](2024年04月04日/Do_Large_Language_Models_Rank_Fairly_An_Empirical_Study_on_the_Fairness_of_LLMs_as_Rankers.md)

    - [翻译: 大型语言模型的排名是否公正？一项针对LLMs作为排名器的公平性经验性研究](2024年04月04日/Do_Large_Language_Models_Rank_Fairly_An_Empirical_Study_on_the_Fairness_of_LLMs_as_Rankers.md)

- [The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models](2024年04月04日/The_Probabilities_Also_Matter_A_More_Faithful_Metric_for_Faithfulness_of_Free-Text_Explanations_in_Large_Language_Models.md)

    - [翻译: 概率的权重：构建更精确衡量大型语言模型自由文本解释准确性的指标](2024年04月04日/The_Probabilities_Also_Matter_A_More_Faithful_Metric_for_Faithfulness_of_Free-Text_Explanations_in_Large_Language_Models.md)

- [Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction](2024年04月04日/Extract,_Define,_Canonicalize_An_LLM-based_Framework_for_Knowledge_Graph_Construction.md)

    - [翻译: 基于大型语言模型，构建知识图谱的新框架：提取信息、明确定义、统一规范。](2024年04月04日/Extract,_Define,_Canonicalize_An_LLM-based_Framework_for_Knowledge_Graph_Construction.md)

- [FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping](2024年04月04日/FFN-SkipLLM_A_Hidden_Gem_for_Autoregressive_Decoding_with_Adaptive_Feed_Forward_Skipping.md)

    - [翻译: FFN-SkipLLM：自回归解码的隐秘利器，通过灵活的前馈网络跳过技术实现。](2024年04月04日/FFN-SkipLLM_A_Hidden_Gem_for_Autoregressive_Decoding_with_Adaptive_Feed_Forward_Skipping.md)

- [Verifiable by Design: Aligning Language Models to Quote from Pre-Training Data](2024年04月04日/Verifiable_by_Design_Aligning_Language_Models_to_Quote_from_Pre-Training_Data.md)

    - [翻译: 设计之初即验证：确保语言模型能够引用预训练数据](2024年04月04日/Verifiable_by_Design_Aligning_Language_Models_to_Quote_from_Pre-Training_Data.md)

- [PARIS3D: Reasoning-based 3D Part Segmentation Using Large Multimodal Model](2024年04月04日/PARIS3D_Reasoning-based_3D_Part_Segmentation_Using_Large_Multimodal_Model.md)

    - [翻译: PARIS3D：借助庞大的多模态模型，实现基于推理的三维部件识别。](2024年04月04日/PARIS3D_Reasoning-based_3D_Part_Segmentation_Using_Large_Multimodal_Model.md)

- [An Investigation into Misuse of Java Security APIs by Large Language Models](2024年04月04日/An_Investigation_into_Misuse_of_Java_Security_APIs_by_Large_Language_Models.md)

    - [翻译: 探究大型语言模型不当使用 Java 安全接口问题](2024年04月04日/An_Investigation_into_Misuse_of_Java_Security_APIs_by_Large_Language_Models.md)

- [Understanding Language Modeling Paradigm Adaptations in Recommender Systems: Lessons Learned and Open Challenges](2024年04月04日/Understanding_Language_Modeling_Paradigm_Adaptations_in_Recommender_Systems_Lessons_Learned_and_Open_Challenges.md)

    - [翻译: 深入探索推荐系统内语言建模范式的调整：吸取的经验与待解难题](2024年04月04日/Understanding_Language_Modeling_Paradigm_Adaptations_in_Recommender_Systems_Lessons_Learned_and_Open_Challenges.md)

- [GenQREnsemble: Zero-Shot LLM Ensemble Prompting for Generative Query Reformulation](2024年04月04日/GenQREnsemble_Zero-Shot_LLM_Ensemble_Prompting_for_Generative_Query_Reformulation.md)

    - [翻译: GenQREnsemble：零-shot 技术打造的大型语言模型集成，为生成式查询改写而生。](2024年04月04日/GenQREnsemble_Zero-Shot_LLM_Ensemble_Prompting_for_Generative_Query_Reformulation.md)

- [Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations](2024年04月04日/Fakes_of_Varying_Shades_How_Warning_Affects_Human_Perception_and_Engagement_Regarding_LLM_Hallucinations.md)

    - [翻译: 虚假的多样性：警示如何改变人们对大型语言模型幻觉的认知和互动](2024年04月04日/Fakes_of_Varying_Shades_How_Warning_Affects_Human_Perception_and_Engagement_Regarding_LLM_Hallucinations.md)

- [SHROOM-INDElab at SemEval-2024 Task 6: Zero- and Few-Shot LLM-Based Classification for Hallucination Detection](2024年04月04日/SHROOM-INDElab_at_SemEval-2024_Task_6_Zero-_and_Few-Shot_LLM-Based_Classification_for_Hallucination_Detection.md)

    - [翻译: SHROOM-INDElab 参与 SemEval-2024 第六任务：基于大型语言模型的零样本和少样本分类技术，以检测文本中的虚构信息。](2024年04月04日/SHROOM-INDElab_at_SemEval-2024_Task_6_Zero-_and_Few-Shot_LLM-Based_Classification_for_Hallucination_Detection.md)

- [Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences](2024年04月04日/Direct_Nash_Optimization_Teaching_Language_Models_to_Self-Improve_with_General_Preferences.md)

    - [翻译: 通过直接纳什优化方法，我们引导语言模型学会根据普遍偏好进行自我优化和提升。](2024年04月04日/Direct_Nash_Optimization_Teaching_Language_Models_to_Self-Improve_with_General_Preferences.md)

- [No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance](2024年04月04日/No_Zero-Shot_Without_Exponential_Data_Pretraining_Concept_Frequency_Determines_Multimodal_Model_Performance.md)

    - [翻译: 脱离大量数据谈"零-shot"不现实：预训练中概念的出现频率是提升多模态模型表现的关键因素。](2024年04月04日/No_Zero-Shot_Without_Exponential_Data_Pretraining_Concept_Frequency_Determines_Multimodal_Model_Performance.md)

- [CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering](2024年04月04日/CBR-RAG_Case-Based_Reasoning_for_Retrieval_Augmented_Generation_in_LLMs_for_Legal_Question_Answering.md)

    - [翻译: CBR-RAG：案例推理辅助生成，提升大型语言模型在法律问答中的检索能力](2024年04月04日/CBR-RAG_Case-Based_Reasoning_for_Retrieval_Augmented_Generation_in_LLMs_for_Legal_Question_Answering.md)

2024年04月03日

- [DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement](2024年04月03日/DIBS_Enhancing_Dense_Video_Captioning_with_Unlabeled_Videos_via_Pseudo_Boundary_Enrichment_and_Online_Refinement.md)

    - [翻译: DIBS 技术：借助伪边界扩展和实时优化，利用未标注视频提升密集视频字幕质量。](2024年04月03日/DIBS_Enhancing_Dense_Video_Captioning_with_Unlabeled_Videos_via_Pseudo_Boundary_Enrichment_and_Online_Refinement.md)

- [Harnessing the Power of Large Vision Language Models for Synthetic Image Detection](2024年04月03日/Harnessing_the_Power_of_Large_Vision_Language_Models_for_Synthetic_Image_Detection.md)

    - [翻译: 借助大型视觉语言模型的力量，我们可以有效检测合成图像。](2024年04月03日/Harnessing_the_Power_of_Large_Vision_Language_Models_for_Synthetic_Image_Detection.md)

- [Automatic Prompt Selection for Large Language Models](2024年04月03日/Automatic_Prompt_Selection_for_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，自动化的提示筛选机制](2024年04月03日/Automatic_Prompt_Selection_for_Large_Language_Models.md)

- [Scalable Model Editing via Customized Expert Networks](2024年04月03日/Scalable_Model_Editing_via_Customized_Expert_Networks.md)

    - [翻译: 本文介绍了一种通过定制专家网络来实现模型编辑的可扩展方法。](2024年04月03日/Scalable_Model_Editing_via_Customized_Expert_Networks.md)

- [Attention is Naturally Sparse with Gaussian Distributed Input](2024年04月03日/Attention_is_Naturally_Sparse_with_Gaussian_Distributed_Input.md)

    - [翻译: 当输入呈现高斯分布时，注意力机制自然而然地表现出稀疏性。](2024年04月03日/Attention_is_Naturally_Sparse_with_Gaussian_Distributed_Input.md)

- [Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models](2024年04月03日/Rethinking_Kullback-Leibler_Divergence_in_Knowledge_Distillation_for_Large_Language_Models.md)

    - [翻译: 在大型语言模型的知识蒸馏过程中，对Kullback-Leibler散度的再认识与应用。](2024年04月03日/Rethinking_Kullback-Leibler_Divergence_in_Knowledge_Distillation_for_Large_Language_Models.md)

- [Calibrating the Confidence of Large Language Models by Eliciting Fidelity](2024年04月03日/Calibrating_the_Confidence_of_Large_Language_Models_by_Eliciting_Fidelity.md)

    - [翻译: 本文探讨了如何通过激发忠诚度来调整大型语言模型的自信度，以提高其预测的准确性。](2024年04月03日/Calibrating_the_Confidence_of_Large_Language_Models_by_Eliciting_Fidelity.md)

- [Towards detecting unanticipated bias in Large Language Models](2024年04月03日/Towards_detecting_unanticipated_bias_in_Large_Language_Models.md)

    - [翻译: 探索发现大型语言模型中的潜在偏见。](2024年04月03日/Towards_detecting_unanticipated_bias_in_Large_Language_Models.md)

- [On the Importance of Uncertainty in Decision-Making with Large Language Models](2024年04月03日/On_the_Importance_of_Uncertainty_in_Decision-Making_with_Large_Language_Models.md)

    - [翻译: 在运用大型语言模型进行决策时，不确定性的角色不容忽视。](2024年04月03日/On_the_Importance_of_Uncertainty_in_Decision-Making_with_Large_Language_Models.md)

- [Vocabulary Attack to Hijack Large Language Model Applications](2024年04月03日/Vocabulary_Attack_to_Hijack_Large_Language_Model_Applications.md)

    - [翻译: 通过词汇攻击，大型语言模型的应用可能被劫持。](2024年04月03日/Vocabulary_Attack_to_Hijack_Large_Language_Model_Applications.md)

- [Improving Topic Relevance Model by Mix-structured Summarization and LLM-based Data Augmentation](2024年04月03日/Improving_Topic_Relevance_Model_by_Mix-structured_Summarization_and_LLM-based_Data_Augmentation.md)

    - [翻译: 通过融合多种结构的摘要技巧以及利用大型语言模型进行数据扩充，我们得以提升主题相关性模型的性能。](2024年04月03日/Improving_Topic_Relevance_Model_by_Mix-structured_Summarization_and_LLM-based_Data_Augmentation.md)

- [Large Language Models for Expansion of Spoken Language Understanding Systems to New Languages](2024年04月03日/Large_Language_Models_for_Expansion_of_Spoken_Language_Understanding_Systems_to_New_Languages.md)

    - [翻译: 借助大型语言模型，拓展口语理解系统至全新语言领域](2024年04月03日/Large_Language_Models_for_Expansion_of_Spoken_Language_Understanding_Systems_to_New_Languages.md)

- [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](2024年04月03日/Language_Models_as_Compilers_Simulating_Pseudocode_Execution_Improves_Algorithmic_Reasoning_in_Language_Models.md)

    - [翻译: 将语言模型视作编译器，通过模拟伪代码的执行，我们能够显著提升模型在算法推理上的能力。](2024年04月03日/Language_Models_as_Compilers_Simulating_Pseudocode_Execution_Improves_Algorithmic_Reasoning_in_Language_Models.md)

- [AI-Tutoring in Software Engineering Education](2024年04月03日/AI-Tutoring_in_Software_Engineering_Education.md)

    - [翻译: 人工智能辅导在软件工程教育领域日益发挥着关键作用，它通过个性化指导和及时反馈显著提升了学习成效。要充分发挥其潜力，我们必须深入探索AI辅导的机制，并有效融合到教学实践中。](2024年04月03日/AI-Tutoring_in_Software_Engineering_Education.md)

- [CSEPrompts: A Benchmark of Introductory Computer Science Prompts](2024年04月03日/CSEPrompts_A_Benchmark_of_Introductory_Computer_Science_Prompts.md)

    - [翻译: CSEPrompts：计算机科学基础教学提示的评估标准](2024年04月03日/CSEPrompts_A_Benchmark_of_Introductory_Computer_Science_Prompts.md)

- [Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game](2024年04月03日/Learn_to_Disguise_Avoid_Refusal_Responses_in_LLM's_Defense_via_a_Multi-agent_Attacker-Disguiser_Game.md)

    - [翻译: 掌握伪装技巧：借助多智能体间的攻击者与伪装者博弈，规避大型语言模型（LLM）防御时的拒绝式回应。](2024年04月03日/Learn_to_Disguise_Avoid_Refusal_Responses_in_LLM's_Defense_via_a_Multi-agent_Attacker-Disguiser_Game.md)

- [Large Language Model for Vulnerability Detection and Repair: Literature Review and Roadmap](2024年04月03日/Large_Language_Model_for_Vulnerability_Detection_and_Repair_Literature_Review_and_Roadmap.md)

    - [翻译: 大型语言模型在漏洞检测与修复领域的文献综述及发展蓝图](2024年04月03日/Large_Language_Model_for_Vulnerability_Detection_and_Repair_Literature_Review_and_Roadmap.md)

- [Towards Large Language Model driven Reference-less Translation Evaluation for English and Indian Languages](2024年04月03日/Towards_Large_Language_Model_driven_Reference-less_Translation_Evaluation_for_English_and_Indian_Languages.md)

    - [翻译: 面向英语和印度语言的大型语言模型驱动的无参考翻译评估研究。](2024年04月03日/Towards_Large_Language_Model_driven_Reference-less_Translation_Evaluation_for_English_and_Indian_Languages.md)

- [VIAssist: Adapting Multi-modal Large Language Models for Users with Visual Impairments](2024年04月03日/VIAssist_Adapting_Multi-modal_Large_Language_Models_for_Users_with_Visual_Impairments.md)

    - [翻译: VIAssist：为视障用户定制的多模态大型语言模型](2024年04月03日/VIAssist_Adapting_Multi-modal_Large_Language_Models_for_Users_with_Visual_Impairments.md)

- [Measuring Social Norms of Large Language Models](2024年04月03日/Measuring_Social_Norms_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的社会规范认知](2024年04月03日/Measuring_Social_Norms_of_Large_Language_Models.md)

- [Prompting for Numerical Sequences: A Case Study on Market Comment Generation](2024年04月03日/Prompting_for_Numerical_Sequences_A_Case_Study_on_Market_Comment_Generation.md)

    - [翻译: 数字序列提示：市场评论生成案例分析](2024年04月03日/Prompting_for_Numerical_Sequences_A_Case_Study_on_Market_Comment_Generation.md)

- [PhonologyBench: Evaluating Phonological Skills of Large Language Models](2024年04月03日/PhonologyBench_Evaluating_Phonological_Skills_of_Large_Language_Models.md)

    - [翻译: PhonologyBench：探究大型语言模型的音系能力](2024年04月03日/PhonologyBench_Evaluating_Phonological_Skills_of_Large_Language_Models.md)

- [Task Agnostic Architecture for Algorithm Induction via Implicit Composition](2024年04月03日/Task_Agnostic_Architecture_for_Algorithm_Induction_via_Implicit_Composition.md)

    - [翻译: 这种架构能够通过隐式组合的方式，适用于各种任务的算法归纳，不受特定任务的限制。](2024年04月03日/Task_Agnostic_Architecture_for_Algorithm_Induction_via_Implicit_Composition.md)

- [Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation: A Systematic Comparison](2024年04月03日/Retrieving_Examples_from_Memory_for_Retrieval_Augmented_Neural_Machine_Translation_A_Systematic_Comparison.md)

    - [翻译: 为了提升神经机器翻译的检索性能，本研究系统地比较了从记忆中检索示例的方法。](2024年04月03日/Retrieving_Examples_from_Memory_for_Retrieval_Augmented_Neural_Machine_Translation_A_Systematic_Comparison.md)

- [uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?](2024年04月03日/uTeBC-NLP_at_SemEval-2024_Task_9_Can_LLMs_be_Lateral_Thinkers.md)

    - [翻译: uTeBC-NLP 参与 SemEval-2024 的第 9 项任务，探讨大型语言模型是否能够进行横向思考。](2024年04月03日/uTeBC-NLP_at_SemEval-2024_Task_9_Can_LLMs_be_Lateral_Thinkers.md)

- [I-Design: Personalized LLM Interior Designer](2024年04月03日/I-Design_Personalized_LLM_Interior_Designer.md)

    - [翻译: I-Design：打造个性化空间，您的专属 LLM 室内设计师。](2024年04月03日/I-Design_Personalized_LLM_Interior_Designer.md)

- [Empowering Biomedical Discovery with AI Agents](2024年04月03日/Empowering_Biomedical_Discovery_with_AI_Agents.md)

    - [翻译: 借助人工智能代理，推动生物医学研究的新发现](2024年04月03日/Empowering_Biomedical_Discovery_with_AI_Agents.md)

- [ALOHa: A New Measure for Hallucination in Captioning Models](2024年04月03日/ALOHa_A_New_Measure_for_Hallucination_in_Captioning_Models.md)

    - [翻译: ALOHa：字幕模型幻觉现象的新衡量标准](2024年04月03日/ALOHa_A_New_Measure_for_Hallucination_in_Captioning_Models.md)

- [MatAtlas: Text-driven Consistent Geometry Texturing and Material Assignment](2024年04月03日/MatAtlas_Text-driven_Consistent_Geometry_Texturing_and_Material_Assignment.md)

    - [翻译: MatAtlas：通过文本驱动，实现一致的几何纹理和材质赋予](2024年04月03日/MatAtlas_Text-driven_Consistent_Geometry_Texturing_and_Material_Assignment.md)

- [ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline](2024年04月03日/ChatGLM-Math_Improving_Math_Problem-Solving_in_Large_Language_Models_with_a_Self-Critique_Pipeline.md)

    - [翻译: ChatGLM-Math：运用自我批评机制，提升大型语言模型解决数学问题的能力](2024年04月03日/ChatGLM-Math_Improving_Math_Problem-Solving_in_Large_Language_Models_with_a_Self-Critique_Pipeline.md)

- [Linear Attention Sequence Parallelism](2024年04月03日/Linear_Attention_Sequence_Parallelism.md)

    - [翻译: 通过线性方法实现注意力机制的序列并行处理](2024年04月03日/Linear_Attention_Sequence_Parallelism.md)

- [Integrating Explanations in Learning LTL Specifications from Demonstrations](2024年04月03日/Integrating_Explanations_in_Learning_LTL_Specifications_from_Demonstrations.md)

    - [翻译: 在学习LTL规范的过程中融合解释](2024年04月03日/Integrating_Explanations_in_Learning_LTL_Specifications_from_Demonstrations.md)

- [Toward Inference-optimal Mixture-of-Expert Large Language Models](2024年04月03日/Toward_Inference-optimal_Mixture-of-Expert_Large_Language_Models.md)

    - [翻译: 为实现最优化推理性能，我们探索了专家混合型大型语言模型的构建。](2024年04月03日/Toward_Inference-optimal_Mixture-of-Expert_Large_Language_Models.md)

- [Cherry on Top: Parameter Heterogeneity and Quantization in Large Language Models](2024年04月03日/Cherry_on_Top_Parameter_Heterogeneity_and_Quantization_in_Large_Language_Models.md)

    - [翻译: 锦上添花：探究大型语言模型中的参数多样性与量化技术](2024年04月03日/Cherry_on_Top_Parameter_Heterogeneity_and_Quantization_in_Large_Language_Models.md)

- [BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models](2024年04月03日/BAdam_A_Memory_Efficient_Full_Parameter_Training_Method_for_Large_Language_Models.md)

    - [翻译: BAdam 为大型语言模型提供了一种内存占用小且高效的全参数训练方式。](2024年04月03日/BAdam_A_Memory_Efficient_Full_Parameter_Training_Method_for_Large_Language_Models.md)

- [Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models](2024年04月03日/Conifer_Improving_Complex_Constrained_Instruction-Following_Ability_of_Large_Language_Models.md)

    - [翻译: Conifer：增强大型语言模型执行复杂指令的能力](2024年04月03日/Conifer_Improving_Complex_Constrained_Instruction-Following_Ability_of_Large_Language_Models.md)

- [A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches](2024年04月03日/A_Survey_of_Optimization-based_Task_and_Motion_Planning_From_Classical_To_Learning_Approaches.md)

    - [翻译: 本综述探讨了从传统到现代基于优化的任务和运动规划方法，特别关注学习方法的应用和发展。](2024年04月03日/A_Survey_of_Optimization-based_Task_and_Motion_Planning_From_Classical_To_Learning_Approaches.md)

- [The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers](2024年04月03日/The_RealHumanEval_Evaluating_Large_Language_Models'_Abilities_to_Support_Programmers.md)

    - [翻译: RealHumanEval：探究大型语言模型在辅助编程方面的实际效能](2024年04月03日/The_RealHumanEval_Evaluating_Large_Language_Models'_Abilities_to_Support_Programmers.md)

- [Efficient Multi-Vector Dense Retrieval Using Bit Vectors](2024年04月03日/Efficient_Multi-Vector_Dense_Retrieval_Using_Bit_Vectors.md)

    - [翻译: 通过位向量实现的多向量密集检索，既高效又精准。](2024年04月03日/Efficient_Multi-Vector_Dense_Retrieval_Using_Bit_Vectors.md)

- [AI and personalized learning: bridging the gap with modern educational goals](2024年04月03日/AI_and_personalized_learning_bridging_the_gap_with_modern_educational_goals.md)

    - [翻译: 通过现代教育目标，人工智能与个性化学习之间的鸿沟得以桥接。](2024年04月03日/AI_and_personalized_learning_bridging_the_gap_with_modern_educational_goals.md)

- [CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech](2024年04月03日/CLaM-TTS_Improving_Neural_Codec_Language_Model_for_Zero-Shot_Text-to-Speech.md)

    - [翻译: CLaM-TTS：优化神经编解码器语言模型，提升零-shot 文本到语音的转换效果](2024年04月03日/CLaM-TTS_Improving_Neural_Codec_Language_Model_for_Zero-Shot_Text-to-Speech.md)

- [FPT: Feature Prompt Tuning for Few-shot Readability Assessment](2024年04月03日/FPT_Feature_Prompt_Tuning_for_Few-shot_Readability_Assessment.md)

    - [翻译: FPT，即特征提示调整技术，旨在提升少样本情境下的文本可读性评估效果。](2024年04月03日/FPT_Feature_Prompt_Tuning_for_Few-shot_Readability_Assessment.md)

- [UniAV: Unified Audio-Visual Perception for Multi-Task Video Localization](2024年04月03日/UniAV_Unified_Audio-Visual_Perception_for_Multi-Task_Video_Localization.md)

    - [翻译: UniAV：集视听感知于一体，实现多任务视频精准定位](2024年04月03日/UniAV_Unified_Audio-Visual_Perception_for_Multi-Task_Video_Localization.md)

- [Multi-modal Learning for WebAssembly Reverse Engineering](2024年04月03日/Multi-modal_Learning_for_WebAssembly_Reverse_Engineering.md)

    - [翻译: 通过多模态学习方法，探索WebAssembly逆向工程的新途径。](2024年04月03日/Multi-modal_Learning_for_WebAssembly_Reverse_Engineering.md)

- [Diverse and Tailored Image Generation for Zero-shot Multi-label Classification](2024年04月03日/Diverse_and_Tailored_Image_Generation_for_Zero-shot_Multi-label_Classification.md)

    - [翻译: 为零-shot多标签分类打造多样化且针对性的图像生成方法。](2024年04月03日/Diverse_and_Tailored_Image_Generation_for_Zero-shot_Multi-label_Classification.md)

- [Robust Pronoun Use Fidelity with English LLMs: Are they Reasoning, Repeating, or Just Biased?](2024年04月03日/Robust_Pronoun_Use_Fidelity_with_English_LLMs_Are_they_Reasoning,_Repeating,_or_Just_Biased.md)

    - [翻译: 英语大型语言模型的代词使用准确度：它们真的在进行逻辑推理，还是仅仅在重复或受到偏见的驱使？](2024年04月03日/Robust_Pronoun_Use_Fidelity_with_English_LLMs_Are_they_Reasoning,_Repeating,_or_Just_Biased.md)

- [Towards Standards-Compliant Assistive Technology Product Specifications via LLMs](2024年04月03日/Towards_Standards-Compliant_Assistive_Technology_Product_Specifications_via_LLMs.md)

    - [翻译: 借助大型语言模型（LLMs），迈向符合标准的辅助技术产品规范。](2024年04月03日/Towards_Standards-Compliant_Assistive_Technology_Product_Specifications_via_LLMs.md)

- [LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models](2024年04月03日/LVLM-Intrepret_An_Interpretability_Tool_for_Large_Vision-Language_Models.md)

    - [翻译: LVLM-解读：为大型视觉-语言模型打造的可解释性工具](2024年04月03日/LVLM-Intrepret_An_Interpretability_Tool_for_Large_Vision-Language_Models.md)

- [Testing the Effect of Code Documentation on Large Language Model Code Understanding](2024年04月03日/Testing_the_Effect_of_Code_Documentation_on_Large_Language_Model_Code_Understanding.md)

    - [翻译: 探究代码注释在提升大型语言模型对代码理解方面的作用](2024年04月03日/Testing_the_Effect_of_Code_Documentation_on_Large_Language_Model_Code_Understanding.md)

- [Auditing the Use of Language Models to Guide Hiring Decisions](2024年04月03日/Auditing_the_Use_of_Language_Models_to_Guide_Hiring_Decisions.md)

    - [翻译: 本文探讨了运用语言模型辅助招聘决策的实践，并评估其有效性与潜在影响。](2024年04月03日/Auditing_the_Use_of_Language_Models_to_Guide_Hiring_Decisions.md)

- [Construction of Functional Materials Knowledge Graph in Multidisciplinary Materials Science via Large Language Model](2024年04月03日/Construction_of_Functional_Materials_Knowledge_Graph_in_Multidisciplinary_Materials_Science_via_Large_Language_Model.md)

    - [翻译: 借助大型语言模型，跨学科材料科学领域正致力于构建功能材料的知识图谱。](2024年04月03日/Construction_of_Functional_Materials_Knowledge_Graph_in_Multidisciplinary_Materials_Science_via_Large_Language_Model.md)

- [Mai Ho'omāuna i ka 'Ai: Language Models Improve Automatic Speech Recognition in Hawaiian](2024年04月03日/Mai_Ho'omāuna_i_ka_'Ai_Language_Models_Improve_Automatic_Speech_Recognition_in_Hawaiian.md)

    - [翻译: 借助语言模型，夏威夷语的自动语音识别技术得到提升](2024年04月03日/Mai_Ho'omāuna_i_ka_'Ai_Language_Models_Improve_Automatic_Speech_Recognition_in_Hawaiian.md)

- [JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks](2024年04月03日/JailBreakV-28K_A_Benchmark_for_Assessing_the_Robustness_of_MultiModal_Large_Language_Models_against_Jailbreak_Attacks.md)

    - [翻译: JailBreakV-28K：针对越狱攻击，评估多模态大型语言模型鲁棒性的基准测试。](2024年04月03日/JailBreakV-28K_A_Benchmark_for_Assessing_the_Robustness_of_MultiModal_Large_Language_Models_against_Jailbreak_Attacks.md)

- [CONFLARE: CONFormal LArge language model REtrieval](2024年04月03日/CONFLARE_CONFormal_LArge_language_model_REtrieval.md)

    - [翻译: CONFLARE：一种适应性强的大型语言模型检索系统](2024年04月03日/CONFLARE_CONFormal_LArge_language_model_REtrieval.md)

- [Language Model Evolution: An Iterated Learning Perspective](2024年04月03日/Language_Model_Evolution_An_Iterated_Learning_Perspective.md)

    - [翻译: 语言模型的进化：从迭代学习的角度看](2024年04月03日/Language_Model_Evolution_An_Iterated_Learning_Perspective.md)

- [MIMIR: A Streamlined Platform for Personalized Agent Tuning in Domain Expertise](2024年04月03日/MIMIR_A_Streamlined_Platform_for_Personalized_Agent_Tuning_in_Domain_Expertise.md)

    - [翻译: MIMIR：领域专家专用，打造个性化智能代理的高效平台](2024年04月03日/MIMIR_A_Streamlined_Platform_for_Personalized_Agent_Tuning_in_Domain_Expertise.md)

2024年04月02日

- [Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack](2024年04月02日/Great,_Now_Write_an_Article_About_That_The_Crescendo_Multi-Turn_LLM_Jailbreak_Attack.md)

    - [翻译: 好极了，那就来谈谈这个主题：《高潮》—— 一种针对多轮大型语言模型的突破性攻击手法](2024年04月02日/Great,_Now_Write_an_Article_About_That_The_Crescendo_Multi-Turn_LLM_Jailbreak_Attack.md)

- [Sentiment Analysis of Citations in Scientific Articles Using ChatGPT: Identifying Potential Biases and Conflicts of Interest](2024年04月02日/Sentiment_Analysis_of_Citations_in_Scientific_Articles_Using_ChatGPT_Identifying_Potential_Biases_and_Conflicts_of_Interest.md)

    - [翻译: 通过 ChatGPT 对科学论文引用的情感分析，揭示可能存在的偏见与利益冲突。](2024年04月02日/Sentiment_Analysis_of_Citations_in_Scientific_Articles_Using_ChatGPT_Identifying_Potential_Biases_and_Conflicts_of_Interest.md)

- [PATCH -- Psychometrics-AssisTed benCHmarking of Large Language Models: A Case Study of Mathematics Proficiency](2024年04月02日/PATCH_--_Psychometrics-AssisTed_benCHmarking_of_Large_Language_Models_A_Case_Study_of_Mathematics_Proficiency.md)

    - [翻译: PATCH——通过心理测量技术辅助的大规模语言模型性能基准测试：以数学能力为例的深入案例分析](2024年04月02日/PATCH_--_Psychometrics-AssisTed_benCHmarking_of_Large_Language_Models_A_Case_Study_of_Mathematics_Proficiency.md)

- [Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation](2024年04月02日/Auditing_Large_Language_Models_for_Enhanced_Text-Based_Stereotype_Detection_and_Probing-Based_Bias_Evaluation.md)

    - [翻译: 通过对大型语言模型进行审查，我们可以提高基于文本的刻板印象检测能力，并进行更为深入的偏见评估。](2024年04月02日/Auditing_Large_Language_Models_for_Enhanced_Text-Based_Stereotype_Detection_and_Probing-Based_Bias_Evaluation.md)

- [Class-Incremental Few-Shot Event Detection](2024年04月02日/Class-Incremental_Few-Shot_Event_Detection.md)

    - [翻译: 在少样本学习环境下，我们提出了一种新颖的事件检测方法，即类增量策略。该方法通过逐步引入新的类别信息，有效地提升了模型在面对类别不断变化的事件中的检测性能。](2024年04月02日/Class-Incremental_Few-Shot_Event_Detection.md)

- [Peer-aided Repairer: Empowering Large Language Models to Repair Advanced Student Assignments](2024年04月02日/Peer-aided_Repairer_Empowering_Large_Language_Models_to_Repair_Advanced_Student_Assignments.md)

    - [翻译: 同伴辅助修复器：赋予大型语言模型修复高级学生作业的能力，旨在提升模型对复杂任务的处理能力。](2024年04月02日/Peer-aided_Repairer_Empowering_Large_Language_Models_to_Repair_Advanced_Student_Assignments.md)

- [M2SA: Multimodal and Multilingual Model for Sentiment Analysis of Tweets](2024年04月02日/M2SA_Multimodal_and_Multilingual_Model_for_Sentiment_Analysis_of_Tweets.md)

    - [翻译: M2SA：一款针对推文情感分析的多模态、多语言模型](2024年04月02日/M2SA_Multimodal_and_Multilingual_Model_for_Sentiment_Analysis_of_Tweets.md)

- [Unleash the Potential of CLIP for Video Highlight Detection](2024年04月02日/Unleash_the_Potential_of_CLIP_for_Video_Highlight_Detection.md)

    - [翻译: 挖掘 CLIP 技术在视频精彩瞬间识别上的潜在力量](2024年04月02日/Unleash_the_Potential_of_CLIP_for_Video_Highlight_Detection.md)

- [Octopus v2: On-device language model for super agent](2024年04月02日/Octopus_v2_On-device_language_model_for_super_agent.md)

    - [翻译: 章鱼 v2：超级智能代理的移动设备语言模型](2024年04月02日/Octopus_v2_On-device_language_model_for_super_agent.md)

- [Transfer Learning from Whisper for Microscopic Intelligibility Prediction](2024年04月02日/Transfer_Learning_from_Whisper_for_Microscopic_Intelligibility_Prediction.md)

    - [翻译: 通过 Whisper 的迁移学习能力来预测细节层面的可理解性。](2024年04月02日/Transfer_Learning_from_Whisper_for_Microscopic_Intelligibility_Prediction.md)

- [Asymptotics of Language Model Alignment](2024年04月02日/Asymptotics_of_Language_Model_Alignment.md)

    - [翻译: 探讨语言模型对齐的极限行为](2024年04月02日/Asymptotics_of_Language_Model_Alignment.md)

- [Self-Improvement Programming for Temporal Knowledge Graph Question Answering](2024年04月02日/Self-Improvement_Programming_for_Temporal_Knowledge_Graph_Question_Answering.md)

    - [翻译: 通过自改进编程技术，提升时序知识图谱的问答能力。](2024年04月02日/Self-Improvement_Programming_for_Temporal_Knowledge_Graph_Question_Answering.md)

- [On the Role of Summary Content Units in Text Summarization Evaluation](2024年04月02日/On_the_Role_of_Summary_Content_Units_in_Text_Summarization_Evaluation.md)

    - [翻译: 文本摘要评估中，摘要内容单元的重要性。](2024年04月02日/On_the_Role_of_Summary_Content_Units_in_Text_Summarization_Evaluation.md)

- [MotionChain: Conversational Motion Controllers via Multimodal Prompts](2024年04月02日/MotionChain_Conversational_Motion_Controllers_via_Multimodal_Prompts.md)

    - [翻译: MotionChain：借助多模态提示实现的交互式动作控制方案](2024年04月02日/MotionChain_Conversational_Motion_Controllers_via_Multimodal_Prompts.md)

- [Towards Generalizable and Faithful Logic Reasoning over Natural Language via Resolution Refutation](2024年04月02日/Towards_Generalizable_and_Faithful_Logic_Reasoning_over_Natural_Language_via_Resolution_Refutation.md)

    - [翻译: 通过解决反驳，我们朝着实现自然语言逻辑推理的普适性和忠实性迈进。](2024年04月02日/Towards_Generalizable_and_Faithful_Logic_Reasoning_over_Natural_Language_via_Resolution_Refutation.md)

- [METAL: Towards Multilingual Meta-Evaluation](2024年04月02日/METAL_Towards_Multilingual_Meta-Evaluation.md)

    - [翻译: METAL：探索多语言间的元评估方法](2024年04月02日/METAL_Towards_Multilingual_Meta-Evaluation.md)

- [CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models](2024年04月02日/CMAT_A_Multi-Agent_Collaboration_Tuning_Framework_for_Enhancing_Small_Language_Models.md)

    - [翻译: CMAT：专为提升小型语言模型性能而设计的多智能体协同优化框架](2024年04月02日/CMAT_A_Multi-Agent_Collaboration_Tuning_Framework_for_Enhancing_Small_Language_Models.md)

- [Release of Pre-Trained Models for the Japanese Language](2024年04月02日/Release_of_Pre-Trained_Models_for_the_Japanese_Language.md)

    - [翻译: 日语预训练模型现已发布。](2024年04月02日/Release_of_Pre-Trained_Models_for_the_Japanese_Language.md)

- [InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis](2024年04月02日/InsightLens_Discovering_and_Exploring_Insights_from_Conversational_Contexts_in_Large-Language-Model-Powered_Data_Analysis.md)

    - [翻译: InsightLens：在大型语言模型支持的数据分析中，挖掘并探究对话语境的深层见解。](2024年04月02日/InsightLens_Discovering_and_Exploring_Insights_from_Conversational_Contexts_in_Large-Language-Model-Powered_Data_Analysis.md)

- [Voice EHR: Introducing Multimodal Audio Data for Health](2024年04月02日/Voice_EHR_Introducing_Multimodal_Audio_Data_for_Health.md)

    - [翻译: 语音电子健康记录（Voice EHR）：为健康领域带来多模态音频数据的新探索。](2024年04月02日/Voice_EHR_Introducing_Multimodal_Audio_Data_for_Health.md)

- [CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions for RAG systems](2024年04月02日/CLAPNQ_Cohesive_Long-form_Answers_from_Passages_in_Natural_Questions_for_RAG_systems.md)

    - [翻译: CLAPNQ：针对RAG系统，从自然语言问题中提取段落，打造连贯且详尽的长篇幅回答。](2024年04月02日/CLAPNQ_Cohesive_Long-form_Answers_from_Passages_in_Natural_Questions_for_RAG_systems.md)

- [Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts](2024年04月02日/Improving_Retrieval_Augmented_Open-Domain_Question-Answering_with_Vectorized_Contexts.md)

    - [翻译: 利用向量化上下文技术，我们旨在提升开放领域问答系统中的检索增强功能。](2024年04月02日/Improving_Retrieval_Augmented_Open-Domain_Question-Answering_with_Vectorized_Contexts.md)

- [Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization](2024年04月02日/Towards_Better_Generalization_in_Open-Domain_Question_Answering_by_Mitigating_Context_Memorization.md)

    - [翻译: 为了在开放领域问答中获得更佳的泛化效果，本研究致力于减轻上下文记忆的影响。](2024年04月02日/Towards_Better_Generalization_in_Open-Domain_Question_Answering_by_Mitigating_Context_Memorization.md)

- [Iterated Learning Improves Compositionality in Large Vision-Language Models](2024年04月02日/Iterated_Learning_Improves_Compositionality_in_Large_Vision-Language_Models.md)

    - [翻译: 通过迭代学习，大型视觉-语言模型的组合能力得到了显著提升。](2024年04月02日/Iterated_Learning_Improves_Compositionality_in_Large_Vision-Language_Models.md)

- [A Survey on Large Language Model-Based Game Agents](2024年04月02日/A_Survey_on_Large_Language_Model-Based_Game_Agents.md)

    - [翻译: 本文综述了基于大型语言模型的游戏代理的研究现状。](2024年04月02日/A_Survey_on_Large_Language_Model-Based_Game_Agents.md)

- [Large Language Models for Orchestrating Bimanual Robots](2024年04月02日/Large_Language_Models_for_Orchestrating_Bimanual_Robots.md)

    - [翻译: 通过大型语言模型，我们能够精准地指挥双手机器人的协同工作。](2024年04月02日/Large_Language_Models_for_Orchestrating_Bimanual_Robots.md)

- [Segment Any 3D Object with Language](2024年04月02日/Segment_Any_3D_Object_with_Language.md)

    - [翻译: 通过语言指令，轻松分割任意三维物体](2024年04月02日/Segment_Any_3D_Object_with_Language.md)

- [Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks](2024年04月02日/Bridging_Language,_Vision_and_Action_Multimodal_VAEs_in_Robotic_Manipulation_Tasks.md)

    - [翻译: 多模态变分自编码器（VAEs）在机器人操控任务中架起了语言、视觉与动作之间的桥梁。尽管如此，我们对于这些多模态VAEs在现实操作中的表现及其成效仍知之甚少。](2024年04月02日/Bridging_Language,_Vision_and_Action_Multimodal_VAEs_in_Robotic_Manipulation_Tasks.md)

- [Topic-based Watermarks for LLM-Generated Text](2024年04月02日/Topic-based_Watermarks_for_LLM-Generated_Text.md)

    - [翻译: 本文介绍了一种为大型语言模型（LLM）生成的文本设计的主题水印方法。](2024年04月02日/Topic-based_Watermarks_for_LLM-Generated_Text.md)

- [ViTamin: Designing Scalable Vision Models in the Vision-Language Era](2024年04月02日/ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era.md)

    - [翻译: ViTamin: 为视觉-语言时代打造可伸缩的视觉模型](2024年04月02日/ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era.md)

- [FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning](2024年04月02日/FLawN-T5_An_Empirical_Examination_of_Effective_Instruction-Tuning_Data_Mixtures_for_Legal_Reasoning.md)

    - [翻译: FLawN-T5：探究法律推理中高效指令调整数据组合的实证分析](2024年04月02日/FLawN-T5_An_Empirical_Examination_of_Effective_Instruction-Tuning_Data_Mixtures_for_Legal_Reasoning.md)

- [Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models](2024年04月02日/Exploring_Automated_Distractor_Generation_for_Math_Multiple-choice_Questions_via_Large_Language_Models.md)

    - [翻译: 本研究利用大型语言模型，探索自动生成数学多项选择题干扰项的方法。](2024年04月02日/Exploring_Automated_Distractor_Generation_for_Math_Multiple-choice_Questions_via_Large_Language_Models.md)

- [Pre-trained Vision and Language Transformers Are Few-Shot Incremental Learners](2024年04月02日/Pre-trained_Vision_and_Language_Transformers_Are_Few-Shot_Incremental_Learners.md)

    - [翻译: 预先训练好的视觉与语言转换器，能够作为少量样本的逐步学习器。](2024年04月02日/Pre-trained_Vision_and_Language_Transformers_Are_Few-Shot_Incremental_Learners.md)

- [GINopic: Topic Modeling with Graph Isomorphism Network](2024年04月02日/GINopic_Topic_Modeling_with_Graph_Isomorphism_Network.md)

    - [翻译: GINopic：借助图同构网络进行主题挖掘与分析](2024年04月02日/GINopic_Topic_Modeling_with_Graph_Isomorphism_Network.md)

- [CameraCtrl: Enabling Camera Control for Text-to-Video Generation](2024年04月02日/CameraCtrl_Enabling_Camera_Control_for_Text-to-Video_Generation.md)

    - [翻译: CameraCtrl：实现文本输入到视频输出的相机操控功能](2024年04月02日/CameraCtrl_Enabling_Camera_Control_for_Text-to-Video_Generation.md)

- [Advancing LLM Reasoning Generalists with Preference Trees](2024年04月02日/Advancing_LLM_Reasoning_Generalists_with_Preference_Trees.md)

    - [翻译: 借助偏好树，我们能够增强大型语言模型的推理能力，使其在处理各种问题时表现得更加全面。](2024年04月02日/Advancing_LLM_Reasoning_Generalists_with_Preference_Trees.md)

- [Digital Forgetting in Large Language Models: A Survey of Unlearning Methods](2024年04月02日/Digital_Forgetting_in_Large_Language_Models_A_Survey_of_Unlearning_Methods.md)

    - [翻译: 大型语言模型中的数字遗忘：对遗忘方法的综述。](2024年04月02日/Digital_Forgetting_in_Large_Language_Models_A_Survey_of_Unlearning_Methods.md)

- [Long-context LLMs Struggle with Long In-context Learning](2024年04月02日/Long-context_LLMs_Struggle_with_Long_In-context_Learning.md)

    - [翻译: 长篇幅的语境对于大型语言模型来说，在进行长距离的情境学习时显得颇为棘手。](2024年04月02日/Long-context_LLMs_Struggle_with_Long_In-context_Learning.md)

- [Deconstructing In-Context Learning: Understanding Prompts via Corruption](2024年04月02日/Deconstructing_In-Context_Learning_Understanding_Prompts_via_Corruption.md)

    - [翻译: 探究上下文学习之谜：通过干扰手段剖析提示的本质](2024年04月02日/Deconstructing_In-Context_Learning_Understanding_Prompts_via_Corruption.md)

- [MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages](2024年04月02日/MultiParaDetox_Extending_Text_Detoxification_with_Parallel_Data_to_New_Languages.md)

    - [翻译: MultiParaDetox：利用并行文本数据，将文本净化技术推广至更多语言。](2024年04月02日/MultiParaDetox_Extending_Text_Detoxification_with_Parallel_Data_to_New_Languages.md)

- [MuxServe: Flexible Multiplexing for Efficient Multiple LLM Serving](2024年04月02日/MuxServe_Flexible_Multiplexing_for_Efficient_Multiple_LLM_Serving.md)

    - [翻译: MuxServe 通过灵活的多路复用技术，为多个大型语言模型（LLM）提供高效服务。](2024年04月02日/MuxServe_Flexible_Multiplexing_for_Efficient_Multiple_LLM_Serving.md)

- [HyperCLOVA X Technical Report](2024年04月02日/HyperCLOVA_X_Technical_Report.md)

    - [翻译: 《超能CLOVA X》技术研究报告](2024年04月02日/HyperCLOVA_X_Technical_Report.md)

- [Towards Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation](2024年04月02日/Towards_Better_Understanding_of_Cybercrime_The_Role_of_Fine-Tuned_LLMs_in_Translation.md)

    - [翻译: 探索网络犯罪的深层含义：精细化调整的大型语言模型在翻译工作中的角色。](2024年04月02日/Towards_Better_Understanding_of_Cybercrime_The_Role_of_Fine-Tuned_LLMs_in_Translation.md)

- [SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation](2024年04月02日/SGSH_Stimulate_Large_Language_Models_with_Skeleton_Heuristics_for_Knowledge_Base_Question_Generation.md)

    - [翻译: SGSH：运用骨架启发式策略激活大型语言模型，助力知识库提问生成。](2024年04月02日/SGSH_Stimulate_Large_Language_Models_with_Skeleton_Heuristics_for_Knowledge_Base_Question_Generation.md)

- [Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack](2024年04月02日/Humanizing_Machine-Generated_Content_Evading_AI-Text_Detection_through_Adversarial_Attack.md)

    - [翻译: 机器内容拟人化：通过对抗性策略规避AI文本识别技术。](2024年04月02日/Humanizing_Machine-Generated_Content_Evading_AI-Text_Detection_through_Adversarial_Attack.md)

- [Minimize Quantization Output Error with Bias Compensation](2024年04月02日/Minimize_Quantization_Output_Error_with_Bias_Compensation.md)

    - [翻译: 采用偏差校正法降低量化输出误差](2024年04月02日/Minimize_Quantization_Output_Error_with_Bias_Compensation.md)

- [Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey](2024年04月02日/Beyond_Accuracy_Evaluating_the_Reasoning_Behavior_of_Large_Language_Models_--_A_Survey.md)

    - [翻译: 探究大型语言模型的推理表现：准确性之外的评估视角 -- 一项全面调查](2024年04月02日/Beyond_Accuracy_Evaluating_the_Reasoning_Behavior_of_Large_Language_Models_--_A_Survey.md)

- [Poro 34B and the Blessing of Multilinguality](2024年04月02日/Poro_34B_and_the_Blessing_of_Multilinguality.md)

    - [翻译: 探索 Poro 34B：多语言能力的优势与挑战](2024年04月02日/Poro_34B_and_the_Blessing_of_Multilinguality.md)

- [Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation](2024年04月02日/Where_to_Move_Next_Zero-shot_Generalization_of_LLMs_for_Next_POI_Recommendation.md)

    - [翻译: 下一站去哪儿：大型语言模型的零-shot 泛化技术助力下一个热门景点推荐](2024年04月02日/Where_to_Move_Next_Zero-shot_Generalization_of_LLMs_for_Next_POI_Recommendation.md)

- [RESSA: Repair Sparse Vision-Language Models via Sparse Cross-Modality Adaptation](2024年04月02日/RESSA_Repair_Sparse_Vision-Language_Models_via_Sparse_Cross-Modality_Adaptation.md)

    - [翻译: RESSA：通过稀疏交叉模态适配技术，完善视觉-语言模型的稀疏性问题。](2024年04月02日/RESSA_Repair_Sparse_Vision-Language_Models_via_Sparse_Cross-Modality_Adaptation.md)

- [Enhancing Low-Resource LLMs Classification with PEFT and Synthetic Data](2024年04月02日/Enhancing_Low-Resource_LLMs_Classification_with_PEFT_and_Synthetic_Data.md)

    - [翻译: 通过 PEFT 和合成数据提升低资源大型语言模型的分类表现。](2024年04月02日/Enhancing_Low-Resource_LLMs_Classification_with_PEFT_and_Synthetic_Data.md)

- [Revisiting subword tokenization: A case study on affixal negation in large language models](2024年04月02日/Revisiting_subword_tokenization_A_case_study_on_affixal_negation_in_large_language_models.md)

    - [翻译: 深入探讨子词切分：以大型语言模型中的词缀否定现象为例](2024年04月02日/Revisiting_subword_tokenization_A_case_study_on_affixal_negation_in_large_language_models.md)

- [What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases](2024年04月02日/What_Are_We_Measuring_When_We_Evaluate_Large_Vision-Language_Models_An_Analysis_of_Latent_Factors_and_Biases.md)

    - [翻译: 评估大型视觉-语言模型时，我们究竟关注哪些指标？本文深入探讨了其中的潜在因素与偏见问题。](2024年04月02日/What_Are_We_Measuring_When_We_Evaluate_Large_Vision-Language_Models_An_Analysis_of_Latent_Factors_and_Biases.md)

- [Exploring Backdoor Vulnerabilities of Chat Models](2024年04月02日/Exploring_Backdoor_Vulnerabilities_of_Chat_Models.md)

    - [翻译: 深入研究聊天机器人的安全漏洞](2024年04月02日/Exploring_Backdoor_Vulnerabilities_of_Chat_Models.md)

- [Benchmarking Large Language Models for Persian: A Preliminary Study Focusing on ChatGPT](2024年04月02日/Benchmarking_Large_Language_Models_for_Persian_A_Preliminary_Study_Focusing_on_ChatGPT.md)

    - [翻译: 探索波斯语大型语言模型：以ChatGPT为焦点的初步研究](2024年04月02日/Benchmarking_Large_Language_Models_for_Persian_A_Preliminary_Study_Focusing_on_ChatGPT.md)

- [Token Trails: Navigating Contextual Depths in Conversational AI with ChatLLM](2024年04月02日/Token_Trails_Navigating_Contextual_Depths_in_Conversational_AI_with_ChatLLM.md)

    - [翻译: Token Trails: 利用ChatLLM探索会话AI中的语境深度](2024年04月02日/Token_Trails_Navigating_Contextual_Depths_in_Conversational_AI_with_ChatLLM.md)

- [Low-resource neural machine translation with morphological modeling](2024年04月02日/Low-resource_neural_machine_translation_with_morphological_modeling.md)

    - [翻译: 在资源有限的情况下，通过形态建模来提升神经机器翻译的性能。](2024年04月02日/Low-resource_neural_machine_translation_with_morphological_modeling.md)

- [On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL](2024年04月02日/On_Linearizing_Structured_Data_in_Encoder-Decoder_Language_Models_Insights_from_Text-to-SQL.md)

    - [翻译: 探究编码器-解码器语言模型中结构化数据的线性化处理：文本转换为SQL的洞见。](2024年04月02日/On_Linearizing_Structured_Data_in_Encoder-Decoder_Language_Models_Insights_from_Text-to-SQL.md)

- [Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors](2024年04月02日/Two_Heads_are_Better_than_One_Nested_PoE_for_Robust_Defense_Against_Multi-Backdoors.md)

    - [翻译: 双脑并用，胜于单机：采用嵌套PoE策略，构筑抵御多重后门攻击的坚实防线。](2024年04月02日/Two_Heads_are_Better_than_One_Nested_PoE_for_Robust_Defense_Against_Multi-Backdoors.md)

- [Multi-BERT: Leveraging Adapters and Prompt Tuning for Low-Resource Multi-Domain Adaptation](2024年04月02日/Multi-BERT_Leveraging_Adapters_and_Prompt_Tuning_for_Low-Resource_Multi-Domain_Adaptation.md)

    - [翻译: Multi-BERT：借助适配器与提示调优，实现低资源条件下的多领域适配。](2024年04月02日/Multi-BERT_Leveraging_Adapters_and_Prompt_Tuning_for_Low-Resource_Multi-Domain_Adaptation.md)

- [Comparative Study of Domain Driven Terms Extraction Using Large Language Models](2024年04月02日/Comparative_Study_of_Domain_Driven_Terms_Extraction_Using_Large_Language_Models.md)

    - [翻译: 本研究通过大型语言模型，对领域驱动的术语提取进行了比较分析。](2024年04月02日/Comparative_Study_of_Domain_Driven_Terms_Extraction_Using_Large_Language_Models.md)

- [Heat Death of Generative Models in Closed-Loop Learning](2024年04月02日/Heat_Death_of_Generative_Models_in_Closed-Loop_Learning.md)

    - [翻译: 闭环学习中生成模型的热寂困境](2024年04月02日/Heat_Death_of_Generative_Models_in_Closed-Loop_Learning.md)

- [Toward Informal Language Processing: Knowledge of Slang in Large Language Models](2024年04月02日/Toward_Informal_Language_Processing_Knowledge_of_Slang_in_Large_Language_Models.md)

    - [翻译: 迈向非正式语言处理：探究大型语言模型中的俚语理解](2024年04月02日/Toward_Informal_Language_Processing_Knowledge_of_Slang_in_Large_Language_Models.md)

- [Prompts As Programs: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization](2024年04月02日/Prompts_As_Programs_A_Structure-Aware_Approach_to_Efficient_Compile-Time_Prompt_Optimization.md)

    - [翻译: 将提示视作程序，本研究提出了一种结构感知的方法，用以在编译时期高效地优化提示。](2024年04月02日/Prompts_As_Programs_A_Structure-Aware_Approach_to_Efficient_Compile-Time_Prompt_Optimization.md)

- [ZeroCAP: Zero-Shot Multi-Robot Context Aware Pattern Formation via Large Language Models](2024年04月02日/ZeroCAP_Zero-Shot_Multi-Robot_Context_Aware_Pattern_Formation_via_Large_Language_Models.md)

    - [翻译: ZeroCAP 利用大型语言模型，实现了零-shot学习下的多机器人系统能够感知上下文并进行模式形成。](2024年04月02日/ZeroCAP_Zero-Shot_Multi-Robot_Context_Aware_Pattern_Formation_via_Large_Language_Models.md)

- [Constrained Robotic Navigation on Preferred Terrains Using LLMs and Speech Instruction: Exploiting the Power of Adverbs](2024年04月02日/Constrained_Robotic_Navigation_on_Preferred_Terrains_Using_LLMs_and_Speech_Instruction_Exploiting_the_Power_of_Adverbs.md)

    - [翻译: 借助副词的威力，通过大型语言模型和语音指令实现机器人在理想地形上的精准导航。](2024年04月02日/Constrained_Robotic_Navigation_on_Preferred_Terrains_Using_LLMs_and_Speech_Instruction_Exploiting_the_Power_of_Adverbs.md)

- [LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages](2024年04月02日/LLMs_in_the_Loop_Leveraging_Large_Language_Model_Annotations_for_Active_Learning_in_Low-Resource_Languages.md)

    - [翻译: 大型语言模型（LLM）循环应用：借助其注释功能，为低资源语言的主动学习提供支持。](2024年04月02日/LLMs_in_the_Loop_Leveraging_Large_Language_Model_Annotations_for_Active_Learning_in_Low-Resource_Languages.md)

- [: A Simple Society of Language Models Solves Complex Reasoning](2024年04月02日/_A_Simple_Society_of_Language_Models_Solves_Complex_Reasoning.md)

    - [翻译: 简单的语言模型集合轻松应对复杂推理挑战](2024年04月02日/_A_Simple_Society_of_Language_Models_Solves_Complex_Reasoning.md)

- [Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices](2024年04月02日/Exploring_How_Multiple_Levels_of_GPT-Generated_Programming_Hints_Support_or_Disappoint_Novices.md)

    - [翻译: 研究多层次 GPT 编程提示对新手的助力与挫败感。](2024年04月02日/Exploring_How_Multiple_Levels_of_GPT-Generated_Programming_Hints_Support_or_Disappoint_Novices.md)

- [Emergent Abilities in Reduced-Scale Generative Language Models](2024年04月02日/Emergent_Abilities_in_Reduced-Scale_Generative_Language_Models.md)

    - [翻译: 在简化版的生成型语言模型中，涌现出了一些新的能力。](2024年04月02日/Emergent_Abilities_in_Reduced-Scale_Generative_Language_Models.md)

- [Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization](2024年04月02日/Self-Organized_Agents_A_LLM_Multi-Agent_Framework_toward_Ultra_Large-Scale_Code_Generation_and_Optimization.md)

    - [翻译: 自组织的智能代理：构建面向极大规模代码生成与优化的多代理大型语言模型框架。](2024年04月02日/Self-Organized_Agents_A_LLM_Multi-Agent_Framework_toward_Ultra_Large-Scale_Code_Generation_and_Optimization.md)

- [CATP: Cross-Attention Token Pruning for Accuracy Preserved Multimodal Model Inference](2024年04月02日/CATP_Cross-Attention_Token_Pruning_for_Accuracy_Preserved_Multimodal_Model_Inference.md)

    - [翻译: CATP 技术通过跨注意力机制对令牌进行剪枝，实现了在多模态模型推理中保持准确度的同时，提高了效率。](2024年04月02日/CATP_Cross-Attention_Token_Pruning_for_Accuracy_Preserved_Multimodal_Model_Inference.md)

2024年04月01日

- [Large Language Model Evaluation Via Multi AI Agents: Preliminary results](2024年04月01日/Large_Language_Model_Evaluation_Via_Multi_AI_Agents_Preliminary_results.md)

    - [翻译: 借助众多AI助手，我们对大型语言模型展开了评估，目前取得了一些初步成果。](2024年04月01日/Large_Language_Model_Evaluation_Via_Multi_AI_Agents_Preliminary_results.md)

- [Source-Aware Training Enables Knowledge Attribution in Language Models](2024年04月01日/Source-Aware_Training_Enables_Knowledge_Attribution_in_Language_Models.md)

    - [翻译: 通过源感知训练，我们能够在语言模型中对知识进行追溯和归属。](2024年04月01日/Source-Aware_Training_Enables_Knowledge_Attribution_in_Language_Models.md)

- [Harnessing Large Language Models for Training-free Video Anomaly Detection](2024年04月01日/Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection.md)

    - [翻译: 通过运用大型语言模型，我们可以实现无需额外训练的视频异常检测技术。](2024年04月01日/Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection.md)

- [Query Performance Prediction using Relevance Judgments Generated by Large Language Models](2024年04月01日/Query_Performance_Prediction_using_Relevance_Judgments_Generated_by_Large_Language_Models.md)

    - [翻译: 通过大型语言模型生成的相关性评估来预测查询性能](2024年04月01日/Query_Performance_Prediction_using_Relevance_Judgments_Generated_by_Large_Language_Models.md)

- [Transforming the Synthesis of Carbon Nanotubes with Machine Learning Models and Automation](2024年04月01日/Transforming_the_Synthesis_of_Carbon_Nanotubes_with_Machine_Learning_Models_and_Automation.md)

    - [翻译: 利用机器学习模型和自动化技术革新碳纳米管的制备过程](2024年04月01日/Transforming_the_Synthesis_of_Carbon_Nanotubes_with_Machine_Learning_Models_and_Automation.md)

- [LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation](2024年04月01日/LLM-RadJudge_Achieving_Radiologist-Level_Evaluation_for_X-Ray_Report_Generation.md)

    - [翻译: LLM-RadJudge：在生成X光报告方面达到放射科医生的评估水准](2024年04月01日/LLM-RadJudge_Achieving_Radiologist-Level_Evaluation_for_X-Ray_Report_Generation.md)

- [Exploring the Nexus of Large Language Models and Legal Systems: A Short Survey](2024年04月01日/Exploring_the_Nexus_of_Large_Language_Models_and_Legal_Systems_A_Short_Survey.md)

    - [翻译: 浅谈大型语言模型与法律体系的交汇点](2024年04月01日/Exploring_the_Nexus_of_Large_Language_Models_and_Legal_Systems_A_Short_Survey.md)

- [Prior Constraints-based Reward Model Training for Aligning Large Language Models](2024年04月01日/Prior_Constraints-based_Reward_Model_Training_for_Aligning_Large_Language_Models.md)

    - [翻译: 通过先验约束引导的奖励模型训练，实现大型语言模型的精准对齐。](2024年04月01日/Prior_Constraints-based_Reward_Model_Training_for_Aligning_Large_Language_Models.md)

- [VideoDistill: Language-aware Vision Distillation for Video Question Answering](2024年04月01日/VideoDistill_Language-aware_Vision_Distillation_for_Video_Question_Answering.md)

    - [翻译: VideoDistill：为视频问答而设计的，融合语言理解的视觉蒸馏技术](2024年04月01日/VideoDistill_Language-aware_Vision_Distillation_for_Video_Question_Answering.md)

- [Exploring and Evaluating Hallucinations in LLM-Powered Code Generation](2024年04月01日/Exploring_and_Evaluating_Hallucinations_in_LLM-Powered_Code_Generation.md)

    - [翻译: 探究与评价由大型语言模型（LLM）驱动的代码生成过程中的虚构现象。](2024年04月01日/Exploring_and_Evaluating_Hallucinations_in_LLM-Powered_Code_Generation.md)

- [AISPACE at SemEval-2024 task 8: A Class-balanced Soft-voting System for Detecting Multi-generator Machine-generated Text](2024年04月01日/AISPACE_at_SemEval-2024_task_8_A_Class-balanced_Soft-voting_System_for_Detecting_Multi-generator_Machine-generated_Text.md)

    - [翻译: AISPACE 参与 SemEval-2024 第 8 项任务：构建一个平衡类别的软投票系统，用于识别由多种生成器产生的机器文本。](2024年04月01日/AISPACE_at_SemEval-2024_task_8_A_Class-balanced_Soft-voting_System_for_Detecting_Multi-generator_Machine-generated_Text.md)

- [Evalverse: Unified and Accessible Library for Large Language Model Evaluation](2024年04月01日/Evalverse_Unified_and_Accessible_Library_for_Large_Language_Model_Evaluation.md)

    - [翻译: Evalverse：为大型语言模型评估打造的一体化、易用资源库](2024年04月01日/Evalverse_Unified_and_Accessible_Library_for_Large_Language_Model_Evaluation.md)

- [Evaluating the Factuality of Large Language Models using Large-Scale Knowledge Graphs](2024年04月01日/Evaluating_the_Factuality_of_Large_Language_Models_using_Large-Scale_Knowledge_Graphs.md)

    - [翻译: 通过大规模知识图谱来评估大型语言模型的真实性。](2024年04月01日/Evaluating_the_Factuality_of_Large_Language_Models_using_Large-Scale_Knowledge_Graphs.md)

- [How Can Large Language Models Enable Better Socially Assistive Human-Robot Interaction: A Brief Survey](2024年04月01日/How_Can_Large_Language_Models_Enable_Better_Socially_Assistive_Human-Robot_Interaction_A_Brief_Survey.md)

    - [翻译: 大型语言模型助力人机社交互动：一项简明调查](2024年04月01日/How_Can_Large_Language_Models_Enable_Better_Socially_Assistive_Human-Robot_Interaction_A_Brief_Survey.md)

- [ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback](2024年04月01日/ChatGLM-RLHF_Practices_of_Aligning_Large_Language_Models_with_Human_Feedback.md)

    - [翻译: ChatGLM-RLHF：探索大型语言模型与人类反馈融合的实践之道](2024年04月01日/ChatGLM-RLHF_Practices_of_Aligning_Large_Language_Models_with_Human_Feedback.md)

- [PSYDIAL: Personality-based Synthetic Dialogue Generation using Large Language Models](2024年04月01日/PSYDIAL_Personality-based_Synthetic_Dialogue_Generation_using_Large_Language_Models.md)

    - [翻译: PSYDIAL：利用大型语言模型生成个性化合成对话](2024年04月01日/PSYDIAL_Personality-based_Synthetic_Dialogue_Generation_using_Large_Language_Models.md)

- [A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias](2024年04月01日/A_Survey_on_Multilingual_Large_Language_Models_Corpora,_Alignment,_and_Bias.md)

    - [翻译: 本文综述了多语言大型语言模型的研究现状，探讨了构建多语言模型所需的语料库资源、不同语言间的对齐问题，以及模型中潜在的偏见问题。](2024年04月01日/A_Survey_on_Multilingual_Large_Language_Models_Corpora,_Alignment,_and_Bias.md)

- [LLMs are Good Sign Language Translators](2024年04月01日/LLMs_are_Good_Sign_Language_Translators.md)

    - [翻译: 大型语言模型擅长于手语翻译。](2024年04月01日/LLMs_are_Good_Sign_Language_Translators.md)

- [Token-Efficient Leverage Learning in Large Language Models](2024年04月01日/Token-Efficient_Leverage_Learning_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的高效利用标记学习，旨在优化学习效率。](2024年04月01日/Token-Efficient_Leverage_Learning_in_Large_Language_Models.md)

- [Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning](2024年04月01日/Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_Reasoning.md)

    - [翻译: 学习通过修正：为零-shot生成性视觉语言推理任务打造高效的调优方案。](2024年04月01日/Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_Reasoning.md)

- [ARAGOG: Advanced RAG Output Grading](2024年04月01日/ARAGOG_Advanced_RAG_Output_Grading.md)

    - [翻译: ARAGOG：精进的RAG成果评定](2024年04月01日/ARAGOG_Advanced_RAG_Output_Grading.md)

- [LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models](2024年04月01日/LLM_as_a_Mastermind_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models.md)

    - [翻译: 大型语言模型：策略性推理的探索之旅](2024年04月01日/LLM_as_a_Mastermind_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models.md)

- [Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward](2024年04月01日/Direct_Preference_Optimization_of_Video_Large_Multimodal_Models_from_Language_Model_Reward.md)

    - [翻译: 通过语言模型奖励，直接对视频大型多模态模型进行偏好优化。](2024年04月01日/Direct_Preference_Optimization_of_Video_Large_Multimodal_Models_from_Language_Model_Reward.md)

- [LITE: Modeling Environmental Ecosystems with Multimodal Large Language Models](2024年04月01日/LITE_Modeling_Environmental_Ecosystems_with_Multimodal_Large_Language_Models.md)

    - [翻译: LITE：借助多模态大型语言模型，构建环境生态系统模型](2024年04月01日/LITE_Modeling_Environmental_Ecosystems_with_Multimodal_Large_Language_Models.md)

- [Prompt Learning for Oriented Power Transmission Tower Detection in High-Resolution SAR Images](2024年04月01日/Prompt_Learning_for_Oriented_Power_Transmission_Tower_Detection_in_High-Resolution_SAR_Images.md)

    - [翻译: 针对高分辨率SAR图像中的定向输电塔检测，本研究采用提示学习方法进行探索。](2024年04月01日/Prompt_Learning_for_Oriented_Power_Transmission_Tower_Detection_in_High-Resolution_SAR_Images.md)

- [Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models](2024年04月01日/Towards_Safety_and_Helpfulness_Balanced_Responses_via_Controllable_Large_Language_Models.md)

    - [翻译: 本研究致力于通过可调控的大型语言模型，实现既安全又有益的智能回应。](2024年04月01日/Towards_Safety_and_Helpfulness_Balanced_Responses_via_Controllable_Large_Language_Models.md)

- [Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided](2024年04月01日/Large_Language_Models_are_Capable_of_Offering_Cognitive_Reappraisal,_if_Guided.md)

    - [翻译: 在适当的引导下，大型语言模型具备进行认知重估的能力。](2024年04月01日/Large_Language_Models_are_Capable_of_Offering_Cognitive_Reappraisal,_if_Guided.md)

- [TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model](2024年04月01日/TWIN-GPT_Digital_Twins_for_Clinical_Trials_via_Large_Language_Model.md)

    - [翻译: TWIN-GPT：借助大型语言模型，为临床试验打造数字孪生技术](2024年04月01日/TWIN-GPT_Digital_Twins_for_Clinical_Trials_via_Large_Language_Model.md)

- [Mapping the Increasing Use of LLMs in Scientific Papers](2024年04月01日/Mapping_the_Increasing_Use_of_LLMs_in_Scientific_Papers.md)

    - [翻译: 科学论文中大型语言模型（LLM）使用频率的增长已被详细记录。](2024年04月01日/Mapping_the_Increasing_Use_of_LLMs_in_Scientific_Papers.md)

- [FABLES: Evaluating faithfulness and content selection in book-length summarization](2024年04月01日/FABLES_Evaluating_faithfulness_and_content_selection_in_book-length_summarization.md)

    - [翻译: FABLES：探究书籍摘要的真实度与内容筛选](2024年04月01日/FABLES_Evaluating_faithfulness_and_content_selection_in_book-length_summarization.md)

- [UniArk: Improving Generalisation and Consistency for Factual Knowledge Extraction through Debiasing](2024年04月01日/UniArk_Improving_Generalisation_and_Consistency_for_Factual_Knowledge_Extraction_through_Debiasing.md)

    - [翻译: UniArk 通过去偏技术，增强了事实知识提取的泛化与一致性，提升了整体性能。](2024年04月01日/UniArk_Improving_Generalisation_and_Consistency_for_Factual_Knowledge_Extraction_through_Debiasing.md)

- [A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](2024年04月01日/A_Statistical_Framework_of_Watermarks_for_Large_Language_Models_Pivot,_Detection_Efficiency_and_Optimal_Rules.md)

    - [翻译: 针对大型语言模型，本文提出了一个水印的统计学框架，探讨了水印的枢纽作用、检测效率以及如何制定最优规则。](2024年04月01日/A_Statistical_Framework_of_Watermarks_for_Large_Language_Models_Pivot,_Detection_Efficiency_and_Optimal_Rules.md)

- [Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models](2024年04月01日/Privacy_Backdoors_Enhancing_Membership_Inference_through_Poisoning_Pre-trained_Models.md)

    - [翻译: 通过在预训练模型中植入污染信息，我们能够增强对模型成员身份的推断能力，从而打开隐私保护的后门。](2024年04月01日/Privacy_Backdoors_Enhancing_Membership_Inference_through_Poisoning_Pre-trained_Models.md)

- [Machine Unlearning for Traditional Models and Large Language Models: A Short Survey](2024年04月01日/Machine_Unlearning_for_Traditional_Models_and_Large_Language_Models_A_Short_Survey.md)

    - [翻译: 本综述简要探讨了传统模型与大型语言模型中的机器去学习技术。](2024年04月01日/Machine_Unlearning_for_Traditional_Models_and_Large_Language_Models_A_Short_Survey.md)

- [The Fine Line: Navigating Large Language Model Pretraining with Down-streaming Capability Analysis](2024年04月01日/The_Fine_Line_Navigating_Large_Language_Model_Pretraining_with_Down-streaming_Capability_Analysis.md)

    - [翻译: 《探寻平衡：借助下游能力分析来引导大型语言模型的预训练》](2024年04月01日/The_Fine_Line_Navigating_Large_Language_Model_Pretraining_with_Down-streaming_Capability_Analysis.md)

- [Getting it Right: Improving Spatial Consistency in Text-to-Image Models](2024年04月01日/Getting_it_Right_Improving_Spatial_Consistency_in_Text-to-Image_Models.md)

    - [翻译: 精准把握：提升文本转图像模型的空间连贯性](2024年04月01日/Getting_it_Right_Improving_Spatial_Consistency_in_Text-to-Image_Models.md)

- [Green AI: Exploring Carbon Footprints, Mitigation Strategies, and Trade Offs in Large Language Model Training](2024年04月01日/Green_AI_Exploring_Carbon_Footprints,_Mitigation_Strategies,_and_Trade_Offs_in_Large_Language_Model_Training.md)

    - [翻译: 绿色AI：研究大型语言模型训练过程中的碳排放、减排措施及其平衡之道。](2024年04月01日/Green_AI_Exploring_Carbon_Footprints,_Mitigation_Strategies,_and_Trade_Offs_in_Large_Language_Model_Training.md)

- [SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining](2024年04月01日/SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining.md)

    - [翻译: SyncMask：为时尚导向视觉-语言预训练设计的同步注意力屏蔽技术](2024年04月01日/SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining.md)

- [Do LLMs Find Human Answers To Fact-Driven Questions Perplexing? A Case Study on Reddit](2024年04月01日/Do_LLMs_Find_Human_Answers_To_Fact-Driven_Questions_Perplexing_A_Case_Study_on_Reddit.md)

    - [翻译: 在Reddit上的案例研究：大型语言模型真的搞不懂人类对事实问题的答案吗？](2024年04月01日/Do_LLMs_Find_Human_Answers_To_Fact-Driven_Questions_Perplexing_A_Case_Study_on_Reddit.md)

- [Enhancing Reasoning Capacity of SLM using Cognitive Enhancement](2024年04月01日/Enhancing_Reasoning_Capacity_of_SLM_using_Cognitive_Enhancement.md)

    - [翻译: 通过认知增强技术，我们能够提升小型语言模型（SLM）的推理能力。](2024年04月01日/Enhancing_Reasoning_Capacity_of_SLM_using_Cognitive_Enhancement.md)

- [Structured Information Matters: Incorporating Abstract Meaning Representation into LLMs for Improved Open-Domain Dialogue Evaluation](2024年04月01日/Structured_Information_Matters_Incorporating_Abstract_Meaning_Representation_into_LLMs_for_Improved_Open-Domain_Dialogue_Evaluation.md)

    - [翻译: 结构化信息至关重要：在大型语言模型中整合抽象意义表示，以优化开放领域对话的评估效果。](2024年04月01日/Structured_Information_Matters_Incorporating_Abstract_Meaning_Representation_into_LLMs_for_Improved_Open-Domain_Dialogue_Evaluation.md)

- [What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety](2024年04月01日/What's_in_Your_Safe_Data_Identifying_Benign_Data_that_Breaks_Safety.md)

    - [翻译: 揭秘“安全”数据：发现看似无害却危害安全的数据。](2024年04月01日/What's_in_Your_Safe_Data_Identifying_Benign_Data_that_Breaks_Safety.md)

- [Enabling Memory Safety of C Programs using LLMs](2024年04月01日/Enabling_Memory_Safety_of_C_Programs_using_LLMs.md)

    - [翻译: 通过大型语言模型 (LLM) 保障 C 程序的内存安全。](2024年04月01日/Enabling_Memory_Safety_of_C_Programs_using_LLMs.md)

- [Efficient Prompting Methods for Large Language Models: A Survey](2024年04月01日/Efficient_Prompting_Methods_for_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型的高效提示技巧：全面调查研究](2024年04月01日/Efficient_Prompting_Methods_for_Large_Language_Models_A_Survey.md)

- [Chat Modeling: Natural Language-based Procedural Modeling of Biological Structures without Training](2024年04月01日/Chat_Modeling_Natural_Language-based_Procedural_Modeling_of_Biological_Structures_without_Training.md)

    - [翻译: 聊天建模：利用自然语言进行生物结构的程序化设计，无需经过训练过程。](2024年04月01日/Chat_Modeling_Natural_Language-based_Procedural_Modeling_of_Biological_Structures_without_Training.md)

- [Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment](2024年04月01日/Regularized_Best-of-N_Sampling_to_Mitigate_Reward_Hacking_for_Language_Model_Alignment.md)

    - [翻译: 为确保语言模型对齐，我们采用正则化的最优 N 选一抽样策略，以降低奖励操纵行为的风险。](2024年04月01日/Regularized_Best-of-N_Sampling_to_Mitigate_Reward_Hacking_for_Language_Model_Alignment.md)

- [Can LLMs get help from other LLMs without revealing private information?](2024年04月01日/Can_LLMs_get_help_from_other_LLMs_without_revealing_private_information.md)

    - [翻译: 大型语言模型能否在保护隐私的前提下互相协助？](2024年04月01日/Can_LLMs_get_help_from_other_LLMs_without_revealing_private_information.md)

- [LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models](2024年04月01日/LLM-ABR_Designing_Adaptive_Bitrate_Algorithms_via_Large_Language_Models.md)

    - [翻译: LLM-ABR：借助大型语言模型打造智能自适应码率算法](2024年04月01日/LLM-ABR_Designing_Adaptive_Bitrate_Algorithms_via_Large_Language_Models.md)

- [Transforming LLMs into Cross-modal and Cross-lingual RetrievalSystems](2024年04月01日/Transforming_LLMs_into_Cross-modal_and_Cross-lingual_RetrievalSystems.md)

    - [翻译: 将大型语言模型打造成跨界的检索系统，实现跨模态与跨语言的无缝对接。](2024年04月01日/Transforming_LLMs_into_Cross-modal_and_Cross-lingual_RetrievalSystems.md)

- [Helmsman of the Masses? Evaluate the Opinion Leadership of Large Language Models in the Werewolf Game](2024年04月01日/Helmsman_of_the_Masses_Evaluate_the_Opinion_Leadership_of_Large_Language_Models_in_the_Werewolf_Game.md)

    - [翻译: 引领民意？探究大型语言模型在狼人游戏中的舆论引导作用。](2024年04月01日/Helmsman_of_the_Masses_Evaluate_the_Opinion_Leadership_of_Large_Language_Models_in_the_Werewolf_Game.md)

- [Classifying Cancer Stage with Open-Source Clinical Large Language Models](2024年04月01日/Classifying_Cancer_Stage_with_Open-Source_Clinical_Large_Language_Models.md)

    - [翻译: 本研究探讨了运用开源临床大型语言模型对癌症阶段进行精确分类的方法。](2024年04月01日/Classifying_Cancer_Stage_with_Open-Source_Clinical_Large_Language_Models.md)

- [Hallucination Diversity-Aware Active Learning for Text Summarization](2024年04月01日/Hallucination_Diversity-Aware_Active_Learning_for_Text_Summarization.md)

    - [翻译: 在文本摘要中，我们采用一种幻觉多样性感知的主动学习方法。](2024年04月01日/Hallucination_Diversity-Aware_Active_Learning_for_Text_Summarization.md)

- [Evaluating Large Language Models Using Contrast Sets: An Experimental Approach](2024年04月01日/Evaluating_Large_Language_Models_Using_Contrast_Sets_An_Experimental_Approach.md)

    - [翻译: 通过对比集对大型语言模型进行评估：探索性实验途径](2024年04月01日/Evaluating_Large_Language_Models_Using_Contrast_Sets_An_Experimental_Approach.md)

- [Automated User Story Generation with Test Case Specification Using Large Language Model](2024年04月01日/Automated_User_Story_Generation_with_Test_Case_Specification_Using_Large_Language_Model.md)

    - [翻译: 借助大型语言模型，实现自动化的用户故事创建，并配备测试用例规范。](2024年04月01日/Automated_User_Story_Generation_with_Test_Case_Specification_Using_Large_Language_Model.md)

- [Octopus: On-device language model for function calling of software APIs](2024年04月01日/Octopus_On-device_language_model_for_function_calling_of_software_APIs.md)

    - [翻译: 章鱼：一款适用于软件API功能调用的设备端语言模型](2024年04月01日/Octopus_On-device_language_model_for_function_calling_of_software_APIs.md)

- [Syntactic Robustness for LLM-based Code Generation](2024年04月01日/Syntactic_Robustness_for_LLM-based_Code_Generation.md)

    - [翻译: 在大型语言模型（LLM）支持下，代码生成的句法鲁棒性研究](2024年04月01日/Syntactic_Robustness_for_LLM-based_Code_Generation.md)

- [Set-Aligning Framework for Auto-Regressive Event Temporal Graph Generation](2024年04月01日/Set-Aligning_Framework_for_Auto-Regressive_Event_Temporal_Graph_Generation.md)

    - [翻译: 自回归事件时序图的生成采用集合对齐框架](2024年04月01日/Set-Aligning_Framework_for_Auto-Regressive_Event_Temporal_Graph_Generation.md)

- [A Study on Scaling Up Multilingual News Framing Analysis](2024年04月01日/A_Study_on_Scaling_Up_Multilingual_News_Framing_Analysis.md)

    - [翻译: 本研究探讨了如何扩展多语言新闻框架分析的规模，旨在提高跨语言和文化背景下新闻报道的理解和分析能力。](2024年04月01日/A_Study_on_Scaling_Up_Multilingual_News_Framing_Analysis.md)

- [TraveLER: A Multi-LMM Agent Framework for Video Question-Answering](2024年04月01日/TraveLER_A_Multi-LMM_Agent_Framework_for_Video_Question-Answering.md)

    - [翻译: TraveLER：面向视频问答任务的多语言模型代理框架](2024年04月01日/TraveLER_A_Multi-LMM_Agent_Framework_for_Video_Question-Answering.md)

- [Are large language models superhuman chemists?](2024年04月01日/Are_large_language_models_superhuman_chemists.md)

    - [翻译: 大型语言模型能否媲美超级化学家？](2024年04月01日/Are_large_language_models_superhuman_chemists.md)

- [Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs](2024年04月01日/Will_the_Real_Linda_Please_Stand_up...to_Large_Language_Models_Examining_the_Representativeness_Heuristic_in_LLMs.md)

    - [翻译: 琳达能否勇敢地面对大型语言模型？探究LLMs中的代表性启发式原理。](2024年04月01日/Will_the_Real_Linda_Please_Stand_up...to_Large_Language_Models_Examining_the_Representativeness_Heuristic_in_LLMs.md)

- [Unveiling Divergent Inductive Biases of LLMs on Temporal Data](2024年04月01日/Unveiling_Divergent_Inductive_Biases_of_LLMs_on_Temporal_Data.md)

    - [翻译: 探究大型语言模型处理时间数据时的多样化归纳偏好](2024年04月01日/Unveiling_Divergent_Inductive_Biases_of_LLMs_on_Temporal_Data.md)

- [Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing Positional Bias in LLMs](2024年04月01日/Position-Aware_Parameter_Efficient_Fine-Tuning_Approach_for_Reducing_Positional_Bias_in_LLMs.md)

    - [翻译: 为了降低大型语言模型中的位置偏见，我们采用了一种位置感知的高效微调策略。](2024年04月01日/Position-Aware_Parameter_Efficient_Fine-Tuning_Approach_for_Reducing_Positional_Bias_in_LLMs.md)

- [A Preliminary Roadmap for LLMs as Assistants in Exploring, Analyzing, and Visualizing Knowledge Graphs](2024年04月01日/A_Preliminary_Roadmap_for_LLMs_as_Assistants_in_Exploring,_Analyzing,_and_Visualizing_Knowledge_Graphs.md)

    - [翻译: 探索、分析及可视化知识图谱的大型语言模型助手的初步指南。](2024年04月01日/A_Preliminary_Roadmap_for_LLMs_as_Assistants_in_Exploring,_Analyzing,_and_Visualizing_Knowledge_Graphs.md)

- [OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation](2024年04月01日/OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation.md)

    - [翻译: OVFoodSeg: 利用图像信息增强文本表达，提升食品图像的开放词汇量分割技术](2024年04月01日/OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation.md)

- [Developing Safe and Responsible Large Language Models -- A Comprehensive Framework](2024年04月01日/Developing_Safe_and_Responsible_Large_Language_Models_--_A_Comprehensive_Framework.md)

    - [翻译: 构建安全可靠的大型语言模型：全方位框架探究](2024年04月01日/Developing_Safe_and_Responsible_Large_Language_Models_--_A_Comprehensive_Framework.md)

- [Prompt-prompted Mixture of Experts for Efficient LLM Generation](2024年04月01日/Prompt-prompted_Mixture_of_Experts_for_Efficient_LLM_Generation.md)

    - [翻译: 通过专家混合的提示-提示策略，我们能够有效地生成大型语言模型。](2024年04月01日/Prompt-prompted_Mixture_of_Experts_for_Efficient_LLM_Generation.md)

- [LLM Attributor: Interactive Visual Attribution for LLM Generation](2024年04月01日/LLM_Attributor_Interactive_Visual_Attribution_for_LLM_Generation.md)

    - [翻译: LLM 属性归因器：为大型语言模型生成提供交互式视觉归因功能。](2024年04月01日/LLM_Attributor_Interactive_Visual_Attribution_for_LLM_Generation.md)

- [Leveraging YOLO-World and GPT-4V LMMs for Zero-Shot Person Detection and Action Recognition in Drone Imagery](2024年04月01日/Leveraging_YOLO-World_and_GPT-4V_LMMs_for_Zero-Shot_Person_Detection_and_Action_Recognition_in_Drone_Imagery.md)

    - [翻译: 通过运用 YOLO-World 与 GPT-4V 语言模型，实现无人机图像中的零-shot 人员探测与行为识别。](2024年04月01日/Leveraging_YOLO-World_and_GPT-4V_LMMs_for_Zero-Shot_Person_Detection_and_Action_Recognition_in_Drone_Imagery.md)