# 2024年04月

2024年04月01日

- [Large Language Model Evaluation Via Multi AI Agents: Preliminary results](2024年04月01日/Large_Language_Model_Evaluation_Via_Multi_AI_Agents_Preliminary_results.md)

    - [翻译: 借助众多AI助手，我们对大型语言模型展开了评估，目前取得了一些初步成果。](2024年04月01日/Large_Language_Model_Evaluation_Via_Multi_AI_Agents_Preliminary_results.md)

- [Source-Aware Training Enables Knowledge Attribution in Language Models](2024年04月01日/Source-Aware_Training_Enables_Knowledge_Attribution_in_Language_Models.md)

    - [翻译: 通过源感知训练，我们能够在语言模型中对知识进行追溯和归属。](2024年04月01日/Source-Aware_Training_Enables_Knowledge_Attribution_in_Language_Models.md)

- [Harnessing Large Language Models for Training-free Video Anomaly Detection](2024年04月01日/Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection.md)

    - [翻译: 通过运用大型语言模型，我们可以实现无需额外训练的视频异常检测技术。](2024年04月01日/Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection.md)

- [Query Performance Prediction using Relevance Judgments Generated by Large Language Models](2024年04月01日/Query_Performance_Prediction_using_Relevance_Judgments_Generated_by_Large_Language_Models.md)

    - [翻译: 通过大型语言模型生成的相关性评估来预测查询性能](2024年04月01日/Query_Performance_Prediction_using_Relevance_Judgments_Generated_by_Large_Language_Models.md)

- [Transforming the Synthesis of Carbon Nanotubes with Machine Learning Models and Automation](2024年04月01日/Transforming_the_Synthesis_of_Carbon_Nanotubes_with_Machine_Learning_Models_and_Automation.md)

    - [翻译: 利用机器学习模型和自动化技术革新碳纳米管的制备过程](2024年04月01日/Transforming_the_Synthesis_of_Carbon_Nanotubes_with_Machine_Learning_Models_and_Automation.md)

- [LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation](2024年04月01日/LLM-RadJudge_Achieving_Radiologist-Level_Evaluation_for_X-Ray_Report_Generation.md)

    - [翻译: LLM-RadJudge：在生成X光报告方面达到放射科医生的评估水准](2024年04月01日/LLM-RadJudge_Achieving_Radiologist-Level_Evaluation_for_X-Ray_Report_Generation.md)

- [Exploring the Nexus of Large Language Models and Legal Systems: A Short Survey](2024年04月01日/Exploring_the_Nexus_of_Large_Language_Models_and_Legal_Systems_A_Short_Survey.md)

    - [翻译: 浅谈大型语言模型与法律体系的交汇点](2024年04月01日/Exploring_the_Nexus_of_Large_Language_Models_and_Legal_Systems_A_Short_Survey.md)

- [Prior Constraints-based Reward Model Training for Aligning Large Language Models](2024年04月01日/Prior_Constraints-based_Reward_Model_Training_for_Aligning_Large_Language_Models.md)

    - [翻译: 通过先验约束引导的奖励模型训练，实现大型语言模型的精准对齐。](2024年04月01日/Prior_Constraints-based_Reward_Model_Training_for_Aligning_Large_Language_Models.md)

- [VideoDistill: Language-aware Vision Distillation for Video Question Answering](2024年04月01日/VideoDistill_Language-aware_Vision_Distillation_for_Video_Question_Answering.md)

    - [翻译: VideoDistill：为视频问答而设计的，融合语言理解的视觉蒸馏技术](2024年04月01日/VideoDistill_Language-aware_Vision_Distillation_for_Video_Question_Answering.md)

- [Exploring and Evaluating Hallucinations in LLM-Powered Code Generation](2024年04月01日/Exploring_and_Evaluating_Hallucinations_in_LLM-Powered_Code_Generation.md)

    - [翻译: 探究与评价由大型语言模型（LLM）驱动的代码生成过程中的虚构现象。](2024年04月01日/Exploring_and_Evaluating_Hallucinations_in_LLM-Powered_Code_Generation.md)

- [AISPACE at SemEval-2024 task 8: A Class-balanced Soft-voting System for Detecting Multi-generator Machine-generated Text](2024年04月01日/AISPACE_at_SemEval-2024_task_8_A_Class-balanced_Soft-voting_System_for_Detecting_Multi-generator_Machine-generated_Text.md)

    - [翻译: AISPACE 参与 SemEval-2024 第 8 项任务：构建一个平衡类别的软投票系统，用于识别由多种生成器产生的机器文本。](2024年04月01日/AISPACE_at_SemEval-2024_task_8_A_Class-balanced_Soft-voting_System_for_Detecting_Multi-generator_Machine-generated_Text.md)

- [Evalverse: Unified and Accessible Library for Large Language Model Evaluation](2024年04月01日/Evalverse_Unified_and_Accessible_Library_for_Large_Language_Model_Evaluation.md)

    - [翻译: Evalverse：为大型语言模型评估打造的一体化、易用资源库](2024年04月01日/Evalverse_Unified_and_Accessible_Library_for_Large_Language_Model_Evaluation.md)

- [Evaluating the Factuality of Large Language Models using Large-Scale Knowledge Graphs](2024年04月01日/Evaluating_the_Factuality_of_Large_Language_Models_using_Large-Scale_Knowledge_Graphs.md)

    - [翻译: 通过大规模知识图谱来评估大型语言模型的真实性。](2024年04月01日/Evaluating_the_Factuality_of_Large_Language_Models_using_Large-Scale_Knowledge_Graphs.md)

- [How Can Large Language Models Enable Better Socially Assistive Human-Robot Interaction: A Brief Survey](2024年04月01日/How_Can_Large_Language_Models_Enable_Better_Socially_Assistive_Human-Robot_Interaction_A_Brief_Survey.md)

    - [翻译: 大型语言模型助力人机社交互动：一项简明调查](2024年04月01日/How_Can_Large_Language_Models_Enable_Better_Socially_Assistive_Human-Robot_Interaction_A_Brief_Survey.md)

- [ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback](2024年04月01日/ChatGLM-RLHF_Practices_of_Aligning_Large_Language_Models_with_Human_Feedback.md)

    - [翻译: ChatGLM-RLHF：探索大型语言模型与人类反馈融合的实践之道](2024年04月01日/ChatGLM-RLHF_Practices_of_Aligning_Large_Language_Models_with_Human_Feedback.md)

- [PSYDIAL: Personality-based Synthetic Dialogue Generation using Large Language Models](2024年04月01日/PSYDIAL_Personality-based_Synthetic_Dialogue_Generation_using_Large_Language_Models.md)

    - [翻译: PSYDIAL：利用大型语言模型生成个性化合成对话](2024年04月01日/PSYDIAL_Personality-based_Synthetic_Dialogue_Generation_using_Large_Language_Models.md)

- [A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias](2024年04月01日/A_Survey_on_Multilingual_Large_Language_Models_Corpora,_Alignment,_and_Bias.md)

    - [翻译: 本文综述了多语言大型语言模型的研究现状，探讨了构建多语言模型所需的语料库资源、不同语言间的对齐问题，以及模型中潜在的偏见问题。](2024年04月01日/A_Survey_on_Multilingual_Large_Language_Models_Corpora,_Alignment,_and_Bias.md)

- [LLMs are Good Sign Language Translators](2024年04月01日/LLMs_are_Good_Sign_Language_Translators.md)

    - [翻译: 大型语言模型擅长于手语翻译。](2024年04月01日/LLMs_are_Good_Sign_Language_Translators.md)

- [Token-Efficient Leverage Learning in Large Language Models](2024年04月01日/Token-Efficient_Leverage_Learning_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的高效利用标记学习，旨在优化学习效率。](2024年04月01日/Token-Efficient_Leverage_Learning_in_Large_Language_Models.md)

- [Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning](2024年04月01日/Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_Reasoning.md)

    - [翻译: 学习通过修正：为零-shot生成性视觉语言推理任务打造高效的调优方案。](2024年04月01日/Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_Reasoning.md)

- [ARAGOG: Advanced RAG Output Grading](2024年04月01日/ARAGOG_Advanced_RAG_Output_Grading.md)

    - [翻译: ARAGOG：精进的RAG成果评定](2024年04月01日/ARAGOG_Advanced_RAG_Output_Grading.md)

- [LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models](2024年04月01日/LLM_as_a_Mastermind_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models.md)

    - [翻译: ](2024年04月01日/LLM_as_a_Mastermind_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models.md)

- [Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward](2024年04月01日/Direct_Preference_Optimization_of_Video_Large_Multimodal_Models_from_Language_Model_Reward.md)

    - [翻译: ](2024年04月01日/Direct_Preference_Optimization_of_Video_Large_Multimodal_Models_from_Language_Model_Reward.md)

- [LITE: Modeling Environmental Ecosystems with Multimodal Large Language Models](2024年04月01日/LITE_Modeling_Environmental_Ecosystems_with_Multimodal_Large_Language_Models.md)

    - [翻译: ](2024年04月01日/LITE_Modeling_Environmental_Ecosystems_with_Multimodal_Large_Language_Models.md)

- [Prompt Learning for Oriented Power Transmission Tower Detection in High-Resolution SAR Images](2024年04月01日/Prompt_Learning_for_Oriented_Power_Transmission_Tower_Detection_in_High-Resolution_SAR_Images.md)

    - [翻译: ](2024年04月01日/Prompt_Learning_for_Oriented_Power_Transmission_Tower_Detection_in_High-Resolution_SAR_Images.md)

- [Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models](2024年04月01日/Towards_Safety_and_Helpfulness_Balanced_Responses_via_Controllable_Large_Language_Models.md)

    - [翻译: ](2024年04月01日/Towards_Safety_and_Helpfulness_Balanced_Responses_via_Controllable_Large_Language_Models.md)

- [Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided](2024年04月01日/Large_Language_Models_are_Capable_of_Offering_Cognitive_Reappraisal,_if_Guided.md)

    - [翻译: ](2024年04月01日/Large_Language_Models_are_Capable_of_Offering_Cognitive_Reappraisal,_if_Guided.md)

- [TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model](2024年04月01日/TWIN-GPT_Digital_Twins_for_Clinical_Trials_via_Large_Language_Model.md)

    - [翻译: ](2024年04月01日/TWIN-GPT_Digital_Twins_for_Clinical_Trials_via_Large_Language_Model.md)

- [Mapping the Increasing Use of LLMs in Scientific Papers](2024年04月01日/Mapping_the_Increasing_Use_of_LLMs_in_Scientific_Papers.md)

    - [翻译: ](2024年04月01日/Mapping_the_Increasing_Use_of_LLMs_in_Scientific_Papers.md)

- [FABLES: Evaluating faithfulness and content selection in book-length summarization](2024年04月01日/FABLES_Evaluating_faithfulness_and_content_selection_in_book-length_summarization.md)

    - [翻译: ](2024年04月01日/FABLES_Evaluating_faithfulness_and_content_selection_in_book-length_summarization.md)

- [UniArk: Improving Generalisation and Consistency for Factual Knowledge Extraction through Debiasing](2024年04月01日/UniArk_Improving_Generalisation_and_Consistency_for_Factual_Knowledge_Extraction_through_Debiasing.md)

    - [翻译: ](2024年04月01日/UniArk_Improving_Generalisation_and_Consistency_for_Factual_Knowledge_Extraction_through_Debiasing.md)

- [A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](2024年04月01日/A_Statistical_Framework_of_Watermarks_for_Large_Language_Models_Pivot,_Detection_Efficiency_and_Optimal_Rules.md)

    - [翻译: ](2024年04月01日/A_Statistical_Framework_of_Watermarks_for_Large_Language_Models_Pivot,_Detection_Efficiency_and_Optimal_Rules.md)

- [Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models](2024年04月01日/Privacy_Backdoors_Enhancing_Membership_Inference_through_Poisoning_Pre-trained_Models.md)

    - [翻译: ](2024年04月01日/Privacy_Backdoors_Enhancing_Membership_Inference_through_Poisoning_Pre-trained_Models.md)

- [Machine Unlearning for Traditional Models and Large Language Models: A Short Survey](2024年04月01日/Machine_Unlearning_for_Traditional_Models_and_Large_Language_Models_A_Short_Survey.md)

    - [翻译: ](2024年04月01日/Machine_Unlearning_for_Traditional_Models_and_Large_Language_Models_A_Short_Survey.md)

- [The Fine Line: Navigating Large Language Model Pretraining with Down-streaming Capability Analysis](2024年04月01日/The_Fine_Line_Navigating_Large_Language_Model_Pretraining_with_Down-streaming_Capability_Analysis.md)

    - [翻译: ](2024年04月01日/The_Fine_Line_Navigating_Large_Language_Model_Pretraining_with_Down-streaming_Capability_Analysis.md)

- [Getting it Right: Improving Spatial Consistency in Text-to-Image Models](2024年04月01日/Getting_it_Right_Improving_Spatial_Consistency_in_Text-to-Image_Models.md)

    - [翻译: ](2024年04月01日/Getting_it_Right_Improving_Spatial_Consistency_in_Text-to-Image_Models.md)

- [Green AI: Exploring Carbon Footprints, Mitigation Strategies, and Trade Offs in Large Language Model Training](2024年04月01日/Green_AI_Exploring_Carbon_Footprints,_Mitigation_Strategies,_and_Trade_Offs_in_Large_Language_Model_Training.md)

    - [翻译: ](2024年04月01日/Green_AI_Exploring_Carbon_Footprints,_Mitigation_Strategies,_and_Trade_Offs_in_Large_Language_Model_Training.md)

- [SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining](2024年04月01日/SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining.md)

    - [翻译: ](2024年04月01日/SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining.md)

- [Do LLMs Find Human Answers To Fact-Driven Questions Perplexing? A Case Study on Reddit](2024年04月01日/Do_LLMs_Find_Human_Answers_To_Fact-Driven_Questions_Perplexing_A_Case_Study_on_Reddit.md)

    - [翻译: ](2024年04月01日/Do_LLMs_Find_Human_Answers_To_Fact-Driven_Questions_Perplexing_A_Case_Study_on_Reddit.md)

- [Enhancing Reasoning Capacity of SLM using Cognitive Enhancement](2024年04月01日/Enhancing_Reasoning_Capacity_of_SLM_using_Cognitive_Enhancement.md)

    - [翻译: ](2024年04月01日/Enhancing_Reasoning_Capacity_of_SLM_using_Cognitive_Enhancement.md)

- [Structured Information Matters: Incorporating Abstract Meaning Representation into LLMs for Improved Open-Domain Dialogue Evaluation](2024年04月01日/Structured_Information_Matters_Incorporating_Abstract_Meaning_Representation_into_LLMs_for_Improved_Open-Domain_Dialogue_Evaluation.md)

    - [翻译: ](2024年04月01日/Structured_Information_Matters_Incorporating_Abstract_Meaning_Representation_into_LLMs_for_Improved_Open-Domain_Dialogue_Evaluation.md)

- [What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety](2024年04月01日/What's_in_Your_Safe_Data_Identifying_Benign_Data_that_Breaks_Safety.md)

    - [翻译: ](2024年04月01日/What's_in_Your_Safe_Data_Identifying_Benign_Data_that_Breaks_Safety.md)

- [Enabling Memory Safety of C Programs using LLMs](2024年04月01日/Enabling_Memory_Safety_of_C_Programs_using_LLMs.md)

    - [翻译: ](2024年04月01日/Enabling_Memory_Safety_of_C_Programs_using_LLMs.md)

- [Efficient Prompting Methods for Large Language Models: A Survey](2024年04月01日/Efficient_Prompting_Methods_for_Large_Language_Models_A_Survey.md)

    - [翻译: ](2024年04月01日/Efficient_Prompting_Methods_for_Large_Language_Models_A_Survey.md)

- [Chat Modeling: Natural Language-based Procedural Modeling of Biological Structures without Training](2024年04月01日/Chat_Modeling_Natural_Language-based_Procedural_Modeling_of_Biological_Structures_without_Training.md)

    - [翻译: ](2024年04月01日/Chat_Modeling_Natural_Language-based_Procedural_Modeling_of_Biological_Structures_without_Training.md)

- [Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment](2024年04月01日/Regularized_Best-of-N_Sampling_to_Mitigate_Reward_Hacking_for_Language_Model_Alignment.md)

    - [翻译: ](2024年04月01日/Regularized_Best-of-N_Sampling_to_Mitigate_Reward_Hacking_for_Language_Model_Alignment.md)

- [Can LLMs get help from other LLMs without revealing private information?](2024年04月01日/Can_LLMs_get_help_from_other_LLMs_without_revealing_private_information.md)

    - [翻译: ](2024年04月01日/Can_LLMs_get_help_from_other_LLMs_without_revealing_private_information.md)