# 2024年04月

2024年04月23日

- [Multimodal Large Language Model is a Human-Aligned Annotator for Text-to-Image Generation](2024年04月23日/Multimodal_Large_Language_Model_is_a_Human-Aligned_Annotator_for_Text-to-Image_Generation.md)

    - [翻译: 多模态大型语言模型，作为文本到图像生成任务的人类对齐注释器，展现出卓越的性能。](2024年04月23日/Multimodal_Large_Language_Model_is_a_Human-Aligned_Annotator_for_Text-to-Image_Generation.md)

- [XFT: Unlocking the Power of Code Instruction Tuning by Simply Merging Upcycled Mixture-of-Experts](2024年04月23日/XFT_Unlocking_the_Power_of_Code_Instruction_Tuning_by_Simply_Merging_Upcycled_Mixture-of-Experts.md)

    - [翻译: XFT：轻松融合再利用的专家混合模型，释放代码指令优化的强大能量。](2024年04月23日/XFT_Unlocking_the_Power_of_Code_Instruction_Tuning_by_Simply_Merging_Upcycled_Mixture-of-Experts.md)

- [Revisiting Unnaturalness for Automated Program Repair in the Era of Large Language Models](2024年04月23日/Revisiting_Unnaturalness_for_Automated_Program_Repair_in_the_Era_of_Large_Language_Models.md)

    - [翻译: 在大型语言模型盛行的当下，我们有必要重新探讨自动化程序修复领域中的“不自然性”问题。](2024年04月23日/Revisiting_Unnaturalness_for_Automated_Program_Repair_in_the_Era_of_Large_Language_Models.md)

- [Re-Thinking Inverse Graphics With Large Language Models](2024年04月23日/Re-Thinking_Inverse_Graphics_With_Large_Language_Models.md)

    - [翻译: 在大型语言模型的辅助下，逆向图形学领域正经历着一场思维革新。尽管如此，LLMs 在图像生成任务上的表现和效率，依旧是一个备受争议的话题。](2024年04月23日/Re-Thinking_Inverse_Graphics_With_Large_Language_Models.md)

- [Setting up the Data Printer with Improved English to Ukrainian Machine Translation](2024年04月23日/Setting_up_the_Data_Printer_with_Improved_English_to_Ukrainian_Machine_Translation.md)

    - [翻译: 配置数据打印设备，以提升英语至乌克兰语的机器翻译质量。](2024年04月23日/Setting_up_the_Data_Printer_with_Improved_English_to_Ukrainian_Machine_Translation.md)

- [Regressive Side Effects of Training Language Models to Mimic Student Misconceptions](2024年04月23日/Regressive_Side_Effects_of_Training_Language_Models_to_Mimic_Student_Misconceptions.md)

    - [翻译: 训练语言模型以模仿学生的错误认知可能导致回归的副作用。](2024年04月23日/Regressive_Side_Effects_of_Training_Language_Models_to_Mimic_Student_Misconceptions.md)

- [Bias patterns in the application of LLMs for clinical decision support: A comprehensive study](2024年04月23日/Bias_patterns_in_the_application_of_LLMs_for_clinical_decision_support_A_comprehensive_study.md)

    - [翻译: 探究大型语言模型在临床决策支持应用中的偏见模式：一项深入的综合研究。](2024年04月23日/Bias_patterns_in_the_application_of_LLMs_for_clinical_decision_support_A_comprehensive_study.md)

- [Rethinking LLM Memorization through the Lens of Adversarial Compression](2024年04月23日/Rethinking_LLM_Memorization_through_the_Lens_of_Adversarial_Compression.md)

    - [翻译: 透过对抗性压缩的透镜，我们重新审视大型语言模型的记忆力。](2024年04月23日/Rethinking_LLM_Memorization_through_the_Lens_of_Adversarial_Compression.md)

- [MedDr: Diagnosis-Guided Bootstrapping for Large-Scale Medical Vision-Language Learning](2024年04月23日/MedDr_Diagnosis-Guided_Bootstrapping_for_Large-Scale_Medical_Vision-Language_Learning.md)

    - [翻译: MedDr：一种诊断导向的自举策略，专为大规模医学视觉与语言学习而设计。](2024年04月23日/MedDr_Diagnosis-Guided_Bootstrapping_for_Large-Scale_Medical_Vision-Language_Learning.md)

- [A Short Review for Ontology Learning from Text: Stride from Shallow Learning, Deep Learning to Large Language Models Trend](2024年04月23日/A_Short_Review_for_Ontology_Learning_from_Text_Stride_from_Shallow_Learning,_Deep_Learning_to_Large_Language_Models_Trend.md)

    - [翻译: 文本本体学习简评：浅学、深学至大型语言模型的演进趋势](2024年04月23日/A_Short_Review_for_Ontology_Learning_from_Text_Stride_from_Shallow_Learning,_Deep_Learning_to_Large_Language_Models_Trend.md)

- [Social Media and Artificial Intelligence for Sustainable Cities and Societies: A Water Quality Analysis Use-case](2024年04月23日/Social_Media_and_Artificial_Intelligence_for_Sustainable_Cities_and_Societies_A_Water_Quality_Analysis_Use-case.md)

    - [翻译: 社交媒体与人工智能在推动可持续城市与社会发展中的应用：以水质分析为例](2024年04月23日/Social_Media_and_Artificial_Intelligence_for_Sustainable_Cities_and_Societies_A_Water_Quality_Analysis_Use-case.md)

- [Vision Beyond Boundaries: An Initial Design Space of Domain-specific Large Vision Models in Human-robot Interaction](2024年04月23日/Vision_Beyond_Boundaries_An_Initial_Design_Space_of_Domain-specific_Large_Vision_Models_in_Human-robot_Interaction.md)

    - [翻译: 视野无界：人机互动领域定制大型视觉模型的初步设计探索。](2024年04月23日/Vision_Beyond_Boundaries_An_Initial_Design_Space_of_Domain-specific_Large_Vision_Models_in_Human-robot_Interaction.md)

- [Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs Perfect Reasoners](2024年04月23日/Achieving_97%_on_GSM8K_Deeply_Understanding_the_Problems_Makes_LLMs_Perfect_Reasoners.md)

    - [翻译: 在 GSM8K 测试中突破 97% 的高标：深入剖析问题，让大型语言模型化身为卓越的推理专家。](2024年04月23日/Achieving_97%_on_GSM8K_Deeply_Understanding_the_Problems_Makes_LLMs_Perfect_Reasoners.md)

- [StoryTTS: A Highly Expressive Text-to-Speech Dataset with Rich Textual Expressiveness Annotations](2024年04月23日/StoryTTS_A_Highly_Expressive_Text-to-Speech_Dataset_with_Rich_Textual_Expressiveness_Annotations.md)

    - [翻译: StoryTTS：一款极具表现力的文本到语音数据集，配备了详尽的文本表达性标注。](2024年04月23日/StoryTTS_A_Highly_Expressive_Text-to-Speech_Dataset_with_Rich_Textual_Expressiveness_Annotations.md)

- [Graph Machine Learning in the Era of Large Language Models (LLMs)](2024年04月23日/Graph_Machine_Learning_in_the_Era_of_Large_Language_Models_(LLMs).md)

    - [翻译: 在大型语言模型（LLMs）盛行的时代，图机器学习正发挥着重要作用。](2024年04月23日/Graph_Machine_Learning_in_the_Era_of_Large_Language_Models_(LLMs).md)

- [Pillars of Grammatical Error Correction: Comprehensive Inspection Of Contemporary Approaches In The Era of Large Language Models](2024年04月23日/Pillars_of_Grammatical_Error_Correction_Comprehensive_Inspection_Of_Contemporary_Approaches_In_The_Era_of_Large_Language_Models.md)

    - [翻译: 语法错误修正的基石：深入审视大型语言模型时代下的现代方法。](2024年04月23日/Pillars_of_Grammatical_Error_Correction_Comprehensive_Inspection_Of_Contemporary_Approaches_In_The_Era_of_Large_Language_Models.md)

- [Beyond Code Generation: An Observational Study of ChatGPT Usage in Software Engineering Practice](2024年04月23日/Beyond_Code_Generation_An_Observational_Study_of_ChatGPT_Usage_in_Software_Engineering_Practice.md)

    - [翻译: 探索代码生成之外：ChatGPT 在软件工程实践中的应用观察研究](2024年04月23日/Beyond_Code_Generation_An_Observational_Study_of_ChatGPT_Usage_in_Software_Engineering_Practice.md)

- [Beyond the Speculative Game: A Survey of Speculative Execution in Large Language Models](2024年04月23日/Beyond_the_Speculative_Game_A_Survey_of_Speculative_Execution_in_Large_Language_Models.md)

    - [翻译: 超越猜测游戏：深入探究大型语言模型中的推测性执行机制](2024年04月23日/Beyond_the_Speculative_Game_A_Survey_of_Speculative_Execution_in_Large_Language_Models.md)

- [Language in Vivo vs. in Silico: Size Matters but Larger Language Models Still Do Not Comprehend Language on a Par with Humans](2024年04月23日/Language_in_Vivo_vs._in_Silico_Size_Matters_but_Larger_Language_Models_Still_Do_Not_Comprehend_Language_on_a_Par_with_Humans.md)

    - [翻译: 活体语言与模拟语言：规模至关重要，然而即便是更庞大的语言模型，其对语言的理解也未能与人类相提并论。](2024年04月23日/Language_in_Vivo_vs._in_Silico_Size_Matters_but_Larger_Language_Models_Still_Do_Not_Comprehend_Language_on_a_Par_with_Humans.md)

- [Automated Commit Message Generation with Large Language Models: An Empirical Study and Beyond](2024年04月23日/Automated_Commit_Message_Generation_with_Large_Language_Models_An_Empirical_Study_and_Beyond.md)

    - [翻译: 大型语言模型在自动生成提交信息方面的应用：一项实证研究及其更深远的探讨](2024年04月23日/Automated_Commit_Message_Generation_with_Large_Language_Models_An_Empirical_Study_and_Beyond.md)

- [Pattern-Aware Chain-of-Thought Prompting in Large Language Models](2024年04月23日/Pattern-Aware_Chain-of-Thought_Prompting_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，引入了一种模式感知的思考链路提示方法。](2024年04月23日/Pattern-Aware_Chain-of-Thought_Prompting_in_Large_Language_Models.md)

- [A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications](2024年04月23日/A_Survey_of_Large_Language_Models_on_Generative_Graph_Analytics_Query,_Learning,_and_Applications.md)

    - [翻译: 大型语言模型在生成图分析领域的研究综述：探讨查询、学习和应用。](2024年04月23日/A_Survey_of_Large_Language_Models_on_Generative_Graph_Analytics_Query,_Learning,_and_Applications.md)

- [DesignProbe: A Graphic Design Benchmark for Multimodal Large Language Models](2024年04月23日/DesignProbe_A_Graphic_Design_Benchmark_for_Multimodal_Large_Language_Models.md)

    - [翻译: DesignProbe：为多模态大型语言模型量身打造的图形设计基准测试工具](2024年04月23日/DesignProbe_A_Graphic_Design_Benchmark_for_Multimodal_Large_Language_Models.md)

- [Talk Too Much: Poisoning Large Language Models under Token Limit](2024年04月23日/Talk_Too_Much_Poisoning_Large_Language_Models_under_Token_Limit.md)

    - [翻译: 言多必失：在令牌限制条件下对大型语言模型进行数据污染](2024年04月23日/Talk_Too_Much_Poisoning_Large_Language_Models_under_Token_Limit.md)

- [LLM-Enhanced Causal Discovery in Temporal Domain from Interventional Data](2024年04月23日/LLM-Enhanced_Causal_Discovery_in_Temporal_Domain_from_Interventional_Data.md)

    - [翻译: 通过干预数据，大型语言模型（LLM）在时间领域的因果发现能力得到了增强。](2024年04月23日/LLM-Enhanced_Causal_Discovery_in_Temporal_Domain_from_Interventional_Data.md)

- [Med42 -- Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches](2024年04月23日/Med42_--_Evaluating_Fine-Tuning_Strategies_for_Medical_LLMs_Full-Parameter_vs._Parameter-Efficient_Approaches.md)

    - [翻译: Med42 -- 探讨医学领域大型语言模型的微调技巧：全面参数调整与高效参数利用策略的对决](2024年04月23日/Med42_--_Evaluating_Fine-Tuning_Strategies_for_Medical_LLMs_Full-Parameter_vs._Parameter-Efficient_Approaches.md)

- [CT-Agent: Clinical Trial Multi-Agent with Large Language Model-based Reasoning](2024年04月23日/CT-Agent_Clinical_Trial_Multi-Agent_with_Large_Language_Model-based_Reasoning.md)

    - [翻译: CT-Agent：融合大型语言模型推理能力的临床试验多智能体系统](2024年04月23日/CT-Agent_Clinical_Trial_Multi-Agent_with_Large_Language_Model-based_Reasoning.md)

- [Contrastive Quantization based Semantic Code for Generative Recommendation](2024年04月23日/Contrastive_Quantization_based_Semantic_Code_for_Generative_Recommendation.md)

    - [翻译: 对比量化语义编码技术在生成推荐系统中的应用](2024年04月23日/Contrastive_Quantization_based_Semantic_Code_for_Generative_Recommendation.md)

- [Simulating Task-Oriented Dialogues with State Transition Graphs and Large Language Models](2024年04月23日/Simulating_Task-Oriented_Dialogues_with_State_Transition_Graphs_and_Large_Language_Models.md)

    - [翻译: 通过状态转移图和先进的大型语言模型，我们能够模拟出面向特定任务的对话场景。](2024年04月23日/Simulating_Task-Oriented_Dialogues_with_State_Transition_Graphs_and_Large_Language_Models.md)

- [Retrieval Augmented Generation for Domain-specific Question Answering](2024年04月23日/Retrieval_Augmented_Generation_for_Domain-specific_Question_Answering.md)

    - [翻译: 为特定领域的问题回答，采用检索增强的生成技术。](2024年04月23日/Retrieval_Augmented_Generation_for_Domain-specific_Question_Answering.md)

- [TAAT: Think and Act from Arbitrary Texts in Text2Motion](2024年04月23日/TAAT_Think_and_Act_from_Arbitrary_Texts_in_Text2Motion.md)

    - [翻译: TAAT：在 Text2Motion 技术中，任意文本触发思考与行动](2024年04月23日/TAAT_Think_and_Act_from_Arbitrary_Texts_in_Text2Motion.md)

- [Generate-on-Graph: Treat LLM as both Agent and KG in Incomplete Knowledge Graph Question Answering](2024年04月23日/Generate-on-Graph_Treat_LLM_as_both_Agent_and_KG_in_Incomplete_Knowledge_Graph_Question_Answering.md)

    - [翻译: 在不完整的知识图谱问答任务中，我们将大型语言模型（LLM）视作既是行动者也是知识库。](2024年04月23日/Generate-on-Graph_Treat_LLM_as_both_Agent_and_KG_in_Incomplete_Knowledge_Graph_Question_Answering.md)

- [From Matching to Generation: A Survey on Generative Information Retrieval](2024年04月23日/From_Matching_to_Generation_A_Survey_on_Generative_Information_Retrieval.md)

    - [翻译: 探索信息检索的创新路径：从匹配到生成的生成式信息检索综述](2024年04月23日/From_Matching_to_Generation_A_Survey_on_Generative_Information_Retrieval.md)

- [Aligning LLM Agents by Learning Latent Preference from User Edits](2024年04月23日/Aligning_LLM_Agents_by_Learning_Latent_Preference_from_User_Edits.md)

    - [翻译: 通过分析用户编辑，我们能够学习到用户的潜在偏好，进而调整大型语言模型（LLM）代理的行为，使之更好地符合用户的需求。](2024年04月23日/Aligning_LLM_Agents_by_Learning_Latent_Preference_from_User_Edits.md)

- [Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models](2024年04月23日/Towards_Systematic_Evaluation_of_Logical_Reasoning_Ability_of_Large_Language_Models.md)

    - [翻译: 迈向对大型语言模型逻辑推理能力进行系统评估的探索](2024年04月23日/Towards_Systematic_Evaluation_of_Logical_Reasoning_Ability_of_Large_Language_Models.md)

- [Visual Delta Generator with Large Multi-modal Models for Semi-supervised Composed Image Retrieval](2024年04月23日/Visual_Delta_Generator_with_Large_Multi-modal_Models_for_Semi-supervised_Composed_Image_Retrieval.md)

    - [翻译: 视觉增量生成器结合大型多模态模型，为半监督的组合图像检索任务提供支持。](2024年04月23日/Visual_Delta_Generator_with_Large_Multi-modal_Models_for_Semi-supervised_Composed_Image_Retrieval.md)

- [ToM-LM: Delegating Theory Of Mind Reasoning to External Symbolic Executors in Large Language Models](2024年04月23日/ToM-LM_Delegating_Theory_Of_Mind_Reasoning_to_External_Symbolic_Executors_in_Large_Language_Models.md)

    - [翻译: ToM-LM：将心理理论推理外包给大型语言模型中的外部符号执行器](2024年04月23日/ToM-LM_Delegating_Theory_Of_Mind_Reasoning_to_External_Symbolic_Executors_in_Large_Language_Models.md)

- [IryoNLP at MEDIQA-CORR 2024: Tackling the Medical Error Detection & Correction Task On the Shoulders of Medical Agents](2024年04月23日/IryoNLP_at_MEDIQA-CORR_2024_Tackling_the_Medical_Error_Detection_&_Correction_Task_On_the_Shoulders_of_Medical_Agents.md)

    - [翻译: 在 2024 年 MEDIQA-CORR 竞赛中，IryoNLP 项目借助医疗代理的力量，致力于攻克医疗错误检测与纠正的挑战。](2024年04月23日/IryoNLP_at_MEDIQA-CORR_2024_Tackling_the_Medical_Error_Detection_&_Correction_Task_On_the_Shoulders_of_Medical_Agents.md)

- [Large Language Models Spot Phishing Emails with Surprising Accuracy: A Comparative Analysis of Performance](2024年04月23日/Large_Language_Models_Spot_Phishing_Emails_with_Surprising_Accuracy_A_Comparative_Analysis_of_Performance.md)

    - [翻译: 大型语言模型（LLM）展现出令人惊叹的精准度，能够识别钓鱼邮件。本文通过比较分析，深入探讨了这些模型在性能上的差异。](2024年04月23日/Large_Language_Models_Spot_Phishing_Emails_with_Surprising_Accuracy_A_Comparative_Analysis_of_Performance.md)

- [Can Large Language Models Learn the Physics of Metamaterials? An Empirical Study with ChatGPT](2024年04月23日/Can_Large_Language_Models_Learn_the_Physics_of_Metamaterials_An_Empirical_Study_with_ChatGPT.md)

    - [翻译: ](2024年04月23日/Can_Large_Language_Models_Learn_the_Physics_of_Metamaterials_An_Empirical_Study_with_ChatGPT.md)

- [FL-TAC: Enhanced Fine-Tuning in Federated Learning via Low-Rank, Task-Specific Adapter Clustering](2024年04月23日/FL-TAC_Enhanced_Fine-Tuning_in_Federated_Learning_via_Low-Rank,_Task-Specific_Adapter_Clustering.md)

    - [翻译: ](2024年04月23日/FL-TAC_Enhanced_Fine-Tuning_in_Federated_Learning_via_Low-Rank,_Task-Specific_Adapter_Clustering.md)

- [Feature Distribution Shift Mitigation with Contrastive Pretraining for Intrusion Detection](2024年04月23日/Feature_Distribution_Shift_Mitigation_with_Contrastive_Pretraining_for_Intrusion_Detection.md)

    - [翻译: ](2024年04月23日/Feature_Distribution_Shift_Mitigation_with_Contrastive_Pretraining_for_Intrusion_Detection.md)

- [Wiki-LLaVA: Hierarchical Retrieval-Augmented Generation for Multimodal LLMs](2024年04月23日/Wiki-LLaVA_Hierarchical_Retrieval-Augmented_Generation_for_Multimodal_LLMs.md)

    - [翻译: ](2024年04月23日/Wiki-LLaVA_Hierarchical_Retrieval-Augmented_Generation_for_Multimodal_LLMs.md)

2024年04月22日

- [Surveying Attitudinal Alignment Between Large Language Models Vs. Humans Towards 17 Sustainable Development Goals](2024年04月22日/Surveying_Attitudinal_Alignment_Between_Large_Language_Models_Vs._Humans_Towards_17_Sustainable_Development_Goals.md)

    - [翻译: 本研究旨在探究大型语言模型与人类对于17项可持续发展目标的态度是否一致。](2024年04月22日/Surveying_Attitudinal_Alignment_Between_Large_Language_Models_Vs._Humans_Towards_17_Sustainable_Development_Goals.md)

- [VALOR-EVAL: Holistic Coverage and Faithfulness Evaluation of Large Vision-Language Models](2024年04月22日/VALOR-EVAL_Holistic_Coverage_and_Faithfulness_Evaluation_of_Large_Vision-Language_Models.md)

    - [翻译: VALOR-EVAL：全面而忠实地评估大型视觉-语言模型的性能](2024年04月22日/VALOR-EVAL_Holistic_Coverage_and_Faithfulness_Evaluation_of_Large_Vision-Language_Models.md)

- [Context-Enhanced Language Models for Generating Multi-Paper Citations](2024年04月22日/Context-Enhanced_Language_Models_for_Generating_Multi-Paper_Citations.md)

    - [翻译: 本文介绍了一种上下文增强的语言模型，旨在生成多篇论文的引用。](2024年04月22日/Context-Enhanced_Language_Models_for_Generating_Multi-Paper_Citations.md)

- [LLMs Know What They Need: Leveraging a Missing Information Guided Framework to Empower Retrieval-Augmented Generation](2024年04月22日/LLMs_Know_What_They_Need_Leveraging_a_Missing_Information_Guided_Framework_to_Empower_Retrieval-Augmented_Generation.md)

    - [翻译: 大型语言模型（LLMs）自有所需：借助缺失信息导向框架，提升检索增强生成能力。](2024年04月22日/LLMs_Know_What_They_Need_Leveraging_a_Missing_Information_Guided_Framework_to_Empower_Retrieval-Augmented_Generation.md)

- [Typos that Broke the RAG's Back: Genetic Attack on RAG Pipeline by Simulating Documents in the Wild via Low-level Perturbations](2024年04月22日/Typos_that_Broke_the_RAG's_Back_Genetic_Attack_on_RAG_Pipeline_by_Simulating_Documents_in_the_Wild_via_Low-level_Perturbations.md)

    - [翻译: 错别字引发的RAG崩溃：通过细微的文字扰动，在现实文档中对RAG流程发起基因级攻击](2024年04月22日/Typos_that_Broke_the_RAG's_Back_Genetic_Attack_on_RAG_Pipeline_by_Simulating_Documents_in_the_Wild_via_Low-level_Perturbations.md)

- [Retrieval-Augmented Audio Deepfake Detection](2024年04月22日/Retrieval-Augmented_Audio_Deepfake_Detection.md)

    - [翻译: 增强检索音频深度伪造检测](2024年04月22日/Retrieval-Augmented_Audio_Deepfake_Detection.md)

- [A Survey on Self-Evolution of Large Language Models](2024年04月22日/A_Survey_on_Self-Evolution_of_Large_Language_Models.md)

    - [翻译: 一篇探讨大型语言模型自我进化的研究综述](2024年04月22日/A_Survey_on_Self-Evolution_of_Large_Language_Models.md)

- [Graphic Design with Large Multimodal Model](2024年04月22日/Graphic_Design_with_Large_Multimodal_Model.md)

    - [翻译: 运用大型多模态模型进行图形设计](2024年04月22日/Graphic_Design_with_Large_Multimodal_Model.md)

- [UrbanCross: Enhancing Satellite Image-Text Retrieval with Cross-Domain Adaptation](2024年04月22日/UrbanCross_Enhancing_Satellite_Image-Text_Retrieval_with_Cross-Domain_Adaptation.md)

    - [翻译: UrbanCross：利用跨领域适配技术提升卫星图像与文本的检索能力](2024年04月22日/UrbanCross_Enhancing_Satellite_Image-Text_Retrieval_with_Cross-Domain_Adaptation.md)

- [Zero-Shot Character Identification and Speaker Prediction in Comics via Iterative Multimodal Fusion](2024年04月22日/Zero-Shot_Character_Identification_and_Speaker_Prediction_in_Comics_via_Iterative_Multimodal_Fusion.md)

    - [翻译: 漫画中零样本字符识别与说话者预测：一种迭代多模态融合方法。](2024年04月22日/Zero-Shot_Character_Identification_and_Speaker_Prediction_in_Comics_via_Iterative_Multimodal_Fusion.md)

- [Boter: Bootstrapping Knowledge Selection and Question Answering for Knowledge-based VQA](2024年04月22日/Boter_Bootstrapping_Knowledge_Selection_and_Question_Answering_for_Knowledge-based_VQA.md)

    - [翻译: Boter：一种自举技术，旨在提升基于知识的 VQA（视觉问答）领域中的知识选择和自动问答能力。](2024年04月22日/Boter_Bootstrapping_Knowledge_Selection_and_Question_Answering_for_Knowledge-based_VQA.md)

- [AutoAD III: The Prequel -- Back to the Pixels](2024年04月22日/AutoAD_III_The_Prequel_--_Back_to_the_Pixels.md)

    - [翻译: AutoAD III：前传 —— 重返像素世界](2024年04月22日/AutoAD_III_The_Prequel_--_Back_to_the_Pixels.md)

- [SpaceByte: Towards Deleting Tokenization from Large Language Modeling](2024年04月22日/SpaceByte_Towards_Deleting_Tokenization_from_Large_Language_Modeling.md)

    - [翻译: SpaceByte：探索在大型语言模型中去除标记化的过程](2024年04月22日/SpaceByte_Towards_Deleting_Tokenization_from_Large_Language_Modeling.md)

- [RTP-LX: Can LLMs Evaluate Toxicity in Multilingual Scenarios?](2024年04月22日/RTP-LX_Can_LLMs_Evaluate_Toxicity_in_Multilingual_Scenarios.md)

    - [翻译: RTP-LX：探讨大型语言模型在多语言环境中毒性评估的能力。](2024年04月22日/RTP-LX_Can_LLMs_Evaluate_Toxicity_in_Multilingual_Scenarios.md)

- [PARAMANU-GANITA: Language Model with Mathematical Capabilities](2024年04月22日/PARAMANU-GANITA_Language_Model_with_Mathematical_Capabilities.md)

    - [翻译: PARAMANU-GANITA：一款具备数学处理能力的先进语言模型](2024年04月22日/PARAMANU-GANITA_Language_Model_with_Mathematical_Capabilities.md)

- [Beyond Scaling: Predicting Patent Approval with Domain-specific Fine-grained Claim Dependency Graph](2024年04月22日/Beyond_Scaling_Predicting_Patent_Approval_with_Domain-specific_Fine-grained_Claim_Dependency_Graph.md)

    - [翻译: 超越规模限制：利用特定领域的精细索赔依赖图来预测专利审批结果](2024年04月22日/Beyond_Scaling_Predicting_Patent_Approval_with_Domain-specific_Fine-grained_Claim_Dependency_Graph.md)

- [Preference Fine-Tuning of LLMs Should Leverage Suboptimal, On-Policy Data](2024年04月22日/Preference_Fine-Tuning_of_LLMs_Should_Leverage_Suboptimal,_On-Policy_Data.md)

    - [翻译: 在对大型语言模型进行偏好微调时，应充分考虑并利用那些并非最优但符合当前策略的数据。](2024年04月22日/Preference_Fine-Tuning_of_LLMs_Should_Leverage_Suboptimal,_On-Policy_Data.md)

- [Better Synthetic Data by Retrieving and Transforming Existing Datasets](2024年04月22日/Better_Synthetic_Data_by_Retrieving_and_Transforming_Existing_Datasets.md)

    - [翻译: 通过检索并转换现有数据集，我们能够生成更优质的合成数据。](2024年04月22日/Better_Synthetic_Data_by_Retrieving_and_Transforming_Existing_Datasets.md)

- [Rethinking Legal Compliance Automation: Opportunities with Large Language Models](2024年04月22日/Rethinking_Legal_Compliance_Automation_Opportunities_with_Large_Language_Models.md)

    - [翻译: 探索法律合规自动化的新路径：大型语言模型带来的机遇](2024年04月22日/Rethinking_Legal_Compliance_Automation_Opportunities_with_Large_Language_Models.md)

- [Calc-CMU at SemEval-2024 Task 7: Pre-Calc -- Learning to Use the Calculator Improves Numeracy in Language Models](2024年04月22日/Calc-CMU_at_SemEval-2024_Task_7_Pre-Calc_--_Learning_to_Use_the_Calculator_Improves_Numeracy_in_Language_Models.md)

    - [翻译: 在 SemEval-2024 的任务 7 中，Calc-CMU 展示了其卓越性能：通过学习使用计算器，语言模型的数学素养得到了显著提升。](2024年04月22日/Calc-CMU_at_SemEval-2024_Task_7_Pre-Calc_--_Learning_to_Use_the_Calculator_Improves_Numeracy_in_Language_Models.md)

- [Automated Long Answer Grading with RiceChem Dataset](2024年04月22日/Automated_Long_Answer_Grading_with_RiceChem_Dataset.md)

    - [翻译: 利用 RiceChem 数据集实现长答案的自动评分系统。](2024年04月22日/Automated_Long_Answer_Grading_with_RiceChem_Dataset.md)

- [Explaining Arguments' Strength: Unveiling the Role of Attacks and Supports (Technical Report)](2024年04月22日/Explaining_Arguments'_Strength_Unveiling_the_Role_of_Attacks_and_Supports_(Technical_Report).md)

    - [翻译: 揭示论点强度：解析攻击与支持的角色（技术报告）](2024年04月22日/Explaining_Arguments'_Strength_Unveiling_the_Role_of_Attacks_and_Supports_(Technical_Report).md)

- [Does Your Neural Code Completion Model Use My Code? A Membership Inference Approach](2024年04月22日/Does_Your_Neural_Code_Completion_Model_Use_My_Code_A_Membership_Inference_Approach.md)

    - [翻译: 你的神经代码补全模型是否侵犯了我的代码？采用成员推断技术进行探究](2024年04月22日/Does_Your_Neural_Code_Completion_Model_Use_My_Code_A_Membership_Inference_Approach.md)

- [A Survey on Efficient Inference for Large Language Models](2024年04月22日/A_Survey_on_Efficient_Inference_for_Large_Language_Models.md)

    - [翻译: 本文综述了大型语言模型在高效推理方面的研究进展。](2024年04月22日/A_Survey_on_Efficient_Inference_for_Large_Language_Models.md)

- [LLM-Personalize: Aligning LLM Planners with Human Preferences via Reinforced Self-Training for Housekeeping Robots](2024年04月22日/LLM-Personalize_Aligning_LLM_Planners_with_Human_Preferences_via_Reinforced_Self-Training_for_Housekeeping_Robots.md)

    - [翻译: LLM-Personalize：通过增强式自我训练，使大型语言模型（LLM）的规划器与人类的偏好保持一致，专为家务机器人设计。](2024年04月22日/LLM-Personalize_Aligning_LLM_Planners_with_Human_Preferences_via_Reinforced_Self-Training_for_Housekeeping_Robots.md)

- [Detecting and Mitigating Hallucination in Large Vision Language Models via Fine-Grained AI Feedback](2024年04月22日/Detecting_and_Mitigating_Hallucination_in_Large_Vision_Language_Models_via_Fine-Grained_AI_Feedback.md)

    - [翻译: 通过精细的人工智能反馈机制，我们能够在大型视觉语言模型中识别并减轻幻觉现象，从而提升模型的准确性和可靠性。](2024年04月22日/Detecting_and_Mitigating_Hallucination_in_Large_Vision_Language_Models_via_Fine-Grained_AI_Feedback.md)

- [Resistance Against Manipulative AI: key factors and possible actions](2024年04月22日/Resistance_Against_Manipulative_AI_key_factors_and_possible_actions.md)

    - [翻译: 抵御操纵性AI：关键要素与可行策略](2024年04月22日/Resistance_Against_Manipulative_AI_key_factors_and_possible_actions.md)

- [An Artificial Neuron for Enhanced Problem Solving in Large Language Models](2024年04月22日/An_Artificial_Neuron_for_Enhanced_Problem_Solving_in_Large_Language_Models.md)

    - [翻译: 为大型语言模型设计的一种人工神经元，旨在增强其问题解决能力。](2024年04月22日/An_Artificial_Neuron_for_Enhanced_Problem_Solving_in_Large_Language_Models.md)

- [Text-Tuple-Table: Towards Information Integration in Text-to-Table Generation via Global Tuple Extraction](2024年04月22日/Text-Tuple-Table_Towards_Information_Integration_in_Text-to-Table_Generation_via_Global_Tuple_Extraction.md)

    - [翻译: Text-Tuple-Table：探索全局元组抽取在文本到表格生成中的信息整合之道](2024年04月22日/Text-Tuple-Table_Towards_Information_Integration_in_Text-to-Table_Generation_via_Global_Tuple_Extraction.md)

- [EnzChemRED, a rich enzyme chemistry relation extraction dataset](2024年04月22日/EnzChemRED,_a_rich_enzyme_chemistry_relation_extraction_dataset.md)

    - [翻译: EnzChemRED，一个涵盖丰富酶化学关系的提取数据集。](2024年04月22日/EnzChemRED,_a_rich_enzyme_chemistry_relation_extraction_dataset.md)

- [TrimCaching: Parameter-sharing Edge Caching for AI Model Downloading](2024年04月22日/TrimCaching_Parameter-sharing_Edge_Caching_for_AI_Model_Downloading.md)

    - [翻译: TrimCaching：一种用于人工智能模型下载的参数共享边缘缓存技术](2024年04月22日/TrimCaching_Parameter-sharing_Edge_Caching_for_AI_Model_Downloading.md)

- [Fine-Tuning Large Language Models to Translate: Will a Touch of Noisy Data in Misaligned Languages Suffice?](2024年04月22日/Fine-Tuning_Large_Language_Models_to_Translate_Will_a_Touch_of_Noisy_Data_in_Misaligned_Languages_Suffice.md)

    - [翻译: 微调大型语言模型以实现翻译：仅需在不匹配的语言中掺入少量噪声数据，是否就已足够？](2024年04月22日/Fine-Tuning_Large_Language_Models_to_Translate_Will_a_Touch_of_Noisy_Data_in_Misaligned_Languages_Suffice.md)

- [No General Code of Ethics for All: Ethical Considerations in Human-bot Psycho-counseling](2024年04月22日/No_General_Code_of_Ethics_for_All_Ethical_Considerations_in_Human-bot_Psycho-counseling.md)

    - [翻译: 并非存在一套放之四海而皆准的道德准则：在人工智能心理辅导领域，我们需深思熟虑的伦理问题。](2024年04月22日/No_General_Code_of_Ethics_for_All_Ethical_Considerations_in_Human-bot_Psycho-counseling.md)

- [How Good Are Low-bit Quantized LLaMA3 Models? An Empirical Study](2024年04月22日/How_Good_Are_Low-bit_Quantized_LLaMA3_Models_An_Empirical_Study.md)

    - [翻译: 低比特量化的 LLaMA3 模型性能如何？实证探究](2024年04月22日/How_Good_Are_Low-bit_Quantized_LLaMA3_Models_An_Empirical_Study.md)

- [CoFInAl: Enhancing Action Quality Assessment with Coarse-to-Fine Instruction Alignment](2024年04月22日/CoFInAl_Enhancing_Action_Quality_Assessment_with_Coarse-to-Fine_Instruction_Alignment.md)

    - [翻译: CoFInAl：利用由粗到细的指导对齐提升动作质量评估的精准度](2024年04月22日/CoFInAl_Enhancing_Action_Quality_Assessment_with_Coarse-to-Fine_Instruction_Alignment.md)

- [Information Re-Organization Improves Reasoning in Large Language Models](2024年04月22日/Information_Re-Organization_Improves_Reasoning_in_Large_Language_Models.md)

    - [翻译: 通过信息的重新组织，我们能够显著提升大型语言模型的推理性能。](2024年04月22日/Information_Re-Organization_Improves_Reasoning_in_Large_Language_Models.md)

- [Protecting Your LLMs with Information Bottleneck](2024年04月22日/Protecting_Your_LLMs_with_Information_Bottleneck.md)

    - [翻译: 通过信息瓶颈策略，为您的大型语言模型筑起防线。](2024年04月22日/Protecting_Your_LLMs_with_Information_Bottleneck.md)

- [How Well Can LLMs Echo Us? Evaluating AI Chatbots' Role-Play Ability with ECHO](2024年04月22日/How_Well_Can_LLMs_Echo_Us_Evaluating_AI_Chatbots'_Role-Play_Ability_with_ECHO.md)

    - [翻译: 大型语言模型（LLM）能如何精准地反映我们的语言？本文通过ECHO评估了AI聊天机器人在角色扮演方面的能力。](2024年04月22日/How_Well_Can_LLMs_Echo_Us_Evaluating_AI_Chatbots'_Role-Play_Ability_with_ECHO.md)

- [Benchmarking Multi-Modal LLMs for Testing Visual Deep Learning Systems Through the Lens of Image Mutation](2024年04月22日/Benchmarking_Multi-Modal_LLMs_for_Testing_Visual_Deep_Learning_Systems_Through_the_Lens_of_Image_Mutation.md)

    - [翻译: 本文旨在通过图像变异的视角，对多模态大型语言模型（LLMs）进行基准测试，以评估视觉深度学习系统的性能。](2024年04月22日/Benchmarking_Multi-Modal_LLMs_for_Testing_Visual_Deep_Learning_Systems_Through_the_Lens_of_Image_Mutation.md)

- [A User-Centric Benchmark for Evaluating Large Language Models](2024年04月22日/A_User-Centric_Benchmark_for_Evaluating_Large_Language_Models.md)

    - [翻译: 用户导向的大型语言模型评估基准](2024年04月22日/A_User-Centric_Benchmark_for_Evaluating_Large_Language_Models.md)

- [MARIO Eval: Evaluate Your Math LLM with your Math LLM--A mathematical dataset evaluation toolkit](2024年04月22日/MARIO_Eval_Evaluate_Your_Math_LLM_with_your_Math_LLM--A_mathematical_dataset_evaluation_toolkit.md)

    - [翻译: MARIO 评估：使用您的数学大型语言模型进行自我评估——一套数学数据集评估工具集。](2024年04月22日/MARIO_Eval_Evaluate_Your_Math_LLM_with_your_Math_LLM--A_mathematical_dataset_evaluation_toolkit.md)

- [Navigating the Path of Writing: Outline-guided Text Generation with Large Language Models](2024年04月22日/Navigating_the_Path_of_Writing_Outline-guided_Text_Generation_with_Large_Language_Models.md)

    - [翻译: 探索写作之道：借助大型语言模型实现基于大纲的文本创作。](2024年04月22日/Navigating_the_Path_of_Writing_Outline-guided_Text_Generation_with_Large_Language_Models.md)

- [Generating Attractive and Authentic Copywriting from Customer Reviews](2024年04月22日/Generating_Attractive_and_Authentic_Copywriting_from_Customer_Reviews.md)

    - [翻译: 提炼客户评论，创作引人入胜且真实的文案](2024年04月22日/Generating_Attractive_and_Authentic_Copywriting_from_Customer_Reviews.md)

- [Pixels and Predictions: Potential of GPT-4V in Meteorological Imagery Analysis and Forecast Communication](2024年04月22日/Pixels_and_Predictions_Potential_of_GPT-4V_in_Meteorological_Imagery_Analysis_and_Forecast_Communication.md)

    - [翻译: 像素与预测：探索 GPT-4V 在气象图像分析及预报传达中的潜在能力](2024年04月22日/Pixels_and_Predictions_Potential_of_GPT-4V_in_Meteorological_Imagery_Analysis_and_Forecast_Communication.md)

- [Expert Router: Orchestrating Efficient Language Model Inference through Prompt Classification](2024年04月22日/Expert_Router_Orchestrating_Efficient_Language_Model_Inference_through_Prompt_Classification.md)

    - [翻译: 专家路由器：通过精准的提示分类，优化语言模型的推理效率。](2024年04月22日/Expert_Router_Orchestrating_Efficient_Language_Model_Inference_through_Prompt_Classification.md)

- [Insights into Alignment: Evaluating DPO and its Variants Across Multiple Tasks](2024年04月22日/Insights_into_Alignment_Evaluating_DPO_and_its_Variants_Across_Multiple_Tasks.md)

    - [翻译: 深入对齐之洞察：跨多任务评估 DPO 及其衍生模型的表现](2024年04月22日/Insights_into_Alignment_Evaluating_DPO_and_its_Variants_Across_Multiple_Tasks.md)

- [Bayesian Example Selection Improves In-Context Learning for Speech, Text, and Visual Modalities](2024年04月22日/Bayesian_Example_Selection_Improves_In-Context_Learning_for_Speech,_Text,_and_Visual_Modalities.md)

    - [翻译: 采用贝叶斯方法精选示例，显著提升了语音、文本和视觉模式的情境学习效果。](2024年04月22日/Bayesian_Example_Selection_Improves_In-Context_Learning_for_Speech,_Text,_and_Visual_Modalities.md)

- [FINEMATCH: Aspect-based Fine-grained Image and Text Mismatch Detection and Correction](2024年04月22日/FINEMATCH_Aspect-based_Fine-grained_Image_and_Text_Mismatch_Detection_and_Correction.md)

    - [翻译: FINEMATCH：面向细粒度的图像与文本不匹配问题的检测与校正技术，专注于基于方面的精准识别与修正。](2024年04月22日/FINEMATCH_Aspect-based_Fine-grained_Image_and_Text_Mismatch_Detection_and_Correction.md)

- [Think-Program-reCtify: 3D Situated Reasoning with Large Language Models](2024年04月22日/Think-Program-reCtify_3D_Situated_Reasoning_with_Large_Language_Models.md)

    - [翻译: 思考、编程、纠正：运用大型语言模型实现三维情境推理](2024年04月22日/Think-Program-reCtify_3D_Situated_Reasoning_with_Large_Language_Models.md)

- [FlashSpeech: Efficient Zero-Shot Speech Synthesis](2024年04月22日/FlashSpeech_Efficient_Zero-Shot_Speech_Synthesis.md)

    - [翻译: FlashSpeech：零次拍摄下的高效语音合成](2024年04月22日/FlashSpeech_Efficient_Zero-Shot_Speech_Synthesis.md)

- [Uncovering Name-Based Biases in Large Language Models Through Simulated Trust Game](2024年04月22日/Uncovering_Name-Based_Biases_in_Large_Language_Models_Through_Simulated_Trust_Game.md)

    - [翻译: 我们通过模拟信任游戏的方式，揭露了大型语言模型中潜藏的基于姓名的偏见。](2024年04月22日/Uncovering_Name-Based_Biases_in_Large_Language_Models_Through_Simulated_Trust_Game.md)

- [Automated Multi-Language to English Machine Translation Using Generative Pre-Trained Transformers](2024年04月22日/Automated_Multi-Language_to_English_Machine_Translation_Using_Generative_Pre-Trained_Transformers.md)

    - [翻译: 利用生成式预训练变换器实现的自动化多语言至英语机器翻译。](2024年04月22日/Automated_Multi-Language_to_English_Machine_Translation_Using_Generative_Pre-Trained_Transformers.md)

- [3DBench: A Scalable 3D Benchmark and Instruction-Tuning Dataset](2024年04月22日/3DBench_A_Scalable_3D_Benchmark_and_Instruction-Tuning_Dataset.md)

    - [翻译: 3DBench：一个可扩展的三维基准测试及指令微调数据集](2024年04月22日/3DBench_A_Scalable_3D_Benchmark_and_Instruction-Tuning_Dataset.md)

- [DreamPBR: Text-driven Generation of High-resolution SVBRDF with Multi-modal Guidance](2024年04月22日/DreamPBR_Text-driven_Generation_of_High-resolution_SVBRDF_with_Multi-modal_Guidance.md)

    - [翻译: DreamPBR：一种文本驱动的高分辨率SVBRDF生成技术，辅以多模态引导功能。](2024年04月22日/DreamPBR_Text-driven_Generation_of_High-resolution_SVBRDF_with_Multi-modal_Guidance.md)

- [NExT: Teaching Large Language Models to Reason about Code Execution](2024年04月22日/NExT_Teaching_Large_Language_Models_to_Reason_about_Code_Execution.md)

    - [翻译: NExT：引导大型语言模型理解代码执行的逻辑](2024年04月22日/NExT_Teaching_Large_Language_Models_to_Reason_about_Code_Execution.md)

- [Exploring and Unleashing the Power of Large Language Models in Automated Code Translation](2024年04月22日/Exploring_and_Unleashing_the_Power_of_Large_Language_Models_in_Automated_Code_Translation.md)

    - [翻译: 深入挖掘并充分发挥大型语言模型在自动化代码翻译领域的潜力。](2024年04月22日/Exploring_and_Unleashing_the_Power_of_Large_Language_Models_in_Automated_Code_Translation.md)

- [Learning Word Embedding with Better Distance Weighting and Window Size Scheduling](2024年04月22日/Learning_Word_Embedding_with_Better_Distance_Weighting_and_Window_Size_Scheduling.md)

    - [翻译: 采用优化的距离权重和窗口大小调整策略，提升词嵌入学习效果。](2024年04月22日/Learning_Word_Embedding_with_Better_Distance_Weighting_and_Window_Size_Scheduling.md)

- [Tree of Reviews: A Tree-based Dynamic Iterative Retrieval Framework for Multi-hop Question Answering](2024年04月22日/Tree_of_Reviews_A_Tree-based_Dynamic_Iterative_Retrieval_Framework_for_Multi-hop_Question_Answering.md)

    - [翻译: 《树状评论：构建基于树的动态迭代检索框架，以应对多跳问答挑战》](2024年04月22日/Tree_of_Reviews_A_Tree-based_Dynamic_Iterative_Retrieval_Framework_for_Multi-hop_Question_Answering.md)

- ["Where am I?" Scene Retrieval with Language](2024年04月22日/Where_am_I_Scene_Retrieval_with_Language.md)

    - [翻译: 我身在何方？用语言探索场景检索](2024年04月22日/Where_am_I_Scene_Retrieval_with_Language.md)

- [Describe-then-Reason: Improving Multimodal Mathematical Reasoning through Visual Comprehension Training](2024年04月22日/Describe-then-Reason_Improving_Multimodal_Mathematical_Reasoning_through_Visual_Comprehension_Training.md)

    - [翻译: 通过视觉理解训练提升多模态数学推理：先描述，再推理](2024年04月22日/Describe-then-Reason_Improving_Multimodal_Mathematical_Reasoning_through_Visual_Comprehension_Training.md)

- [WangLab at MEDIQA-M3G 2024: Multimodal Medical Answer Generation using Large Language Models](2024年04月22日/WangLab_at_MEDIQA-M3G_2024_Multimodal_Medical_Answer_Generation_using_Large_Language_Models.md)

    - [翻译: 2024年，WangLab 在 MEDIQA-M3G 竞赛中展示了他们的成果：利用大型语言模型，实现了多模态医学答案的生成。](2024年04月22日/WangLab_at_MEDIQA-M3G_2024_Multimodal_Medical_Answer_Generation_using_Large_Language_Models.md)

2024年04月21日

- [Understanding the role of FFNs in driving multilingual behaviour in LLMs](2024年04月21日/Understanding_the_role_of_FFNs_in_driving_multilingual_behaviour_in_LLMs.md)

    - [翻译: 深入探究FFN在促进大型语言模型（LLM）多语言能力发展中的角色](2024年04月21日/Understanding_the_role_of_FFNs_in_driving_multilingual_behaviour_in_LLMs.md)

- [EventLens: Leveraging Event-Aware Pretraining and Cross-modal Linking Enhances Visual Commonsense Reasoning](2024年04月21日/EventLens_Leveraging_Event-Aware_Pretraining_and_Cross-modal_Linking_Enhances_Visual_Commonsense_Reasoning.md)

    - [翻译: EventLens：通过事件驱动的预训练和多模态关联，提升了视觉常识推理的能力。](2024年04月21日/EventLens_Leveraging_Event-Aware_Pretraining_and_Cross-modal_Linking_Enhances_Visual_Commonsense_Reasoning.md)

- [From LLM to NMT: Advancing Low-Resource Machine Translation with Claude](2024年04月21日/From_LLM_to_NMT_Advancing_Low-Resource_Machine_Translation_with_Claude.md)

    - [翻译: 探索从大型语言模型（LLM）向神经机器翻译（NMT）的演进之路，利用 Claude 技术提升低资源语言的机器翻译能力。](2024年04月21日/From_LLM_to_NMT_Advancing_Low-Resource_Machine_Translation_with_Claude.md)

- [Evaluating Retrieval Quality in Retrieval-Augmented Generation](2024年04月21日/Evaluating_Retrieval_Quality_in_Retrieval-Augmented_Generation.md)

    - [翻译: 在检索增强生成领域，对检索质量的评估至关重要。](2024年04月21日/Evaluating_Retrieval_Quality_in_Retrieval-Augmented_Generation.md)

- [SciDaSynth: Interactive Structured Knowledge Extraction and Synthesis from Scientific Literature with Large Language Model](2024年04月21日/SciDaSynth_Interactive_Structured_Knowledge_Extraction_and_Synthesis_from_Scientific_Literature_with_Large_Language_Model.md)

    - [翻译: SciDaSynth：一款利用大型语言模型实现科学文献中结构化知识的互动式提取与合成的工具。](2024年04月21日/SciDaSynth_Interactive_Structured_Knowledge_Extraction_and_Synthesis_from_Scientific_Literature_with_Large_Language_Model.md)

- [Towards General Conceptual Model Editing via Adversarial Representation Engineering](2024年04月21日/Towards_General_Conceptual_Model_Editing_via_Adversarial_Representation_Engineering.md)

    - [翻译: 探索通过对抗性表示工程实现通用概念模型编辑的新路径。](2024年04月21日/Towards_General_Conceptual_Model_Editing_via_Adversarial_Representation_Engineering.md)

- [SVGEditBench: A Benchmark Dataset for Quantitative Assessment of LLM's SVG Editing Capabilities](2024年04月21日/SVGEditBench_A_Benchmark_Dataset_for_Quantitative_Assessment_of_LLM's_SVG_Editing_Capabilities.md)

    - [翻译: SVGEditBench：一个专为衡量大型语言模型在SVG编辑领域量化能力的基准数据集。](2024年04月21日/SVGEditBench_A_Benchmark_Dataset_for_Quantitative_Assessment_of_LLM's_SVG_Editing_Capabilities.md)

- [FiLo: Zero-Shot Anomaly Detection by Fine-Grained Description and High-Quality Localization](2024年04月21日/FiLo_Zero-Shot_Anomaly_Detection_by_Fine-Grained_Description_and_High-Quality_Localization.md)

    - [翻译: FiLo：一种零样本异常检测方法，它利用精细描述和精准定位来识别异常。](2024年04月21日/FiLo_Zero-Shot_Anomaly_Detection_by_Fine-Grained_Description_and_High-Quality_Localization.md)

- [Trojan Detection in Large Language Models: Insights from The Trojan Detection Challenge](2024年04月21日/Trojan_Detection_in_Large_Language_Models_Insights_from_The_Trojan_Detection_Challenge.md)

    - [翻译: 探索大型语言模型中的特洛伊木马识别：特洛伊木马检测挑战赛的深刻见解。](2024年04月21日/Trojan_Detection_in_Large_Language_Models_Insights_from_The_Trojan_Detection_Challenge.md)

- [Mixture of LoRA Experts](2024年04月21日/Mixture_of_LoRA_Experts.md)

    - [翻译: LoRA 专家的融合](2024年04月21日/Mixture_of_LoRA_Experts.md)

- [NegotiationToM: A Benchmark for Stress-testing Machine Theory of Mind on Negotiation Surrounding](2024年04月21日/NegotiationToM_A_Benchmark_for_Stress-testing_Machine_Theory_of_Mind_on_Negotiation_Surrounding.md)

    - [翻译: NegotiationToM：一个专门用于检验机器在谈判场景中理论思维能力的测试基准](2024年04月21日/NegotiationToM_A_Benchmark_for_Stress-testing_Machine_Theory_of_Mind_on_Negotiation_Surrounding.md)

- [The Branch Not Taken: Predicting Branching in Online Conversations](2024年04月21日/The_Branch_Not_Taken_Predicting_Branching_in_Online_Conversations.md)

    - [翻译: 未踏之路：在线对话分支预测](2024年04月21日/The_Branch_Not_Taken_Predicting_Branching_in_Online_Conversations.md)

- ["A good pun is its own reword": Can Large Language Models Understand Puns?](2024年04月21日/A_good_pun_is_its_own_reword_Can_Large_Language_Models_Understand_Puns.md)

    - [翻译: 妙语如珠，自成一格：大型语言模型能否领会双关之妙？](2024年04月21日/A_good_pun_is_its_own_reword_Can_Large_Language_Models_Understand_Puns.md)

- [Lost in Space: Probing Fine-grained Spatial Understanding in Vision and Language Resamplers](2024年04月21日/Lost_in_Space_Probing_Fine-grained_Spatial_Understanding_in_Vision_and_Language_Resamplers.md)

    - [翻译: 探索视觉与语言重采样器中的精细空间认知](2024年04月21日/Lost_in_Space_Probing_Fine-grained_Spatial_Understanding_in_Vision_and_Language_Resamplers.md)

- [MARVEL: Multidimensional Abstraction and Reasoning through Visual Evaluation and Learning](2024年04月21日/MARVEL_Multidimensional_Abstraction_and_Reasoning_through_Visual_Evaluation_and_Learning.md)

    - [翻译: MARVEL：视觉评估与学习驱动的多维抽象与推理。](2024年04月21日/MARVEL_Multidimensional_Abstraction_and_Reasoning_through_Visual_Evaluation_and_Learning.md)

- [Test-Time Training on Graphs with Large Language Models (LLMs)](2024年04月21日/Test-Time_Training_on_Graphs_with_Large_Language_Models_(LLMs).md)

    - [翻译: 在图结构数据上，利用大型语言模型（LLMs）进行测试阶段的训练。](2024年04月21日/Test-Time_Training_on_Graphs_with_Large_Language_Models_(LLMs).md)

- [LASER: Tuning-Free LLM-Driven Attention Control for Efficient Text-conditioned Image-to-Animation](2024年04月21日/LASER_Tuning-Free_LLM-Driven_Attention_Control_for_Efficient_Text-conditioned_Image-to-Animation.md)

    - [翻译: LASER技术：一种无需调整的大型语言模型驱动的注意力控制系统，旨在实现文本驱动的图像到动画的高效转换。](2024年04月21日/LASER_Tuning-Free_LLM-Driven_Attention_Control_for_Efficient_Text-conditioned_Image-to-Animation.md)

- [ChatRetriever: Adapting Large Language Models for Generalized and Robust Conversational Dense Retrieval](2024年04月21日/ChatRetriever_Adapting_Large_Language_Models_for_Generalized_and_Robust_Conversational_Dense_Retrieval.md)

    - [翻译: ChatRetriever：为对话式密集检索而优化的大型语言模型，旨在实现更广泛和更稳健的对话检索能力。](2024年04月21日/ChatRetriever_Adapting_Large_Language_Models_for_Generalized_and_Robust_Conversational_Dense_Retrieval.md)

- [General Item Representation Learning for Cold-start Content Recommendations](2024年04月21日/General_Item_Representation_Learning_for_Cold-start_Content_Recommendations.md)

    - [翻译: 为冷启动内容推荐而设计的通用物品表示学习](2024年04月21日/General_Item_Representation_Learning_for_Cold-start_Content_Recommendations.md)

- [MixLoRA: Enhancing Large Language Models Fine-Tuning with LoRA based Mixture of Experts](2024年04月21日/MixLoRA_Enhancing_Large_Language_Models_Fine-Tuning_with_LoRA_based_Mixture_of_Experts.md)

    - [翻译: MixLoRA：借助 LoRA 技术，通过专家混合策略提升大型语言模型的微调效果。](2024年04月21日/MixLoRA_Enhancing_Large_Language_Models_Fine-Tuning_with_LoRA_based_Mixture_of_Experts.md)

- [FASTTRACK: Fast and Accurate Fact Tracing for LLMs](2024年04月21日/FASTTRACK_Fast_and_Accurate_Fact_Tracing_for_LLMs.md)

    - [翻译: FASTTRACK：一种为大型语言模型（LLMs）量身定制的高效精准事实追踪技术。](2024年04月21日/FASTTRACK_Fast_and_Accurate_Fact_Tracing_for_LLMs.md)

- [Interpreting COVID Lateral Flow Tests' Results with Foundation Models](2024年04月21日/Interpreting_COVID_Lateral_Flow_Tests'_Results_with_Foundation_Models.md)

    - [翻译: 借助基础模型，我们能够更准确地解读 COVID 侧向流动测试的结果。](2024年04月21日/Interpreting_COVID_Lateral_Flow_Tests'_Results_with_Foundation_Models.md)

2024年04月20日

- [A Survey on the Memory Mechanism of Large Language Model based Agents](2024年04月20日/A_Survey_on_the_Memory_Mechanism_of_Large_Language_Model_based_Agents.md)

    - [翻译: 本文综述了基于大型语言模型的智能代理中的记忆机制。](2024年04月20日/A_Survey_on_the_Memory_Mechanism_of_Large_Language_Model_based_Agents.md)

- [Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study](2024年04月20日/Evaluating_the_Effectiveness_of_LLMs_in_Introductory_Computer_Science_Education_A_Semester-Long_Field_Study.md)

    - [翻译: 探究大型语言模型在入门计算机科学教学中的应用效果：一项历时一学期的实地考察。](2024年04月20日/Evaluating_the_Effectiveness_of_LLMs_in_Introductory_Computer_Science_Education_A_Semester-Long_Field_Study.md)

- ["I Wish There Were an AI": Challenges and AI Potential in Cancer Patient-Provider Communication](2024年04月20日/I_Wish_There_Were_an_AI_Challenges_and_AI_Potential_in_Cancer_Patient-Provider_Communication.md)

    - [翻译: 癌症患者与医疗提供者之间的沟通充满了挑战，但人工智能的介入潜力巨大。我们渴望有AI的助力，以改善这一沟通过程。](2024年04月20日/I_Wish_There_Were_an_AI_Challenges_and_AI_Potential_in_Cancer_Patient-Provider_Communication.md)

- [Intrusion Detection at Scale with the Assistance of a Command-line Language Model](2024年04月20日/Intrusion_Detection_at_Scale_with_the_Assistance_of_a_Command-line_Language_Model.md)

    - [翻译: 借助命令行语言模型的力量，实现大规模入侵检测。](2024年04月20日/Intrusion_Detection_at_Scale_with_the_Assistance_of_a_Command-line_Language_Model.md)

- [Retrieval-Augmented Generation-based Relation Extraction](2024年04月20日/Retrieval-Augmented_Generation-based_Relation_Extraction.md)

    - [翻译: 检索增强型生成式关系提取](2024年04月20日/Retrieval-Augmented_Generation-based_Relation_Extraction.md)

- [Movie101v2: Improved Movie Narration Benchmark](2024年04月20日/Movie101v2_Improved_Movie_Narration_Benchmark.md)

    - [翻译: Movie101v2：提升版的电影叙事基准](2024年04月20日/Movie101v2_Improved_Movie_Narration_Benchmark.md)

- [Generating Daylight-driven Architectural Design via Diffusion Models](2024年04月20日/Generating_Daylight-driven_Architectural_Design_via_Diffusion_Models.md)

    - [翻译: 利用扩散模型打造以日光为驱动力的建筑设计。](2024年04月20日/Generating_Daylight-driven_Architectural_Design_via_Diffusion_Models.md)

- [UnibucLLM: Harnessing LLMs for Automated Prediction of Item Difficulty and Response Time for Multiple-Choice Questions](2024年04月20日/UnibucLLM_Harnessing_LLMs_for_Automated_Prediction_of_Item_Difficulty_and_Response_Time_for_Multiple-Choice_Questions.md)

    - [翻译: UnibucLLM：运用大型语言模型（LLM）智能预测多选题的难度与答题时长。](2024年04月20日/UnibucLLM_Harnessing_LLMs_for_Automated_Prediction_of_Item_Difficulty_and_Response_Time_for_Multiple-Choice_Questions.md)

- [Large Language Models as Test Case Generators: Performance Evaluation and Enhancement](2024年04月20日/Large_Language_Models_as_Test_Case_Generators_Performance_Evaluation_and_Enhancement.md)

    - [翻译: 将大型语言模型用作测试用例生成器：对性能进行评估并探索提升之道。](2024年04月20日/Large_Language_Models_as_Test_Case_Generators_Performance_Evaluation_and_Enhancement.md)

- [FakeBench: Uncover the Achilles' Heels of Fake Images with Large Multimodal Models](2024年04月20日/FakeBench_Uncover_the_Achilles'_Heels_of_Fake_Images_with_Large_Multimodal_Models.md)

    - [翻译: FakeBench：借助大型多模态模型，揭开假图像的阿喀琉斯之踵。](2024年04月20日/FakeBench_Uncover_the_Achilles'_Heels_of_Fake_Images_with_Large_Multimodal_Models.md)

- [PCQA: A Strong Baseline for AIGC Quality Assessment Based on Prompt Condition](2024年04月20日/PCQA_A_Strong_Baseline_for_AIGC_Quality_Assessment_Based_on_Prompt_Condition.md)

    - [翻译: PCQA：一种基于提示条件的AIGC（人工智能生成内容）质量评估的强有力基准模型](2024年04月20日/PCQA_A_Strong_Baseline_for_AIGC_Quality_Assessment_Based_on_Prompt_Condition.md)

- [Augmented Object Intelligence: Making the Analog World Interactable with XR-Objects](2024年04月20日/Augmented_Object_Intelligence_Making_the_Analog_World_Interactable_with_XR-Objects.md)

    - [翻译: 增强型对象智能：借助 XR-Objects，让现实世界可与扩展现实技术互动](2024年04月20日/Augmented_Object_Intelligence_Making_the_Analog_World_Interactable_with_XR-Objects.md)

- [Multi-Cell Decoder and Mutual Learning for Table Structure and Character Recognition](2024年04月20日/Multi-Cell_Decoder_and_Mutual_Learning_for_Table_Structure_and_Character_Recognition.md)

    - [翻译: 采用多单元解码器结合互学习技术，提升表格结构和字符识别的准确性。](2024年04月20日/Multi-Cell_Decoder_and_Mutual_Learning_for_Table_Structure_and_Character_Recognition.md)

- [Demystify Adult Learning: A Social Network and Large Language Model Assisted Approach](2024年04月20日/Demystify_Adult_Learning_A_Social_Network_and_Large_Language_Model_Assisted_Approach.md)

    - [翻译: 揭秘成人学习：结合社交网络与大型语言模型的辅助策略](2024年04月20日/Demystify_Adult_Learning_A_Social_Network_and_Large_Language_Model_Assisted_Approach.md)

2024年04月19日

- [Eyes Can Deceive: Benchmarking Counterfactual Reasoning Abilities of Multi-modal Large Language Models](2024年04月19日/Eyes_Can_Deceive_Benchmarking_Counterfactual_Reasoning_Abilities_of_Multi-modal_Large_Language_Models.md)

    - [翻译: 眼见未必为实：多模态大型语言模型反事实推理能力的评估基准](2024年04月19日/Eyes_Can_Deceive_Benchmarking_Counterfactual_Reasoning_Abilities_of_Multi-modal_Large_Language_Models.md)

- [How Does the Textual Information Affect the Retrieval of Multimodal In-Context Learning?](2024年04月19日/How_Does_the_Textual_Information_Affect_the_Retrieval_of_Multimodal_In-Context_Learning.md)

    - [翻译: 文本信息对多模态上下文内学习的信息检索有何影响？](2024年04月19日/How_Does_the_Textual_Information_Affect_the_Retrieval_of_Multimodal_In-Context_Learning.md)

- [Rethinking the Evaluation of Dialogue Systems: Effects of User Feedback on Crowdworkers and LLMs](2024年04月19日/Rethinking_the_Evaluation_of_Dialogue_Systems_Effects_of_User_Feedback_on_Crowdworkers_and_LLMs.md)

    - [翻译: 对话系统评估新视角：用户反馈如何影响众包工作者与大型语言模型。](2024年04月19日/Rethinking_the_Evaluation_of_Dialogue_Systems_Effects_of_User_Feedback_on_Crowdworkers_and_LLMs.md)

- [FineRec:Exploring Fine-grained Sequential Recommendation](2024年04月19日/FineRecExploring_Fine-grained_Sequential_Recommendation.md)

    - [翻译: FineRec：深入挖掘细粒度的序列化推荐技术](2024年04月19日/FineRecExploring_Fine-grained_Sequential_Recommendation.md)

- [Towards Reliable Latent Knowledge Estimation in LLMs: In-Context Learning vs. Prompting Based Factual Knowledge Extraction](2024年04月19日/Towards_Reliable_Latent_Knowledge_Estimation_in_LLMs_In-Context_Learning_vs._Prompting_Based_Factual_Knowledge_Extraction.md)

    - [翻译: 探索大型语言模型中可靠的潜在知识评估：比较了情境学习与基于提示的事实知识抽取方法。](2024年04月19日/Towards_Reliable_Latent_Knowledge_Estimation_in_LLMs_In-Context_Learning_vs._Prompting_Based_Factual_Knowledge_Extraction.md)

- [Physical Backdoor Attack can Jeopardize Driving with Vision-Large-Language Models](2024年04月19日/Physical_Backdoor_Attack_can_Jeopardize_Driving_with_Vision-Large-Language_Models.md)

    - [翻译: 物理后门攻击可能对采用视觉技术的大规模语言模型的驾驶安全构成威胁。](2024年04月19日/Physical_Backdoor_Attack_can_Jeopardize_Driving_with_Vision-Large-Language_Models.md)

- [Large Language Models for Networking: Workflow, Advances and Challenges](2024年04月19日/Large_Language_Models_for_Networking_Workflow,_Advances_and_Challenges.md)

    - [翻译: 探索网络领域中的大规模语言模型：工作流程、最新进展与面临的挑战。](2024年04月19日/Large_Language_Models_for_Networking_Workflow,_Advances_and_Challenges.md)

- [Enabling Natural Zero-Shot Prompting on Encoder Models via Statement-Tuning](2024年04月19日/Enabling_Natural_Zero-Shot_Prompting_on_Encoder_Models_via_Statement-Tuning.md)

    - [翻译: 通过声明调优技术，实现了在编码器模型上的自然零样本提示功能。](2024年04月19日/Enabling_Natural_Zero-Shot_Prompting_on_Encoder_Models_via_Statement-Tuning.md)

- [Unlocking Multi-View Insights in Knowledge-Dense Retrieval-Augmented Generation](2024年04月19日/Unlocking_Multi-View_Insights_in_Knowledge-Dense_Retrieval-Augmented_Generation.md)

    - [翻译: 探索知识密集型检索增强生成中的多视角洞察。](2024年04月19日/Unlocking_Multi-View_Insights_in_Knowledge-Dense_Retrieval-Augmented_Generation.md)

- [LLM-R2: A Large Language Model Enhanced Rule-based Rewrite System for Boosting Query Efficiency](2024年04月19日/LLM-R2_A_Large_Language_Model_Enhanced_Rule-based_Rewrite_System_for_Boosting_Query_Efficiency.md)

    - [翻译: LLM-R2：一款搭载强化规则重写系统的大型语言模型，旨在提升查询性能。](2024年04月19日/LLM-R2_A_Large_Language_Model_Enhanced_Rule-based_Rewrite_System_for_Boosting_Query_Efficiency.md)

- [Towards Logically Consistent Language Models via Probabilistic Reasoning](2024年04月19日/Towards_Logically_Consistent_Language_Models_via_Probabilistic_Reasoning.md)

    - [翻译: 通过概率推理方法，推动语言模型向逻辑一致性方向发展。](2024年04月19日/Towards_Logically_Consistent_Language_Models_via_Probabilistic_Reasoning.md)

- [ECOR: Explainable CLIP for Object Recognition](2024年04月19日/ECOR_Explainable_CLIP_for_Object_Recognition.md)

    - [翻译: ECOR：为对象识别提供可解释性的 CLIP](2024年04月19日/ECOR_Explainable_CLIP_for_Object_Recognition.md)

- [How Far Can We Go with Practical Function-Level Program Repair?](2024年04月19日/How_Far_Can_We_Go_with_Practical_Function-Level_Program_Repair.md)

    - [翻译: 实用的函数级程序修复能带我们走多远？](2024年04月19日/How_Far_Can_We_Go_with_Practical_Function-Level_Program_Repair.md)

- [LiMe: a Latin Corpus of Late Medieval Criminal Sentences](2024年04月19日/LiMe_a_Latin_Corpus_of_Late_Medieval_Criminal_Sentences.md)

    - [翻译: LiMe：一部汇集了中世纪晚期刑事判决案例的拉丁文语料库。](2024年04月19日/LiMe_a_Latin_Corpus_of_Late_Medieval_Criminal_Sentences.md)

- [TextSquare: Scaling up Text-Centric Visual Instruction Tuning](2024年04月19日/TextSquare_Scaling_up_Text-Centric_Visual_Instruction_Tuning.md)

    - [翻译: TextSquare：提升文本导向视觉指令调优的规模](2024年04月19日/TextSquare_Scaling_up_Text-Centric_Visual_Instruction_Tuning.md)

- [Generating Test Scenarios from NL Requirements using Retrieval-Augmented LLMs: An Industrial Study](2024年04月19日/Generating_Test_Scenarios_from_NL_Requirements_using_Retrieval-Augmented_LLMs_An_Industrial_Study.md)

    - [翻译: 本工业研究探讨了如何利用增强检索功能的大型语言模型，从自然语言需求中生成测试场景。](2024年04月19日/Generating_Test_Scenarios_from_NL_Requirements_using_Retrieval-Augmented_LLMs_An_Industrial_Study.md)

- [AutoCrawler: A Progressive Understanding Web Agent for Web Crawler Generation](2024年04月19日/AutoCrawler_A_Progressive_Understanding_Web_Agent_for_Web_Crawler_Generation.md)

    - [翻译: AutoCrawler：一种渐进式理解的网络代理，专为网络爬虫生成而设计。](2024年04月19日/AutoCrawler_A_Progressive_Understanding_Web_Agent_for_Web_Crawler_Generation.md)

- [Beyond Human Norms: Unveiling Unique Values of Large Language Models through Interdisciplinary Approaches](2024年04月19日/Beyond_Human_Norms_Unveiling_Unique_Values_of_Large_Language_Models_through_Interdisciplinary_Approaches.md)

    - [翻译: 跨越人类常规，透过跨学科视角，揭开大型语言模型的独特价值。](2024年04月19日/Beyond_Human_Norms_Unveiling_Unique_Values_of_Large_Language_Models_through_Interdisciplinary_Approaches.md)

- [The Solution for the CVPR2024 NICE Image Captioning Challenge](2024年04月19日/The_Solution_for_the_CVPR2024_NICE_Image_Captioning_Challenge.md)

    - [翻译: CVPR2024 NICE图像标题挑战赛的解决之道](2024年04月19日/The_Solution_for_the_CVPR2024_NICE_Image_Captioning_Challenge.md)

- [LLM App Store Analysis: A Vision and Roadmap](2024年04月19日/LLM_App_Store_Analysis_A_Vision_and_Roadmap.md)

    - [翻译: 大型语言模型应用商店解析：展望与规划蓝图](2024年04月19日/LLM_App_Store_Analysis_A_Vision_and_Roadmap.md)

- [Large Language Model Supply Chain: A Research Agenda](2024年04月19日/Large_Language_Model_Supply_Chain_A_Research_Agenda.md)

    - [翻译: 探索大型语言模型的供应链：制定研究路线图](2024年04月19日/Large_Language_Model_Supply_Chain_A_Research_Agenda.md)

- [Relevant or Random: Can LLMs Truly Perform Analogical Reasoning?](2024年04月19日/Relevant_or_Random_Can_LLMs_Truly_Perform_Analogical_Reasoning.md)

    - [翻译: 关联性抑或随机性：大型语言模型（LLM）是否真正具备类比推理的能力？](2024年04月19日/Relevant_or_Random_Can_LLMs_Truly_Perform_Analogical_Reasoning.md)

- [Evaluating Character Understanding of Large Language Models via Character Profiling from Fictional Works](2024年04月19日/Evaluating_Character_Understanding_of_Large_Language_Models_via_Character_Profiling_from_Fictional_Works.md)

    - [翻译: 通过分析虚构作品中的角色档案，我们对大型语言模型在角色理解方面的能力进行了评估。](2024年04月19日/Evaluating_Character_Understanding_of_Large_Language_Models_via_Character_Profiling_from_Fictional_Works.md)

- [Enabling Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration](2024年04月19日/Enabling_Ensemble_Learning_for_Heterogeneous_Large_Language_Models_with_Deep_Parallel_Collaboration.md)

    - [翻译: 通过深度并行合作，实现异构大型语言模型的集成学习。](2024年04月19日/Enabling_Ensemble_Learning_for_Heterogeneous_Large_Language_Models_with_Deep_Parallel_Collaboration.md)

- [Can LLMs Understand Computer Networks? Towards a Virtual System Administrator](2024年04月19日/Can_LLMs_Understand_Computer_Networks_Towards_a_Virtual_System_Administrator.md)

    - [翻译: 大型语言模型能否洞悉计算机网络的奥秘？探索成为虚拟系统管理员之路。](2024年04月19日/Can_LLMs_Understand_Computer_Networks_Towards_a_Virtual_System_Administrator.md)

- [SOS-1K: A Fine-grained Suicide Risk Classification Dataset for Chinese Social Media Analysis](2024年04月19日/SOS-1K_A_Fine-grained_Suicide_Risk_Classification_Dataset_for_Chinese_Social_Media_Analysis.md)

    - [翻译: SOS-1K：专为中文社交媒体分析设计的细致自杀风险分类数据集](2024年04月19日/SOS-1K_A_Fine-grained_Suicide_Risk_Classification_Dataset_for_Chinese_Social_Media_Analysis.md)

- [Multi-Objective Fine-Tuning for Enhanced Program Repair with LLMs](2024年04月19日/Multi-Objective_Fine-Tuning_for_Enhanced_Program_Repair_with_LLMs.md)

    - [翻译: 通过多目标微调，我们提升了利用大型语言模型进行程序修复的能力。](2024年04月19日/Multi-Objective_Fine-Tuning_for_Enhanced_Program_Repair_with_LLMs.md)

- [MoVA: Adapting Mixture of Vision Experts to Multimodal Context](2024年04月19日/MoVA_Adapting_Mixture_of_Vision_Experts_to_Multimodal_Context.md)

    - [翻译: MoVA：将视觉专家的混合模型适配至多模态环境](2024年04月19日/MoVA_Adapting_Mixture_of_Vision_Experts_to_Multimodal_Context.md)

- [Groma: Localized Visual Tokenization for Grounding Multimodal Large Language Models](2024年04月19日/Groma_Localized_Visual_Tokenization_for_Grounding_Multimodal_Large_Language_Models.md)

    - [翻译: Groma：为多模态大型语言模型提供精准定位的视觉标记化技术](2024年04月19日/Groma_Localized_Visual_Tokenization_for_Grounding_Multimodal_Large_Language_Models.md)

- [Unified Scene Representation and Reconstruction for 3D Large Language Models](2024年04月19日/Unified_Scene_Representation_and_Reconstruction_for_3D_Large_Language_Models.md)

    - [翻译: 为3D大型语言模型提供统一的场景表示与重建。](2024年04月19日/Unified_Scene_Representation_and_Reconstruction_for_3D_Large_Language_Models.md)

- [Data Alignment for Zero-Shot Concept Generation in Dermatology AI](2024年04月19日/Data_Alignment_for_Zero-Shot_Concept_Generation_in_Dermatology_AI.md)

    - [翻译: 为皮肤科AI中的零样本概念生成实现数据对齐。](2024年04月19日/Data_Alignment_for_Zero-Shot_Concept_Generation_in_Dermatology_AI.md)

- [Sample Design Engineering: An Empirical Study of What Makes Good Downstream Fine-Tuning Samples for LLMs](2024年04月19日/Sample_Design_Engineering_An_Empirical_Study_of_What_Makes_Good_Downstream_Fine-Tuning_Samples_for_LLMs.md)

    - [翻译: 样本设计工程：探究何种样本能成为大型语言模型（LLM）下游微调的优质选择的实证研究](2024年04月19日/Sample_Design_Engineering_An_Empirical_Study_of_What_Makes_Good_Downstream_Fine-Tuning_Samples_for_LLMs.md)

- [When Life gives you LLMs, make LLM-ADE: Large Language Models with Adaptive Data Engineering](2024年04月19日/When_Life_gives_you_LLMs,_make_LLM-ADE_Large_Language_Models_with_Adaptive_Data_Engineering.md)

    - [翻译: 生活赋予你大型语言模型（LLMs），便创造 LLM-ADE：融入自适应数据工程的先进语言模型。](2024年04月19日/When_Life_gives_you_LLMs,_make_LLM-ADE_Large_Language_Models_with_Adaptive_Data_Engineering.md)

- [Stronger Random Baselines for In-Context Learning](2024年04月19日/Stronger_Random_Baselines_for_In-Context_Learning.md)

    - [翻译: 为上下文内学习构建更强大的随机基线](2024年04月19日/Stronger_Random_Baselines_for_In-Context_Learning.md)

- [Personalized Wireless Federated Learning for Large Language Models](2024年04月19日/Personalized_Wireless_Federated_Learning_for_Large_Language_Models.md)

    - [翻译: 为大型语言模型量身定制的无线联合学习技术](2024年04月19日/Personalized_Wireless_Federated_Learning_for_Large_Language_Models.md)

- [LLMChain: Blockchain-based Reputation System for Sharing and Evaluating Large Language Models](2024年04月19日/LLMChain_Blockchain-based_Reputation_System_for_Sharing_and_Evaluating_Large_Language_Models.md)

    - [翻译: LLMChain：一个利用区块链技术构建的声誉系统，旨在促进大型语言模型的共享与评估。](2024年04月19日/LLMChain_Blockchain-based_Reputation_System_for_Sharing_and_Evaluating_Large_Language_Models.md)

- [STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases](2024年04月19日/STaRK_Benchmarking_LLM_Retrieval_on_Textual_and_Relational_Knowledge_Bases.md)

    - [翻译: STaRK：为大型语言模型在文本与关系知识库检索上设立的基准测试。](2024年04月19日/STaRK_Benchmarking_LLM_Retrieval_on_Textual_and_Relational_Knowledge_Bases.md)

- [Action Contextualization: Adaptive Task Planning and Action Tuning using Large Language Models](2024年04月19日/Action_Contextualization_Adaptive_Task_Planning_and_Action_Tuning_using_Large_Language_Models.md)

    - [翻译: 动作情境化：利用大型语言模型实现任务规划与动作调节的智能适应。](2024年04月19日/Action_Contextualization_Adaptive_Task_Planning_and_Action_Tuning_using_Large_Language_Models.md)

- [CyberSecEval 2: A Wide-Ranging Cybersecurity Evaluation Suite for Large Language Models](2024年04月19日/CyberSecEval_2_A_Wide-Ranging_Cybersecurity_Evaluation_Suite_for_Large_Language_Models.md)

    - [翻译: CyberSecEval 2：为大型语言模型量身打造的全面网络安全评估工具集。](2024年04月19日/CyberSecEval_2_A_Wide-Ranging_Cybersecurity_Evaluation_Suite_for_Large_Language_Models.md)

- [Beyond Self-Consistency: Ensemble Reasoning Boosts Consistency and Accuracy of LLMs in Cancer Staging](2024年04月19日/Beyond_Self-Consistency_Ensemble_Reasoning_Boosts_Consistency_and_Accuracy_of_LLMs_in_Cancer_Staging.md)

    - [翻译: 超越单一自洽：通过集成推理，我们提升了大型语言模型在癌症分期任务中的一致性和准确度。](2024年04月19日/Beyond_Self-Consistency_Ensemble_Reasoning_Boosts_Consistency_and_Accuracy_of_LLMs_in_Cancer_Staging.md)

- [Mathify: Evaluating Large Language Models on Mathematical Problem Solving Tasks](2024年04月19日/Mathify_Evaluating_Large_Language_Models_on_Mathematical_Problem_Solving_Tasks.md)

    - [翻译: Mathify：探究大型语言模型在数学问题解决任务上的应用与效能](2024年04月19日/Mathify_Evaluating_Large_Language_Models_on_Mathematical_Problem_Solving_Tasks.md)

2024年04月18日

- [BLINK: Multimodal Large Language Models Can See but Not Perceive](2024年04月18日/BLINK_Multimodal_Large_Language_Models_Can_See_but_Not_Perceive.md)

    - [翻译: BLINK：多模态的大型语言模型具备视觉识别能力，但却无法实现深层次的感知理解。](2024年04月18日/BLINK_Multimodal_Large_Language_Models_Can_See_but_Not_Perceive.md)

- [MedThink: Explaining Medical Visual Question Answering via Multimodal Decision-Making Rationale](2024年04月18日/MedThink_Explaining_Medical_Visual_Question_Answering_via_Multimodal_Decision-Making_Rationale.md)

    - [翻译: MedThink：揭示医学视觉问答背后的多模态决策推理过程](2024年04月18日/MedThink_Explaining_Medical_Visual_Question_Answering_via_Multimodal_Decision-Making_Rationale.md)

- [When LLMs are Unfit Use FastFit: Fast and Effective Text Classification with Many Classes](2024年04月18日/When_LLMs_are_Unfit_Use_FastFit_Fast_and_Effective_Text_Classification_with_Many_Classes.md)

    - [翻译: 在大型语言模型（LLMs）不适宜的情况下，不妨试试 FastFit，这是一种高效且迅速的文本分类技术，尤其适用于多类别场景。](2024年04月18日/When_LLMs_are_Unfit_Use_FastFit_Fast_and_Effective_Text_Classification_with_Many_Classes.md)

- [Towards a Foundation Model for Partial Differential Equation: Multi-Operator Learning and Extrapolation](2024年04月18日/Towards_a_Foundation_Model_for_Partial_Differential_Equation_Multi-Operator_Learning_and_Extrapolation.md)

    - [翻译: 迈向构建偏微分方程基础模型之路：探究多操作符学习与外推技术](2024年04月18日/Towards_a_Foundation_Model_for_Partial_Differential_Equation_Multi-Operator_Learning_and_Extrapolation.md)

- [V2Xum-LLM: Cross-Modal Video Summarization with Temporal Prompt Instruction Tuning](2024年04月18日/V2Xum-LLM_Cross-Modal_Video_Summarization_with_Temporal_Prompt_Instruction_Tuning.md)

    - [翻译: V2Xum-LLM：利用时间提示指令优化的跨模态视频摘要技术](2024年04月18日/V2Xum-LLM_Cross-Modal_Video_Summarization_with_Temporal_Prompt_Instruction_Tuning.md)

- [Point-In-Context: Understanding Point Cloud via In-Context Learning](2024年04月18日/Point-In-Context_Understanding_Point_Cloud_via_In-Context_Learning.md)

    - [翻译: 点云上下文理解：通过情境学习深入洞察点云数据](2024年04月18日/Point-In-Context_Understanding_Point_Cloud_via_In-Context_Learning.md)

- [Large Language Models in Targeted Sentiment Analysis](2024年04月18日/Large_Language_Models_in_Targeted_Sentiment_Analysis.md)

    - [翻译: 在针对性情感分析领域，大型语言模型发挥着重要作用。](2024年04月18日/Large_Language_Models_in_Targeted_Sentiment_Analysis.md)

- [Normative Requirements Operationalization with Large Language Models](2024年04月18日/Normative_Requirements_Operationalization_with_Large_Language_Models.md)

    - [翻译: 通过大型语言模型，将规范性要求转化为可操作的标准。](2024年04月18日/Normative_Requirements_Operationalization_with_Large_Language_Models.md)

- [Large Language Models for Synthetic Participatory Planning of Shared Automated Electric Mobility Systems](2024年04月18日/Large_Language_Models_for_Synthetic_Participatory_Planning_of_Shared_Automated_Electric_Mobility_Systems.md)

    - [翻译: 大型语言模型在共享自动电动移动系统综合参与式规划中的应用。](2024年04月18日/Large_Language_Models_for_Synthetic_Participatory_Planning_of_Shared_Automated_Electric_Mobility_Systems.md)

- [Simultaneous Interpretation Corpus Construction by Large Language Models in Distant Language Pair](2024年04月18日/Simultaneous_Interpretation_Corpus_Construction_by_Large_Language_Models_in_Distant_Language_Pair.md)

    - [翻译: 利用大型语言模型打造远距离语言对的同声传译语料库。](2024年04月18日/Simultaneous_Interpretation_Corpus_Construction_by_Large_Language_Models_in_Distant_Language_Pair.md)

- [Augmenting emotion features in irony detection with Large language modeling](2024年04月18日/Augmenting_emotion_features_in_irony_detection_with_Large_language_modeling.md)

    - [翻译: 利用大型语言模型增强情感特征，提升讽刺检测的准确性](2024年04月18日/Augmenting_emotion_features_in_irony_detection_with_Large_language_modeling.md)

- [Enhancing Embedding Performance through Large Language Model-based Text Enrichment and Rewriting](2024年04月18日/Enhancing_Embedding_Performance_through_Large_Language_Model-based_Text_Enrichment_and_Rewriting.md)

    - [翻译: 利用大型语言模型对文本进行丰富和改写，可以有效提升嵌入技术的表现。](2024年04月18日/Enhancing_Embedding_Performance_through_Large_Language_Model-based_Text_Enrichment_and_Rewriting.md)

- [Advancing the Robustness of Large Language Models through Self-Denoised Smoothing](2024年04月18日/Advancing_the_Robustness_of_Large_Language_Models_through_Self-Denoised_Smoothing.md)

    - [翻译: 本文探讨了一种提升大型语言模型鲁棒性的方法——自我去噪平滑技术。通过这种技术，我们能够有效地增强模型在面对噪声干扰时的稳定性和可靠性。](2024年04月18日/Advancing_the_Robustness_of_Large_Language_Models_through_Self-Denoised_Smoothing.md)

- [FedEval-LLM: Federated Evaluation of Large Language Models on Downstream Tasks with Collective Wisdom](2024年04月18日/FedEval-LLM_Federated_Evaluation_of_Large_Language_Models_on_Downstream_Tasks_with_Collective_Wisdom.md)

    - [翻译: FedEval-LLM：借助集体智慧，对大型语言模型在下游任务中的性能进行联合评估。](2024年04月18日/FedEval-LLM_Federated_Evaluation_of_Large_Language_Models_on_Downstream_Tasks_with_Collective_Wisdom.md)

- [Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences](2024年04月18日/Who_Validates_the_Validators_Aligning_LLM-Assisted_Evaluation_of_LLM_Outputs_with_Human_Preferences.md)

    - [翻译: 谁来校验校验者？将大型语言模型（LLM）辅助的输出评估与人类偏好相协调](2024年04月18日/Who_Validates_the_Validators_Aligning_LLM-Assisted_Evaluation_of_LLM_Outputs_with_Human_Preferences.md)

- [Concept Induction: Analyzing Unstructured Text with High-Level Concepts Using LLooM](2024年04月18日/Concept_Induction_Analyzing_Unstructured_Text_with_High-Level_Concepts_Using_LLooM.md)

    - [翻译: 概念归纳：运用高级概念对非结构化文本进行分析的 LLooM技术](2024年04月18日/Concept_Induction_Analyzing_Unstructured_Text_with_High-Level_Concepts_Using_LLooM.md)

- [DeepLocalization: Using change point detection for Temporal Action Localization](2024年04月18日/DeepLocalization_Using_change_point_detection_for_Temporal_Action_Localization.md)

    - [翻译: DeepLocalization：运用变点检测技术实现动作的时序定位](2024年04月18日/DeepLocalization_Using_change_point_detection_for_Temporal_Action_Localization.md)

- [Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing](2024年04月18日/Toward_Self-Improvement_of_LLMs_via_Imagination,_Searching,_and_Criticizing.md)

    - [翻译: 探索大型语言模型自我完善的路径：借助想象、搜索与批判。](2024年04月18日/Toward_Self-Improvement_of_LLMs_via_Imagination,_Searching,_and_Criticizing.md)

- [De-DSI: Decentralised Differentiable Search Index](2024年04月18日/De-DSI_Decentralised_Differentiable_Search_Index.md)

    - [翻译: De-DSI：分布式可微搜索索引](2024年04月18日/De-DSI_Decentralised_Differentiable_Search_Index.md)

- [Aligning Actions and Walking to LLM-Generated Textual Descriptions](2024年04月18日/Aligning_Actions_and_Walking_to_LLM-Generated_Textual_Descriptions.md)

    - [翻译: 将行动和行走与大型语言模型（LLM）生成的文本描述进行匹配。](2024年04月18日/Aligning_Actions_and_Walking_to_LLM-Generated_Textual_Descriptions.md)

- [Stance Detection on Social Media with Fine-Tuned Large Language Models](2024年04月18日/Stance_Detection_on_Social_Media_with_Fine-Tuned_Large_Language_Models.md)

    - [翻译: 通过精心调校的大型语言模型，我们在社交媒体上开展立场检测。](2024年04月18日/Stance_Detection_on_Social_Media_with_Fine-Tuned_Large_Language_Models.md)

- [AccidentBlip2: Accident Detection With Multi-View MotionBlip2](2024年04月18日/AccidentBlip2_Accident_Detection_With_Multi-View_MotionBlip2.md)

    - [翻译: AccidentBlip2：运用多视角 MotionBlip2 技术进行事故识别。](2024年04月18日/AccidentBlip2_Accident_Detection_With_Multi-View_MotionBlip2.md)

- [From Form(s) to Meaning: Probing the Semantic Depths of Language Models Using Multisense Consistency](2024年04月18日/From_Form(s)_to_Meaning_Probing_the_Semantic_Depths_of_Language_Models_Using_Multisense_Consistency.md)

    - [翻译: 由表及里：透过多义一致性，深入挖掘语言模型的语义内涵。](2024年04月18日/From_Form(s)_to_Meaning_Probing_the_Semantic_Depths_of_Language_Models_Using_Multisense_Consistency.md)

- [Character is Destiny: Can Large Language Models Simulate Persona-Driven Decisions in Role-Playing?](2024年04月18日/Character_is_Destiny_Can_Large_Language_Models_Simulate_Persona-Driven_Decisions_in_Role-Playing.md)

    - [翻译: 性格决定命运：大型语言模型能否在角色扮演游戏中模拟出由角色个性所驱动的决策过程？](2024年04月18日/Character_is_Destiny_Can_Large_Language_Models_Simulate_Persona-Driven_Decisions_in_Role-Playing.md)

- [mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture](2024年04月18日/mABC_multi-Agent_Blockchain-Inspired_Collaboration_for_root_cause_analysis_in_micro-services_architecture.md)

    - [翻译: mABC：一种受区块链启发的多代理协作机制，专为微服务架构中的根本原因分析而设计。](2024年04月18日/mABC_multi-Agent_Blockchain-Inspired_Collaboration_for_root_cause_analysis_in_micro-services_architecture.md)

- [RAGAR, Your Falsehood RADAR: RAG-Augmented Reasoning for Political Fact-Checking using Multimodal Large Language Models](2024年04月18日/RAGAR,_Your_Falsehood_RADAR_RAG-Augmented_Reasoning_for_Political_Fact-Checking_using_Multimodal_Large_Language_Models.md)

    - [翻译: RAGAR，您的虚假信息侦测器：一种利用多模态大型语言模型增强推理能力，专为政治事实核查而设计的方法。](2024年04月18日/RAGAR,_Your_Falsehood_RADAR_RAG-Augmented_Reasoning_for_Political_Fact-Checking_using_Multimodal_Large_Language_Models.md)

- [Can We Catch the Elephant? The Evolvement of Hallucination Evaluation on Natural Language Generation: A Survey](2024年04月18日/Can_We_Catch_the_Elephant_The_Evolvement_of_Hallucination_Evaluation_on_Natural_Language_Generation_A_Survey.md)

    - [翻译: 能否捕捉巨象？自然语言生成中幻觉评估的发展综述](2024年04月18日/Can_We_Catch_the_Elephant_The_Evolvement_of_Hallucination_Evaluation_on_Natural_Language_Generation_A_Survey.md)

- [Uncovering Safety Risks in Open-source LLMs through Concept Activation Vector](2024年04月18日/Uncovering_Safety_Risks_in_Open-source_LLMs_through_Concept_Activation_Vector.md)

    - [翻译: 利用概念激活向量技术，深入挖掘开源大型语言模型（LLM）中潜藏的安全风险。](2024年04月18日/Uncovering_Safety_Risks_in_Open-source_LLMs_through_Concept_Activation_Vector.md)

- [Parallel Decoding via Hidden Transfer for Lossless Large Language Model Acceleration](2024年04月18日/Parallel_Decoding_via_Hidden_Transfer_for_Lossless_Large_Language_Model_Acceleration.md)

    - [翻译: 采用隐藏层传输技术，实现大型语言模型的并行解码，从而加速模型的无损运行。](2024年04月18日/Parallel_Decoding_via_Hidden_Transfer_for_Lossless_Large_Language_Model_Acceleration.md)

- [What does CLIP know about peeling a banana?](2024年04月18日/What_does_CLIP_know_about_peeling_a_banana.md)

    - [翻译: CLIP 对于如何剥香蕉有何认知？](2024年04月18日/What_does_CLIP_know_about_peeling_a_banana.md)

- [ParaFusion: A Large-Scale LLM-Driven English Paraphrase Dataset Infused with High-Quality Lexical and Syntactic Diversity](2024年04月18日/ParaFusion_A_Large-Scale_LLM-Driven_English_Paraphrase_Dataset_Infused_with_High-Quality_Lexical_and_Syntactic_Diversity.md)

    - [翻译: ParaFusion 是一个由大型语言模型（LLM）驱动的英语释义数据集，它注入了丰富的词汇和句法多样性，为语言模型的训练和评估提供了高质量的语料。](2024年04月18日/ParaFusion_A_Large-Scale_LLM-Driven_English_Paraphrase_Dataset_Infused_with_High-Quality_Lexical_and_Syntactic_Diversity.md)

- [Token-level Direct Preference Optimization](2024年04月18日/Token-level_Direct_Preference_Optimization.md)

    - [翻译: 直接偏好优化（DPO）是一种在生成模型中针对用户偏好进行优化的策略，该策略通过微调模型产出的每个语义单元（标记）来精准实现。](2024年04月18日/Token-level_Direct_Preference_Optimization.md)

- [EVIT: Event-Oriented Instruction Tuning for Event Reasoning](2024年04月18日/EVIT_Event-Oriented_Instruction_Tuning_for_Event_Reasoning.md)

    - [翻译: EVIT：针对事件推理的事件驱动指令优化](2024年04月18日/EVIT_Event-Oriented_Instruction_Tuning_for_Event_Reasoning.md)

- [Large Language Models: From Notes to Musical Form](2024年04月18日/Large_Language_Models_From_Notes_to_Musical_Form.md)

    - [翻译: 大型语言模型：将笔记转化为音乐篇章](2024年04月18日/Large_Language_Models_From_Notes_to_Musical_Form.md)

- [Exploring the landscape of large language models: Foundations, techniques, and challenges](2024年04月18日/Exploring_the_landscape_of_large_language_models_Foundations,_techniques,_and_challenges.md)

    - [翻译: 深入探究大型语言模型的疆域：从基础理论到技术应用，再到面临的挑战。](2024年04月18日/Exploring_the_landscape_of_large_language_models_Foundations,_techniques,_and_challenges.md)

- [Aligning Language Models to Explicitly Handle Ambiguity](2024年04月18日/Aligning_Language_Models_to_Explicitly_Handle_Ambiguity.md)

    - [翻译: 对齐语言模型以明确处理歧义](2024年04月18日/Aligning_Language_Models_to_Explicitly_Handle_Ambiguity.md)

- [From Language Models to Practical Self-Improving Computer Agents](2024年04月18日/From_Language_Models_to_Practical_Self-Improving_Computer_Agents.md)

    - [翻译: 语言模型向实用自我进化计算机代理的转变](2024年04月18日/From_Language_Models_to_Practical_Self-Improving_Computer_Agents.md)

- [Generating Diverse Criteria On-the-Fly to Improve Point-wise LLM Rankers](2024年04月18日/Generating_Diverse_Criteria_On-the-Fly_to_Improve_Point-wise_LLM_Rankers.md)

    - [翻译: 动态生成多样化评判标准，以提升大型语言模型的逐点排名性能。](2024年04月18日/Generating_Diverse_Criteria_On-the-Fly_to_Improve_Point-wise_LLM_Rankers.md)

- [Sketch-guided Image Inpainting with Partial Discrete Diffusion Process](2024年04月18日/Sketch-guided_Image_Inpainting_with_Partial_Discrete_Diffusion_Process.md)

    - [翻译: 草图引导的图像修复技术，借助部分离散扩散过程实现](2024年04月18日/Sketch-guided_Image_Inpainting_with_Partial_Discrete_Diffusion_Process.md)

- [AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration](2024年04月18日/AgentCoord_Visually_Exploring_Coordination_Strategy_for_LLM-based_Multi-Agent_Collaboration.md)

    - [翻译: AgentCoord：探索基于大型语言模型的多智能体协作的视觉协调策略](2024年04月18日/AgentCoord_Visually_Exploring_Coordination_Strategy_for_LLM-based_Multi-Agent_Collaboration.md)

- [CrossIn: An Efficient Instruction Tuning Approach for Cross-Lingual Knowledge Alignment](2024年04月18日/CrossIn_An_Efficient_Instruction_Tuning_Approach_for_Cross-Lingual_Knowledge_Alignment.md)

    - [翻译: CrossIn：一种高效指令调优策略，专为跨语言知识对齐而设计](2024年04月18日/CrossIn_An_Efficient_Instruction_Tuning_Approach_for_Cross-Lingual_Knowledge_Alignment.md)

- [TriForce: Lossless Acceleration of Long Sequence Generation with Hierarchical Speculative Decoding](2024年04月18日/TriForce_Lossless_Acceleration_of_Long_Sequence_Generation_with_Hierarchical_Speculative_Decoding.md)

    - [翻译: TriForce：采用分层推测解码技术，实现长序列生成的高效无损加速。](2024年04月18日/TriForce_Lossless_Acceleration_of_Long_Sequence_Generation_with_Hierarchical_Speculative_Decoding.md)

- [Enhancing Financial Inclusion and Regulatory Challenges: A Critical Analysis of Digital Banks and Alternative Lenders Through Digital Platforms, Machine Learning, and Large Language Models Integration](2024年04月18日/Enhancing_Financial_Inclusion_and_Regulatory_Challenges_A_Critical_Analysis_of_Digital_Banks_and_Alternative_Lenders_Through_Digital_Platforms,_Machine_Learning,_and_Large_Language_Models_Integration.md)

    - [翻译: 提升金融普惠与应对监管难题：深入剖析数字银行及替代性贷款机构如何通过整合数字平台、机器学习技术以及大型语言模型来应对挑战。](2024年04月18日/Enhancing_Financial_Inclusion_and_Regulatory_Challenges_A_Critical_Analysis_of_Digital_Banks_and_Alternative_Lenders_Through_Digital_Platforms,_Machine_Learning,_and_Large_Language_Models_Integration.md)

- [Large Language Models Can Plan Your Travels Rigorously with Formal Verification Tools](2024年04月18日/Large_Language_Models_Can_Plan_Your_Travels_Rigorously_with_Formal_Verification_Tools.md)

    - [翻译: 利用形式化验证工具，大型语言模型（LLMs）能够为您的旅行提供严谨的规划。](2024年04月18日/Large_Language_Models_Can_Plan_Your_Travels_Rigorously_with_Formal_Verification_Tools.md)

- [iRAG: An Incremental Retrieval Augmented Generation System for Videos](2024年04月18日/iRAG_An_Incremental_Retrieval_Augmented_Generation_System_for_Videos.md)

    - [翻译: iRAG：一种为视频内容设计的渐进式检索增强生成系统](2024年04月18日/iRAG_An_Incremental_Retrieval_Augmented_Generation_System_for_Videos.md)

- [Sequential Compositional Generalization in Multimodal Models](2024年04月18日/Sequential_Compositional_Generalization_in_Multimodal_Models.md)

    - [翻译: 多模态模型中的顺序组合泛化研究](2024年04月18日/Sequential_Compositional_Generalization_in_Multimodal_Models.md)

- [Deep and Dynamic Metabolic and Structural Imaging in Living Tissues](2024年04月18日/Deep_and_Dynamic_Metabolic_and_Structural_Imaging_in_Living_Tissues.md)

    - [翻译: 深入探索活体组织，实现动态代谢与结构成像。](2024年04月18日/Deep_and_Dynamic_Metabolic_and_Structural_Imaging_in_Living_Tissues.md)

- [Parameter Efficient Diverse Paraphrase Generation Using Sequence-Level Knowledge Distillation](2024年04月18日/Parameter_Efficient_Diverse_Paraphrase_Generation_Using_Sequence-Level_Knowledge_Distillation.md)

    - [翻译: 通过序列层级的知识蒸馏技术，实现参数高效且多样化的释义生成。](2024年04月18日/Parameter_Efficient_Diverse_Paraphrase_Generation_Using_Sequence-Level_Knowledge_Distillation.md)

- [Dubo-SQL: Diverse Retrieval-Augmented Generation and Fine Tuning for Text-to-SQL](2024年04月18日/Dubo-SQL_Diverse_Retrieval-Augmented_Generation_and_Fine_Tuning_for_Text-to-SQL.md)

    - [翻译: Dubo-SQL：为文本到SQL任务，引入多样化的检索增强生成技术与精细调优方法。](2024年04月18日/Dubo-SQL_Diverse_Retrieval-Augmented_Generation_and_Fine_Tuning_for_Text-to-SQL.md)

- [Just Like Me: The Role of Opinions and Personal Experiences in The Perception of Explanations in Subjective Decision-Making](2024年04月18日/Just_Like_Me_The_Role_of_Opinions_and_Personal_Experiences_in_The_Perception_of_Explanations_in_Subjective_Decision-Making.md)

    - [翻译: 《与我相似：观点与个人经历在主观决策中对解释感知的影响》](2024年04月18日/Just_Like_Me_The_Role_of_Opinions_and_Personal_Experiences_in_The_Perception_of_Explanations_in_Subjective_Decision-Making.md)

- [Cocoon: Semantic Table Profiling Using Large Language Models](2024年04月18日/Cocoon_Semantic_Table_Profiling_Using_Large_Language_Models.md)

    - [翻译: Cocoon：运用大型语言模型进行语义化表格剖析](2024年04月18日/Cocoon_Semantic_Table_Profiling_Using_Large_Language_Models.md)

- ["If the Machine Is As Good As Me, Then What Use Am I?" -- How the Use of ChatGPT Changes Young Professionals' Perception of Productivity and Accomplishment](2024年04月18日/If_the_Machine_Is_As_Good_As_Me,_Then_What_Use_Am_I_--_How_the_Use_of_ChatGPT_Changes_Young_Professionals'_Perception_of_Productivity_and_Accomplishment.md)

    - [翻译: 机器若能与我匹敌，我的价值何在？——探讨 ChatGPT 如何重塑年轻职场人士对效率与成就的认知](2024年04月18日/If_the_Machine_Is_As_Good_As_Me,_Then_What_Use_Am_I_--_How_the_Use_of_ChatGPT_Changes_Young_Professionals'_Perception_of_Productivity_and_Accomplishment.md)

- [HalluciBot: Is There No Such Thing as a Bad Question?](2024年04月18日/HalluciBot_Is_There_No_Such_Thing_as_a_Bad_Question.md)

    - [翻译: HalluciBot：世上真有所谓的“坏问题”吗？](2024年04月18日/HalluciBot_Is_There_No_Such_Thing_as_a_Bad_Question.md)

- [Towards Large Language Models as Copilots for Theorem Proving in Lean](2024年04月18日/Towards_Large_Language_Models_as_Copilots_for_Theorem_Proving_in_Lean.md)

    - [翻译: 探索大型语言模型作为 Lean 定理证明的智能辅助工具](2024年04月18日/Towards_Large_Language_Models_as_Copilots_for_Theorem_Proving_in_Lean.md)

- [UIClip: A Data-driven Model for Assessing User Interface Design](2024年04月18日/UIClip_A_Data-driven_Model_for_Assessing_User_Interface_Design.md)

    - [翻译: UIClip：一种数据驱动的模型，专为评估用户界面设计而设计](2024年04月18日/UIClip_A_Data-driven_Model_for_Assessing_User_Interface_Design.md)

- [BIRD: A Trustworthy Bayesian Inference Framework for Large Language Models](2024年04月18日/BIRD_A_Trustworthy_Bayesian_Inference_Framework_for_Large_Language_Models.md)

    - [翻译: BIRD：为大型语言模型量身打造的可信贝叶斯推断框架](2024年04月18日/BIRD_A_Trustworthy_Bayesian_Inference_Framework_for_Large_Language_Models.md)

- [NORMAD: A Benchmark for Measuring the Cultural Adaptability of Large Language Models](2024年04月18日/NORMAD_A_Benchmark_for_Measuring_the_Cultural_Adaptability_of_Large_Language_Models.md)

    - [翻译: NORMAD：衡量大型语言模型文化适应性的基准测试。](2024年04月18日/NORMAD_A_Benchmark_for_Measuring_the_Cultural_Adaptability_of_Large_Language_Models.md)

- [NLP-enabled trajectory map-matching in urban road networks using transformer sequence-to-sequence model](2024年04月18日/NLP-enabled_trajectory_map-matching_in_urban_road_networks_using_transformer_sequence-to-sequence_model.md)

    - [翻译: 利用变换器序列对序列模型，实现城市路网中基于自然语言处理（NLP）的轨迹地图匹配技术。](2024年04月18日/NLP-enabled_trajectory_map-matching_in_urban_road_networks_using_transformer_sequence-to-sequence_model.md)

- [RAGCache: Efficient Knowledge Caching for Retrieval-Augmented Generation](2024年04月18日/RAGCache_Efficient_Knowledge_Caching_for_Retrieval-Augmented_Generation.md)

    - [翻译: RAGCache：为检索增强型生成提供高效的知识缓存解决方案](2024年04月18日/RAGCache_Efficient_Knowledge_Caching_for_Retrieval-Augmented_Generation.md)

2024年04月17日

- [Single-temporal Supervised Remote Change Detection for Domain Generalization](2024年04月17日/Single-temporal_Supervised_Remote_Change_Detection_for_Domain_Generalization.md)

    - [翻译: 在领域泛化中，单时相的遥感变化检测技术得到了监督学习的应用。](2024年04月17日/Single-temporal_Supervised_Remote_Change_Detection_for_Domain_Generalization.md)

- [Exploring the Transferability of Visual Prompting for Multimodal Large Language Models](2024年04月17日/Exploring_the_Transferability_of_Visual_Prompting_for_Multimodal_Large_Language_Models.md)

    - [翻译: 本文旨在探究多模态大型语言模型中视觉提示的迁移能力。](2024年04月17日/Exploring_the_Transferability_of_Visual_Prompting_for_Multimodal_Large_Language_Models.md)

- [DUPE: Detection Undermining via Prompt Engineering for Deepfake Text](2024年04月17日/DUPE_Detection_Undermining_via_Prompt_Engineering_for_Deepfake_Text.md)

    - [翻译: DUPE：利用提示工程技术揭露深度伪造文本的侦测机制](2024年04月17日/DUPE_Detection_Undermining_via_Prompt_Engineering_for_Deepfake_Text.md)

- [From Image to UML: First Results of Image Based UML Diagram Generation Using LLMs](2024年04月17日/From_Image_to_UML_First_Results_of_Image_Based_UML_Diagram_Generation_Using_LLMs.md)

    - [翻译: 图像转 UML：利用大型语言模型实现图像驱动的 UML 图表生成的首份成果报告。](2024年04月17日/From_Image_to_UML_First_Results_of_Image_Based_UML_Diagram_Generation_Using_LLMs.md)

- [Text-controlled Motion Mamba: Text-Instructed Temporal Grounding of Human Motion](2024年04月17日/Text-controlled_Motion_Mamba_Text-Instructed_Temporal_Grounding_of_Human_Motion.md)

    - [翻译: 文本操控的“运动曼巴”：通过文本指令实现人体动作的时间定位](2024年04月17日/Text-controlled_Motion_Mamba_Text-Instructed_Temporal_Grounding_of_Human_Motion.md)

- [Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender System](2024年04月17日/Large_Language_Models_meet_Collaborative_Filtering_An_Efficient_All-round_LLM-based_Recommender_System.md)

    - [翻译: 当大型语言模型邂逅协同过滤，便诞生了一个全面而高效的基于LLM的推荐系统。](2024年04月17日/Large_Language_Models_meet_Collaborative_Filtering_An_Efficient_All-round_LLM-based_Recommender_System.md)

- [LLMs for Cyber Security: New Opportunities](2024年04月17日/LLMs_for_Cyber_Security_New_Opportunities.md)

    - [翻译: 大型语言模型（LLM）在网络安全领域的应用：开启新机遇](2024年04月17日/LLMs_for_Cyber_Security_New_Opportunities.md)

- [Improving Composed Image Retrieval via Contrastive Learning with Scaling Positives and Negatives](2024年04月17日/Improving_Composed_Image_Retrieval_via_Contrastive_Learning_with_Scaling_Positives_and_Negatives.md)

    - [翻译: 通过扩展正负样本的对比学习优化组合图像检索对比学习在提升组合图像检索性能方面展现出巨大潜力。现有技术在平衡正负样本时面临挑战，这限制了检索效果。本研究引入了一种创新的对比学习方法，通过优化正负样本的扩展来克服这一难题。该方法不仅显著提升了检索效率，还增强了模型对多样化图像内容的适应性和泛化力。](2024年04月17日/Improving_Composed_Image_Retrieval_via_Contrastive_Learning_with_Scaling_Positives_and_Negatives.md)

- [To Drop or Not to Drop? Predicting Argument Ellipsis Judgments: A Case Study in Japanese](2024年04月17日/To_Drop_or_Not_to_Drop_Predicting_Argument_Ellipsis_Judgments_A_Case_Study_in_Japanese.md)

    - [翻译: 省略还是不省略？论元省略判断的预测：以日语为例](2024年04月17日/To_Drop_or_Not_to_Drop_Predicting_Argument_Ellipsis_Judgments_A_Case_Study_in_Japanese.md)

- [A Preference-driven Paradigm for Enhanced Translation with Large Language Models](2024年04月17日/A_Preference-driven_Paradigm_for_Enhanced_Translation_with_Large_Language_Models.md)

    - [翻译: 一种以用户偏好为驱动的翻译范式，旨在提升大型语言模型的翻译效果。](2024年04月17日/A_Preference-driven_Paradigm_for_Enhanced_Translation_with_Large_Language_Models.md)

- [RD2Bench: Toward Data-Centric Automatic R&D](2024年04月17日/RD2Bench_Toward_Data-Centric_Automatic_R&D.md)

    - [翻译: RD2Bench：探索数据驱动的自动化研发新路径](2024年04月17日/RD2Bench_Toward_Data-Centric_Automatic_R&D.md)

- [Towards Human Awareness in Robot Task Planning with Large Language Models](2024年04月17日/Towards_Human_Awareness_in_Robot_Task_Planning_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，机器人任务规划正逐步迈向具备人类意识的新阶段。](2024年04月17日/Towards_Human_Awareness_in_Robot_Task_Planning_with_Large_Language_Models.md)

- [Sampling-based Pseudo-Likelihood for Membership Inference Attacks](2024年04月17日/Sampling-based_Pseudo-Likelihood_for_Membership_Inference_Attacks.md)

    - [翻译: 采用抽样方法构建的伪似然模型，用于执行成员推断攻击。](2024年04月17日/Sampling-based_Pseudo-Likelihood_for_Membership_Inference_Attacks.md)

- [A Progressive Framework of Vision-language Knowledge Distillation and Alignment for Multilingual Scene](2024年04月17日/A_Progressive_Framework_of_Vision-language_Knowledge_Distillation_and_Alignment_for_Multilingual_Scene.md)

    - [翻译: 提出了一种渐进式框架，用于实现多语言场景中视觉与语言知识的蒸馏和对齐。](2024年04月17日/A_Progressive_Framework_of_Vision-language_Knowledge_Distillation_and_Alignment_for_Multilingual_Scene.md)

- [Unlocking Memories with AI: Exploring the Role of AI-Generated Cues in Personal Reminiscing](2024年04月17日/Unlocking_Memories_with_AI_Exploring_the_Role_of_AI-Generated_Cues_in_Personal_Reminiscing.md)

    - [翻译: 用AI唤醒往昔：探究AI生成线索在个人怀旧中扮演的角色。](2024年04月17日/Unlocking_Memories_with_AI_Exploring_the_Role_of_AI-Generated_Cues_in_Personal_Reminiscing.md)

- [In-Context Learning State Vector with Inner and Momentum Optimization](2024年04月17日/In-Context_Learning_State_Vector_with_Inner_and_Momentum_Optimization.md)

    - [翻译: 通过内嵌式和动量优化提升上下文学习状态向量。](2024年04月17日/In-Context_Learning_State_Vector_with_Inner_and_Momentum_Optimization.md)

- [Position Engineering: Boosting Large Language Models through Positional Information Manipulation](2024年04月17日/Position_Engineering_Boosting_Large_Language_Models_through_Positional_Information_Manipulation.md)

    - [翻译: 位置工程：通过巧妙操纵位置信息，增强大型语言模型的性能](2024年04月17日/Position_Engineering_Boosting_Large_Language_Models_through_Positional_Information_Manipulation.md)

- [Prompt-Guided Generation of Structured Chest X-Ray Report Using a Pre-trained LLM](2024年04月17日/Prompt-Guided_Generation_of_Structured_Chest_X-Ray_Report_Using_a_Pre-trained_LLM.md)

    - [翻译: 借助预训练的大型语言模型，通过引导式生成技术，自动撰写结构化的胸部X光报告。](2024年04月17日/Prompt-Guided_Generation_of_Structured_Chest_X-Ray_Report_Using_a_Pre-trained_LLM.md)

- [Low-Cost Language Models: Survey and Performance Evaluation on Python Code Generation](2024年04月17日/Low-Cost_Language_Models_Survey_and_Performance_Evaluation_on_Python_Code_Generation.md)

    - [翻译: 经济型语言模型：对 Python 代码生成任务的调研与性能测评。](2024年04月17日/Low-Cost_Language_Models_Survey_and_Performance_Evaluation_on_Python_Code_Generation.md)

- [Fact :Teaching MLLMs with Faithful, Concise and Transferable Rationales](2024年04月17日/Fact_Teaching_MLLMs_with_Faithful,_Concise_and_Transferable_Rationales.md)

    - [翻译: 事实：以忠实、精炼且易于迁移的理由来指导机器学习大型语言模型（MLLMs）的教学。](2024年04月17日/Fact_Teaching_MLLMs_with_Faithful,_Concise_and_Transferable_Rationales.md)

- [Small Language Models are Good Too: An Empirical Study of Zero-Shot Classification](2024年04月17日/Small_Language_Models_are_Good_Too_An_Empirical_Study_of_Zero-Shot_Classification.md)

    - [翻译: 小型语言模型同样出色：一项关于零样本分类的实证研究](2024年04月17日/Small_Language_Models_are_Good_Too_An_Empirical_Study_of_Zero-Shot_Classification.md)

- [TransLinkGuard: Safeguarding Transformer Models Against Model Stealing in Edge Deployment](2024年04月17日/TransLinkGuard_Safeguarding_Transformer_Models_Against_Model_Stealing_in_Edge_Deployment.md)

    - [翻译: TransLinkGuard：在边缘计算环境中，为 Transformer 模型提供防护，防止模型被窃取。](2024年04月17日/TransLinkGuard_Safeguarding_Transformer_Models_Against_Model_Stealing_in_Edge_Deployment.md)

- [Inductive-Deductive Strategy Reuse for Multi-Turn Instructional Dialogues](2024年04月17日/Inductive-Deductive_Strategy_Reuse_for_Multi-Turn_Instructional_Dialogues.md)

    - [翻译: 在多轮指导性对话中，归纳与演绎策略的巧妙运用](2024年04月17日/Inductive-Deductive_Strategy_Reuse_for_Multi-Turn_Instructional_Dialogues.md)

- [ViLLM-Eval: A Comprehensive Evaluation Suite for Vietnamese Large Language Models](2024年04月17日/ViLLM-Eval_A_Comprehensive_Evaluation_Suite_for_Vietnamese_Large_Language_Models.md)

    - [翻译: ViLLM-Eval：为越南大型语言模型量身定制的全面评估工具集](2024年04月17日/ViLLM-Eval_A_Comprehensive_Evaluation_Suite_for_Vietnamese_Large_Language_Models.md)

- [Large Language Models Meet User Interfaces: The Case of Provisioning Feedback](2024年04月17日/Large_Language_Models_Meet_User_Interfaces_The_Case_of_Provisioning_Feedback.md)

    - [翻译: 当大型语言模型邂逅用户界面：探索反馈机制的实践案例](2024年04月17日/Large_Language_Models_Meet_User_Interfaces_The_Case_of_Provisioning_Feedback.md)

- [Octopus v3: Technical Report for On-device Sub-billion Multimodal AI Agent](2024年04月17日/Octopus_v3_Technical_Report_for_On-device_Sub-billion_Multimodal_AI_Agent.md)

    - [翻译: 章鱼 v3：设备端十亿级以下多模态人工智能代理技术报告](2024年04月17日/Octopus_v3_Technical_Report_for_On-device_Sub-billion_Multimodal_AI_Agent.md)

- [Open-Ended Wargames with Large Language Models](2024年04月17日/Open-Ended_Wargames_with_Large_Language_Models.md)

    - [翻译: 大型语言模型在开放式战争游戏中的运用](2024年04月17日/Open-Ended_Wargames_with_Large_Language_Models.md)

- [VG4D: Vision-Language Model Goes 4D Video Recognition](2024年04月17日/VG4D_Vision-Language_Model_Goes_4D_Video_Recognition.md)

    - [翻译: VG4D：视觉与语言模型跨入四维视频识别的新纪元](2024年04月17日/VG4D_Vision-Language_Model_Goes_4D_Video_Recognition.md)

- [A Deep Dive into Large Language Models for Automated Bug Localization and Repair](2024年04月17日/A_Deep_Dive_into_Large_Language_Models_for_Automated_Bug_Localization_and_Repair.md)

    - [翻译: 本文深入剖析了大型语言模型在自动化缺陷定位与修复领域的应用。](2024年04月17日/A_Deep_Dive_into_Large_Language_Models_for_Automated_Bug_Localization_and_Repair.md)

- [LLMTune: Accelerate Database Knob Tuning with Large Language Models](2024年04月17日/LLMTune_Accelerate_Database_Knob_Tuning_with_Large_Language_Models.md)

    - [翻译: LLMTune：借助大型语言模型，让数据库参数调优更高效。](2024年04月17日/LLMTune_Accelerate_Database_Knob_Tuning_with_Large_Language_Models.md)

- [On the Scalability of GNNs for Molecular Graphs](2024年04月17日/On_the_Scalability_of_GNNs_for_Molecular_Graphs.md)

    - [翻译: 图神经网络（GNN）在处理分子图时的扩展性研究](2024年04月17日/On_the_Scalability_of_GNNs_for_Molecular_Graphs.md)

- [MoA: Mixture-of-Attention for Subject-Context Disentanglement in Personalized Image Generation](2024年04月17日/MoA_Mixture-of-Attention_for_Subject-Context_Disentanglement_in_Personalized_Image_Generation.md)

    - [翻译: MoA：一种注意力混合机制，专为个性化图像生成中的主体与上下文解耦而设计。](2024年04月17日/MoA_Mixture-of-Attention_for_Subject-Context_Disentanglement_in_Personalized_Image_Generation.md)

- [Quantifying Multilingual Performance of Large Language Models Across Languages](2024年04月17日/Quantifying_Multilingual_Performance_of_Large_Language_Models_Across_Languages.md)

    - [翻译: 本文旨在量化并分析大型语言模型在跨语言应用中的多语言表现。](2024年04月17日/Quantifying_Multilingual_Performance_of_Large_Language_Models_Across_Languages.md)

- [A Lean Simulation Framework for Stress Testing IoT Cloud Systems](2024年04月17日/A_Lean_Simulation_Framework_for_Stress_Testing_IoT_Cloud_Systems.md)

    - [翻译: 本文提出了一个精益的模拟框架，专为物联网云系统的压力测试而设计。](2024年04月17日/A_Lean_Simulation_Framework_for_Stress_Testing_IoT_Cloud_Systems.md)

- [Select and Reorder: A Novel Approach for Neural Sign Language Production](2024年04月17日/Select_and_Reorder_A_Novel_Approach_for_Neural_Sign_Language_Production.md)

    - [翻译: 新颖方法：选择与重组，开启神经手语生成的新篇章](2024年04月17日/Select_and_Reorder_A_Novel_Approach_for_Neural_Sign_Language_Production.md)

- [Pack of LLMs: Model Fusion at Test-Time via Perplexity Optimization](2024年04月17日/Pack_of_LLMs_Model_Fusion_at_Test-Time_via_Perplexity_Optimization.md)

    - [翻译: 大型语言模型集群：在测试阶段通过优化困惑度实现模型融合。](2024年04月17日/Pack_of_LLMs_Model_Fusion_at_Test-Time_via_Perplexity_Optimization.md)

- [Embedding Privacy in Computational Social Science and Artificial Intelligence Research](2024年04月17日/Embedding_Privacy_in_Computational_Social_Science_and_Artificial_Intelligence_Research.md)

    - [翻译: 将隐私保护融入计算社会科学与人工智能研究的实践](2024年04月17日/Embedding_Privacy_in_Computational_Social_Science_and_Artificial_Intelligence_Research.md)

- [Towards Coarse-to-Fine Evaluation of Inference Efficiency for Large Language Models](2024年04月17日/Towards_Coarse-to-Fine_Evaluation_of_Inference_Efficiency_for_Large_Language_Models.md)

    - [翻译: 本研究提出了一种从宏观到微观的评估框架，用以细致考察大型语言模型在推理效率方面的表现。](2024年04月17日/Towards_Coarse-to-Fine_Evaluation_of_Inference_Efficiency_for_Large_Language_Models.md)

- [Paraphrase and Solve: Exploring and Exploiting the Impact of Surface Form on Mathematical Reasoning in Large Language Models](2024年04月17日/Paraphrase_and_Solve_Exploring_and_Exploiting_the_Impact_of_Surface_Form_on_Mathematical_Reasoning_in_Large_Language_Models.md)

    - [翻译: 重构与求解：深入探究并发挥语言表层形式对大型语言模型数学推理能力的影响](2024年04月17日/Paraphrase_and_Solve_Exploring_and_Exploiting_the_Impact_of_Surface_Form_on_Mathematical_Reasoning_in_Large_Language_Models.md)

- [A Federated Learning Approach to Privacy Preserving Offensive Language Identification](2024年04月17日/A_Federated_Learning_Approach_to_Privacy_Preserving_Offensive_Language_Identification.md)

    - [翻译: 本文提出了一种保护隐私的联邦学习方法，用于识别攻击性语言，旨在在不侵犯用户隐私的前提下，提高对网络攻击性言论的识别能力。](2024年04月17日/A_Federated_Learning_Approach_to_Privacy_Preserving_Offensive_Language_Identification.md)

- [Unifying Bias and Unfairness in Information Retrieval: A Survey of Challenges and Opportunities with Large Language Models](2024年04月17日/Unifying_Bias_and_Unfairness_in_Information_Retrieval_A_Survey_of_Challenges_and_Opportunities_with_Large_Language_Models.md)

    - [翻译: 探索信息检索中的偏见与不公：大型语言模型面临的挑战与机遇综述](2024年04月17日/Unifying_Bias_and_Unfairness_in_Information_Retrieval_A_Survey_of_Challenges_and_Opportunities_with_Large_Language_Models.md)

- [AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts](2024年04月17日/AI-Enhanced_Cognitive_Behavioral_Therapy_Deep_Learning_and_Large_Language_Models_for_Extracting_Cognitive_Pathways_from_Social_Media_Texts.md)

    - [翻译: 利用AI提升认知行为疗法：结合深度学习和大型语言模型，从社交媒体文本中挖掘认知路径。](2024年04月17日/AI-Enhanced_Cognitive_Behavioral_Therapy_Deep_Learning_and_Large_Language_Models_for_Extracting_Cognitive_Pathways_from_Social_Media_Texts.md)

- [Concept Induction using LLMs: a user experiment for assessment](2024年04月17日/Concept_Induction_using_LLMs_a_user_experiment_for_assessment.md)

    - [翻译: 通过大型语言模型实现概念归纳：一项旨在评估的用户实验](2024年04月17日/Concept_Induction_using_LLMs_a_user_experiment_for_assessment.md)

- [From Image to Video, what do we need in multimodal LLMs?](2024年04月17日/From_Image_to_Video,_what_do_we_need_in_multimodal_LLMs.md)

    - [翻译: 在多模态的大型语言模型（LLMs）中，我们应如何从图像迈向视频？](2024年04月17日/From_Image_to_Video,_what_do_we_need_in_multimodal_LLMs.md)

- [CAUS: A Dataset for Question Generation based on Human Cognition Leveraging Large Language Models](2024年04月17日/CAUS_A_Dataset_for_Question_Generation_based_on_Human_Cognition_Leveraging_Large_Language_Models.md)

    - [翻译: CAUS：一个依托于人类认知，利用大型语言模型来生成问题的数据集。](2024年04月17日/CAUS_A_Dataset_for_Question_Generation_based_on_Human_Cognition_Leveraging_Large_Language_Models.md)

- [AdvisorQA: Towards Helpful and Harmless Advice-seeking Question Answering with Collective Intelligence](2024年04月17日/AdvisorQA_Towards_Helpful_and_Harmless_Advice-seeking_Question_Answering_with_Collective_Intelligence.md)

    - [翻译: AdvisorQA：借助集体智慧，迈向提供有益且无害的建议型问答系统](2024年04月17日/AdvisorQA_Towards_Helpful_and_Harmless_Advice-seeking_Question_Answering_with_Collective_Intelligence.md)

- [When are Foundation Models Effective? Understanding the Suitability for Pixel-Level Classification Using Multispectral Imagery](2024年04月17日/When_are_Foundation_Models_Effective_Understanding_the_Suitability_for_Pixel-Level_Classification_Using_Multispectral_Imagery.md)

    - [翻译: 何时基础模型更有效？深入探究其在多光谱图像像素级分类任务中的适用性。](2024年04月17日/When_are_Foundation_Models_Effective_Understanding_the_Suitability_for_Pixel-Level_Classification_Using_Multispectral_Imagery.md)

- [Automated Social Science: Language Models as Scientist and Subjects](2024年04月17日/Automated_Social_Science_Language_Models_as_Scientist_and_Subjects.md)

    - [翻译: 自动化社会科学：语言模型的双重角色——科学家与研究主体](2024年04月17日/Automated_Social_Science_Language_Models_as_Scientist_and_Subjects.md)

- [Enhancing Q&A with Domain-Specific Fine-Tuning and Iterative Reasoning: A Comparative Study](2024年04月17日/Enhancing_Q&A_with_Domain-Specific_Fine-Tuning_and_Iterative_Reasoning_A_Comparative_Study.md)

    - [翻译: 通过针对特定领域的精细调整和循环推理，提升问答系统的性能：一项对比分析研究](2024年04月17日/Enhancing_Q&A_with_Domain-Specific_Fine-Tuning_and_Iterative_Reasoning_A_Comparative_Study.md)

- [Retrieval-Augmented Embodied Agents](2024年04月17日/Retrieval-Augmented_Embodied_Agents.md)

    - [翻译: 增强检索的具身智能代理](2024年04月17日/Retrieval-Augmented_Embodied_Agents.md)

- [MemLLM: Finetuning LLMs to Use An Explicit Read-Write Memory](2024年04月17日/MemLLM_Finetuning_LLMs_to_Use_An_Explicit_Read-Write_Memory.md)

    - [翻译: MemLLM：为大型语言模型（LLM）定制优化，引入明确的读写记忆功能。](2024年04月17日/MemLLM_Finetuning_LLMs_to_Use_An_Explicit_Read-Write_Memory.md)

- [3D object quality prediction for Metal Jet Printer with Multimodal thermal encoder](2024年04月17日/3D_object_quality_prediction_for_Metal_Jet_Printer_with_Multimodal_thermal_encoder.md)

    - [翻译: 采用多模态热编码器技术，对金属喷墨打印机的3D打印对象质量进行精准预测。](2024年04月17日/3D_object_quality_prediction_for_Metal_Jet_Printer_with_Multimodal_thermal_encoder.md)

- [Pretraining Billion-scale Geospatial Foundational Models on Frontier](2024年04月17日/Pretraining_Billion-scale_Geospatial_Foundational_Models_on_Frontier.md)

    - [翻译: 我们正致力于在前沿科技领域预训练规模达十亿级的地理空间基础模型。](2024年04月17日/Pretraining_Billion-scale_Geospatial_Foundational_Models_on_Frontier.md)

- [TREACLE: Thrifty Reasoning via Context-Aware LLM and Prompt Selection](2024年04月17日/TREACLE_Thrifty_Reasoning_via_Context-Aware_LLM_and_Prompt_Selection.md)

    - [翻译: TREACLE：一种通过考虑上下文的大型语言模型和精心选择的提示来实现高效推理的方法。](2024年04月17日/TREACLE_Thrifty_Reasoning_via_Context-Aware_LLM_and_Prompt_Selection.md)

- [The Landscape of Emerging AI Agent Architectures for Reasoning, Planning, and Tool Calling: A Survey](2024年04月17日/The_Landscape_of_Emerging_AI_Agent_Architectures_for_Reasoning,_Planning,_and_Tool_Calling_A_Survey.md)

    - [翻译: 探索新兴AI代理架构：推理、规划与工具调用的全景调查](2024年04月17日/The_Landscape_of_Emerging_AI_Agent_Architectures_for_Reasoning,_Planning,_and_Tool_Calling_A_Survey.md)

2024年04月16日

- [Construction of Domain-specified Japanese Large Language Model for Finance through Continual Pre-training](2024年04月16日/Construction_of_Domain-specified_Japanese_Large_Language_Model_for_Finance_through_Continual_Pre-training.md)

    - [翻译: 本研究旨在通过持续预训练的方法，打造一款专门针对金融领域的日语大型语言模型。](2024年04月16日/Construction_of_Domain-specified_Japanese_Large_Language_Model_for_Finance_through_Continual_Pre-training.md)

- [Unveiling the Misuse Potential of Base Large Language Models via In-Context Learning](2024年04月16日/Unveiling_the_Misuse_Potential_of_Base_Large_Language_Models_via_In-Context_Learning.md)

    - [翻译: 借助上下文学习，探究基础大型语言模型潜在的滥用风险](2024年04月16日/Unveiling_the_Misuse_Potential_of_Base_Large_Language_Models_via_In-Context_Learning.md)

- [CoTAR: Chain-of-Thought Attribution Reasoning with Multi-level Granularity](2024年04月16日/CoTAR_Chain-of-Thought_Attribution_Reasoning_with_Multi-level_Granularity.md)

    - [翻译: CoTAR：采用多级细节的思考路径归因分析](2024年04月16日/CoTAR_Chain-of-Thought_Attribution_Reasoning_with_Multi-level_Granularity.md)

- [White Men Lead, Black Women Help: Uncovering Gender, Racial, and Intersectional Bias in Language Agency](2024年04月16日/White_Men_Lead,_Black_Women_Help_Uncovering_Gender,_Racial,_and_Intersectional_Bias_in_Language_Agency.md)

    - [翻译: 白人男性主导，黑人女性助力：揭秘语言代理中的性别、种族及交叉性偏见。](2024年04月16日/White_Men_Lead,_Black_Women_Help_Uncovering_Gender,_Racial,_and_Intersectional_Bias_in_Language_Agency.md)

- [When Emotional Stimuli meet Prompt Designing: An Auto-Prompt Graphical Paradigm](2024年04月16日/When_Emotional_Stimuli_meet_Prompt_Designing_An_Auto-Prompt_Graphical_Paradigm.md)

    - [翻译: 情感刺激与提示设计相遇：探索自动生成提示的图形化方法](2024年04月16日/When_Emotional_Stimuli_meet_Prompt_Designing_An_Auto-Prompt_Graphical_Paradigm.md)

- [Spiral of Silences: How is Large Language Model Killing Information Retrieval? -- A Case Study on Open Domain Question Answering](2024年04月16日/Spiral_of_Silences_How_is_Large_Language_Model_Killing_Information_Retrieval_--_A_Case_Study_on_Open_Domain_Question_Answering.md)

    - [翻译: 沉默螺旋：大型语言模型如何影响信息检索？以开放领域问答为案例进行探讨。](2024年04月16日/Spiral_of_Silences_How_is_Large_Language_Model_Killing_Information_Retrieval_--_A_Case_Study_on_Open_Domain_Question_Answering.md)

- [DESTEIN: Navigating Detoxification of Language Models via Universal Steering Pairs and Head-wise Activation Fusion](2024年04月16日/DESTEIN_Navigating_Detoxification_of_Language_Models_via_Universal_Steering_Pairs_and_Head-wise_Activation_Fusion.md)

    - [翻译: DESTEIN：利用通用指令对和逐步激活整合技术引导语言模型净化之旅](2024年04月16日/DESTEIN_Navigating_Detoxification_of_Language_Models_via_Universal_Steering_Pairs_and_Head-wise_Activation_Fusion.md)

- [MEEL: Multi-Modal Event Evolution Learning](2024年04月16日/MEEL_Multi-Modal_Event_Evolution_Learning.md)

    - [翻译: MEEL 代表多模态事件演化学习，这是一种结合多种数据形式以更好地理解和学习事件发展过程的方法。](2024年04月16日/MEEL_Multi-Modal_Event_Evolution_Learning.md)

- [VDTuner: Automated Performance Tuning for Vector Data Management Systems](2024年04月16日/VDTuner_Automated_Performance_Tuning_for_Vector_Data_Management_Systems.md)

    - [翻译: VDTuner：自动优化向量数据管理系统的性能](2024年04月16日/VDTuner_Automated_Performance_Tuning_for_Vector_Data_Management_Systems.md)

- [Reasoning on Efficient Knowledge Paths:Knowledge Graph Guides Large Language Model for Domain Question Answering](2024年04月16日/Reasoning_on_Efficient_Knowledge_PathsKnowledge_Graph_Guides_Large_Language_Model_for_Domain_Question_Answering.md)

    - [翻译: 高效知识路径推理：知识图谱助力大型语言模型解答领域问题](2024年04月16日/Reasoning_on_Efficient_Knowledge_PathsKnowledge_Graph_Guides_Large_Language_Model_for_Domain_Question_Answering.md)

- [Self-Explore to Avoid the Pit: Improving the Reasoning Capabilities of Language Models with Fine-grained Rewards](2024年04月16日/Self-Explore_to_Avoid_the_Pit_Improving_the_Reasoning_Capabilities_of_Language_Models_with_Fine-grained_Rewards.md)

    - [翻译: 探索自救，远离陷阱：利用精细奖励机制增强语言模型的推理能力](2024年04月16日/Self-Explore_to_Avoid_the_Pit_Improving_the_Reasoning_Capabilities_of_Language_Models_with_Fine-grained_Rewards.md)

- [Efficiently Adversarial Examples Generation for Visual-Language Models under Targeted Transfer Scenarios using Diffusion Models](2024年04月16日/Efficiently_Adversarial_Examples_Generation_for_Visual-Language_Models_under_Targeted_Transfer_Scenarios_using_Diffusion_Models.md)

    - [翻译: 针对特定目标转移情境，本研究利用扩散模型，探索了一种高效的生成视觉-语言模型对抗样本的方法。](2024年04月16日/Efficiently_Adversarial_Examples_Generation_for_Visual-Language_Models_under_Targeted_Transfer_Scenarios_using_Diffusion_Models.md)

- [Prescribing the Right Remedy: Mitigating Hallucinations in Large Vision-Language Models via Targeted Instruction Tuning](2024年04月16日/Prescribing_the_Right_Remedy_Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_Targeted_Instruction_Tuning.md)

    - [翻译: 对症下药：通过针对性指令调整，缓解大型视觉-语言模型中的幻觉问题](2024年04月16日/Prescribing_the_Right_Remedy_Mitigating_Hallucinations_in_Large_Vision-Language_Models_via_Targeted_Instruction_Tuning.md)

- [Towards Complex Ontology Alignment using Large Language Models](2024年04月16日/Towards_Complex_Ontology_Alignment_using_Large_Language_Models.md)

    - [翻译: 利用大型语言模型实现复杂本体的精准对齐](2024年04月16日/Towards_Complex_Ontology_Alignment_using_Large_Language_Models.md)

- [Exact and Efficient Unlearning for Large Language Model-based Recommendation](2024年04月16日/Exact_and_Efficient_Unlearning_for_Large_Language_Model-based_Recommendation.md)

    - [翻译: 在大型语言模型驱动的推荐系统中，实现精确而高效的“忘却”机制显得尤为关键。](2024年04月16日/Exact_and_Efficient_Unlearning_for_Large_Language_Model-based_Recommendation.md)

- [LLMs4OM: Matching Ontologies with Large Language Models](2024年04月16日/LLMs4OM_Matching_Ontologies_with_Large_Language_Models.md)

    - [翻译: LLMs4OM：借助大型语言模型实现本体匹配](2024年04月16日/LLMs4OM_Matching_Ontologies_with_Large_Language_Models.md)

- [Enhancing Confidence Expression in Large Language Models Through Learning from Past Experience](2024年04月16日/Enhancing_Confidence_Expression_in_Large_Language_Models_Through_Learning_from_Past_Experience.md)

    - [翻译: 本研究探讨了如何通过借鉴历史经验，增强大型语言模型在表达信心方面的能力。](2024年04月16日/Enhancing_Confidence_Expression_in_Large_Language_Models_Through_Learning_from_Past_Experience.md)

- [Hierarchical Context Merging: Better Long Context Understanding for Pre-trained LLMs](2024年04月16日/Hierarchical_Context_Merging_Better_Long_Context_Understanding_for_Pre-trained_LLMs.md)

    - [翻译: 通过层级上下文融合，我们能够提升预训练大型语言模型对长篇幅上下文的把握与理解能力。](2024年04月16日/Hierarchical_Context_Merging_Better_Long_Context_Understanding_for_Pre-trained_LLMs.md)

- [Balancing Speciality and Versatility: a Coarse to Fine Framework for Supervised Fine-tuning Large Language Model](2024年04月16日/Balancing_Speciality_and_Versatility_a_Coarse_to_Fine_Framework_for_Supervised_Fine-tuning_Large_Language_Model.md)

    - [翻译: 为了兼顾专业性与通用性，本文提出了一种由粗到细的监督微调框架，旨在优化大型语言模型的性能。](2024年04月16日/Balancing_Speciality_and_Versatility_a_Coarse_to_Fine_Framework_for_Supervised_Fine-tuning_Large_Language_Model.md)

- [LLM-Powered Test Case Generation for Detecting Tricky Bugs](2024年04月16日/LLM-Powered_Test_Case_Generation_for_Detecting_Tricky_Bugs.md)

    - [翻译: 借助大型语言模型（LLM）的力量，我们能够生成测试用例来捕捉那些难以发现的软件缺陷。](2024年04月16日/LLM-Powered_Test_Case_Generation_for_Detecting_Tricky_Bugs.md)

- [Nearly Optimal Algorithms for Contextual Dueling Bandits from Adversarial Feedback](2024年04月16日/Nearly_Optimal_Algorithms_for_Contextual_Dueling_Bandits_from_Adversarial_Feedback.md)

    - [翻译: 通过对抗性反馈优化的情境对决强盗算法接近最优解](2024年04月16日/Nearly_Optimal_Algorithms_for_Contextual_Dueling_Bandits_from_Adversarial_Feedback.md)

- [Deep Learning and LLM-based Methods Applied to Stellar Lightcurve Classification](2024年04月16日/Deep_Learning_and_LLM-based_Methods_Applied_to_Stellar_Lightcurve_Classification.md)

    - [翻译: 深度学习与基于大型语言模型的技术在恒星光变曲线的分类上得到了应用。](2024年04月16日/Deep_Learning_and_LLM-based_Methods_Applied_to_Stellar_Lightcurve_Classification.md)

- [Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study](2024年04月16日/Is_DPO_Superior_to_PPO_for_LLM_Alignment_A_Comprehensive_Study.md)

    - [翻译: 在大型语言模型 (LLM) 对齐方面，DPO 是否超越了 PPO？本研究进行了深入全面的比较分析。](2024年04月16日/Is_DPO_Superior_to_PPO_for_LLM_Alignment_A_Comprehensive_Study.md)

- [An empirical study on code review activity prediction in practice](2024年04月16日/An_empirical_study_on_code_review_activity_prediction_in_practice.md)

    - [翻译: 实际应用中对代码审查活动进行预测的经验性研究](2024年04月16日/An_empirical_study_on_code_review_activity_prediction_in_practice.md)

- [Automating REST API Postman Test Cases Using LLM](2024年04月16日/Automating_REST_API_Postman_Test_Cases_Using_LLM.md)

    - [翻译: 借助大型语言模型 (LLM)，我们可以实现 REST API Postman 测试用例的自动化，从而提高测试效率和准确性。](2024年04月16日/Automating_REST_API_Postman_Test_Cases_Using_LLM.md)

- [ViTextVQA: A Large-Scale Visual Question Answering Dataset for Evaluating Vietnamese Text Comprehension in Images](2024年04月16日/ViTextVQA_A_Large-Scale_Visual_Question_Answering_Dataset_for_Evaluating_Vietnamese_Text_Comprehension_in_Images.md)

    - [翻译: ViTextVQA：一套大型视觉问答数据集，旨在评估图像中的越南文理解能力。](2024年04月16日/ViTextVQA_A_Large-Scale_Visual_Question_Answering_Dataset_for_Evaluating_Vietnamese_Text_Comprehension_in_Images.md)

- [Self-playing Adversarial Language Game Enhances LLM Reasoning](2024年04月16日/Self-playing_Adversarial_Language_Game_Enhances_LLM_Reasoning.md)

    - [翻译: 通过自我对弈的对抗性语言游戏，有效提升了大型语言模型的推理水平。](2024年04月16日/Self-playing_Adversarial_Language_Game_Enhances_LLM_Reasoning.md)

- [HLAT: High-quality Large Language Model Pre-trained on AWS Trainium](2024年04月16日/HLAT_High-quality_Large_Language_Model_Pre-trained_on_AWS_Trainium.md)

    - [翻译: HLAT：依托 AWS Trainium 打造的高品质大型语言模型](2024年04月16日/HLAT_High-quality_Large_Language_Model_Pre-trained_on_AWS_Trainium.md)

- [Private Attribute Inference from Images with Vision-Language Models](2024年04月16日/Private_Attribute_Inference_from_Images_with_Vision-Language_Models.md)

    - [翻译: 通过视觉-语言模型从图像中推断个人隐私属性](2024年04月16日/Private_Attribute_Inference_from_Images_with_Vision-Language_Models.md)

- [Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases](2024年04月16日/Automated_Evaluation_of_Large_Vision-Language_Models_on_Self-driving_Corner_Cases.md)

    - [翻译: 本文探讨了如何对大型视觉-语言模型在自动驾驶领域的边缘案例中进行自动化评估。](2024年04月16日/Automated_Evaluation_of_Large_Vision-Language_Models_on_Self-driving_Corner_Cases.md)

- [MiniCheck: Efficient Fact-Checking of LLMs on Grounding Documents](2024年04月16日/MiniCheck_Efficient_Fact-Checking_of_LLMs_on_Grounding_Documents.md)

    - [翻译: MiniCheck：一种高效的事实核查工具，专为在基础文档上验证大型语言模型（LLMs）的准确性而设计。](2024年04月16日/MiniCheck_Efficient_Fact-Checking_of_LLMs_on_Grounding_Documents.md)

- [An Empirical Evaluation of Pre-trained Large Language Models for Repairing Declarative Formal Specifications](2024年04月16日/An_Empirical_Evaluation_of_Pre-trained_Large_Language_Models_for_Repairing_Declarative_Formal_Specifications.md)

    - [翻译: 本研究通过实证评估，探讨了预训练的大型语言模型在修复声明式形式规范方面的应用和效果。](2024年04月16日/An_Empirical_Evaluation_of_Pre-trained_Large_Language_Models_for_Repairing_Declarative_Formal_Specifications.md)

- [Stepwise Alignment for Constrained Language Model Policy Optimization](2024年04月16日/Stepwise_Alignment_for_Constrained_Language_Model_Policy_Optimization.md)

    - [翻译: 渐进式对齐：优化受限语言模型策略的新途径](2024年04月16日/Stepwise_Alignment_for_Constrained_Language_Model_Policy_Optimization.md)

- [Offset Unlearning for Large Language Models](2024年04月16日/Offset_Unlearning_for_Large_Language_Models.md)

    - [翻译: 为大型语言模型消除偏差学习](2024年04月16日/Offset_Unlearning_for_Large_Language_Models.md)

- [On the Empirical Complexity of Reasoning and Planning in LLMs](2024年04月16日/On_the_Empirical_Complexity_of_Reasoning_and_Planning_in_LLMs.md)

    - [翻译: 探究大型语言模型在推理与规划方面的经验复杂性](2024年04月16日/On_the_Empirical_Complexity_of_Reasoning_and_Planning_in_LLMs.md)

- [Empowering Large Language Models on Robotic Manipulation with Affordance Prompting](2024年04月16日/Empowering_Large_Language_Models_on_Robotic_Manipulation_with_Affordance_Prompting.md)

    - [翻译: 通过提供可负担性提示，我们增强了大型语言模型在机器人操控领域的应用能力。](2024年04月16日/Empowering_Large_Language_Models_on_Robotic_Manipulation_with_Affordance_Prompting.md)

- [Many-Shot In-Context Learning](2024年04月16日/Many-Shot_In-Context_Learning.md)

    - [翻译: 多次射击上下文学习](2024年04月16日/Many-Shot_In-Context_Learning.md)

- [OVAL-Prompt: Open-Vocabulary Affordance Localization for Robot Manipulation through LLM Affordance-Grounding](2024年04月16日/OVAL-Prompt_Open-Vocabulary_Affordance_Localization_for_Robot_Manipulation_through_LLM_Affordance-Grounding.md)

    - [翻译: OVAL-Prompt：一种开放式词汇的可操作性定位方法，利用大型语言模型（LLM）为机器人操控提供支持。](2024年04月16日/OVAL-Prompt_Open-Vocabulary_Affordance_Localization_for_Robot_Manipulation_through_LLM_Affordance-Grounding.md)

- [Automating Personalized Parsons Problems with Customized Contexts and Concepts](2024年04月16日/Automating_Personalized_Parsons_Problems_with_Customized_Contexts_and_Concepts.md)

    - [翻译: 通过定制上下文和概念，实现个性化帕森斯问题的自动化解决方案。](2024年04月16日/Automating_Personalized_Parsons_Problems_with_Customized_Contexts_and_Concepts.md)

- [A Survey on Retrieval-Augmented Text Generation for Large Language Models](2024年04月16日/A_Survey_on_Retrieval-Augmented_Text_Generation_for_Large_Language_Models.md)

    - [翻译: 针对大型语言模型，本文进行了一项关于检索增强文本生成的研究调查。](2024年04月16日/A_Survey_on_Retrieval-Augmented_Text_Generation_for_Large_Language_Models.md)

- [Procedural Dilemma Generation for Evaluating Moral Reasoning in Humans and Language Models](2024年04月16日/Procedural_Dilemma_Generation_for_Evaluating_Moral_Reasoning_in_Humans_and_Language_Models.md)

    - [翻译: 生成程序性道德困境，以评估人类和语言模型的道德推理能力。](2024年04月16日/Procedural_Dilemma_Generation_for_Evaluating_Moral_Reasoning_in_Humans_and_Language_Models.md)

- [Uncertainty-Based Abstention in LLMs Improves Safety and Reduces Hallucinations](2024年04月16日/Uncertainty-Based_Abstention_in_LLMs_Improves_Safety_and_Reduces_Hallucinations.md)

    - [翻译: 在大型语言模型（LLM）中，采纳基于不确定性的策略可以显著提升模型的安全性，同时有效减少错误信息的产生，即所谓的“幻觉”现象。](2024年04月16日/Uncertainty-Based_Abstention_in_LLMs_Improves_Safety_and_Reduces_Hallucinations.md)

- [Shears: Unstructured Sparsity with Neural Low-rank Adapter Search](2024年04月16日/Shears_Unstructured_Sparsity_with_Neural_Low-rank_Adapter_Search.md)

    - [翻译: Shears：利用神经网络低秩适配器搜索技术，实现模型的非结构化稀疏化。](2024年04月16日/Shears_Unstructured_Sparsity_with_Neural_Low-rank_Adapter_Search.md)

- [LLMem: Estimating GPU Memory Usage for Fine-Tuning Pre-Trained LLMs](2024年04月16日/LLMem_Estimating_GPU_Memory_Usage_for_Fine-Tuning_Pre-Trained_LLMs.md)

    - [翻译: LLMem：为预训练的大型语言模型（LLM）的微调过程估算 GPU 内存需求。](2024年04月16日/LLMem_Estimating_GPU_Memory_Usage_for_Fine-Tuning_Pre-Trained_LLMs.md)

- [Teaching a Multilingual Large Language Model to Understand Multilingual Speech via Multi-Instructional Training](2024年04月16日/Teaching_a_Multilingual_Large_Language_Model_to_Understand_Multilingual_Speech_via_Multi-Instructional_Training.md)

    - [翻译: 本文介绍了一种多指令训练方法，旨在提升多语言大型语言模型对多语言语音的理解能力。通过这种方法，模型能够更准确地识别和处理不同语言的语音输入，从而在多语言语音识别和理解方面取得更好的性能。](2024年04月16日/Teaching_a_Multilingual_Large_Language_Model_to_Understand_Multilingual_Speech_via_Multi-Instructional_Training.md)

- [From a Lossless (~1.5:1) Compression Algorithm for Llama2 7B Weights to Variable Precision, Variable Range, Compressed Numeric Data Types for CNNs and LLMs](2024年04月16日/From_a_Lossless_(~1.51)_Compression_Algorithm_for_Llama2_7B_Weights_to_Variable_Precision,_Variable_Range,_Compressed_Numeric_Data_Types_for_CNNs_and_LLMs.md)

    - [翻译: 我们提出了一种无损压缩算法，专为 Llama2 7B 模型的权重设计，压缩比接近1.5:1。此外，我们还开发了一种适用于卷积神经网络和大型语言模型的新型压缩数值数据类型，这些数据类型具备可变精度和可变范围的特性。](2024年04月16日/From_a_Lossless_(~1.51)_Compression_Algorithm_for_Llama2_7B_Weights_to_Variable_Precision,_Variable_Range,_Compressed_Numeric_Data_Types_for_CNNs_and_LLMs.md)

- [Exploring Augmentation and Cognitive Strategies for AI based Synthetic Personae](2024年04月16日/Exploring_Augmentation_and_Cognitive_Strategies_for_AI_based_Synthetic_Personae.md)

    - [翻译: 本文旨在探讨如何通过增强和认知策略，提升基于人工智能合成人物角色的性能。](2024年04月16日/Exploring_Augmentation_and_Cognitive_Strategies_for_AI_based_Synthetic_Personae.md)

- [Course Recommender Systems Need to Consider the Job Market](2024年04月16日/Course_Recommender_Systems_Need_to_Consider_the_Job_Market.md)

    - [翻译: 课程推荐系统在设计时必须顾及就业市场的需求。](2024年04月16日/Course_Recommender_Systems_Need_to_Consider_the_Job_Market.md)

- [A Dataset for Large Language Model-Driven AI Accelerator Generation](2024年04月16日/A_Dataset_for_Large_Language_Model-Driven_AI_Accelerator_Generation.md)

    - [翻译: 为大型语言模型所驱动的人工智能加速器生成而设计的数据集。](2024年04月16日/A_Dataset_for_Large_Language_Model-Driven_AI_Accelerator_Generation.md)

- [Vocabulary-free Image Classification and Semantic Segmentation](2024年04月16日/Vocabulary-free_Image_Classification_and_Semantic_Segmentation.md)

    - [翻译: 无需词汇的图像分类与语义分割技术](2024年04月16日/Vocabulary-free_Image_Classification_and_Semantic_Segmentation.md)

- [Forcing Diffuse Distributions out of Language Models](2024年04月16日/Forcing_Diffuse_Distributions_out_of_Language_Models.md)

    - [翻译: 从语言模型中驱逐扩散分布](2024年04月16日/Forcing_Diffuse_Distributions_out_of_Language_Models.md)

- [D3CODE: Disentangling Disagreements in Data across Cultures on Offensiveness Detection and Evaluation](2024年04月16日/D3CODE_Disentangling_Disagreements_in_Data_across_Cultures_on_Offensiveness_Detection_and_Evaluation.md)

    - [翻译: D3CODE：揭示跨文化数据中关于冒犯性识别与评估的分歧。](2024年04月16日/D3CODE_Disentangling_Disagreements_in_Data_across_Cultures_on_Offensiveness_Detection_and_Evaluation.md)

- [Dynamic Self-adaptive Multiscale Distillation from Pre-trained Multimodal Large Model for Efficient Cross-modal Representation Learning](2024年04月16日/Dynamic_Self-adaptive_Multiscale_Distillation_from_Pre-trained_Multimodal_Large_Model_for_Efficient_Cross-modal_Representation_Learning.md)

    - [翻译: 本研究提出了一种动态自适应的多尺度蒸馏方法，该方法源自预训练的多模态大型模型，旨在实现高效的跨模态表示学习。通过这种方法，我们能够从大规模多模态数据中提取深层次的特征，进而提升模型在不同模态任务上的表现。](2024年04月16日/Dynamic_Self-adaptive_Multiscale_Distillation_from_Pre-trained_Multimodal_Large_Model_for_Efficient_Cross-modal_Representation_Learning.md)

- [Fewer Truncations Improve Language Modeling](2024年04月16日/Fewer_Truncations_Improve_Language_Modeling.md)

    - [翻译: 减少截断，优化语言模型性能](2024年04月16日/Fewer_Truncations_Improve_Language_Modeling.md)

- [Multi-Task Multi-Modal Self-Supervised Learning for Facial Expression Recognition](2024年04月16日/Multi-Task_Multi-Modal_Self-Supervised_Learning_for_Facial_Expression_Recognition.md)

    - [翻译: 多模态自监督学习在面部表情识别任务中实现了多任务处理能力。](2024年04月16日/Multi-Task_Multi-Modal_Self-Supervised_Learning_for_Facial_Expression_Recognition.md)

- [SuRe: Summarizing Retrievals using Answer Candidates for Open-domain QA of LLMs](2024年04月16日/SuRe_Summarizing_Retrievals_using_Answer_Candidates_for_Open-domain_QA_of_LLMs.md)

    - [翻译: SuRe：为大型语言模型（LLMs）的开放域问答任务，通过候选答案对检索结果进行精炼总结。](2024年04月16日/SuRe_Summarizing_Retrievals_using_Answer_Candidates_for_Open-domain_QA_of_LLMs.md)

2024年04月15日

- [Harnessing GPT-4V(ision) for Insurance: A Preliminary Exploration](2024年04月15日/Harnessing_GPT-4V(ision)_for_Insurance_A_Preliminary_Exploration.md)

    - [翻译: 探索 GPT-4V(ision) 在保险领域的应用：一项初步研究](2024年04月15日/Harnessing_GPT-4V(ision)_for_Insurance_A_Preliminary_Exploration.md)

- [Bridging Vision and Language Spaces with Assignment Prediction](2024年04月15日/Bridging_Vision_and_Language_Spaces_with_Assignment_Prediction.md)

    - [翻译: 通过预测任务分配，架起视觉与语言之间的桥梁](2024年04月15日/Bridging_Vision_and_Language_Spaces_with_Assignment_Prediction.md)

- [AesExpert: Towards Multi-modality Foundation Model for Image Aesthetics Perception](2024年04月15日/AesExpert_Towards_Multi-modality_Foundation_Model_for_Image_Aesthetics_Perception.md)

    - [翻译: AesExpert：探索构建多模态基础模型，以提升图像美学感知能力。](2024年04月15日/AesExpert_Towards_Multi-modality_Foundation_Model_for_Image_Aesthetics_Perception.md)

- [MMCode: Evaluating Multi-Modal Code Large Language Models with Visually Rich Programming Problems](2024年04月15日/MMCode_Evaluating_Multi-Modal_Code_Large_Language_Models_with_Visually_Rich_Programming_Problems.md)

    - [翻译: MMCode：利用视觉丰富的编程挑战，评估融合多模态信息的大型语言模型。](2024年04月15日/MMCode_Evaluating_Multi-Modal_Code_Large_Language_Models_with_Visually_Rich_Programming_Problems.md)

- [in2IN: Leveraging individual Information to Generate Human INteractions](2024年04月15日/in2IN_Leveraging_individual_Information_to_Generate_Human_INteractions.md)

    - [翻译: in2IN：借助个体信息打造真实人际互动体验](2024年04月15日/in2IN_Leveraging_individual_Information_to_Generate_Human_INteractions.md)

- [OneChart: Purify the Chart Structural Extraction via One Auxiliary Token](2024年04月15日/OneChart_Purify_the_Chart_Structural_Extraction_via_One_Auxiliary_Token.md)

    - [翻译: OneChart：利用单一辅助标记净化图表结构提取过程。](2024年04月15日/OneChart_Purify_the_Chart_Structural_Extraction_via_One_Auxiliary_Token.md)

- [Memory Sharing for Large Language Model based Agents](2024年04月15日/Memory_Sharing_for_Large_Language_Model_based_Agents.md)

    - [翻译: 在大型语言模型代理中，内存共享的策略得以运用。](2024年04月15日/Memory_Sharing_for_Large_Language_Model_based_Agents.md)

- [Context Does Matter: Implications for Crowdsourced Evaluation Labels in Task-Oriented Dialogue Systems](2024年04月15日/Context_Does_Matter_Implications_for_Crowdsourced_Evaluation_Labels_in_Task-Oriented_Dialogue_Systems.md)

    - [翻译: 上下文在任务导向对话系统的众包评估标签中具有重要意义。](2024年04月15日/Context_Does_Matter_Implications_for_Crowdsourced_Evaluation_Labels_in_Task-Oriented_Dialogue_Systems.md)

- [Constructing Benchmarks and Interventions for Combating Hallucinations in LLMs](2024年04月15日/Constructing_Benchmarks_and_Interventions_for_Combating_Hallucinations_in_LLMs.md)

    - [翻译: 为了对抗大型语言模型中的幻觉现象，我们正在构建一系列基准测试和干预策略。](2024年04月15日/Constructing_Benchmarks_and_Interventions_for_Combating_Hallucinations_in_LLMs.md)

- [Tango 2: Aligning Diffusion-based Text-to-Audio Generations through Direct Preference Optimization](2024年04月15日/Tango_2_Aligning_Diffusion-based_Text-to-Audio_Generations_through_Direct_Preference_Optimization.md)

    - [翻译: Tango 2：借助直接偏好优化技术，实现基于扩散模型的文本到音频生成精准对齐](2024年04月15日/Tango_2_Aligning_Diffusion-based_Text-to-Audio_Generations_through_Direct_Preference_Optimization.md)

- [LLMorpheus: Mutation Testing using Large Language Models](2024年04月15日/LLMorpheus_Mutation_Testing_using_Large_Language_Models.md)

    - [翻译: LLMorpheus：借助大型语言模型进行变异测试研究](2024年04月15日/LLMorpheus_Mutation_Testing_using_Large_Language_Models.md)

- [Knowledge-enhanced Visual-Language Pretraining for Computational Pathology](2024年04月15日/Knowledge-enhanced_Visual-Language_Pretraining_for_Computational_Pathology.md)

    - [翻译: 计算病理学领域中，通过知识增强的视觉-语言预训练方法，旨在提升模型的性能。](2024年04月15日/Knowledge-enhanced_Visual-Language_Pretraining_for_Computational_Pathology.md)

- [Evolving Interpretable Visual Classifiers with Large Language Models](2024年04月15日/Evolving_Interpretable_Visual_Classifiers_with_Large_Language_Models.md)

    - [翻译: 通过结合大型语言模型，我们不断优化和提升视觉分类器的可解释性。](2024年04月15日/Evolving_Interpretable_Visual_Classifiers_with_Large_Language_Models.md)

- [A Survey on Deep Learning for Theorem Proving](2024年04月15日/A_Survey_on_Deep_Learning_for_Theorem_Proving.md)

    - [翻译: 本文综述了深度学习在定理证明领域的研究进展。](2024年04月15日/A_Survey_on_Deep_Learning_for_Theorem_Proving.md)

- [Compression Represents Intelligence Linearly](2024年04月15日/Compression_Represents_Intelligence_Linearly.md)

    - [翻译: 压缩与智能之间呈现出线性的正相关性。](2024年04月15日/Compression_Represents_Intelligence_Linearly.md)

- [HOI-Ref: Hand-Object Interaction Referral in Egocentric Vision](2024年04月15日/HOI-Ref_Hand-Object_Interaction_Referral_in_Egocentric_Vision.md)

    - [翻译: HOI-Ref：自我视角视觉中的手部与物体互动参照](2024年04月15日/HOI-Ref_Hand-Object_Interaction_Referral_in_Egocentric_Vision.md)

- [Foundational Challenges in Assuring Alignment and Safety of Large Language Models](2024年04月15日/Foundational_Challenges_in_Assuring_Alignment_and_Safety_of_Large_Language_Models.md)

    - [翻译: 在确保大型语言模型的一致性和安全性方面，我们面临着根本性的挑战。](2024年04月15日/Foundational_Challenges_in_Assuring_Alignment_and_Safety_of_Large_Language_Models.md)

- [Zero-shot detection of buildings in mobile LiDAR using Language Vision Model](2024年04月15日/Zero-shot_detection_of_buildings_in_mobile_LiDAR_using_Language_Vision_Model.md)

    - [翻译: 借助语言视觉模型，实现移动激光雷达中建筑物的零次检测。](2024年04月15日/Zero-shot_detection_of_buildings_in_mobile_LiDAR_using_Language_Vision_Model.md)

- [Zero-shot Building Age Classification from Facade Image Using GPT-4](2024年04月15日/Zero-shot_Building_Age_Classification_from_Facade_Image_Using_GPT-4.md)

    - [翻译: 借助 GPT-4，我们能够直接从建筑立面图片中判断建筑的年代，无需事先了解具体建筑信息。](2024年04月15日/Zero-shot_Building_Age_Classification_from_Facade_Image_Using_GPT-4.md)

- [Glitch Tokens in Large Language Models: Categorization Taxonomy and Effective Detection](2024年04月15日/Glitch_Tokens_in_Large_Language_Models_Categorization_Taxonomy_and_Effective_Detection.md)

    - [翻译: 大型语言模型里，错误标记的分类及其检测策略。](2024年04月15日/Glitch_Tokens_in_Large_Language_Models_Categorization_Taxonomy_and_Effective_Detection.md)

- [Conditional Prototype Rectification Prompt Learning](2024年04月15日/Conditional_Prototype_Rectification_Prompt_Learning.md)

    - [翻译: 条件原型调整提示学习法](2024年04月15日/Conditional_Prototype_Rectification_Prompt_Learning.md)

- [AI-Driven Statutory Reasoning via Software Engineering Methods](2024年04月15日/AI-Driven_Statutory_Reasoning_via_Software_Engineering_Methods.md)

    - [翻译: 借助软件工程技术，实现人工智能推动的法定逻辑推理。](2024年04月15日/AI-Driven_Statutory_Reasoning_via_Software_Engineering_Methods.md)

- [Reimagining Self-Adaptation in the Age of Large Language Models](2024年04月15日/Reimagining_Self-Adaptation_in_the_Age_of_Large_Language_Models.md)

    - [翻译: 在大型语言模型时代，重新构想自我适应的概念](2024年04月15日/Reimagining_Self-Adaptation_in_the_Age_of_Large_Language_Models.md)

- [Anatomy of Industrial Scale Multilingual ASR](2024年04月15日/Anatomy_of_Industrial_Scale_Multilingual_ASR.md)

    - [翻译: 探究工业级多语言自动语音识别的内在机制](2024年04月15日/Anatomy_of_Industrial_Scale_Multilingual_ASR.md)

- [How Far Have We Gone in Stripped Binary Code Understanding Using Large Language Models](2024年04月15日/How_Far_Have_We_Gone_in_Stripped_Binary_Code_Understanding_Using_Large_Language_Models.md)

    - [翻译: 通过大型语言模型，我们在解析简化的二进制代码理解方面取得了哪些进展？](2024年04月15日/How_Far_Have_We_Gone_in_Stripped_Binary_Code_Understanding_Using_Large_Language_Models.md)

- [Benchmarking Llama2, Mistral, Gemma and GPT for Factuality, Toxicity, Bias and Propensity for Hallucinations](2024年04月15日/Benchmarking_Llama2,_Mistral,_Gemma_and_GPT_for_Factuality,_Toxicity,_Bias_and_Propensity_for_Hallucinations.md)

    - [翻译: 本研究旨在对Llama2、Mistral、Gemma以及GPT等模型进行综合评估，探究它们在事实准确性、有害内容产生、偏见表现以及产生幻觉文本的倾向上的差异性。](2024年04月15日/Benchmarking_Llama2,_Mistral,_Gemma_and_GPT_for_Factuality,_Toxicity,_Bias_and_Propensity_for_Hallucinations.md)

- [Language-Agnostic Modeling of Wikipedia Articles for Content Quality Assessment across Languages](2024年04月15日/Language-Agnostic_Modeling_of_Wikipedia_Articles_for_Content_Quality_Assessment_across_Languages.md)

    - [翻译: 本文提出了一种语言无关的方法，用于评估维基百科文章的内容质量，该方法适用于不同语言。](2024年04月15日/Language-Agnostic_Modeling_of_Wikipedia_Articles_for_Content_Quality_Assessment_across_Languages.md)

- [KG-CTG: Citation Generation through Knowledge Graph-guided Large Language Models](2024年04月15日/KG-CTG_Citation_Generation_through_Knowledge_Graph-guided_Large_Language_Models.md)

    - [翻译: KG-CTG：借助知识图谱引导的大型语言模型实现引文自动生成](2024年04月15日/KG-CTG_Citation_Generation_through_Knowledge_Graph-guided_Large_Language_Models.md)

- [Resilience of Large Language Models for Noisy Instructions](2024年04月15日/Resilience_of_Large_Language_Models_for_Noisy_Instructions.md)

    - [翻译: 大型语言模型在应对噪声指令时展现出的韧性](2024年04月15日/Resilience_of_Large_Language_Models_for_Noisy_Instructions.md)

- [Personalized Collaborative Fine-Tuning for On-Device Large Language Models](2024年04月15日/Personalized_Collaborative_Fine-Tuning_for_On-Device_Large_Language_Models.md)

    - [翻译: 针对移动设备的大型语言模型，采用个性化协同微调技术](2024年04月15日/Personalized_Collaborative_Fine-Tuning_for_On-Device_Large_Language_Models.md)

- [AMPCliff: quantitative definition and benchmarking of activity cliffs in antimicrobial peptides](2024年04月15日/AMPCliff_quantitative_definition_and_benchmarking_of_activity_cliffs_in_antimicrobial_peptides.md)

    - [翻译: AMPCliff 研究：为抗微生物肽中的活性差异设立定量标准，并进行性能基准评估](2024年04月15日/AMPCliff_quantitative_definition_and_benchmarking_of_activity_cliffs_in_antimicrobial_peptides.md)

- [Quantization of Large Language Models with an Overdetermined Basis](2024年04月15日/Quantization_of_Large_Language_Models_with_an_Overdetermined_Basis.md)

    - [翻译: 通过过定基数基实现大型语言模型的量化](2024年04月15日/Quantization_of_Large_Language_Models_with_an_Overdetermined_Basis.md)

- [Unveiling Imitation Learning: Exploring the Impact of Data Falsity to Large Language Model](2024年04月15日/Unveiling_Imitation_Learning_Exploring_the_Impact_of_Data_Falsity_to_Large_Language_Model.md)

    - [翻译: 揭秘模仿学习：探究数据不真实性如何影响大型语言模型的表现。](2024年04月15日/Unveiling_Imitation_Learning_Exploring_the_Impact_of_Data_Falsity_to_Large_Language_Model.md)

- [Enhancing Robot Explanation Capabilities through Vision-Language Models: a Preliminary Study by Interpreting Visual Inputs for Improved Human-Robot Interaction](2024年04月15日/Enhancing_Robot_Explanation_Capabilities_through_Vision-Language_Models_a_Preliminary_Study_by_Interpreting_Visual_Inputs_for_Improved_Human-Robot_Interaction.md)

    - [翻译: 本初步研究探讨了如何通过视觉-语言模型提升机器人的解释能力，通过解读视觉信息来优化人机互动体验。](2024年04月15日/Enhancing_Robot_Explanation_Capabilities_through_Vision-Language_Models_a_Preliminary_Study_by_Interpreting_Visual_Inputs_for_Improved_Human-Robot_Interaction.md)

- [Generative AI for Game Theory-based Mobile Networking](2024年04月15日/Generative_AI_for_Game_Theory-based_Mobile_Networking.md)

    - [翻译: 在移动网络领域，生成性AI运用博弈论原理，为网络通信带来创新性解决方案。](2024年04月15日/Generative_AI_for_Game_Theory-based_Mobile_Networking.md)

- [Are Large Language Models Reliable Argument Quality Annotators?](2024年04月15日/Are_Large_Language_Models_Reliable_Argument_Quality_Annotators.md)

    - [翻译: 大型语言模型能否成为值得信赖的论证质量评价者？](2024年04月15日/Are_Large_Language_Models_Reliable_Argument_Quality_Annotators.md)

- [LoRAP: Transformer Sub-Layers Deserve Differentiated Structured Compression for Large Language Models](2024年04月15日/LoRAP_Transformer_Sub-Layers_Deserve_Differentiated_Structured_Compression_for_Large_Language_Models.md)

    - [翻译: LoRAP: 针对大型语言模型，Transformer子层需差异化结构压缩技术](2024年04月15日/LoRAP_Transformer_Sub-Layers_Deserve_Differentiated_Structured_Compression_for_Large_Language_Models.md)

- [Multi-News+: Cost-efficient Dataset Cleansing via LLM-based Data Annotation](2024年04月15日/Multi-News+_Cost-efficient_Dataset_Cleansing_via_LLM-based_Data_Annotation.md)

    - [翻译: Multi-News+：利用大型语言模型实现高效数据集净化与注释](2024年04月15日/Multi-News+_Cost-efficient_Dataset_Cleansing_via_LLM-based_Data_Annotation.md)

- [Do LLMs Understand Visual Anomalies? Uncovering LLM Capabilities in Zero-shot Anomaly Detection](2024年04月15日/Do_LLMs_Understand_Visual_Anomalies_Uncovering_LLM_Capabilities_in_Zero-shot_Anomaly_Detection.md)

    - [翻译: 大型语言模型能否洞察视觉异常？探究LLM在无先验知识下的异常检测技能。](2024年04月15日/Do_LLMs_Understand_Visual_Anomalies_Uncovering_LLM_Capabilities_in_Zero-shot_Anomaly_Detection.md)

- [UNIAA: A Unified Multi-modal Image Aesthetic Assessment Baseline and Benchmark](2024年04月15日/UNIAA_A_Unified_Multi-modal_Image_Aesthetic_Assessment_Baseline_and_Benchmark.md)

    - [翻译: UNIAA：构建统一的多模态图像审美评估基准与评测标准](2024年04月15日/UNIAA_A_Unified_Multi-modal_Image_Aesthetic_Assessment_Baseline_and_Benchmark.md)

- [A Self-feedback Knowledge Elicitation Approach for Chemical Reaction Predictions](2024年04月15日/A_Self-feedback_Knowledge_Elicitation_Approach_for_Chemical_Reaction_Predictions.md)

    - [翻译: 采用自反馈知识提取方法，提升化学反应预测的准确性](2024年04月15日/A_Self-feedback_Knowledge_Elicitation_Approach_for_Chemical_Reaction_Predictions.md)

- [Improving Recall of Large Language Models: A Model Collaboration Approach for Relational Triple Extraction](2024年04月15日/Improving_Recall_of_Large_Language_Models_A_Model_Collaboration_Approach_for_Relational_Triple_Extraction.md)

    - [翻译: 为了提升大型语言模型在关系三元组提取方面的召回率，本文提出了一种模型协作方法。通过这种方法，多个模型可以协同工作，共同提高对实体间关系的识别和提取能力。](2024年04月15日/Improving_Recall_of_Large_Language_Models_A_Model_Collaboration_Approach_for_Relational_Triple_Extraction.md)

- [Modelling Language](2024年04月15日/Modelling_Language.md)

    - [翻译: 语言建模是一门研究如何根据上下文预测和生成语言数据的科学。](2024年04月15日/Modelling_Language.md)

- [Large language models and linguistic intentionality](2024年04月15日/Large_language_models_and_linguistic_intentionality.md)

    - [翻译: 在探讨大型语言模型时，我们不可忽视语言的意图性。](2024年04月15日/Large_language_models_and_linguistic_intentionality.md)

- [Prepacking: A Simple Method for Fast Prefilling and Increased Throughput in Large Language Models](2024年04月15日/Prepacking_A_Simple_Method_for_Fast_Prefilling_and_Increased_Throughput_in_Large_Language_Models.md)

    - [翻译: 预打包技术：轻松实现大型语言模型的快速填充与吞吐量提升](2024年04月15日/Prepacking_A_Simple_Method_for_Fast_Prefilling_and_Increased_Throughput_in_Large_Language_Models.md)

- [LoongServe: Efficiently Serving Long-context Large Language Models with Elastic Sequence Parallelism](2024年04月15日/LoongServe_Efficiently_Serving_Long-context_Large_Language_Models_with_Elastic_Sequence_Parallelism.md)

    - [翻译: LoongServe 通过灵活的序列并行技术，高效地处理长文本的大型语言模型，以满足不同的需求。](2024年04月15日/LoongServe_Efficiently_Serving_Long-context_Large_Language_Models_with_Elastic_Sequence_Parallelism.md)

- [Bridging the Gap between Different Vocabularies for LLM Ensemble](2024年04月15日/Bridging_the_Gap_between_Different_Vocabularies_for_LLM_Ensemble.md)

    - [翻译: 搭建桥梁，实现大型语言模型集合中词汇差异的融合](2024年04月15日/Bridging_the_Gap_between_Different_Vocabularies_for_LLM_Ensemble.md)

- [Large Language Models Can Automatically Engineer Features for Few-Shot Tabular Learning](2024年04月15日/Large_Language_Models_Can_Automatically_Engineer_Features_for_Few-Shot_Tabular_Learning.md)

    - [翻译: 大型语言模型能够自动设计特征，以助力少次表格学习任务。](2024年04月15日/Large_Language_Models_Can_Automatically_Engineer_Features_for_Few-Shot_Tabular_Learning.md)

- [TextCoT: Zoom In for Enhanced Multimodal Text-Rich Image Understanding](2024年04月15日/TextCoT_Zoom_In_for_Enhanced_Multimodal_Text-Rich_Image_Understanding.md)

    - [翻译: TextCoT：深入探索，提升图文融合的多模态理解](2024年04月15日/TextCoT_Zoom_In_for_Enhanced_Multimodal_Text-Rich_Image_Understanding.md)

- [Uncovering Latent Arguments in Social Media Messaging by Employing LLMs-in-the-Loop Strategy](2024年04月15日/Uncovering_Latent_Arguments_in_Social_Media_Messaging_by_Employing_LLMs-in-the-Loop_Strategy.md)

    - [翻译: 利用LLM参与策略，挖掘社交媒体通讯中的隐性争议。](2024年04月15日/Uncovering_Latent_Arguments_in_Social_Media_Messaging_by_Employing_LLMs-in-the-Loop_Strategy.md)

- [MoE-TinyMed: Mixture of Experts for Tiny Medical Large Vision-Language Models](2024年04月15日/MoE-TinyMed_Mixture_of_Experts_for_Tiny_Medical_Large_Vision-Language_Models.md)

    - [翻译: MoE-TinyMed：面向小型医疗领域的大型视觉-语言模型的专家融合方法](2024年04月15日/MoE-TinyMed_Mixture_of_Experts_for_Tiny_Medical_Large_Vision-Language_Models.md)

- [Generative Text Steganography with Large Language Model](2024年04月15日/Generative_Text_Steganography_with_Large_Language_Model.md)

    - [翻译: 借助大型语言模型，探索生成性文本隐写技术。](2024年04月15日/Generative_Text_Steganography_with_Large_Language_Model.md)

- [Find The Gap: Knowledge Base Reasoning For Visual Question Answering](2024年04月15日/Find_The_Gap_Knowledge_Base_Reasoning_For_Visual_Question_Answering.md)

    - [翻译: 揭秘背后：视觉问答中的知识库逻辑推理](2024年04月15日/Find_The_Gap_Knowledge_Base_Reasoning_For_Visual_Question_Answering.md)

- [Demonstration of DB-GPT: Next Generation Data Interaction System Empowered by Large Language Models](2024年04月15日/Demonstration_of_DB-GPT_Next_Generation_Data_Interaction_System_Empowered_by_Large_Language_Models.md)

    - [翻译: DB-GPT 演示：下一代数据交互系统，由先进的大型语言模型赋能。](2024年04月15日/Demonstration_of_DB-GPT_Next_Generation_Data_Interaction_System_Empowered_by_Large_Language_Models.md)

- [TEL'M: Test and Evaluation of Language Models](2024年04月15日/TEL'M_Test_and_Evaluation_of_Language_Models.md)

    - [翻译: TEL'M：对语言模型进行测试与评价的研究](2024年04月15日/TEL'M_Test_and_Evaluation_of_Language_Models.md)

- [CULTURE-GEN: Revealing Global Cultural Perception in Language Models through Natural Language Prompting](2024年04月15日/CULTURE-GEN_Revealing_Global_Cultural_Perception_in_Language_Models_through_Natural_Language_Prompting.md)

    - [翻译: CULTURE-GEN：透过自然语言提示，探究语言模型中的全球文化认知](2024年04月15日/CULTURE-GEN_Revealing_Global_Cultural_Perception_in_Language_Models_through_Natural_Language_Prompting.md)

- [How faithful are RAG models? Quantifying the tug-of-war between RAG and LLMs' internal prior](2024年04月15日/How_faithful_are_RAG_models_Quantifying_the_tug-of-war_between_RAG_and_LLMs'_internal_prior.md)

    - [翻译: RAG模型的准确性有多高？探究RAG与大型语言模型内在先验之间的相互制衡。](2024年04月15日/How_faithful_are_RAG_models_Quantifying_the_tug-of-war_between_RAG_and_LLMs'_internal_prior.md)

- [Numerical Attributes Learning for Cardiac Failure Diagnostic from Clinical Narratives - A LESA-CamemBERT-bio Approach](2024年04月15日/Numerical_Attributes_Learning_for_Cardiac_Failure_Diagnostic_from_Clinical_Narratives_-_A_LESA-CamemBERT-bio_Approach.md)

    - [翻译: 利用 LESA-CamemBERT-bio 方法，通过临床叙述学习数值属性以诊断心脏衰竭](2024年04月15日/Numerical_Attributes_Learning_for_Cardiac_Failure_Diagnostic_from_Clinical_Narratives_-_A_LESA-CamemBERT-bio_Approach.md)

- [Deceiving to Enlighten: Coaxing LLMs to Self-Reflection for Enhanced Bias Detection and Mitigation](2024年04月15日/Deceiving_to_Enlighten_Coaxing_LLMs_to_Self-Reflection_for_Enhanced_Bias_Detection_and_Mitigation.md)

    - [翻译: 启迪而非欺骗：引导大型语言模型（LLM）自我审视，提升偏见识别与减缓能力。](2024年04月15日/Deceiving_to_Enlighten_Coaxing_LLMs_to_Self-Reflection_for_Enhanced_Bias_Detection_and_Mitigation.md)

- [Quality Assessment of Prompts Used in Code Generation](2024年04月15日/Quality_Assessment_of_Prompts_Used_in_Code_Generation.md)

    - [翻译: 评估代码生成中提示的质量](2024年04月15日/Quality_Assessment_of_Prompts_Used_in_Code_Generation.md)

- [TabSQLify: Enhancing Reasoning Capabilities of LLMs Through Table Decomposition](2024年04月15日/TabSQLify_Enhancing_Reasoning_Capabilities_of_LLMs_Through_Table_Decomposition.md)

    - [翻译: TabSQLify：通过表格解构，提升大型语言模型的推理技能](2024年04月15日/TabSQLify_Enhancing_Reasoning_Capabilities_of_LLMs_Through_Table_Decomposition.md)

- [Cross-Modal Self-Training: Aligning Images and Pointclouds to Learn Classification without Labels](2024年04月15日/Cross-Modal_Self-Training_Aligning_Images_and_Pointclouds_to_Learn_Classification_without_Labels.md)

    - [翻译: 通过跨模态自训练，我们能够将图像与点云数据对齐，从而在无需标签的情况下学习分类，这一方法为无监督学习开辟了新的可能性。](2024年04月15日/Cross-Modal_Self-Training_Aligning_Images_and_Pointclouds_to_Learn_Classification_without_Labels.md)

- [ANCHOR: LLM-driven News Subject Conditioning for Text-to-Image Synthesis](2024年04月15日/ANCHOR_LLM-driven_News_Subject_Conditioning_for_Text-to-Image_Synthesis.md)

    - [翻译: 锚定：借助大型语言模型实现文本至图像合成中的新闻主题条件设置](2024年04月15日/ANCHOR_LLM-driven_News_Subject_Conditioning_for_Text-to-Image_Synthesis.md)

- [Language Model Cascades: Token-level uncertainty and beyond](2024年04月15日/Language_Model_Cascades_Token-level_uncertainty_and_beyond.md)

    - [翻译: 语言模型级联：探究Token层级的不确定性及其更深层次的影响](2024年04月15日/Language_Model_Cascades_Token-level_uncertainty_and_beyond.md)

- [PRODIS - a speech database and a phoneme-based language model for the study of predictability effects in Polish](2024年04月15日/PRODIS_-_a_speech_database_and_a_phoneme-based_language_model_for_the_study_of_predictability_effects_in_Polish.md)

    - [翻译: PRODIS 是一个语音数据库，它配备了基于音素的语言模型，专门用于探究波兰语中的可预测性效应。](2024年04月15日/PRODIS_-_a_speech_database_and_a_phoneme-based_language_model_for_the_study_of_predictability_effects_in_Polish.md)

- [LLM-based Test-driven Interactive Code Generation: User Study and Empirical Evaluation](2024年04月15日/LLM-based_Test-driven_Interactive_Code_Generation_User_Study_and_Empirical_Evaluation.md)

    - [翻译: 基于大型语言模型的测试驱动交互式代码生成：用户研究与实证评估探究](2024年04月15日/LLM-based_Test-driven_Interactive_Code_Generation_User_Study_and_Empirical_Evaluation.md)

- [LegalPro-BERT: Classification of Legal Provisions by fine-tuning BERT Large Language Model](2024年04月15日/LegalPro-BERT_Classification_of_Legal_Provisions_by_fine-tuning_BERT_Large_Language_Model.md)

    - [翻译: LegalPro-BERT：借助 BERT 大型语言模型的微调技术，实现对法律条文的精准分类。](2024年04月15日/LegalPro-BERT_Classification_of_Legal_Provisions_by_fine-tuning_BERT_Large_Language_Model.md)

- [Group-wise Prompting for Synthetic Tabular Data Generation using Large Language Models](2024年04月15日/Group-wise_Prompting_for_Synthetic_Tabular_Data_Generation_using_Large_Language_Models.md)

    - [翻译: 本文介绍了一种利用大型语言模型进行合成表格数据生成的策略，即通过组内提示来实现。](2024年04月15日/Group-wise_Prompting_for_Synthetic_Tabular_Data_Generation_using_Large_Language_Models.md)

- [Improving the Capabilities of Large Language Model Based Marketing Analytics Copilots With Semantic Search And Fine-Tuning](2024年04月15日/Improving_the_Capabilities_of_Large_Language_Model_Based_Marketing_Analytics_Copilots_With_Semantic_Search_And_Fine-Tuning.md)

    - [翻译: 利用语义搜索和微调技术，增强大型语言模型在营销分析领域的应用能力。](2024年04月15日/Improving_the_Capabilities_of_Large_Language_Model_Based_Marketing_Analytics_Copilots_With_Semantic_Search_And_Fine-Tuning.md)

- [LLM Evaluators Recognize and Favor Their Own Generations](2024年04月15日/LLM_Evaluators_Recognize_and_Favor_Their_Own_Generations.md)

    - [翻译: 大型语言模型的评估者们能够辨识并倾向于偏好自己产出的结果。](2024年04月15日/LLM_Evaluators_Recognize_and_Favor_Their_Own_Generations.md)

- [Towards Compositionally Generalizable Semantic Parsing in Large Language Models: A Survey](2024年04月15日/Towards_Compositionally_Generalizable_Semantic_Parsing_in_Large_Language_Models_A_Survey.md)

    - [翻译: 探索大型语言模型中的组合泛化语义解析：综述研究](2024年04月15日/Towards_Compositionally_Generalizable_Semantic_Parsing_in_Large_Language_Models_A_Survey.md)

- [Modeling Emotions and Ethics with Large Language Models](2024年04月15日/Modeling_Emotions_and_Ethics_with_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，情感与伦理的建模是一个重要议题。](2024年04月15日/Modeling_Emotions_and_Ethics_with_Large_Language_Models.md)

2024年04月14日

- [A Survey on Integration of Large Language Models with Intelligent Robots](2024年04月14日/A_Survey_on_Integration_of_Large_Language_Models_with_Intelligent_Robots.md)

    - [翻译: 本文综述了大型语言模型与智能机器人的融合应用，探讨了两者结合的潜力与挑战。](2024年04月14日/A_Survey_on_Integration_of_Large_Language_Models_with_Intelligent_Robots.md)

- [TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models](2024年04月14日/TextHawk_Exploring_Efficient_Fine-Grained_Perception_of_Multimodal_Large_Language_Models.md)

    - [翻译: TextHawk：高效精准感知多模态大型语言模型的新探索](2024年04月14日/TextHawk_Exploring_Efficient_Fine-Grained_Perception_of_Multimodal_Large_Language_Models.md)

- [Tri-modal Confluence with Temporal Dynamics for Scene Graph Generation in Operating Rooms](2024年04月14日/Tri-modal_Confluence_with_Temporal_Dynamics_for_Scene_Graph_Generation_in_Operating_Rooms.md)

    - [翻译: 在手术室场景中，结合时间动态的三模态交汇技术，用于生成场景图。](2024年04月14日/Tri-modal_Confluence_with_Temporal_Dynamics_for_Scene_Graph_Generation_in_Operating_Rooms.md)

- [DreamScape: 3D Scene Creation via Gaussian Splatting joint Correlation Modeling](2024年04月14日/DreamScape_3D_Scene_Creation_via_Gaussian_Splatting_joint_Correlation_Modeling.md)

    - [翻译: DreamScape：运用高斯溅射与联合相关性建模技术打造三维场景](2024年04月14日/DreamScape_3D_Scene_Creation_via_Gaussian_Splatting_joint_Correlation_Modeling.md)

- [Compass: Large Multilingual Language Model for South-east Asia](2024年04月14日/Compass_Large_Multilingual_Language_Model_for_South-east_Asia.md)

    - [翻译: 指南针：为东南亚地区量身打造的大型多语言语言模型](2024年04月14日/Compass_Large_Multilingual_Language_Model_for_South-east_Asia.md)

- [DetCLIPv3: Towards Versatile Generative Open-vocabulary Object Detection](2024年04月14日/DetCLIPv3_Towards_Versatile_Generative_Open-vocabulary_Object_Detection.md)

    - [翻译: DetCLIPv3 致力于实现多样化的开放词汇目标检测，旨在提升生成式目标检测的灵活性与适应性。](2024年04月14日/DetCLIPv3_Towards_Versatile_Generative_Open-vocabulary_Object_Detection.md)

- [DKE-Research at SemEval-2024 Task 2: Incorporating Data Augmentation with Generative Models and Biomedical Knowledge to Enhance Inference Robustness](2024年04月14日/DKE-Research_at_SemEval-2024_Task_2_Incorporating_Data_Augmentation_with_Generative_Models_and_Biomedical_Knowledge_to_Enhance_Inference_Robustness.md)

    - [翻译: DKE-Research 参与 SemEval-2024 的第二项任务，通过融合生成模型与生物医学知识进行数据增强，旨在增强推理过程的稳健性。](2024年04月14日/DKE-Research_at_SemEval-2024_Task_2_Incorporating_Data_Augmentation_with_Generative_Models_and_Biomedical_Knowledge_to_Enhance_Inference_Robustness.md)

- [TransformerFAM: Feedback attention is working memory](2024年04月14日/TransformerFAM_Feedback_attention_is_working_memory.md)

    - [翻译: TransformerFAM 模型中，反馈注意力机制扮演着工作记忆的角色。](2024年04月14日/TransformerFAM_Feedback_attention_is_working_memory.md)

- [Post-Semantic-Thinking: A Robust Strategy to Distill Reasoning Capacity from Large Language Models](2024年04月14日/Post-Semantic-Thinking_A_Robust_Strategy_to_Distill_Reasoning_Capacity_from_Large_Language_Models.md)

    - [翻译: 探索后语义思维：高效提炼大型语言模型的推理能力](2024年04月14日/Post-Semantic-Thinking_A_Robust_Strategy_to_Distill_Reasoning_Capacity_from_Large_Language_Models.md)

- [GeMQuAD : Generating Multilingual Question Answering Datasets from Large Language Models using Few Shot Learning](2024年04月14日/GeMQuAD__Generating_Multilingual_Question_Answering_Datasets_from_Large_Language_Models_using_Few_Shot_Learning.md)

    - [翻译: GeMQuAD：借助少量样本学习技术，从大型语言模型中打造多语言问答数据集。](2024年04月14日/GeMQuAD__Generating_Multilingual_Question_Answering_Datasets_from_Large_Language_Models_using_Few_Shot_Learning.md)

- [From Bytes to Borsch: Fine-Tuning Gemma and Mistral for the Ukrainian Language Representation](2024年04月14日/From_Bytes_to_Borsch_Fine-Tuning_Gemma_and_Mistral_for_the_Ukrainian_Language_Representation.md)

    - [翻译: 跨越字节界限，迈向罗宋汤的风味：精心调整吉玛与米斯特拉，以提升乌克兰语的表现力。](2024年04月14日/From_Bytes_to_Borsch_Fine-Tuning_Gemma_and_Mistral_for_the_Ukrainian_Language_Representation.md)

- [Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A~Case~Study~at~HCMUT](2024年04月14日/Cross-Data_Knowledge_Graph_Construction_for_LLM-enabled_Educational_Question-Answering_System_A~Case~Study~at~HCMUT.md)

    - [翻译: 构建跨数据知识图，助力LLM驱动的教育问答系统——以HCMUT为例](2024年04月14日/Cross-Data_Knowledge_Graph_Construction_for_LLM-enabled_Educational_Question-Answering_System_A~Case~Study~at~HCMUT.md)

- [Knowledgeable Agents by Offline Reinforcement Learning from Large Language Model Rollouts](2024年04月14日/Knowledgeable_Agents_by_Offline_Reinforcement_Learning_from_Large_Language_Model_Rollouts.md)

    - [翻译: 通过大型语言模型的模拟数据进行离线强化学习，打造出见多识广的智能代理。](2024年04月14日/Knowledgeable_Agents_by_Offline_Reinforcement_Learning_from_Large_Language_Model_Rollouts.md)

- [RankCLIP: Ranking-Consistent Language-Image Pretraining](2024年04月14日/RankCLIP_Ranking-Consistent_Language-Image_Pretraining.md)

    - [翻译: RankCLIP：实现语言与图像预训练的排名一致性](2024年04月14日/RankCLIP_Ranking-Consistent_Language-Image_Pretraining.md)

- [Tasks People Prompt: A Taxonomy of LLM Downstream Tasks in Software Verification and Falsification Approaches](2024年04月14日/Tasks_People_Prompt_A_Taxonomy_of_LLM_Downstream_Tasks_in_Software_Verification_and_Falsification_Approaches.md)

    - [翻译: 任务人员提示：对大型语言模型在软件验证与错误检测方法中的下游任务进行分类](2024年04月14日/Tasks_People_Prompt_A_Taxonomy_of_LLM_Downstream_Tasks_in_Software_Verification_and_Falsification_Approaches.md)

- [Can AI Understand Our Universe? Test of Fine-Tuning GPT by Astrophysical Data](2024年04月14日/Can_AI_Understand_Our_Universe_Test_of_Fine-Tuning_GPT_by_Astrophysical_Data.md)

    - [翻译: 人工智能能否洞悉宇宙之谜？本研究通过天体物理数据对GPT模型进行精细调整，以测试其理解宇宙的能力。](2024年04月14日/Can_AI_Understand_Our_Universe_Test_of_Fine-Tuning_GPT_by_Astrophysical_Data.md)

- [Evidence from counterfactual tasks supports emergent analogical reasoning in large language models](2024年04月14日/Evidence_from_counterfactual_tasks_supports_emergent_analogical_reasoning_in_large_language_models.md)

    - [翻译: 反事实任务的证据表明，大型语言模型能够展现出类比推理的能力。](2024年04月14日/Evidence_from_counterfactual_tasks_supports_emergent_analogical_reasoning_in_large_language_models.md)

- [Integrating Physiological Data with Large Language Models for Empathic Human-AI Interaction](2024年04月14日/Integrating_Physiological_Data_with_Large_Language_Models_for_Empathic_Human-AI_Interaction.md)

    - [翻译: ](2024年04月14日/Integrating_Physiological_Data_with_Large_Language_Models_for_Empathic_Human-AI_Interaction.md)

2024年04月13日

- [Unveiling LLM Evaluation Focused on Metrics: Challenges and Solutions](2024年04月13日/Unveiling_LLM_Evaluation_Focused_on_Metrics_Challenges_and_Solutions.md)

    - [翻译: 揭秘大型语言模型（LLM）评估：聚焦于度量指标的挑战与应对策略](2024年04月13日/Unveiling_LLM_Evaluation_Focused_on_Metrics_Challenges_and_Solutions.md)

- [Interactive Generative AI Agents for Satellite Networks through a Mixture of Experts Transmission](2024年04月13日/Interactive_Generative_AI_Agents_for_Satellite_Networks_through_a_Mixture_of_Experts_Transmission.md)

    - [翻译: 本研究探讨了通过专家混合传输技术实现卫星网络中的交互式生成性人工智能代理，旨在提高通信效率和性能。](2024年04月13日/Interactive_Generative_AI_Agents_for_Satellite_Networks_through_a_Mixture_of_Experts_Transmission.md)

- [When Hindsight is Not 20/20: Testing Limits on Reflective Thinking in Large Language Models](2024年04月13日/When_Hindsight_is_Not_2020_Testing_Limits_on_Reflective_Thinking_in_Large_Language_Models.md)

    - [翻译: 后见之明并不总是清晰透彻：探究大型语言模型反思性思维的边界](2024年04月13日/When_Hindsight_is_Not_2020_Testing_Limits_on_Reflective_Thinking_in_Large_Language_Models.md)

- [Confidence Calibration and Rationalization for LLMs via Multi-Agent Deliberation](2024年04月13日/Confidence_Calibration_and_Rationalization_for_LLMs_via_Multi-Agent_Deliberation.md)

    - [翻译: 本研究通过多智能体协商机制，对大型语言模型（LLM）的置信度进行校准与合理化，以提升模型的预测准确性和解释性。](2024年04月13日/Confidence_Calibration_and_Rationalization_for_LLMs_via_Multi-Agent_Deliberation.md)

- [CuriousLLM: Elevating Multi-Document QA with Reasoning-Infused Knowledge Graph Prompting](2024年04月13日/CuriousLLM_Elevating_Multi-Document_QA_with_Reasoning-Infused_Knowledge_Graph_Prompting.md)

    - [翻译: CuriousLLM 通过结合推理知识图谱的提示，提升了多文档问答的能力。](2024年04月13日/CuriousLLM_Elevating_Multi-Document_QA_with_Reasoning-Infused_Knowledge_Graph_Prompting.md)

- [Adapting Mental Health Prediction Tasks for Cross-lingual Learning via Meta-Training and In-context Learning with Large Language Model](2024年04月13日/Adapting_Mental_Health_Prediction_Tasks_for_Cross-lingual_Learning_via_Meta-Training_and_In-context_Learning_with_Large_Language_Model.md)

    - [翻译: 通过利用大型语言模型的元训练和上下文学习，我们调整心理健康预测任务，以便在跨语言学习中取得更好的效果。](2024年04月13日/Adapting_Mental_Health_Prediction_Tasks_for_Cross-lingual_Learning_via_Meta-Training_and_In-context_Learning_with_Large_Language_Model.md)

- [Do LLMs Play Dice? Exploring Probability Distribution Sampling in Large Language Models for Behavioral Simulation](2024年04月13日/Do_LLMs_Play_Dice_Exploring_Probability_Distribution_Sampling_in_Large_Language_Models_for_Behavioral_Simulation.md)

    - [翻译: 大型语言模型是否遵循随机规则？本研究探讨了在行为模拟中，大型语言模型是如何进行概率分布采样的。](2024年04月13日/Do_LLMs_Play_Dice_Exploring_Probability_Distribution_Sampling_in_Large_Language_Models_for_Behavioral_Simulation.md)

- [Three Disclaimers for Safe Disclosure: A Cardwriter for Reporting the Use of Generative AI in Writing Process](2024年04月13日/Three_Disclaimers_for_Safe_Disclosure_A_Cardwriter_for_Reporting_the_Use_of_Generative_AI_in_Writing_Process.md)

    - [翻译: 写作过程中使用生成型AI需注意三大免责声明：这是一份为报告而生的卡片式指南。](2024年04月13日/Three_Disclaimers_for_Safe_Disclosure_A_Cardwriter_for_Reporting_the_Use_of_Generative_AI_in_Writing_Process.md)

- [MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts](2024年04月13日/MING-MOE_Enhancing_Medical_Multi-Task_Learning_in_Large_Language_Models_with_Sparse_Mixture_of_Low-Rank_Adapter_Experts.md)

    - [翻译: MING-MOE 通过引入稀疏的低秩适配器专家混合技术，旨在提升大型语言模型在医学多任务学习领域的性能。](2024年04月13日/MING-MOE_Enhancing_Medical_Multi-Task_Learning_in_Large_Language_Models_with_Sparse_Mixture_of_Low-Rank_Adapter_Experts.md)

- [Navigating the Landscape of Large Language Models: A Comprehensive Review and Analysis of Paradigms and Fine-Tuning Strategies](2024年04月13日/Navigating_the_Landscape_of_Large_Language_Models_A_Comprehensive_Review_and_Analysis_of_Paradigms_and_Fine-Tuning_Strategies.md)

    - [翻译: 驾驭大型语言模型的疆域：一篇深入剖析各种范式与微调手法的综述文章](2024年04月13日/Navigating_the_Landscape_of_Large_Language_Models_A_Comprehensive_Review_and_Analysis_of_Paradigms_and_Fine-Tuning_Strategies.md)

- [PracticalDG: Perturbation Distillation on Vision-Language Models for Hybrid Domain Generalization](2024年04月13日/PracticalDG_Perturbation_Distillation_on_Vision-Language_Models_for_Hybrid_Domain_Generalization.md)

    - [翻译: 实用数字生成（PracticalDG）：通过在视觉-语言模型中应用扰动蒸馏技术，实现跨领域的有效泛化。](2024年04月13日/PracticalDG_Perturbation_Distillation_on_Vision-Language_Models_for_Hybrid_Domain_Generalization.md)

- [WikiSplit++: Easy Data Refinement for Split and Rephrase](2024年04月13日/WikiSplit++_Easy_Data_Refinement_for_Split_and_Rephrase.md)

    - [翻译: WikiSplit++：轻松优化数据，让分割与改述更简单](2024年04月13日/WikiSplit++_Easy_Data_Refinement_for_Split_and_Rephrase.md)

- [Intuition-aware Mixture-of-Rank-1-Experts for Parameter Efficient Finetuning](2024年04月13日/Intuition-aware_Mixture-of-Rank-1-Experts_for_Parameter_Efficient_Finetuning.md)

    - [翻译: 在参数高效微调中，我们引入了一种直觉感知的混合Rank-1专家模型，旨在通过熵正则化来优化模型性能。](2024年04月13日/Intuition-aware_Mixture-of-Rank-1-Experts_for_Parameter_Efficient_Finetuning.md)

- [Incremental Residual Concept Bottleneck Models](2024年04月13日/Incremental_Residual_Concept_Bottleneck_Models.md)

    - [翻译: 逐步深入的残差概念瓶颈模型](2024年04月13日/Incremental_Residual_Concept_Bottleneck_Models.md)

- [RoNID: New Intent Discovery with Generated-Reliable Labels and Cluster-friendly Representations](2024年04月13日/RoNID_New_Intent_Discovery_with_Generated-Reliable_Labels_and_Cluster-friendly_Representations.md)

    - [翻译: RoNID：探索新意图，借助生成的可靠标签与便于聚类的表示法](2024年04月13日/RoNID_New_Intent_Discovery_with_Generated-Reliable_Labels_and_Cluster-friendly_Representations.md)

- [OOVs in the Spotlight: How to Inflect them?](2024年04月13日/OOVs_in_the_Spotlight_How_to_Inflect_them.md)

    - [翻译: 词汇表之外的词汇（OOVs）备受关注：我们该如何调整它们呢？](2024年04月13日/OOVs_in_the_Spotlight_How_to_Inflect_them.md)

- [Large Language Models for Mobile GUI Text Input Generation: An Empirical Study](2024年04月13日/Large_Language_Models_for_Mobile_GUI_Text_Input_Generation_An_Empirical_Study.md)

    - [翻译: 面向移动设备图形界面文本输入的大型语言模型：实证分析](2024年04月13日/Large_Language_Models_for_Mobile_GUI_Text_Input_Generation_An_Empirical_Study.md)

- [Zero-Shot Code Representation Learning via Prompt Tuning](2024年04月13日/Zero-Shot_Code_Representation_Learning_via_Prompt_Tuning.md)

    - [翻译: 通过提示调整实现零-shot环境下的代码表示学习。](2024年04月13日/Zero-Shot_Code_Representation_Learning_via_Prompt_Tuning.md)

- [Introducing Super RAGs in Mistral 8x7B-v1](2024年04月13日/Introducing_Super_RAGs_in_Mistral_8x7B-v1.md)

    - [翻译: Mistral 8x7B-v1 版本中，我们迎来了超级 RAGs 的登场。](2024年04月13日/Introducing_Super_RAGs_in_Mistral_8x7B-v1.md)

- [Towards Efficient Resume Understanding: A Multi-Granularity Multi-Modal Pre-Training Approach](2024年04月13日/Towards_Efficient_Resume_Understanding_A_Multi-Granularity_Multi-Modal_Pre-Training_Approach.md)

    - [翻译: 迈向高效简历解析：采用多粒度多模态的预训练策略](2024年04月13日/Towards_Efficient_Resume_Understanding_A_Multi-Granularity_Multi-Modal_Pre-Training_Approach.md)

2024年04月12日

- [Enhancing Visual Question Answering through Question-Driven Image Captions as Prompts](2024年04月12日/Enhancing_Visual_Question_Answering_through_Question-Driven_Image_Captions_as_Prompts.md)

    - [翻译: 借助问题引导的图像描述作为前置提示，提升视觉问答系统的性能。](2024年04月12日/Enhancing_Visual_Question_Answering_through_Question-Driven_Image_Captions_as_Prompts.md)

- [Enhancing Autonomous Vehicle Training with Language Model Integration and Critical Scenario Generation](2024年04月12日/Enhancing_Autonomous_Vehicle_Training_with_Language_Model_Integration_and_Critical_Scenario_Generation.md)

    - [翻译: 结合语言模型和关键情景生成技术，提升自动驾驶车辆的训练效果](2024年04月12日/Enhancing_Autonomous_Vehicle_Training_with_Language_Model_Integration_and_Critical_Scenario_Generation.md)

- [RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs](2024年04月12日/RLHF_Deciphered_A_Critical_Analysis_of_Reinforcement_Learning_from_Human_Feedback_for_LLMs.md)

    - [翻译: 深度剖析RLHF：揭秘人类反馈在大型语言模型强化学习中的作用](2024年04月12日/RLHF_Deciphered_A_Critical_Analysis_of_Reinforcement_Learning_from_Human_Feedback_for_LLMs.md)

- [Online Safety Analysis for LLMs: a Benchmark, an Assessment, and a Path Forward](2024年04月12日/Online_Safety_Analysis_for_LLMs_a_Benchmark,_an_Assessment,_and_a_Path_Forward.md)

    - [翻译: 针对大型语言模型的网络安全评估：建立行业标准，进行全面审视，并规划未来发展方向。](2024年04月12日/Online_Safety_Analysis_for_LLMs_a_Benchmark,_an_Assessment,_and_a_Path_Forward.md)

- [Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction](2024年04月12日/Efficient_Interactive_LLM_Serving_with_Proxy_Model-based_Sequence_Length_Prediction.md)

    - [翻译: 通过代理模型预测序列长度，实现大型语言模型（LLM）的高效互动服务。](2024年04月12日/Efficient_Interactive_LLM_Serving_with_Proxy_Model-based_Sequence_Length_Prediction.md)

- [LaSagnA: Language-based Segmentation Assistant for Complex Queries](2024年04月12日/LaSagnA_Language-based_Segmentation_Assistant_for_Complex_Queries.md)

    - [翻译: LaSagnA：复杂查询的语言分割助理](2024年04月12日/LaSagnA_Language-based_Segmentation_Assistant_for_Complex_Queries.md)

- [Strategic Interactions between Large Language Models-based Agents in Beauty Contests](2024年04月12日/Strategic_Interactions_between_Large_Language_Models-based_Agents_in_Beauty_Contests.md)

    - [翻译: 选美竞技中，大型语言模型驱动的智能体展开策略博弈。](2024年04月12日/Strategic_Interactions_between_Large_Language_Models-based_Agents_in_Beauty_Contests.md)

- [Mitigating Language-Level Performance Disparity in mPLMs via Teacher Language Selection and Cross-lingual Self-Distillation](2024年04月12日/Mitigating_Language-Level_Performance_Disparity_in_mPLMs_via_Teacher_Language_Selection_and_Cross-lingual_Self-Distillation.md)

    - [翻译: 为了缩小多语言预训练语言模型（mPLMs）在不同语言间性能的差距，本研究采用了教师语言选择和跨语言自我蒸馏的策略。](2024年04月12日/Mitigating_Language-Level_Performance_Disparity_in_mPLMs_via_Teacher_Language_Selection_and_Cross-lingual_Self-Distillation.md)

- [Thematic Analysis with Large Language Models: does it work with languages other than English? A targeted test in Italian](2024年04月12日/Thematic_Analysis_with_Large_Language_Models_does_it_work_with_languages_other_than_English_A_targeted_test_in_Italian.md)

    - [翻译: 大型语言模型进行主题分析：非英语语言是否同样有效？一项针对意大利语的专项测试探究](2024年04月12日/Thematic_Analysis_with_Large_Language_Models_does_it_work_with_languages_other_than_English_A_targeted_test_in_Italian.md)

- [Comparing Apples to Oranges: LLM-powered Multimodal Intention Prediction in an Object Categorization Task](2024年04月12日/Comparing_Apples_to_Oranges_LLM-powered_Multimodal_Intention_Prediction_in_an_Object_Categorization_Task.md)

    - [翻译: 在对象分类任务中，利用大型语言模型进行多模态意图预测的苹果与橙子之比较。](2024年04月12日/Comparing_Apples_to_Oranges_LLM-powered_Multimodal_Intention_Prediction_in_an_Object_Categorization_Task.md)

- [AdapterSwap: Continuous Training of LLMs with Data Removal and Access-Control Guarantees](2024年04月12日/AdapterSwap_Continuous_Training_of_LLMs_with_Data_Removal_and_Access-Control_Guarantees.md)

    - [翻译: AdapterSwap 技术能够在确保数据安全删除和访问受限的前提下，对大型语言模型（LLM）实施持续的训练与优化。](2024年04月12日/AdapterSwap_Continuous_Training_of_LLMs_with_Data_Removal_and_Access-Control_Guarantees.md)

- [Look at the Text: Instruction-Tuned Language Models are More Robust Multiple Choice Selectors than You Think](2024年04月12日/Look_at_the_Text_Instruction-Tuned_Language_Models_are_More_Robust_Multiple_Choice_Selectors_than_You_Think.md)

    - [翻译: 细读这篇文章：经过指令调优的语言模型，在多项选择任务上的筛选能力比你想象的要强大得多。](2024年04月12日/Look_at_the_Text_Instruction-Tuned_Language_Models_are_More_Robust_Multiple_Choice_Selectors_than_You_Think.md)

- [Gaining More Insight into Neural Semantic Parsing with Challenging Benchmarks](2024年04月12日/Gaining_More_Insight_into_Neural_Semantic_Parsing_with_Challenging_Benchmarks.md)

    - [翻译: 借助富有挑战性的基准测试，我们能够更深入地洞察神经网络在语义解析方面的表现。](2024年04月12日/Gaining_More_Insight_into_Neural_Semantic_Parsing_with_Challenging_Benchmarks.md)

- [Toward a Theory of Tokenization in LLMs](2024年04月12日/Toward_a_Theory_of_Tokenization_in_LLMs.md)

    - [翻译: 探索大型语言模型中的分词原理](2024年04月12日/Toward_a_Theory_of_Tokenization_in_LLMs.md)

- [Subtoxic Questions: Dive Into Attitude Change of LLM's Response in Jailbreak Attempts](2024年04月12日/Subtoxic_Questions_Dive_Into_Attitude_Change_of_LLM's_Response_in_Jailbreak_Attempts.md)

    - [翻译: Subtoxic Questions: 探究在越狱尝试中大型语言模型回应的态度转变](2024年04月12日/Subtoxic_Questions_Dive_Into_Attitude_Change_of_LLM's_Response_in_Jailbreak_Attempts.md)

- [Pretraining and Updating Language- and Domain-specific Large Language Model: A Case Study in Japanese Business Domain](2024年04月12日/Pretraining_and_Updating_Language-_and_Domain-specific_Large_Language_Model_A_Case_Study_in_Japanese_Business_Domain.md)

    - [翻译: 探索日本商业领域：预训练与更新特定语言和领域大型语言模型的案例分析](2024年04月12日/Pretraining_and_Updating_Language-_and_Domain-specific_Large_Language_Model_A_Case_Study_in_Japanese_Business_Domain.md)

- [Investigating Neural Machine Translation for Low-Resource Languages: Using Bavarian as a Case Study](2024年04月12日/Investigating_Neural_Machine_Translation_for_Low-Resource_Languages_Using_Bavarian_as_a_Case_Study.md)

    - [翻译: 探索低资源语言的神经机器翻译：以巴伐利亚语为案例研究](2024年04月12日/Investigating_Neural_Machine_Translation_for_Low-Resource_Languages_Using_Bavarian_as_a_Case_Study.md)

- [Pre-training Small Base LMs with Fewer Tokens](2024年04月12日/Pre-training_Small_Base_LMs_with_Fewer_Tokens.md)

    - [翻译: 在预训练小型基础语言模型时，采用更少的标记。](2024年04月12日/Pre-training_Small_Base_LMs_with_Fewer_Tokens.md)

- [Is Next Token Prediction Sufficient for GPT? Exploration on Code Logic Comprehension](2024年04月12日/Is_Next_Token_Prediction_Sufficient_for_GPT_Exploration_on_Code_Logic_Comprehension.md)

    - [翻译: GPT仅凭下一个词的预测是否足够？探究其在代码逻辑理解方面的表现](2024年04月12日/Is_Next_Token_Prediction_Sufficient_for_GPT_Exploration_on_Code_Logic_Comprehension.md)

- [Generative AI Agent for Next-Generation MIMO Design: Fundamentals, Challenges, and Vision](2024年04月12日/Generative_AI_Agent_for_Next-Generation_MIMO_Design_Fundamentals,_Challenges,_and_Vision.md)

    - [翻译: 下一代MIMO设计中的生成型AI代理：基础原理、面临挑战及未来展望](2024年04月12日/Generative_AI_Agent_for_Next-Generation_MIMO_Design_Fundamentals,_Challenges,_and_Vision.md)

- [Aligning LLMs for FL-free Program Repair](2024年04月12日/Aligning_LLMs_for_FL-free_Program_Repair.md)

    - [翻译: 在无需特征标注的情况下，对大型语言模型进行优化以实现程序修复](2024年04月12日/Aligning_LLMs_for_FL-free_Program_Repair.md)

- [LLM In-Context Recall is Prompt Dependent](2024年04月12日/LLM_In-Context_Recall_is_Prompt_Dependent.md)

    - [翻译: 在大型语言模型中，上下文记忆的召回效果与提示密切相关。](2024年04月12日/LLM_In-Context_Recall_is_Prompt_Dependent.md)

- [On Speculative Decoding for Multimodal Large Language Models](2024年04月12日/On_Speculative_Decoding_for_Multimodal_Large_Language_Models.md)

    - [翻译: 探索多模态大型语言模型的推测性解码技术](2024年04月12日/On_Speculative_Decoding_for_Multimodal_Large_Language_Models.md)

- [Assessing Economic Viability: A Comparative Analysis of Total Cost of Ownership for Domain-Adapted Large Language Models versus State-of-the-art Counterparts in Chip Design Coding Assistance](2024年04月12日/Assessing_Economic_Viability_A_Comparative_Analysis_of_Total_Cost_of_Ownership_for_Domain-Adapted_Large_Language_Models_versus_State-of-the-art_Counterparts_in_Chip_Design_Coding_Assistance.md)

    - [翻译: 探究经济价值：比较分析领域定制大型语言模型与芯片设计编码辅助领域中尖端技术的总成本拥有情况。](2024年04月12日/Assessing_Economic_Viability_A_Comparative_Analysis_of_Total_Cost_of_Ownership_for_Domain-Adapted_Large_Language_Models_versus_State-of-the-art_Counterparts_in_Chip_Design_Coding_Assistance.md)

- [Experimental Design for Active Transductive Inference in Large Language Models](2024年04月12日/Experimental_Design_for_Active_Transductive_Inference_in_Large_Language_Models.md)

    - [翻译: 本文探讨了大型语言模型中主动归纳推理的实验设计方案。](2024年04月12日/Experimental_Design_for_Active_Transductive_Inference_in_Large_Language_Models.md)

- ["Don't forget to put the milk back!" Dataset for Enabling Embodied Agents to Detect Anomalous Situations](2024年04月12日/Don't_forget_to_put_the_milk_back!_Dataset_for_Enabling_Embodied_Agents_to_Detect_Anomalous_Situations.md)

    - [翻译: "记得把牛奶归位哦！" 这个数据集旨在帮助具身智能体识别不寻常的场景。](2024年04月12日/Don't_forget_to_put_the_milk_back!_Dataset_for_Enabling_Embodied_Agents_to_Detect_Anomalous_Situations.md)

- [Inverse Kinematics for Neuro-Robotic Grasping with Humanoid Embodied Agents](2024年04月12日/Inverse_Kinematics_for_Neuro-Robotic_Grasping_with_Humanoid_Embodied_Agents.md)

    - [翻译: 本文探讨了逆运动学在人形机器人抓取任务中的应用，特别是针对具有人形体现的神经机器人代理。](2024年04月12日/Inverse_Kinematics_for_Neuro-Robotic_Grasping_with_Humanoid_Embodied_Agents.md)

- [The Illusion of State in State-Space Models](2024年04月12日/The_Illusion_of_State_in_State-Space_Models.md)

    - [翻译: 状态空间模型中的状态幻觉](2024年04月12日/The_Illusion_of_State_in_State-Space_Models.md)

- [Evaluating the Quality of Answers in Political Q&A Sessions with Large Language Models](2024年04月12日/Evaluating_the_Quality_of_Answers_in_Political_Q&A_Sessions_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，我们探讨了政治问答环节中答案的质量评估问题。](2024年04月12日/Evaluating_the_Quality_of_Answers_in_Political_Q&A_Sessions_with_Large_Language_Models.md)

- [Reducing the Barriers to Entry for Foundation Model Training](2024年04月12日/Reducing_the_Barriers_to_Entry_for_Foundation_Model_Training.md)

    - [翻译: 本文旨在探讨如何减少进入基础模型训练领域的障碍，以便更多的研究人员和开发者能够参与并推动这一领域的进步。](2024年04月12日/Reducing_the_Barriers_to_Entry_for_Foundation_Model_Training.md)

- [CreativEval: Evaluating Creativity of LLM-Based Hardware Code Generation](2024年04月12日/CreativEval_Evaluating_Creativity_of_LLM-Based_Hardware_Code_Generation.md)

    - [翻译: CreativEval：探究大型语言模型在硬件代码创造中的表现](2024年04月12日/CreativEval_Evaluating_Creativity_of_LLM-Based_Hardware_Code_Generation.md)

- [JailbreakLens: Visual Analysis of Jailbreak Attacks Against Large Language Models](2024年04月12日/JailbreakLens_Visual_Analysis_of_Jailbreak_Attacks_Against_Large_Language_Models.md)

    - [翻译: JailbreakLens：揭秘大型语言模型面临的越狱攻击的视觉解析](2024年04月12日/JailbreakLens_Visual_Analysis_of_Jailbreak_Attacks_Against_Large_Language_Models.md)

- [LLM-Seg: Bridging Image Segmentation and Large Language Model Reasoning](2024年04月12日/LLM-Seg_Bridging_Image_Segmentation_and_Large_Language_Model_Reasoning.md)

    - [翻译: LLM-Seg：融合图像分割与大型语言模型的推理能力](2024年04月12日/LLM-Seg_Bridging_Image_Segmentation_and_Large_Language_Model_Reasoning.md)

- [CATS: Contextually-Aware Thresholding for Sparsity in Large Language Models](2024年04月12日/CATS_Contextually-Aware_Thresholding_for_Sparsity_in_Large_Language_Models.md)

    - [翻译: CATS：针对大型语言模型的稀疏性，采用情境感知的阈值策略](2024年04月12日/CATS_Contextually-Aware_Thresholding_for_Sparsity_in_Large_Language_Models.md)

- [The Generation Gap:Exploring Age Bias in Large Language Models](2024年04月12日/The_Generation_GapExploring_Age_Bias_in_Large_Language_Models.md)

    - [翻译: 探究大型语言模型中的年龄偏见：揭秘生成差距](2024年04月12日/The_Generation_GapExploring_Age_Bias_in_Large_Language_Models.md)

- [Training a Vision Language Model as Smartphone Assistant](2024年04月12日/Training_a_Vision_Language_Model_as_Smartphone_Assistant.md)

    - [翻译: 将视觉语言模型打造成智能手机助理。](2024年04月12日/Training_a_Vision_Language_Model_as_Smartphone_Assistant.md)

- [VizGroup: An AI-Assisted Event-Driven System for Real-Time Collaborative Programming Learning Analytics](2024年04月12日/VizGroup_An_AI-Assisted_Event-Driven_System_for_Real-Time_Collaborative_Programming_Learning_Analytics.md)

    - [翻译: VizGroup：一款人工智能驱动的实时协作编程学习分析系统，采用事件触发机制。](2024年04月12日/VizGroup_An_AI-Assisted_Event-Driven_System_for_Real-Time_Collaborative_Programming_Learning_Analytics.md)

- [Can LLMs substitute SQL? Comparing Resource Utilization of Querying LLMs versus Traditional Relational Databases](2024年04月12日/Can_LLMs_substitute_SQL_Comparing_Resource_Utilization_of_Querying_LLMs_versus_Traditional_Relational_Databases.md)

    - [翻译: 大型语言模型能否取代SQL？探究在查询过程中，LLMs与传统关系型数据库在资源消耗方面的对比。](2024年04月12日/Can_LLMs_substitute_SQL_Comparing_Resource_Utilization_of_Querying_LLMs_versus_Traditional_Relational_Databases.md)

2024年04月11日

- [OpenBias: Open-set Bias Detection in Text-to-Image Generative Models](2024年04月11日/OpenBias_Open-set_Bias_Detection_in_Text-to-Image_Generative_Models.md)

    - [翻译: OpenBias 旨在揭示文本到图像生成模型中的开放集偏差问题，为这一领域的研究和改进提供了新的视角。](2024年04月11日/OpenBias_Open-set_Bias_Detection_in_Text-to-Image_Generative_Models.md)

- [Any2Point: Empowering Any-modality Large Models for Efficient 3D Understanding](2024年04月11日/Any2Point_Empowering_Any-modality_Large_Models_for_Efficient_3D_Understanding.md)

    - [翻译: Any2Point：激活各类大型模型，实现精准高效的三维理解](2024年04月11日/Any2Point_Empowering_Any-modality_Large_Models_for_Efficient_3D_Understanding.md)

- [Language Imbalance Can Boost Cross-lingual Generalisation](2024年04月11日/Language_Imbalance_Can_Boost_Cross-lingual_Generalisation.md)

    - [翻译: 在跨语言学习中，语言的不平衡现象有时反而能增强模型的泛化性能。](2024年04月11日/Language_Imbalance_Can_Boost_Cross-lingual_Generalisation.md)

- [Manipulating Large Language Models to Increase Product Visibility](2024年04月11日/Manipulating_Large_Language_Models_to_Increase_Product_Visibility.md)

    - [翻译: 通过调整大型语言模型，我们可以有效提升产品的曝光率。](2024年04月11日/Manipulating_Large_Language_Models_to_Increase_Product_Visibility.md)

- [LLoCO: Learning Long Contexts Offline](2024年04月11日/LLoCO_Learning_Long_Contexts_Offline.md)

    - [翻译: LLoCO：探索离线长文本学习在离线模式下，长文本环境的学习与处理仍充满挑战，有待我们进一步探索和突破。](2024年04月11日/LLoCO_Learning_Long_Contexts_Offline.md)

- [Ferret-v2: An Improved Baseline for Referring and Grounding with Large Language Models](2024年04月11日/Ferret-v2_An_Improved_Baseline_for_Referring_and_Grounding_with_Large_Language_Models.md)

    - [翻译: Ferret-v2：提升大型语言模型指代解析与实体定位的进阶基准。](2024年04月11日/Ferret-v2_An_Improved_Baseline_for_Referring_and_Grounding_with_Large_Language_Models.md)

- [Leveraging Large Language Models (LLMs) to Support Collaborative Human-AI Online Risk Data Annotation](2024年04月11日/Leveraging_Large_Language_Models_(LLMs)_to_Support_Collaborative_Human-AI_Online_Risk_Data_Annotation.md)

    - [翻译: 本文探讨了如何运用大型语言模型（LLMs）来加强人类与AI之间的协作，以共同完成在线风险数据的标注工作。](2024年04月11日/Leveraging_Large_Language_Models_(LLMs)_to_Support_Collaborative_Human-AI_Online_Risk_Data_Annotation.md)

- [LaVy: Vietnamese Multimodal Large Language Model](2024年04月11日/LaVy_Vietnamese_Multimodal_Large_Language_Model.md)

    - [翻译: LaVy，一款融合多模态特性的越南大型语言模型。](2024年04月11日/LaVy_Vietnamese_Multimodal_Large_Language_Model.md)

- [AmpleGCG: Learning a Universal and Transferable Generative Model of Adversarial Suffixes for Jailbreaking Both Open and Closed LLMs](2024年04月11日/AmpleGCG_Learning_a_Universal_and_Transferable_Generative_Model_of_Adversarial_Suffixes_for_Jailbreaking_Both_Open_and_Closed_LLMs.md)

    - [翻译: AmpleGCG 致力于开发一种普适且具备迁移能力的对抗性后缀生成模型，旨在解放开放与封闭的大型语言模型（LLM）的潜能。](2024年04月11日/AmpleGCG_Learning_a_Universal_and_Transferable_Generative_Model_of_Adversarial_Suffixes_for_Jailbreaking_Both_Open_and_Closed_LLMs.md)

- [DesignQA: A Multimodal Benchmark for Evaluating Large Language Models' Understanding of Engineering Documentation](2024年04月11日/DesignQA_A_Multimodal_Benchmark_for_Evaluating_Large_Language_Models'_Understanding_of_Engineering_Documentation.md)

    - [翻译: DesignQA：一个多模态基准，用于评测大型语言模型对工程文档的理解力。](2024年04月11日/DesignQA_A_Multimodal_Benchmark_for_Evaluating_Large_Language_Models'_Understanding_of_Engineering_Documentation.md)

- [High-Dimension Human Value Representation in Large Language Models](2024年04月11日/High-Dimension_Human_Value_Representation_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的人类价值，以高维度形式呈现。](2024年04月11日/High-Dimension_Human_Value_Representation_in_Large_Language_Models.md)

- [Guiding Large Language Models to Post-Edit Machine Translation with Error Annotations](2024年04月11日/Guiding_Large_Language_Models_to_Post-Edit_Machine_Translation_with_Error_Annotations.md)

    - [翻译: 通过错误注释指导大型语言模型对机器翻译进行精准修正](2024年04月11日/Guiding_Large_Language_Models_to_Post-Edit_Machine_Translation_with_Error_Annotations.md)

- [Nostra Domina at EvaLatin 2024: Improving Latin Polarity Detection through Data Augmentation](2024年04月11日/Nostra_Domina_at_EvaLatin_2024_Improving_Latin_Polarity_Detection_through_Data_Augmentation.md)

    - [翻译: 在 2024 年的 EvaLatin 会议上，Nostra Domina 通过采用数据增强技术，有效提升了拉丁语极性检测的准确性。](2024年04月11日/Nostra_Domina_at_EvaLatin_2024_Improving_Latin_Polarity_Detection_through_Data_Augmentation.md)

- [Discourse-Aware In-Context Learning for Temporal Expression Normalization](2024年04月11日/Discourse-Aware_In-Context_Learning_for_Temporal_Expression_Normalization.md)

    - [翻译: 在时间表达归一化任务中，采用话语感知的上下文学习方法，以提高处理效果。](2024年04月11日/Discourse-Aware_In-Context_Learning_for_Temporal_Expression_Normalization.md)

- [AnnoCTR: A Dataset for Detecting and Linking Entities, Tactics, and Techniques in Cyber Threat Reports](2024年04月11日/AnnoCTR_A_Dataset_for_Detecting_and_Linking_Entities,_Tactics,_and_Techniques_in_Cyber_Threat_Reports.md)

    - [翻译: AnnoCTR：网络威胁报告中实体、策略与技术检测与关联的数据集](2024年04月11日/AnnoCTR_A_Dataset_for_Detecting_and_Linking_Entities,_Tactics,_and_Techniques_in_Cyber_Threat_Reports.md)

- [Generating consistent PDDL domains with Large Language Models](2024年04月11日/Generating_consistent_PDDL_domains_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，打造统一的PDDL领域](2024年04月11日/Generating_consistent_PDDL_domains_with_Large_Language_Models.md)

- [ResearchAgent: Iterative Research Idea Generation over Scientific Literature with Large Language Models](2024年04月11日/ResearchAgent_Iterative_Research_Idea_Generation_over_Scientific_Literature_with_Large_Language_Models.md)

    - [翻译: ResearchAgent：借助大型语言模型，通过科学文献实现研究创意的迭代产生](2024年04月11日/ResearchAgent_Iterative_Research_Idea_Generation_over_Scientific_Literature_with_Large_Language_Models.md)

- [Unraveling the Dilemma of AI Errors: Exploring the Effectiveness of Human and Machine Explanations for Large Language Models](2024年04月11日/Unraveling_the_Dilemma_of_AI_Errors_Exploring_the_Effectiveness_of_Human_and_Machine_Explanations_for_Large_Language_Models.md)

    - [翻译: 探究AI误差之谜：研究人类与机器解释在大型语言模型中的有效性。](2024年04月11日/Unraveling_the_Dilemma_of_AI_Errors_Exploring_the_Effectiveness_of_Human_and_Machine_Explanations_for_Large_Language_Models.md)

- [Automatic Generation and Evaluation of Reading Comprehension Test Items with Large Language Models](2024年04月11日/Automatic_Generation_and_Evaluation_of_Reading_Comprehension_Test_Items_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，实现阅读理解试题的自动生成与评估](2024年04月11日/Automatic_Generation_and_Evaluation_of_Reading_Comprehension_Test_Items_with_Large_Language_Models.md)

- [Reflectance Estimation for Proximity Sensing by Vision-Language Models: Utilizing Distributional Semantics for Low-Level Cognition in Robotics](2024年04月11日/Reflectance_Estimation_for_Proximity_Sensing_by_Vision-Language_Models_Utilizing_Distributional_Semantics_for_Low-Level_Cognition_in_Robotics.md)

    - [翻译: 视觉-语言模型用于邻近感知的反射率估算：在机器人学领域，运用分布式语义学来实现低层次认知。](2024年04月11日/Reflectance_Estimation_for_Proximity_Sensing_by_Vision-Language_Models_Utilizing_Distributional_Semantics_for_Low-Level_Cognition_in_Robotics.md)

- [ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs](2024年04月11日/ODA_Observation-Driven_Agent_for_integrating_LLMs_and_Knowledge_Graphs.md)

    - [翻译: ODA，即观察驱动代理，旨在融合大型语言模型与知识图谱，提升智能代理的性能。](2024年04月11日/ODA_Observation-Driven_Agent_for_integrating_LLMs_and_Knowledge_Graphs.md)

- [rollama: An R package for using generative large language models through Ollama](2024年04月11日/rollama_An_R_package_for_using_generative_large_language_models_through_Ollama.md)

    - [翻译: Rollama，一个借助Ollama实现的R语言包，用于调用和利用生成式大型语言模型。](2024年04月11日/rollama_An_R_package_for_using_generative_large_language_models_through_Ollama.md)

- [Why do small language models underperform? Studying Language Model Saturation via the Softmax Bottleneck](2024年04月11日/Why_do_small_language_models_underperform_Studying_Language_Model_Saturation_via_the_Softmax_Bottleneck.md)

    - [翻译: 小型语言模型为何表现不尽人意？探究 Softmax 瓶颈背后的语言模型饱和现象。](2024年04月11日/Why_do_small_language_models_underperform_Studying_Language_Model_Saturation_via_the_Softmax_Bottleneck.md)

- [Audio Dialogues: Dialogues dataset for audio and music understanding](2024年04月11日/Audio_Dialogues_Dialogues_dataset_for_audio_and_music_understanding.md)

    - [翻译: 音频对话集：为深入理解和分析音频及音乐而打造的对话数据集。](2024年04月11日/Audio_Dialogues_Dialogues_dataset_for_audio_and_music_understanding.md)

- [Medical mT5: An Open-Source Multilingual Text-to-Text LLM for The Medical Domain](2024年04月11日/Medical_mT5_An_Open-Source_Multilingual_Text-to-Text_LLM_for_The_Medical_Domain.md)

    - [翻译: Medical mT5：一款面向医学领域的开源多语言文本到文本转换的大型语言模型。](2024年04月11日/Medical_mT5_An_Open-Source_Multilingual_Text-to-Text_LLM_for_The_Medical_Domain.md)

- [Measuring Geographic Diversity of Foundation Models with a Natural Language--based Geo-guessing Experiment on GPT-4](2024年04月11日/Measuring_Geographic_Diversity_of_Foundation_Models_with_a_Natural_Language--based_Geo-guessing_Experiment_on_GPT-4.md)

    - [翻译: 通过在GPT-4上开展一项自然语言地理猜测实验，我们探究了基础模型的地理多样性。](2024年04月11日/Measuring_Geographic_Diversity_of_Foundation_Models_with_a_Natural_Language--based_Geo-guessing_Experiment_on_GPT-4.md)

- [NoticIA: A Clickbait Article Summarization Dataset in Spanish](2024年04月11日/NoticIA_A_Clickbait_Article_Summarization_Dataset_in_Spanish.md)

    - [翻译: NoticIA：西班牙语点击诱饵文章的摘要数据集](2024年04月11日/NoticIA_A_Clickbait_Article_Summarization_Dataset_in_Spanish.md)

- [Implicit and Explicit Language Guidance for Diffusion-based Visual Perception](2024年04月11日/Implicit_and_Explicit_Language_Guidance_for_Diffusion-based_Visual_Perception.md)

    - [翻译: 在基于扩散模型的视觉感知任务中，隐性与显性语言引导的结合运用](2024年04月11日/Implicit_and_Explicit_Language_Guidance_for_Diffusion-based_Visual_Perception.md)

- [UltraEval: A Lightweight Platform for Flexible and Comprehensive Evaluation for LLMs](2024年04月11日/UltraEval_A_Lightweight_Platform_for_Flexible_and_Comprehensive_Evaluation_for_LLMs.md)

    - [翻译: UltraEval：为大型语言模型（LLMs）提供了一个轻巧、灵活且全面的评估平台。](2024年04月11日/UltraEval_A_Lightweight_Platform_for_Flexible_and_Comprehensive_Evaluation_for_LLMs.md)

- [Can Vehicle Motion Planning Generalize to Realistic Long-tail Scenarios?](2024年04月11日/Can_Vehicle_Motion_Planning_Generalize_to_Realistic_Long-tail_Scenarios.md)

    - [翻译: 车辆运动规划能否适应现实世界中的长尾情景？](2024年04月11日/Can_Vehicle_Motion_Planning_Generalize_to_Realistic_Long-tail_Scenarios.md)

- [Comments as Natural Logic Pivots: Improve Code Generation via Comment Perspective](2024年04月11日/Comments_as_Natural_Logic_Pivots_Improve_Code_Generation_via_Comment_Perspective.md)

    - [翻译: 将评论视作自然逻辑的转换点，以此来提升代码生成的效果。](2024年04月11日/Comments_as_Natural_Logic_Pivots_Improve_Code_Generation_via_Comment_Perspective.md)

- [Decomposing Label Space, Format and Discrimination: Rethinking How LLMs Respond and Solve Tasks via In-Context Learning](2024年04月11日/Decomposing_Label_Space,_Format_and_Discrimination_Rethinking_How_LLMs_Respond_and_Solve_Tasks_via_In-Context_Learning.md)

    - [翻译: 解构标签空间、格式与歧视现象：深入探讨大型语言模型（LLM）通过上下文学习应对与解决问题的机制。](2024年04月11日/Decomposing_Label_Space,_Format_and_Discrimination_Rethinking_How_LLMs_Respond_and_Solve_Tasks_via_In-Context_Learning.md)

- [From Words to Numbers: Your Large Language Model Is Secretly A Capable Regressor When Given In-Context Examples](2024年04月11日/From_Words_to_Numbers_Your_Large_Language_Model_Is_Secretly_A_Capable_Regressor_When_Given_In-Context_Examples.md)

    - [翻译: 单词变身数字：揭示大型语言模型在上下文示例辅助下的隐秘回归能力。](2024年04月11日/From_Words_to_Numbers_Your_Large_Language_Model_Is_Secretly_A_Capable_Regressor_When_Given_In-Context_Examples.md)

- [Best Practices and Lessons Learned on Synthetic Data for Language Models](2024年04月11日/Best_Practices_and_Lessons_Learned_on_Synthetic_Data_for_Language_Models.md)

    - [翻译: 在语言模型的合成数据应用中，我们总结了一些最佳实践和所汲取的教训。](2024年04月11日/Best_Practices_and_Lessons_Learned_on_Synthetic_Data_for_Language_Models.md)

- [Can Large Language Models Assess Serendipity in Recommender Systems?](2024年04月11日/Can_Large_Language_Models_Assess_Serendipity_in_Recommender_Systems.md)

    - [翻译: 大型语言模型能否对推荐系统里的惊喜元素进行评价？](2024年04月11日/Can_Large_Language_Models_Assess_Serendipity_in_Recommender_Systems.md)

- [Neural Fault Injection: Generating Software Faults from Natural Language](2024年04月11日/Neural_Fault_Injection_Generating_Software_Faults_from_Natural_Language.md)

    - [翻译: 神经故障注入技术：利用自然语言创建软件缺陷](2024年04月11日/Neural_Fault_Injection_Generating_Software_Faults_from_Natural_Language.md)

- [Multimodal Emotion Recognition by Fusing Video Semantic in MOOC Learning Scenarios](2024年04月11日/Multimodal_Emotion_Recognition_by_Fusing_Video_Semantic_in_MOOC_Learning_Scenarios.md)

    - [翻译: 在大规模在线开放课程（MOOC）的学习环境中，通过整合视频中的语义信息，实现对学习者情感的多维度识别。](2024年04月11日/Multimodal_Emotion_Recognition_by_Fusing_Video_Semantic_in_MOOC_Learning_Scenarios.md)

- [Scalable Language Model with Generalized Continual Learning](2024年04月11日/Scalable_Language_Model_with_Generalized_Continual_Learning.md)

    - [翻译: 本文介绍了一种具有泛化持续学习能力的可扩展语言模型。](2024年04月11日/Scalable_Language_Model_with_Generalized_Continual_Learning.md)

- [Improving Continuous Sign Language Recognition with Adapted Image Models](2024年04月11日/Improving_Continuous_Sign_Language_Recognition_with_Adapted_Image_Models.md)

    - [翻译: 借助调整后的图像模型，提升连续手语识别的准确性](2024年04月11日/Improving_Continuous_Sign_Language_Recognition_with_Adapted_Image_Models.md)

- [Reducing hallucination in structured outputs via Retrieval-Augmented Generation](2024年04月11日/Reducing_hallucination_in_structured_outputs_via_Retrieval-Augmented_Generation.md)

    - [翻译: 利用检索辅助生成技术，降低结构化输出中的失真现象](2024年04月11日/Reducing_hallucination_in_structured_outputs_via_Retrieval-Augmented_Generation.md)

- [Distilling Algorithmic Reasoning from LLMs via Explaining Solution Programs](2024年04月11日/Distilling_Algorithmic_Reasoning_from_LLMs_via_Explaining_Solution_Programs.md)

    - [翻译: 通过解析解题程序，从大型语言模型 (LLM) 中提取算法推理能力。](2024年04月11日/Distilling_Algorithmic_Reasoning_from_LLMs_via_Explaining_Solution_Programs.md)

- [Generative Information Retrieval Evaluation](2024年04月11日/Generative_Information_Retrieval_Evaluation.md)

    - [翻译: 在生成式信息检索领域，评估方法的创新和优化是推动技术进步的关键。通过对检索结果的生成质量、相关性和实用性进行综合评估，我们可以更好地理解和提升系统的性能。](2024年04月11日/Generative_Information_Retrieval_Evaluation.md)

- [Auctions with LLM Summaries](2024年04月11日/Auctions_with_LLM_Summaries.md)

    - [翻译: 在拍卖中，利用大型语言模型（LLM）提供的摘要可以为参与者提供更丰富、直观的信息，从而提高拍卖的透明度和效率。](2024年04月11日/Auctions_with_LLM_Summaries.md)

- [Data-Augmentation-Based Dialectal Adaptation for LLMs](2024年04月11日/Data-Augmentation-Based_Dialectal_Adaptation_for_LLMs.md)

    - [翻译: 针对大型语言模型，采用数据增强技术进行方言适配。](2024年04月11日/Data-Augmentation-Based_Dialectal_Adaptation_for_LLMs.md)

- [SQBC: Active Learning using LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions](2024年04月11日/SQBC_Active_Learning_using_LLM-Generated_Synthetic_Data_for_Stance_Detection_in_Online_Political_Discussions.md)

    - [翻译: SQBC：运用由大型语言模型生成的合成数据，主动学习以识别在线政治讨论中的立场。](2024年04月11日/SQBC_Active_Learning_using_LLM-Generated_Synthetic_Data_for_Stance_Detection_in_Online_Political_Discussions.md)

- [MSciNLI: A Diverse Benchmark for Scientific Natural Language Inference](2024年04月11日/MSciNLI_A_Diverse_Benchmark_for_Scientific_Natural_Language_Inference.md)

    - [翻译: MSciNLI：为科学领域量身打造的自然语言推理多维度评测基准](2024年04月11日/MSciNLI_A_Diverse_Benchmark_for_Scientific_Natural_Language_Inference.md)

- [Latent Guard: a Safety Framework for Text-to-image Generation](2024年04月11日/Latent_Guard_a_Safety_Framework_for_Text-to-image_Generation.md)

    - [翻译: 《潜在守卫》：为文本生成图像提供的安全框架](2024年04月11日/Latent_Guard_a_Safety_Framework_for_Text-to-image_Generation.md)

- [A Multi-Expert Large Language Model Architecture for Verilog Code Generation](2024年04月11日/A_Multi-Expert_Large_Language_Model_Architecture_for_Verilog_Code_Generation.md)

    - [翻译: 本文介绍了一种面向 Verilog 代码生成的多专家大型语言模型架构。](2024年04月11日/A_Multi-Expert_Large_Language_Model_Architecture_for_Verilog_Code_Generation.md)

- [Augmenting Knowledge Graph Hierarchies Using Neural Transformers](2024年04月11日/Augmenting_Knowledge_Graph_Hierarchies_Using_Neural_Transformers.md)

    - [翻译: 通过神经变换器技术，我们能够提升知识图谱的层级结构。](2024年04月11日/Augmenting_Knowledge_Graph_Hierarchies_Using_Neural_Transformers.md)

- [MM-PhyQA: Multimodal Physics Question-Answering With Multi-Image CoT Prompting](2024年04月11日/MM-PhyQA_Multimodal_Physics_Question-Answering_With_Multi-Image_CoT_Prompting.md)

    - [翻译: MM-PhyQA：运用多张图片的 CoT 提示技术，实现多模态物理问答功能。](2024年04月11日/MM-PhyQA_Multimodal_Physics_Question-Answering_With_Multi-Image_CoT_Prompting.md)

2024年04月10日

- [UMBRAE: Unified Multimodal Decoding of Brain Signals](2024年04月10日/UMBRAE_Unified_Multimodal_Decoding_of_Brain_Signals.md)

    - [翻译: UMBRAE：一种整合多种模式的脑信号解读技术](2024年04月10日/UMBRAE_Unified_Multimodal_Decoding_of_Brain_Signals.md)

- [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](2024年04月10日/Leave_No_Context_Behind_Efficient_Infinite_Context_Transformers_with_Infini-attention.md)

    - [翻译: 全面覆盖：搭载无限注意力机制的高效无限上下文变换器，让每个细节都得到关注。](2024年04月10日/Leave_No_Context_Behind_Efficient_Infinite_Context_Transformers_with_Infini-attention.md)

- [What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation](2024年04月10日/What_needs_to_go_right_for_an_induction_head_A_mechanistic_study_of_in-context_learning_circuits_and_their_formation.md)

    - [翻译: 要让感应头部发挥作用，需要哪些关键因素？本文通过机械性研究，深入探讨了上下文学习电路及其形成过程。](2024年04月10日/What_needs_to_go_right_for_an_induction_head_A_mechanistic_study_of_in-context_learning_circuits_and_their_formation.md)

- [Continuous Language Model Interpolation for Dynamic and Controllable Text Generation](2024年04月10日/Continuous_Language_Model_Interpolation_for_Dynamic_and_Controllable_Text_Generation.md)

    - [翻译: 通过连续性的语言模型融合技术，实现文本生成的动态调整与精准控制。](2024年04月10日/Continuous_Language_Model_Interpolation_for_Dynamic_and_Controllable_Text_Generation.md)

- [From Model-centered to Human-Centered: Revision Distance as a Metric for Text Evaluation in LLMs-based Applications](2024年04月10日/From_Model-centered_to_Human-Centered_Revision_Distance_as_a_Metric_for_Text_Evaluation_in_LLMs-based_Applications.md)

    - [翻译: 将视角从模型转向人类，修订距离被提出作为评估基于大型语言模型（LLMs）应用中文本质量的新指标。](2024年04月10日/From_Model-centered_to_Human-Centered_Revision_Distance_as_a_Metric_for_Text_Evaluation_in_LLMs-based_Applications.md)

- [Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs](2024年04月10日/Graph_Chain-of-Thought_Augmenting_Large_Language_Models_by_Reasoning_on_Graphs.md)

    - [翻译: 图链思考：借助图谱推理，提升大型语言模型的智能水平。](2024年04月10日/Graph_Chain-of-Thought_Augmenting_Large_Language_Models_by_Reasoning_on_Graphs.md)

- [Dynamic Generation of Personalities with Large Language Models](2024年04月10日/Dynamic_Generation_of_Personalities_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，实现个性化人格的动态塑造](2024年04月10日/Dynamic_Generation_of_Personalities_with_Large_Language_Models.md)

- [VLLMs Provide Better Context for Emotion Understanding Through Common Sense Reasoning](2024年04月10日/VLLMs_Provide_Better_Context_for_Emotion_Understanding_Through_Common_Sense_Reasoning.md)

    - [翻译: 借助常识推理，超大型语言模型（VLLMs）能够更精准地把握情感理解的脉络。](2024年04月10日/VLLMs_Provide_Better_Context_for_Emotion_Understanding_Through_Common_Sense_Reasoning.md)

- [Exploring Concept Depth: How Large Language Models Acquire Knowledge at Different Layers?](2024年04月10日/Exploring_Concept_Depth_How_Large_Language_Models_Acquire_Knowledge_at_Different_Layers.md)

    - [翻译: 深入概念探究：大型语言模型是如何在各自的层次上吸收知识的呢？](2024年04月10日/Exploring_Concept_Depth_How_Large_Language_Models_Acquire_Knowledge_at_Different_Layers.md)

- [Groundedness in Retrieval-augmented Long-form Generation: An Empirical Study](2024年04月10日/Groundedness_in_Retrieval-augmented_Long-form_Generation_An_Empirical_Study.md)

    - [翻译: 本实证研究深入探讨了检索辅助长篇文章生成中的 Groundedness 问题。](2024年04月10日/Groundedness_in_Retrieval-augmented_Long-form_Generation_An_Empirical_Study.md)

- [ORacle: Large Vision-Language Models for Knowledge-Guided Holistic OR Domain Modeling](2024年04月10日/ORacle_Large_Vision-Language_Models_for_Knowledge-Guided_Holistic_OR_Domain_Modeling.md)

    - [翻译: ORacle：面向整体OR领域建模的知识引导型大型视觉-语言模型](2024年04月10日/ORacle_Large_Vision-Language_Models_for_Knowledge-Guided_Holistic_OR_Domain_Modeling.md)

- [A Mathematical Theory for Learning Semantic Languages by Abstract Learners](2024年04月10日/A_Mathematical_Theory_for_Learning_Semantic_Languages_by_Abstract_Learners.md)

    - [翻译: 抽象学习者学习语义语言的数学理论探究](2024年04月10日/A_Mathematical_Theory_for_Learning_Semantic_Languages_by_Abstract_Learners.md)

- [WordDecipher: Enhancing Digital Workspace Communication with Explainable AI for Non-native English Speakers](2024年04月10日/WordDecipher_Enhancing_Digital_Workspace_Communication_with_Explainable_AI_for_Non-native_English_Speakers.md)

    - [翻译: WordDecipher：借助可解释AI技术，提升非英语母语者在数字工作空间的沟通体验](2024年04月10日/WordDecipher_Enhancing_Digital_Workspace_Communication_with_Explainable_AI_for_Non-native_English_Speakers.md)

- [LM Transparency Tool: Interactive Tool for Analyzing Transformer Language Models](2024年04月10日/LM_Transparency_Tool_Interactive_Tool_for_Analyzing_Transformer_Language_Models.md)

    - [翻译: LM 透明度工具：深入剖析 Transformer 语言模型的互动利器](2024年04月10日/LM_Transparency_Tool_Interactive_Tool_for_Analyzing_Transformer_Language_Models.md)

- [Event Grounded Criminal Court View Generation withCooperative (Large) Language Models](2024年04月10日/Event_Grounded_Criminal_Court_View_Generation_withCooperative_(Large)_Language_Models.md)

    - [翻译: 刑事法庭视角生成：基于事件的合作大型语言模型应用](2024年04月10日/Event_Grounded_Criminal_Court_View_Generation_withCooperative_(Large)_Language_Models.md)

- [Hybrid Multi-stage Decoding for Few-shot NER with Entity-aware Contrastive Learning](2024年04月10日/Hybrid_Multi-stage_Decoding_for_Few-shot_NER_with_Entity-aware_Contrastive_Learning.md)

    - [翻译: 本文提出了一种结合实体感知对比学习的方法，用于少样本命名实体识别（NER）的混合多阶段解码策略。](2024年04月10日/Hybrid_Multi-stage_Decoding_for_Few-shot_NER_with_Entity-aware_Contrastive_Learning.md)

- [Advancing Real-time Pandemic Forecasting Using Large Language Models: A COVID-19 Case Study](2024年04月10日/Advancing_Real-time_Pandemic_Forecasting_Using_Large_Language_Models_A_COVID-19_Case_Study.md)

    - [翻译: 借助大型语言模型，提升实时疫情预测的准确性：以COVID-19为例的深入分析](2024年04月10日/Advancing_Real-time_Pandemic_Forecasting_Using_Large_Language_Models_A_COVID-19_Case_Study.md)

- [Accelerating Inference in Large Language Models with a Unified Layer Skipping Strategy](2024年04月10日/Accelerating_Inference_in_Large_Language_Models_with_a_Unified_Layer_Skipping_Strategy.md)

    - [翻译: 通过统一的层跳过技巧，我们能够加快大型语言模型的推理速度。](2024年04月10日/Accelerating_Inference_in_Large_Language_Models_with_a_Unified_Layer_Skipping_Strategy.md)

- [MetaCheckGPT -- A Multi-task Hallucination Detection Using LLM Uncertainty and Meta-models](2024年04月10日/MetaCheckGPT_--_A_Multi-task_Hallucination_Detection_Using_LLM_Uncertainty_and_Meta-models.md)

    - [翻译: MetaCheckGPT —— 通过 LLM 的不确定性和元模型实现多任务幻觉检测](2024年04月10日/MetaCheckGPT_--_A_Multi-task_Hallucination_Detection_Using_LLM_Uncertainty_and_Meta-models.md)

- [GoEX: Perspectives and Designs Towards a Runtime for Autonomous LLM Applications](2024年04月10日/GoEX_Perspectives_and_Designs_Towards_a_Runtime_for_Autonomous_LLM_Applications.md)

    - [翻译: GoEX：探索构建自主大型语言模型应用运行时的视角与设计理念](2024年04月10日/GoEX_Perspectives_and_Designs_Towards_a_Runtime_for_Autonomous_LLM_Applications.md)

- [HRVDA: High-Resolution Visual Document Assistant](2024年04月10日/HRVDA_High-Resolution_Visual_Document_Assistant.md)

    - [翻译: HRVDA：高清视觉文档辅助工具](2024年04月10日/HRVDA_High-Resolution_Visual_Document_Assistant.md)

- [Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation](2024年04月10日/Superposition_Prompting_Improving_and_Accelerating_Retrieval-Augmented_Generation.md)

    - [翻译: 超位置提示技术：提升并加快检索辅助生成的效果](2024年04月10日/Superposition_Prompting_Improving_and_Accelerating_Retrieval-Augmented_Generation.md)

- [SARA: Smart AI Reading Assistant for Reading Comprehension](2024年04月10日/SARA_Smart_AI_Reading_Assistant_for_Reading_Comprehension.md)

    - [翻译: SARA：智能AI阅读助手，助力阅读理解](2024年04月10日/SARA_Smart_AI_Reading_Assistant_for_Reading_Comprehension.md)

- [Vision-Language Model-based Physical Reasoning for Robot Liquid Perception](2024年04月10日/Vision-Language_Model-based_Physical_Reasoning_for_Robot_Liquid_Perception.md)

    - [翻译: 利用视觉-语言模型，实现机器人对液体的物理识别与推理。](2024年04月10日/Vision-Language_Model-based_Physical_Reasoning_for_Robot_Liquid_Perception.md)

- [Beyond Random Inputs: A Novel ML-Based Hardware Fuzzing](2024年04月10日/Beyond_Random_Inputs_A_Novel_ML-Based_Hardware_Fuzzing.md)

    - [翻译: 除了随机输入，我们还探索了一种基于机器学习的创新硬件模糊测试方法。](2024年04月10日/Beyond_Random_Inputs_A_Novel_ML-Based_Hardware_Fuzzing.md)

- [Does Mapo Tofu Contain Coffee? Probing LLMs for Food-related Cultural Knowledge](2024年04月10日/Does_Mapo_Tofu_Contain_Coffee_Probing_LLMs_for_Food-related_Cultural_Knowledge.md)

    - [翻译: 麻婆豆腐是否含有咖啡成分？深挖大型语言模型对食物文化知识的掌握](2024年04月10日/Does_Mapo_Tofu_Contain_Coffee_Probing_LLMs_for_Food-related_Cultural_Knowledge.md)

- [Not All Contexts Are Equal: Teaching LLMs Credibility-aware Generation](2024年04月10日/Not_All_Contexts_Are_Equal_Teaching_LLMs_Credibility-aware_Generation.md)

    - [翻译: 上下文并非一视同仁：引导大型语言模型（LLM）进行可信度敏感的内容生成。](2024年04月10日/Not_All_Contexts_Are_Equal_Teaching_LLMs_Credibility-aware_Generation.md)

- [MedRG: Medical Report Grounding with Multi-modal Large Language Model](2024年04月10日/MedRG_Medical_Report_Grounding_with_Multi-modal_Large_Language_Model.md)

    - [翻译: MedRG：借助多模态大型语言模型实现医学报告的精准定位](2024年04月10日/MedRG_Medical_Report_Grounding_with_Multi-modal_Large_Language_Model.md)

- [Adapting LLaMA Decoder to Vision Transformer](2024年04月10日/Adapting_LLaMA_Decoder_to_Vision_Transformer.md)

    - [翻译: 适配 LLaMA 解码器至视觉变换网络](2024年04月10日/Adapting_LLaMA_Decoder_to_Vision_Transformer.md)

- [Personality-aware Student Simulation for Conversational Intelligent Tutoring Systems](2024年04月10日/Personality-aware_Student_Simulation_for_Conversational_Intelligent_Tutoring_Systems.md)

    - [翻译: 为了会话式智能辅导系统，我们开发了一种能够感知学生个性的模拟技术。](2024年04月10日/Personality-aware_Student_Simulation_for_Conversational_Intelligent_Tutoring_Systems.md)

- [Language Generation in the Limit](2024年04月10日/Language_Generation_in_the_Limit.md)

    - [翻译: 极限下的语言生成](2024年04月10日/Language_Generation_in_the_Limit.md)

- [Frontier AI Ethics: Anticipating and Evaluating the Societal Impacts of Generative Agents](2024年04月10日/Frontier_AI_Ethics_Anticipating_and_Evaluating_the_Societal_Impacts_of_Generative_Agents.md)

    - [翻译: 探索AI伦理新境界：洞悉并评估生成性智能体对社会的深远影响](2024年04月10日/Frontier_AI_Ethics_Anticipating_and_Evaluating_the_Societal_Impacts_of_Generative_Agents.md)

- [Transferable and Efficient Non-Factual Content Detection via Probe Training with Offline Consistency Checking](2024年04月10日/Transferable_and_Efficient_Non-Factual_Content_Detection_via_Probe_Training_with_Offline_Consistency_Checking.md)

    - [翻译: 本研究通过探针训练结合离线一致性检查，提出了一种可迁移且高效的非事实内容检测方法。](2024年04月10日/Transferable_and_Efficient_Non-Factual_Content_Detection_via_Probe_Training_with_Offline_Consistency_Checking.md)

- [Accuracy of a Large Language Model in Distinguishing Anti- And Pro-vaccination Messages on Social Media: The Case of Human Papillomavirus Vaccination](2024年04月10日/Accuracy_of_a_Large_Language_Model_in_Distinguishing_Anti-_And_Pro-vaccination_Messages_on_Social_Media_The_Case_of_Human_Papillomavirus_Vaccination.md)

    - [翻译: 社交媒体上，大型语言模型识别反疫苗与支持疫苗信息的准确度探究：以人乳头瘤病毒疫苗为案例分析。](2024年04月10日/Accuracy_of_a_Large_Language_Model_in_Distinguishing_Anti-_And_Pro-vaccination_Messages_on_Social_Media_The_Case_of_Human_Papillomavirus_Vaccination.md)

- [Towards Robustness of Text-to-Visualization Translation against Lexical and Phrasal Variability](2024年04月10日/Towards_Robustness_of_Text-to-Visualization_Translation_against_Lexical_and_Phrasal_Variability.md)

    - [翻译: 为提升文本至可视化翻译的稳定性，本研究致力于应对词汇与短语多样性所带来的挑战。](2024年04月10日/Towards_Robustness_of_Text-to-Visualization_Translation_against_Lexical_and_Phrasal_Variability.md)

- [GoodDrag: Towards Good Practices for Drag Editing with Diffusion Models](2024年04月10日/GoodDrag_Towards_Good_Practices_for_Drag_Editing_with_Diffusion_Models.md)

    - [翻译: GoodDrag：探索扩散模型在拖拽编辑中的优良实践方法](2024年04月10日/GoodDrag_Towards_Good_Practices_for_Drag_Editing_with_Diffusion_Models.md)

- ["Confidently Nonsensical?'': A Critical Survey on the Perspectives and Challenges of 'Hallucinations' in NLP](2024年04月10日/Confidently_Nonsensical''_A_Critical_Survey_on_the_Perspectives_and_Challenges_of_'Hallucinations'_in_NLP.md)

    - [翻译: 《荒谬与否？——自然语言处理中“幻觉”现象的批判性审视与挑战探讨》](2024年04月10日/Confidently_Nonsensical''_A_Critical_Survey_on_the_Perspectives_and_Challenges_of_'Hallucinations'_in_NLP.md)

- [WESE: Weak Exploration to Strong Exploitation for LLM Agents](2024年04月10日/WESE_Weak_Exploration_to_Strong_Exploitation_for_LLM_Agents.md)

    - [翻译: WESE：为大型语言模型代理实现从浅尝辄止到深度挖掘的转变](2024年04月10日/WESE_Weak_Exploration_to_Strong_Exploitation_for_LLM_Agents.md)

- [RiskLabs: Predicting Financial Risk Using Large Language Model Based on Multi-Sources Data](2024年04月10日/RiskLabs_Predicting_Financial_Risk_Using_Large_Language_Model_Based_on_Multi-Sources_Data.md)

    - [翻译: RiskLabs 项目利用大型语言模型，结合多源数据，旨在预测金融风险。](2024年04月10日/RiskLabs_Predicting_Financial_Risk_Using_Large_Language_Model_Based_on_Multi-Sources_Data.md)

- [Learning to Localize Objects Improves Spatial Reasoning in Visual-LLMs](2024年04月10日/Learning_to_Localize_Objects_Improves_Spatial_Reasoning_in_Visual-LLMs.md)

    - [翻译: 通过学习识别物体的位置，视觉-大型语言模型在空间推理方面的表现得到了显著提升。](2024年04月10日/Learning_to_Localize_Objects_Improves_Spatial_Reasoning_in_Visual-LLMs.md)

- [Transferable and Principled Efficiency for Open-Vocabulary Segmentation](2024年04月10日/Transferable_and_Principled_Efficiency_for_Open-Vocabulary_Segmentation.md)

    - [翻译: 开放词汇分割的可迁移性和原则性高效性](2024年04月10日/Transferable_and_Principled_Efficiency_for_Open-Vocabulary_Segmentation.md)

- [Data-Driven Portfolio Management for Motion Pictures Industry: A New Data-Driven Optimization Methodology Using a Large Language Model as the Expert](2024年04月10日/Data-Driven_Portfolio_Management_for_Motion_Pictures_Industry_A_New_Data-Driven_Optimization_Methodology_Using_a_Large_Language_Model_as_the_Expert.md)

    - [翻译: 电影产业采用数据驱动策略：借助大型语言模型的专业知识，探索一种创新的数据驱动优化方法。](2024年04月10日/Data-Driven_Portfolio_Management_for_Motion_Pictures_Industry_A_New_Data-Driven_Optimization_Methodology_Using_a_Large_Language_Model_as_the_Expert.md)

- [AdaDemo: Data-Efficient Demonstration Expansion for Generalist Robotic Agent](2024年04月10日/AdaDemo_Data-Efficient_Demonstration_Expansion_for_Generalist_Robotic_Agent.md)

    - [翻译: AdaDemo 通过数据高效的方式扩展通用机器人代理的演示，助力其更好地学习和适应多样化任务。](2024年04月10日/AdaDemo_Data-Efficient_Demonstration_Expansion_for_Generalist_Robotic_Agent.md)

- [CopilotCAD: Empowering Radiologists with Report Completion Models and Quantitative Evidence from Medical Image Foundation Models](2024年04月10日/CopilotCAD_Empowering_Radiologists_with_Report_Completion_Models_and_Quantitative_Evidence_from_Medical_Image_Foundation_Models.md)

    - [翻译: CopilotCAD：借助医学影像基础模型的报告完成模型和定量证据，提升放射科医生的工作效率](2024年04月10日/CopilotCAD_Empowering_Radiologists_with_Report_Completion_Models_and_Quantitative_Evidence_from_Medical_Image_Foundation_Models.md)

- [JetMoE: Reaching Llama2 Performance with 0.1M Dollars](2024年04月10日/JetMoE_Reaching_Llama2_Performance_with_0.1M_Dollars.md)

    - [翻译: JetMoE：以百万美元级成本实现Llama2级别性能](2024年04月10日/JetMoE_Reaching_Llama2_Performance_with_0.1M_Dollars.md)

- [LLMs in Biomedicine: A study on clinical Named Entity Recognition](2024年04月10日/LLMs_in_Biomedicine_A_study_on_clinical_Named_Entity_Recognition.md)

    - [翻译: 在生物医学领域，LLMs的应用：探究临床命名实体识别的研究成果](2024年04月10日/LLMs_in_Biomedicine_A_study_on_clinical_Named_Entity_Recognition.md)

- [Analyzing the Performance of Large Language Models on Code Summarization](2024年04月10日/Analyzing_the_Performance_of_Large_Language_Models_on_Code_Summarization.md)

    - [翻译: 探究大型语言模型在代码摘要任务上的表现](2024年04月10日/Analyzing_the_Performance_of_Large_Language_Models_on_Code_Summarization.md)

- [Is Your LLM Outdated? Benchmarking LLMs & Alignment Algorithms for Time-Sensitive Knowledge](2024年04月10日/Is_Your_LLM_Outdated_Benchmarking_LLMs_&_Alignment_Algorithms_for_Time-Sensitive_Knowledge.md)

    - [翻译: 你的大型语言模型（LLM）落伍了吗？本文旨在评估适用于时效性知识的 LLM 和对齐算法的性能基准。](2024年04月10日/Is_Your_LLM_Outdated_Benchmarking_LLMs_&_Alignment_Algorithms_for_Time-Sensitive_Knowledge.md)

- [Enhancing Question Answering for Enterprise Knowledge Bases using Large Language Models](2024年04月10日/Enhancing_Question_Answering_for_Enterprise_Knowledge_Bases_using_Large_Language_Models.md)

    - [翻译: 通过运用大型语言模型，我们能够提升企业知识库中的问答体验。](2024年04月10日/Enhancing_Question_Answering_for_Enterprise_Knowledge_Bases_using_Large_Language_Models.md)

2024年04月09日

- [Text-Based Reasoning About Vector Graphics](2024年04月09日/Text-Based_Reasoning_About_Vector_Graphics.md)

    - [翻译: 通过文本解读矢量图形的逻辑推理](2024年04月09日/Text-Based_Reasoning_About_Vector_Graphics.md)

- [VISION2UI: A Real-World Dataset with Layout for Code Generation from UI Designs](2024年04月09日/VISION2UI_A_Real-World_Dataset_with_Layout_for_Code_Generation_from_UI_Designs.md)

    - [翻译: VISION2UI：一个包含布局信息的真实世界数据集，用于从UI设计生成代码。](2024年04月09日/VISION2UI_A_Real-World_Dataset_with_Layout_for_Code_Generation_from_UI_Designs.md)

- [InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD](2024年04月09日/InternLM-XComposer2-4KHD_A_Pioneering_Large_Vision-Language_Model_Handling_Resolutions_from_336_Pixels_to_4K_HD.md)

    - [翻译: InternLM-XComposer2-4KHD，作为先锋的大型视觉-语言模型，能够应对从336像素直至4K高清的多样分辨率。](2024年04月09日/InternLM-XComposer2-4KHD_A_Pioneering_Large_Vision-Language_Model_Handling_Resolutions_from_336_Pixels_to_4K_HD.md)

- [Can Feedback Enhance Semantic Grounding in Large Vision-Language Models?](2024年04月09日/Can_Feedback_Enhance_Semantic_Grounding_in_Large_Vision-Language_Models.md)

    - [翻译: 反馈是否能够提升大型视觉-语言模型的语义理解能力？](2024年04月09日/Can_Feedback_Enhance_Semantic_Grounding_in_Large_Vision-Language_Models.md)

- [Reconstructing Hand-Held Objects in 3D](2024年04月09日/Reconstructing_Hand-Held_Objects_in_3D.md)

    - [翻译: 三维空间中手持物体的重建](2024年04月09日/Reconstructing_Hand-Held_Objects_in_3D.md)

- [Pitfalls of Conversational LLMs on News Debiasing](2024年04月09日/Pitfalls_of_Conversational_LLMs_on_News_Debiasing.md)

    - [翻译: 对话型大型语言模型在新闻去偏见方面的潜在问题](2024年04月09日/Pitfalls_of_Conversational_LLMs_on_News_Debiasing.md)

- [Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks](2024年04月09日/Ada-LEval_Evaluating_long-context_LLMs_with_length-adaptable_benchmarks.md)

    - [翻译: Ada-LEval：通过可伸缩的评估标准，对长文本处理能力的大型语言模型进行评测。](2024年04月09日/Ada-LEval_Evaluating_long-context_LLMs_with_length-adaptable_benchmarks.md)

- [Automated Federated Pipeline for Parameter-Efficient Fine-Tuning of Large Language Models](2024年04月09日/Automated_Federated_Pipeline_for_Parameter-Efficient_Fine-Tuning_of_Large_Language_Models.md)

    - [翻译: 本文介绍了一种自动化联邦管道技术，旨在实现大型语言模型微调过程中的参数高效利用。](2024年04月09日/Automated_Federated_Pipeline_for_Parameter-Efficient_Fine-Tuning_of_Large_Language_Models.md)

- [Large Language Models to the Rescue: Deadlock Resolution in Multi-Robot Systems](2024年04月09日/Large_Language_Models_to_the_Rescue_Deadlock_Resolution_in_Multi-Robot_Systems.md)

    - [翻译: 大型语言模型破解僵局：多机器人系统的死锁难题](2024年04月09日/Large_Language_Models_to_the_Rescue_Deadlock_Resolution_in_Multi-Robot_Systems.md)

- [AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents](2024年04月09日/AgentQuest_A_Modular_Benchmark_Framework_to_Measure_Progress_and_Improve_LLM_Agents.md)

    - [翻译: AgentQuest：构建模块化基准，助力大型语言模型（LLM）代理的发展与优化。](2024年04月09日/AgentQuest_A_Modular_Benchmark_Framework_to_Measure_Progress_and_Improve_LLM_Agents.md)

- [Take a Look at it! Rethinking How to Evaluate Language Model Jailbreak](2024年04月09日/Take_a_Look_at_it!_Rethinking_How_to_Evaluate_Language_Model_Jailbreak.md)

    - [翻译: 来一探究竟吧！重新审视评估语言模型突破的方法。](2024年04月09日/Take_a_Look_at_it!_Rethinking_How_to_Evaluate_Language_Model_Jailbreak.md)

- [Apprentices to Research Assistants: Advancing Research with Large Language Models](2024年04月09日/Apprentices_to_Research_Assistants_Advancing_Research_with_Large_Language_Models.md)

    - [翻译: 学徒变身研究助手：借助大型语言模型助力研究进步](2024年04月09日/Apprentices_to_Research_Assistants_Advancing_Research_with_Large_Language_Models.md)

- [MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies](2024年04月09日/MiniCPM_Unveiling_the_Potential_of_Small_Language_Models_with_Scalable_Training_Strategies.md)

    - [翻译: MiniCPM：借助可扩展训练策略，挖掘小型语言模型的潜在力量](2024年04月09日/MiniCPM_Unveiling_the_Potential_of_Small_Language_Models_with_Scalable_Training_Strategies.md)

- [MuPT: A Generative Symbolic Music Pretrained Transformer](2024年04月09日/MuPT_A_Generative_Symbolic_Music_Pretrained_Transformer.md)

    - [翻译: MuPT：一款预训练的变换器，专注于生成富有象征意义的音乐作品。](2024年04月09日/MuPT_A_Generative_Symbolic_Music_Pretrained_Transformer.md)

- [Latent Distance Guided Alignment Training for Large Language Models](2024年04月09日/Latent_Distance_Guided_Alignment_Training_for_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，采用潜在距离引导的对齐训练方法。](2024年04月09日/Latent_Distance_Guided_Alignment_Training_for_Large_Language_Models.md)

- [Model Generation from Requirements with LLMs: an Exploratory Study](2024年04月09日/Model_Generation_from_Requirements_with_LLMs_an_Exploratory_Study.md)

    - [翻译: 基于需求，利用大型语言模型生成模型：探索性研究](2024年04月09日/Model_Generation_from_Requirements_with_LLMs_an_Exploratory_Study.md)

- [Enhancing Decision Analysis with a Large Language Model: pyDecision a Comprehensive Library of MCDA Methods in Python](2024年04月09日/Enhancing_Decision_Analysis_with_a_Large_Language_Model_pyDecision_a_Comprehensive_Library_of_MCDA_Methods_in_Python.md)

    - [翻译: 借助大型语言模型，pyDecision 成为一个全面的 Python 多准则决策分析（MCDA）方法库，有效提升决策分析的效率和准确性。](2024年04月09日/Enhancing_Decision_Analysis_with_a_Large_Language_Model_pyDecision_a_Comprehensive_Library_of_MCDA_Methods_in_Python.md)

- [ClinLinker: Medical Entity Linking of Clinical Concept Mentions in Spanish](2024年04月09日/ClinLinker_Medical_Entity_Linking_of_Clinical_Concept_Mentions_in_Spanish.md)

    - [翻译: ClinLinker：将西班牙语临床术语中的医疗实体进行链接](2024年04月09日/ClinLinker_Medical_Entity_Linking_of_Clinical_Concept_Mentions_in_Spanish.md)

- [CausalBench: A Comprehensive Benchmark for Causal Learning Capability of Large Language Models](2024年04月09日/CausalBench_A_Comprehensive_Benchmark_for_Causal_Learning_Capability_of_Large_Language_Models.md)

    - [翻译: CausalBench：为大型语言模型的因果学习能力提供全面评估的基准测试平台](2024年04月09日/CausalBench_A_Comprehensive_Benchmark_for_Causal_Learning_Capability_of_Large_Language_Models.md)

- [AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning](2024年04月09日/AgentsCoDriver_Large_Language_Model_Empowered_Collaborative_Driving_with_Lifelong_Learning.md)

    - [翻译: AgentsCoDriver：借助大型语言模型实现的协作驾驶，采用终身学习机制。](2024年04月09日/AgentsCoDriver_Large_Language_Model_Empowered_Collaborative_Driving_with_Lifelong_Learning.md)

- [DRE: Generating Recommendation Explanations by Aligning Large Language Models at Data-level](2024年04月09日/DRE_Generating_Recommendation_Explanations_by_Aligning_Large_Language_Models_at_Data-level.md)

    - [翻译: DRE：通过数据层面的大型语言模型对齐，打造推荐解释的生成机制](2024年04月09日/DRE_Generating_Recommendation_Explanations_by_Aligning_Large_Language_Models_at_Data-level.md)

- [Exploring the True Potential: Evaluating the Black-box Optimization Capability of Large Language Models](2024年04月09日/Exploring_the_True_Potential_Evaluating_the_Black-box_Optimization_Capability_of_Large_Language_Models.md)

    - [翻译: 挖掘深层能力：对大型语言模型进行黑盒优化性能评估](2024年04月09日/Exploring_the_True_Potential_Evaluating_the_Black-box_Optimization_Capability_of_Large_Language_Models.md)

- [LLMs' Reading Comprehension Is Affected by Parametric Knowledge and Struggles with Hypothetical Statements](2024年04月09日/LLMs'_Reading_Comprehension_Is_Affected_by_Parametric_Knowledge_and_Struggles_with_Hypothetical_Statements.md)

    - [翻译: 大型语言模型在阅读理解方面易受参数知识左右，面对假设性语句时往往力不从心。](2024年04月09日/LLMs'_Reading_Comprehension_Is_Affected_by_Parametric_Knowledge_and_Struggles_with_Hypothetical_Statements.md)

- [Understanding Cross-Lingual Alignment -- A Survey](2024年04月09日/Understanding_Cross-Lingual_Alignment_--_A_Survey.md)

    - [翻译: 探索跨语言一致性：一项全面调查](2024年04月09日/Understanding_Cross-Lingual_Alignment_--_A_Survey.md)

- [Multimodal Road Network Generation Based on Large Language Model](2024年04月09日/Multimodal_Road_Network_Generation_Based_on_Large_Language_Model.md)

    - [翻译: 利用大型语言模型实现多模态道路网络的构建](2024年04月09日/Multimodal_Road_Network_Generation_Based_on_Large_Language_Model.md)

- [Low-Cost Generation and Evaluation of Dictionary Example Sentences](2024年04月09日/Low-Cost_Generation_and_Evaluation_of_Dictionary_Example_Sentences.md)

    - [翻译: 通过低成本的方式生成和评价词典中的示例句子，旨在高效地提升语言学习资源的质量。](2024年04月09日/Low-Cost_Generation_and_Evaluation_of_Dictionary_Example_Sentences.md)

- [OmniFusion Technical Report](2024年04月09日/OmniFusion_Technical_Report.md)

    - [翻译: OmniFusion 技术报告，全面解析](2024年04月09日/OmniFusion_Technical_Report.md)

- [Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models](2024年04月09日/Elephants_Never_Forget_Memorization_and_Learning_of_Tabular_Data_in_Large_Language_Models.md)

    - [翻译: 大象记忆力惊人，这篇文章探讨了大型语言模型如何记忆和学习表格数据。](2024年04月09日/Elephants_Never_Forget_Memorization_and_Learning_of_Tabular_Data_in_Large_Language_Models.md)

- [Open-Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning](2024年04月09日/Open-Source_AI-based_SE_Tools_Opportunities_and_Challenges_of_Collaborative_Software_Learning.md)

    - [翻译: 开源AI驱动的软件工程工具：携手共进的软件学习新机遇与面临挑战](2024年04月09日/Open-Source_AI-based_SE_Tools_Opportunities_and_Challenges_of_Collaborative_Software_Learning.md)

- [Exploring the Potential of Large Foundation Models for Open-Vocabulary HOI Detection](2024年04月09日/Exploring_the_Potential_of_Large_Foundation_Models_for_Open-Vocabulary_HOI_Detection.md)

    - [翻译: 本研究旨在挖掘大型基础模型在开放词汇表人体姿态识别（HOI）检测中的应用潜力。](2024年04月09日/Exploring_the_Potential_of_Large_Foundation_Models_for_Open-Vocabulary_HOI_Detection.md)

- [Clue-Instruct: Text-Based Clue Generation for Educational Crossword Puzzles](2024年04月09日/Clue-Instruct_Text-Based_Clue_Generation_for_Educational_Crossword_Puzzles.md)

    - [翻译: Clue-Instruct：为教育性填字游戏设计的文本线索生成方法](2024年04月09日/Clue-Instruct_Text-Based_Clue_Generation_for_Educational_Crossword_Puzzles.md)

- [Characterizing Multimodal Long-form Summarization: A Case Study on Financial Reports](2024年04月09日/Characterizing_Multimodal_Long-form_Summarization_A_Case_Study_on_Financial_Reports.md)

    - [翻译: 探究多模态长文本摘要：以金融报告分析为例](2024年04月09日/Characterizing_Multimodal_Long-form_Summarization_A_Case_Study_on_Financial_Reports.md)

- [Cendol: Open Instruction-tuned Generative Large Language Models for Indonesian Languages](2024年04月09日/Cendol_Open_Instruction-tuned_Generative_Large_Language_Models_for_Indonesian_Languages.md)

    - [翻译: Cendol：面向印尼语言的开放指令调整生成型大型语言模型](2024年04月09日/Cendol_Open_Instruction-tuned_Generative_Large_Language_Models_for_Indonesian_Languages.md)

- [Communication-Efficient Large-Scale Distributed Deep Learning: A Comprehensive Survey](2024年04月09日/Communication-Efficient_Large-Scale_Distributed_Deep_Learning_A_Comprehensive_Survey.md)

    - [翻译: 大规模分布式深度学习中的通信效率：一篇全面综述](2024年04月09日/Communication-Efficient_Large-Scale_Distributed_Deep_Learning_A_Comprehensive_Survey.md)

- [A RAG Method for Source Code Inquiry Tailored to Long-Context LLMs](2024年04月09日/A_RAG_Method_for_Source_Code_Inquiry_Tailored_to_Long-Context_LLMs.md)

    - [翻译: 为长文本环境下的大型语言模型（LLMs）设计了一种源代码查询的随机访问图（RAG）策略。](2024年04月09日/A_RAG_Method_for_Source_Code_Inquiry_Tailored_to_Long-Context_LLMs.md)

- [Unified Multi-modal Diagnostic Framework with Reconstruction Pre-training and Heterogeneity-combat Tuning](2024年04月09日/Unified_Multi-modal_Diagnostic_Framework_with_Reconstruction_Pre-training_and_Heterogeneity-combat_Tuning.md)

    - [翻译: 本研究提出了一种集成的多模态诊断框架，该框架通过重建预训练和针对性的异质性调整，实现了对不同数据源的高效融合与诊断。](2024年04月09日/Unified_Multi-modal_Diagnostic_Framework_with_Reconstruction_Pre-training_and_Heterogeneity-combat_Tuning.md)

- [On Evaluating the Efficiency of Source Code Generated by LLMs](2024年04月09日/On_Evaluating_the_Efficiency_of_Source_Code_Generated_by_LLMs.md)

    - [翻译: 探讨大型语言模型生成源代码的效率评估](2024年04月09日/On_Evaluating_the_Efficiency_of_Source_Code_Generated_by_LLMs.md)

- [PM4Py.LLM: a Comprehensive Module for Implementing PM on LLMs](2024年04月09日/PM4Py.LLM_a_Comprehensive_Module_for_Implementing_PM_on_LLMs.md)

    - [翻译: PM4Py.LLM：为在大型语言模型 (LLM) 中应用过程挖掘 (PM) 而设计的全方位模块。](2024年04月09日/PM4Py.LLM_a_Comprehensive_Module_for_Implementing_PM_on_LLMs.md)

- [FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models](2024年04月09日/FreeEval_A_Modular_Framework_for_Trustworthy_and_Efficient_Evaluation_of_Large_Language_Models.md)

    - [翻译: FreeEval 是一个模块化的评估框架，旨在为大型语言模型提供可靠和高效的评估方法。](2024年04月09日/FreeEval_A_Modular_Framework_for_Trustworthy_and_Efficient_Evaluation_of_Large_Language_Models.md)

- [Privacy Preserving Prompt Engineering: A Survey](2024年04月09日/Privacy_Preserving_Prompt_Engineering_A_Survey.md)

    - [翻译: 本调查研究了如何在保护隐私的前提下，通过提示工程技术提升大型语言模型的性能。](2024年04月09日/Privacy_Preserving_Prompt_Engineering_A_Survey.md)

- [RAR-b: Reasoning as Retrieval Benchmark](2024年04月09日/RAR-b_Reasoning_as_Retrieval_Benchmark.md)

    - [翻译: RAR-b：将推理视作检索的基准测试](2024年04月09日/RAR-b_Reasoning_as_Retrieval_Benchmark.md)

- [Dimensionality Reduction in Sentence Transformer Vector Databases with Fast Fourier Transform](2024年04月09日/Dimensionality_Reduction_in_Sentence_Transformer_Vector_Databases_with_Fast_Fourier_Transform.md)

    - [翻译: 通过快速傅里叶变换技术，实现句子转换器向量数据库的高效降维处理。](2024年04月09日/Dimensionality_Reduction_in_Sentence_Transformer_Vector_Databases_with_Fast_Fourier_Transform.md)

- [AiSAQ: All-in-Storage ANNS with Product Quantization for DRAM-free Information Retrieval](2024年04月09日/AiSAQ_All-in-Storage_ANNS_with_Product_Quantization_for_DRAM-free_Information_Retrieval.md)

    - [翻译: AiSAQ: 采用产品量化技术的全存储式近似最近邻搜索（ANNS），为无需DRAM的信息检索提供解决方案。](2024年04月09日/AiSAQ_All-in-Storage_ANNS_with_Product_Quantization_for_DRAM-free_Information_Retrieval.md)

- [Llama-VITS: Enhancing TTS Synthesis with Semantic Awareness](2024年04月09日/Llama-VITS_Enhancing_TTS_Synthesis_with_Semantic_Awareness.md)

    - [翻译: Llama-VITS：借助语义理解提升TTS语音合成效果](2024年04月09日/Llama-VITS_Enhancing_TTS_Synthesis_with_Semantic_Awareness.md)

- [MathVC: An LLM-Simulated Multi-Character Virtual Classroom for Mathematics Education](2024年04月09日/MathVC_An_LLM-Simulated_Multi-Character_Virtual_Classroom_for_Mathematics_Education.md)

    - [翻译: MathVC：借助大型语言模型打造的多角色虚拟教室，致力于提升数学教学效果。](2024年04月09日/MathVC_An_LLM-Simulated_Multi-Character_Virtual_Classroom_for_Mathematics_Education.md)

- [CQIL: Inference Latency Optimization with Concurrent Computation of Quasi-Independent Layers](2024年04月09日/CQIL_Inference_Latency_Optimization_with_Concurrent_Computation_of_Quasi-Independent_Layers.md)

    - [翻译: CQIL技术：通过同时处理准独立层次以减少推理过程的延迟](2024年04月09日/CQIL_Inference_Latency_Optimization_with_Concurrent_Computation_of_Quasi-Independent_Layers.md)

- [Onco-Retriever: Generative Classifier for Retrieval of EHR Records in Oncology](2024年04月09日/Onco-Retriever_Generative_Classifier_for_Retrieval_of_EHR_Records_in_Oncology.md)

    - [翻译: Onco-Retriever：一种创新的生成式分类器，专门用于在肿瘤学领域快速准确地检索电子健康记录（EHR）。](2024年04月09日/Onco-Retriever_Generative_Classifier_for_Retrieval_of_EHR_Records_in_Oncology.md)

- [Toward Cross-Layer Energy Optimizations in Machine Learning Systems](2024年04月09日/Toward_Cross-Layer_Energy_Optimizations_in_Machine_Learning_Systems.md)

    - [翻译: 探索机器学习系统中的跨层能源优化](2024年04月09日/Toward_Cross-Layer_Energy_Optimizations_in_Machine_Learning_Systems.md)

- [CulturalTeaming: AI-Assisted Interactive Red-Teaming for Challenging LLMs' (Lack of) Multicultural Knowledge](2024年04月09日/CulturalTeaming_AI-Assisted_Interactive_Red-Teaming_for_Challenging_LLMs'_(Lack_of)_Multicultural_Knowledge.md)

    - [翻译: CulturalTeaming：借助人工智能的互动红队策略，挑战大型语言模型在多元文化知识方面的不足。](2024年04月09日/CulturalTeaming_AI-Assisted_Interactive_Red-Teaming_for_Challenging_LLMs'_(Lack_of)_Multicultural_Knowledge.md)

- [RULER: What's the Real Context Size of Your Long-Context Language Models?](2024年04月09日/RULER_What's_the_Real_Context_Size_of_Your_Long-Context_Language_Models.md)

    - [翻译: RULER: 长语境语言模型的实际上下文容量究竟有多大？](2024年04月09日/RULER_What's_the_Real_Context_Size_of_Your_Long-Context_Language_Models.md)

- [GenCHiP: Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks](2024年04月09日/GenCHiP_Generating_Robot_Policy_Code_for_High-Precision_and_Contact-Rich_Manipulation_Tasks.md)

    - [翻译: GenCHiP：针对精密操作和丰富接触任务，自动编写机器人策略代码](2024年04月09日/GenCHiP_Generating_Robot_Policy_Code_for_High-Precision_and_Contact-Rich_Manipulation_Tasks.md)

- [Khayyam Challenge (PersianMMLU): Is Your LLM Truly Wise to The Persian Language?](2024年04月09日/Khayyam_Challenge_(PersianMMLU)_Is_Your_LLM_Truly_Wise_to_The_Persian_Language.md)

    - [翻译: Khayyam挑战赛（PersianMMLU）：你的LLM真的精通波斯语吗？](2024年04月09日/Khayyam_Challenge_(PersianMMLU)_Is_Your_LLM_Truly_Wise_to_The_Persian_Language.md)

- [Perplexed: Understanding When Large Language Models are Confused](2024年04月09日/Perplexed_Understanding_When_Large_Language_Models_are_Confused.md)

    - [翻译: 探究困惑：揭秘大型语言模型何时陷入迷茫](2024年04月09日/Perplexed_Understanding_When_Large_Language_Models_are_Confused.md)

- [What is Your Favorite Gender, MLM? Gender Bias Evaluation in Multilingual Masked Language Models](2024年04月09日/What_is_Your_Favorite_Gender,_MLM_Gender_Bias_Evaluation_in_Multilingual_Masked_Language_Models.md)

    - [翻译: MLM，你偏好的性别是什么？探究多语言掩码语言模型中的性别歧视问题](2024年04月09日/What_is_Your_Favorite_Gender,_MLM_Gender_Bias_Evaluation_in_Multilingual_Masked_Language_Models.md)

- [Less is More for Improving Automatic Evaluation of Factual Consistency](2024年04月09日/Less_is_More_for_Improving_Automatic_Evaluation_of_Factual_Consistency.md)

    - [翻译: 简化方法更有助于提升事实一致性的自动评估效果。](2024年04月09日/Less_is_More_for_Improving_Automatic_Evaluation_of_Factual_Consistency.md)

- [Building A Knowledge Graph to Enrich ChatGPT Responses in Manufacturing Service Discovery](2024年04月09日/Building_A_Knowledge_Graph_to_Enrich_ChatGPT_Responses_in_Manufacturing_Service_Discovery.md)

    - [翻译: 打造知识图谱，提升ChatGPT在制造服务业发现中的答复质量。](2024年04月09日/Building_A_Knowledge_Graph_to_Enrich_ChatGPT_Responses_in_Manufacturing_Service_Discovery.md)

- [Deep Generative Data Assimilation in Multimodal Setting](2024年04月09日/Deep_Generative_Data_Assimilation_in_Multimodal_Setting.md)

    - [翻译: 深度生成式数据融合技术在多模态环境下的应用](2024年04月09日/Deep_Generative_Data_Assimilation_in_Multimodal_Setting.md)

- [Training-Free Open-Vocabulary Segmentation with Offline Diffusion-Augmented Prototype Generation](2024年04月09日/Training-Free_Open-Vocabulary_Segmentation_with_Offline_Diffusion-Augmented_Prototype_Generation.md)

    - [翻译: 通过离线扩散技术增强原型生成，实现无需训练的开放词汇文本分割。](2024年04月09日/Training-Free_Open-Vocabulary_Segmentation_with_Offline_Diffusion-Augmented_Prototype_Generation.md)

- [Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition](2024年04月09日/Sample-Efficient_Human_Evaluation_of_Large_Language_Models_via_Maximum_Discrepancy_Competition.md)

    - [翻译: 利用最大差异竞赛，高效地进行人类对大型语言模型的样本评估](2024年04月09日/Sample-Efficient_Human_Evaluation_of_Large_Language_Models_via_Maximum_Discrepancy_Competition.md)

- [Apollonion: Profile-centric Dialog Agent](2024年04月09日/Apollonion_Profile-centric_Dialog_Agent.md)

    - [翻译: Apollonion：以用户画像为核心的智能对话助手。](2024年04月09日/Apollonion_Profile-centric_Dialog_Agent.md)

- [Text2Grasp: Grasp synthesis by text prompts of object grasping parts](2024年04月09日/Text2Grasp_Grasp_synthesis_by_text_prompts_of_object_grasping_parts.md)

    - [翻译: Text2Grasp：通过文字描述物体的抓握部位来实现抓取动作的合成](2024年04月09日/Text2Grasp_Grasp_synthesis_by_text_prompts_of_object_grasping_parts.md)

2024年04月08日

- [A Large-Scale Exploration of $μ$-Transfer](2024年04月08日/A_Large-Scale_Exploration_of_$μ$-Transfer.md)

    - [翻译: 本研究进行了对 $μ$-转移的大规模探索，旨在深入理解其在不同情境下的应用和影响。](2024年04月08日/A_Large-Scale_Exploration_of_$μ$-Transfer.md)

- [MA-LMM: Memory-Augmented Large Multimodal Model for Long-Term Video Understanding](2024年04月08日/MA-LMM_Memory-Augmented_Large_Multimodal_Model_for_Long-Term_Video_Understanding.md)

    - [翻译: MA-LMM 模型：为深入理解长时段视频内容而设计的具有记忆功能的多模态大型模型。](2024年04月08日/MA-LMM_Memory-Augmented_Large_Multimodal_Model_for_Long-Term_Video_Understanding.md)

- [Ferret-UI: Grounded Mobile UI Understanding with Multimodal LLMs](2024年04月08日/Ferret-UI_Grounded_Mobile_UI_Understanding_with_Multimodal_LLMs.md)

    - [翻译: Ferret-UI 利用多模态大型语言模型，实现对移动用户界面的深入理解。](2024年04月08日/Ferret-UI_Grounded_Mobile_UI_Understanding_with_Multimodal_LLMs.md)

- [Comprehensive Study on German Language Models for Clinical and Biomedical Text Understanding](2024年04月08日/Comprehensive_Study_on_German_Language_Models_for_Clinical_and_Biomedical_Text_Understanding.md)

    - [翻译: 本研究深入探讨了德语语言模型在临床及生物医学文本理解方面的表现。](2024年04月08日/Comprehensive_Study_on_German_Language_Models_for_Clinical_and_Biomedical_Text_Understanding.md)

- [Evaluating Mathematical Reasoning Beyond Accuracy](2024年04月08日/Evaluating_Mathematical_Reasoning_Beyond_Accuracy.md)

    - [翻译: 数学推理的评估，超越了单纯的准确率](2024年04月08日/Evaluating_Mathematical_Reasoning_Beyond_Accuracy.md)

- [Retrieval-Augmented Open-Vocabulary Object Detection](2024年04月08日/Retrieval-Augmented_Open-Vocabulary_Object_Detection.md)

    - [翻译: 开放词汇表的目标检测通过检索增强技术得以实现。](2024年04月08日/Retrieval-Augmented_Open-Vocabulary_Object_Detection.md)

- [MoMA: Multimodal LLM Adapter for Fast Personalized Image Generation](2024年04月08日/MoMA_Multimodal_LLM_Adapter_for_Fast_Personalized_Image_Generation.md)

    - [翻译: MoMA 是一款多模态适配器，专为大型语言模型打造，旨在实现快速且个性化的图像创作。](2024年04月08日/MoMA_Multimodal_LLM_Adapter_for_Fast_Personalized_Image_Generation.md)

- [CoReS: Orchestrating the Dance of Reasoning and Segmentation](2024年04月08日/CoReS_Orchestrating_the_Dance_of_Reasoning_and_Segmentation.md)

    - [翻译: CoReS：协同演绎推理与分割的协奏曲](2024年04月08日/CoReS_Orchestrating_the_Dance_of_Reasoning_and_Segmentation.md)

- [Fighting crime with Transformers: Empirical analysis of address parsing methods in payment data](2024年04月08日/Fighting_crime_with_Transformers_Empirical_analysis_of_address_parsing_methods_in_payment_data.md)

    - [翻译: 以变换器助力打击犯罪：对支付数据中地址解析方法的实证研究](2024年04月08日/Fighting_crime_with_Transformers_Empirical_analysis_of_address_parsing_methods_in_payment_data.md)

- [LTNER: Large Language Model Tagging for Named Entity Recognition with Contextualized Entity Marking](2024年04月08日/LTNER_Large_Language_Model_Tagging_for_Named_Entity_Recognition_with_Contextualized_Entity_Marking.md)

    - [翻译: LTNER：一种大型语言模型，通过情境化标记技术，专门用于命名实体的识别。](2024年04月08日/LTNER_Large_Language_Model_Tagging_for_Named_Entity_Recognition_with_Contextualized_Entity_Marking.md)

- [AnchorAL: Computationally Efficient Active Learning for Large and Imbalanced Datasets](2024年04月08日/AnchorAL_Computationally_Efficient_Active_Learning_for_Large_and_Imbalanced_Datasets.md)

    - [翻译: AnchorAL 采用了一种计算高效的方法，专为处理规模庞大且不平衡的数据集而设计的主动学习技术。](2024年04月08日/AnchorAL_Computationally_Efficient_Active_Learning_for_Large_and_Imbalanced_Datasets.md)

- [MULTIFLOW: Shifting Towards Task-Agnostic Vision-Language Pruning](2024年04月08日/MULTIFLOW_Shifting_Towards_Task-Agnostic_Vision-Language_Pruning.md)

    - [翻译: MULTIFLOW：迈向与任务无关的视觉-语言模型精简方法](2024年04月08日/MULTIFLOW_Shifting_Towards_Task-Agnostic_Vision-Language_Pruning.md)

- [MedExpQA: Multilingual Benchmarking of Large Language Models for Medical Question Answering](2024年04月08日/MedExpQA_Multilingual_Benchmarking_of_Large_Language_Models_for_Medical_Question_Answering.md)

    - [翻译: MedExpQA：多语言环境下大型语言模型在医学问答任务中的评估基准](2024年04月08日/MedExpQA_Multilingual_Benchmarking_of_Large_Language_Models_for_Medical_Question_Answering.md)

- [360°REA: Towards A Reusable Experience Accumulation with 360° Assessment for Multi-Agent System](2024年04月08日/360°REA_Towards_A_Reusable_Experience_Accumulation_with_360°_Assessment_for_Multi-Agent_System.md)

    - [翻译: 360°REA：探索多智能体系统中可复用的经验积累，通过全方位的360°评估来实现。](2024年04月08日/360°REA_Towards_A_Reusable_Experience_Accumulation_with_360°_Assessment_for_Multi-Agent_System.md)

- [Evaluating Interventional Reasoning Capabilities of Large Language Models](2024年04月08日/Evaluating_Interventional_Reasoning_Capabilities_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的干预性推理能力](2024年04月08日/Evaluating_Interventional_Reasoning_Capabilities_of_Large_Language_Models.md)

- [OPSD: an Offensive Persian Social media Dataset and its baseline evaluations](2024年04月08日/OPSD_an_Offensive_Persian_Social_media_Dataset_and_its_baseline_evaluations.md)

    - [翻译: OPSD：一个针对波斯语社交媒体的攻击性行为数据集及其基础性能评价](2024年04月08日/OPSD_an_Offensive_Persian_Social_media_Dataset_and_its_baseline_evaluations.md)

- [Best-of-Venom: Attacking RLHF by Injecting Poisoned Preference Data](2024年04月08日/Best-of-Venom_Attacking_RLHF_by_Injecting_Poisoned_Preference_Data.md)

    - [翻译: 《最佳毒液：注入恶意偏好数据以攻击强化学习人类反馈》](2024年04月08日/Best-of-Venom_Attacking_RLHF_by_Injecting_Poisoned_Preference_Data.md)

- [3DMambaIPF: A State Space Model for Iterative Point Cloud Filtering via Differentiable Rendering](2024年04月08日/3DMambaIPF_A_State_Space_Model_for_Iterative_Point_Cloud_Filtering_via_Differentiable_Rendering.md)

    - [翻译: 3DMambaIPF：一种利用可微渲染技术实现迭代点云滤波的状态空间模型。](2024年04月08日/3DMambaIPF_A_State_Space_Model_for_Iterative_Point_Cloud_Filtering_via_Differentiable_Rendering.md)

- [The Fact Selection Problem in LLM-Based Program Repair](2024年04月08日/The_Fact_Selection_Problem_in_LLM-Based_Program_Repair.md)

    - [翻译: 在利用大型语言模型（LLM）进行程序修复时，事实选择问题尤为突出。](2024年04月08日/The_Fact_Selection_Problem_in_LLM-Based_Program_Repair.md)

- [Synergy of Large Language Model and Model Driven Engineering for Automated Development of Centralized Vehicular Systems](2024年04月08日/Synergy_of_Large_Language_Model_and_Model_Driven_Engineering_for_Automated_Development_of_Centralized_Vehicular_Systems.md)

    - [翻译: 大型语言模型与模型驱动工程相结合，为集中式车辆系统的自动化开发提供强大助力。](2024年04月08日/Synergy_of_Large_Language_Model_and_Model_Driven_Engineering_for_Automated_Development_of_Centralized_Vehicular_Systems.md)

- [Constraining Large Language Model for Generating Computer-Parsable Content](2024年04月08日/Constraining_Large_Language_Model_for_Generating_Computer-Parsable_Content.md)

    - [翻译: 通过对大型语言模型施加限制，我们能够生成计算机能够理解和解析的内容。](2024年04月08日/Constraining_Large_Language_Model_for_Generating_Computer-Parsable_Content.md)

- [HAMMR: HierArchical MultiModal React agents for generic VQA](2024年04月08日/HAMMR_HierArchical_MultiModal_React_agents_for_generic_VQA.md)

    - [翻译: HAMMR：构建通用视觉问答系统中的层级多模态智能反应代理](2024年04月08日/HAMMR_HierArchical_MultiModal_React_agents_for_generic_VQA.md)

- [RoT: Enhancing Large Language Models with Reflection on Search Trees](2024年04月08日/RoT_Enhancing_Large_Language_Models_with_Reflection_on_Search_Trees.md)

    - [翻译: RoT 技术：借助搜索树反思，提升大型语言模型的性能](2024年04月08日/RoT_Enhancing_Large_Language_Models_with_Reflection_on_Search_Trees.md)

- [XL$^2$Bench: A Benchmark for Extremely Long Context Understanding with Long-range Dependencies](2024年04月08日/XL$^2$Bench_A_Benchmark_for_Extremely_Long_Context_Understanding_with_Long-range_Dependencies.md)

    - [翻译: XL$^2$Bench：针对极长上下文理解及其长距离依赖性的基准测试平台。](2024年04月08日/XL$^2$Bench_A_Benchmark_for_Extremely_Long_Context_Understanding_with_Long-range_Dependencies.md)

- [Unlocking Adaptive User Experience with Generative AI](2024年04月08日/Unlocking_Adaptive_User_Experience_with_Generative_AI.md)

    - [翻译: 利用生成性 AI 打造个性化用户体验](2024年04月08日/Unlocking_Adaptive_User_Experience_with_Generative_AI.md)

- [Language Models on a Diet: Cost-Efficient Development of Encoders for Closely-Related Languages via Additional Pretraining](2024年04月08日/Language_Models_on_a_Diet_Cost-Efficient_Development_of_Encoders_for_Closely-Related_Languages_via_Additional_Pretraining.md)

    - [翻译: 节食中的语言模型：通过额外的预训练，经济高效地为近缘语言打造编码器。](2024年04月08日/Language_Models_on_a_Diet_Cost-Efficient_Development_of_Encoders_for_Closely-Related_Languages_via_Additional_Pretraining.md)

- [AutoCodeRover: Autonomous Program Improvement](2024年04月08日/AutoCodeRover_Autonomous_Program_Improvement.md)

    - [翻译: AutoCodeRover：智能程序优化专家](2024年04月08日/AutoCodeRover_Autonomous_Program_Improvement.md)

- [Test-Time Zero-Shot Temporal Action Localization](2024年04月08日/Test-Time_Zero-Shot_Temporal_Action_Localization.md)

    - [翻译: 在测试阶段实现零-shot技术的时间动作定位](2024年04月08日/Test-Time_Zero-Shot_Temporal_Action_Localization.md)

- [Relation Extraction Using Large Language Models: A Case Study on Acupuncture Point Locations](2024年04月08日/Relation_Extraction_Using_Large_Language_Models_A_Case_Study_on_Acupuncture_Point_Locations.md)

    - [翻译: 通过大型语言模型进行关系提取研究：以针灸穴位位置为例](2024年04月08日/Relation_Extraction_Using_Large_Language_Models_A_Case_Study_on_Acupuncture_Point_Locations.md)

- [Know When To Stop: A Study of Semantic Drift in Text Generation](2024年04月08日/Know_When_To_Stop_A_Study_of_Semantic_Drift_in_Text_Generation.md)

    - [翻译: 适时止步：探究文本创造中的语义漂移现象](2024年04月08日/Know_When_To_Stop_A_Study_of_Semantic_Drift_in_Text_Generation.md)

- [PerkwE_COQA: enhance Persian Conversational Question Answering by combining contextual keyword extraction with Large Language Models](2024年04月08日/PerkwE_COQA_enhance_Persian_Conversational_Question_Answering_by_combining_contextual_keyword_extraction_with_Large_Language_Models.md)

    - [翻译: PerkwE_COQA：融合上下文关键词抓取与大型语言模型，提升波斯语对话问答系统的性能。](2024年04月08日/PerkwE_COQA_enhance_Persian_Conversational_Question_Answering_by_combining_contextual_keyword_extraction_with_Large_Language_Models.md)

- [SafetyPrompts: a Systematic Review of Open Datasets for Evaluating and Improving Large Language Model Safety](2024年04月08日/SafetyPrompts_a_Systematic_Review_of_Open_Datasets_for_Evaluating_and_Improving_Large_Language_Model_Safety.md)

    - [翻译: 《安全提示：大型语言模型安全性评估与提升的开放数据集系统综述》](2024年04月08日/SafetyPrompts_a_Systematic_Review_of_Open_Datasets_for_Evaluating_and_Improving_Large_Language_Model_Safety.md)

- [Towards Objectively Benchmarking Social Intelligence for Language Agents at Action Level](2024年04月08日/Towards_Objectively_Benchmarking_Social_Intelligence_for_Language_Agents_at_Action_Level.md)

    - [翻译: 旨在客观地衡量语言代理在行动层面的社会智能。](2024年04月08日/Towards_Objectively_Benchmarking_Social_Intelligence_for_Language_Agents_at_Action_Level.md)

- [Long-horizon Locomotion and Manipulation on a Quadrupedal Robot with Large Language Models](2024年04月08日/Long-horizon_Locomotion_and_Manipulation_on_a_Quadrupedal_Robot_with_Large_Language_Models.md)

    - [翻译: 在四足机器人上，结合大型语言模型实现远程运动与操控](2024年04月08日/Long-horizon_Locomotion_and_Manipulation_on_a_Quadrupedal_Robot_with_Large_Language_Models.md)

- [Unbridled Icarus: A Survey of the Potential Perils of Image Inputs in Multimodal Large Language Model Security](2024年04月08日/Unbridled_Icarus_A_Survey_of_the_Potential_Perils_of_Image_Inputs_in_Multimodal_Large_Language_Model_Security.md)

    - [翻译: 伊卡洛斯之翼：探究多模态大型语言模型安全性中图像输入可能带来的风险](2024年04月08日/Unbridled_Icarus_A_Survey_of_the_Potential_Perils_of_Image_Inputs_in_Multimodal_Large_Language_Model_Security.md)

- [PromptAD: Learning Prompts with only Normal Samples for Few-Shot Anomaly Detection](2024年04月08日/PromptAD_Learning_Prompts_with_only_Normal_Samples_for_Few-Shot_Anomaly_Detection.md)

    - [翻译: PromptAD 研究：仅通过正常样本进行学习，实现少样本情况下的高效异常检测。](2024年04月08日/PromptAD_Learning_Prompts_with_only_Normal_Samples_for_Few-Shot_Anomaly_Detection.md)

- [LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding](2024年04月08日/LayoutLLM_Layout_Instruction_Tuning_with_Large_Language_Models_for_Document_Understanding.md)

    - [翻译: LayoutLLM：利用大型语言模型对布局指令进行优化，提升文档理解能力](2024年04月08日/LayoutLLM_Layout_Instruction_Tuning_with_Large_Language_Models_for_Document_Understanding.md)

- [LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models](2024年04月08日/LLM_Reasoners_New_Evaluation,_Library,_and_Analysis_of_Step-by-Step_Reasoning_with_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的推理能力：构建新评估体系、推理资源库，并深入分析其逐步推理过程。](2024年04月08日/LLM_Reasoners_New_Evaluation,_Library,_and_Analysis_of_Step-by-Step_Reasoning_with_Large_Language_Models.md)

- [Have You Merged My Model? On The Robustness of Large Language Model IP Protection Methods Against Model Merging](2024年04月08日/Have_You_Merged_My_Model_On_The_Robustness_of_Large_Language_Model_IP_Protection_Methods_Against_Model_Merging.md)

    - [翻译: 我的模型被合并了吗？探究大型语言模型知识产权防护措施在抵御模型合并攻击时的坚固程度。](2024年04月08日/Have_You_Merged_My_Model_On_The_Robustness_of_Large_Language_Model_IP_Protection_Methods_Against_Model_Merging.md)

- [Progressive Alignment with VLM-LLM Feature to Augment Defect Classification for the ASE Dataset](2024年04月08日/Progressive_Alignment_with_VLM-LLM_Feature_to_Augment_Defect_Classification_for_the_ASE_Dataset.md)

    - [翻译: 通过 VLM-LLM 特征的渐进式对齐方法，提升 ASE 数据集中缺陷识别的准确性。](2024年04月08日/Progressive_Alignment_with_VLM-LLM_Feature_to_Augment_Defect_Classification_for_the_ASE_Dataset.md)

- [DLoRA: Distributed Parameter-Efficient Fine-Tuning Solution for Large Language Model](2024年04月08日/DLoRA_Distributed_Parameter-Efficient_Fine-Tuning_Solution_for_Large_Language_Model.md)

    - [翻译: DLoRA 为大型语言模型提供了一种分布式的、参数高效的微调方法。](2024年04月08日/DLoRA_Distributed_Parameter-Efficient_Fine-Tuning_Solution_for_Large_Language_Model.md)

- [Enhancing Software Related Information Extraction with Generative Language Models through Single-Choice Question Answering](2024年04月08日/Enhancing_Software_Related_Information_Extraction_with_Generative_Language_Models_through_Single-Choice_Question_Answering.md)

    - [翻译: 借助生成性语言模型，我们可以通过单选题问答的方式，提升软件信息抽取的效果。](2024年04月08日/Enhancing_Software_Related_Information_Extraction_with_Generative_Language_Models_through_Single-Choice_Question_Answering.md)

- [Responsible Visual Editing](2024年04月08日/Responsible_Visual_Editing.md)

    - [翻译: 在视觉编辑领域，我们强调负责任的实践，旨在确保编辑过程不仅追求美观，而且兼顾道德和文化敏感性。](2024年04月08日/Responsible_Visual_Editing.md)

- [AEGIS: Online Adaptive AI Content Safety Moderation with Ensemble of LLM Experts](2024年04月08日/AEGIS_Online_Adaptive_AI_Content_Safety_Moderation_with_Ensemble_of_LLM_Experts.md)

    - [翻译: AEGIS：借助众多大型语言模型专家的协同力量，实现在线内容的自适应AI安全审核。](2024年04月08日/AEGIS_Online_Adaptive_AI_Content_Safety_Moderation_with_Ensemble_of_LLM_Experts.md)

- [Automatic Authorities: Power and AI](2024年04月08日/Automatic_Authorities_Power_and_AI.md)

    - [翻译: 自动权威：探讨权力与AI的结合](2024年04月08日/Automatic_Authorities_Power_and_AI.md)

- [Optimization Methods for Personalizing Large Language Models through Retrieval Augmentation](2024年04月08日/Optimization_Methods_for_Personalizing_Large_Language_Models_through_Retrieval_Augmentation.md)

    - [翻译: 通过检索增强技术，优化大型语言模型的个性化方法研究](2024年04月08日/Optimization_Methods_for_Personalizing_Large_Language_Models_through_Retrieval_Augmentation.md)

- [LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders](2024年04月08日/LLM2Vec_Large_Language_Models_Are_Secretly_Powerful_Text_Encoders.md)

    - [翻译: LLM2Vec：大型语言模型，悄然成为强大的文本编码利器](2024年04月08日/LLM2Vec_Large_Language_Models_Are_Secretly_Powerful_Text_Encoders.md)

- [VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?](2024年04月08日/VisualWebBench_How_Far_Have_Multimodal_LLMs_Evolved_in_Web_Page_Understanding_and_Grounding.md)

    - [翻译: VisualWebBench: 多模态LLM在网页理解和定位领域究竟取得了多大的进展？](2024年04月08日/VisualWebBench_How_Far_Have_Multimodal_LLMs_Evolved_in_Web_Page_Understanding_and_Grounding.md)

- [The Hallucinations Leaderboard -- An Open Effort to Measure Hallucinations in Large Language Models](2024年04月08日/The_Hallucinations_Leaderboard_--_An_Open_Effort_to_Measure_Hallucinations_in_Large_Language_Models.md)

    - [翻译: 《幻觉排行榜》—— 一场旨在衡量大型语言模型幻觉现象的公开行动。](2024年04月08日/The_Hallucinations_Leaderboard_--_An_Open_Effort_to_Measure_Hallucinations_in_Large_Language_Models.md)

- [WILBUR: Adaptive In-Context Learning for Robust and Accurate Web Agents](2024年04月08日/WILBUR_Adaptive_In-Context_Learning_for_Robust_and_Accurate_Web_Agents.md)

    - [翻译: WILBUR：为打造强大精准的网络代理，采用自适应式上下文学习方法](2024年04月08日/WILBUR_Adaptive_In-Context_Learning_for_Robust_and_Accurate_Web_Agents.md)

- [Use of a Structured Knowledge Base Enhances Metadata Curation by Large Language Models](2024年04月08日/Use_of_a_Structured_Knowledge_Base_Enhances_Metadata_Curation_by_Large_Language_Models.md)

    - [翻译: 借助结构化知识库，大型语言模型在元数据策划方面的能力得到提升。](2024年04月08日/Use_of_a_Structured_Knowledge_Base_Enhances_Metadata_Curation_by_Large_Language_Models.md)

- [Eraser: Jailbreaking Defense in Large Language Models via Unlearning Harmful Knowledge](2024年04月08日/Eraser_Jailbreaking_Defense_in_Large_Language_Models_via_Unlearning_Harmful_Knowledge.md)

    - [翻译: Eraser：通过摒弃有害知识，打破大型语言模型的束缚](2024年04月08日/Eraser_Jailbreaking_Defense_in_Large_Language_Models_via_Unlearning_Harmful_Knowledge.md)

- [Event-enhanced Retrieval in Real-time Search](2024年04月08日/Event-enhanced_Retrieval_in_Real-time_Search.md)

    - [翻译: 实时搜索中，通过事件增强的检索技术可以有效提升搜索质量。但目前，我们对于如何充分发挥事件信息的作用，以优化检索结果的相关性和准确性，尚存诸多不明之处。本研究致力于探索事件信息在实时搜索中的应用，并分析其对提升检索效能的具体影响。](2024年04月08日/Event-enhanced_Retrieval_in_Real-time_Search.md)

- [Xiwu: A Basis Flexible and Learnable LLM for High Energy Physics](2024年04月08日/Xiwu_A_Basis_Flexible_and_Learnable_LLM_for_High_Energy_Physics.md)

    - [翻译: Xiwu：一款适应高能物理领域的基础性、灵活性强且具备学习能力的大型语言模型](2024年04月08日/Xiwu_A_Basis_Flexible_and_Learnable_LLM_for_High_Energy_Physics.md)

2024年04月07日

- [Linguistic Changes in Spontaneous Speech for Detecting Parkinsons Disease Using Large Language Models](2024年04月07日/Linguistic_Changes_in_Spontaneous_Speech_for_Detecting_Parkinsons_Disease_Using_Large_Language_Models.md)

    - [翻译: 通过分析自发口语中的语言变化，借助大型语言模型来识别帕金森病的迹象。](2024年04月07日/Linguistic_Changes_in_Spontaneous_Speech_for_Detecting_Parkinsons_Disease_Using_Large_Language_Models.md)

- [Enhancing Clinical Efficiency through LLM: Discharge Note Generation for Cardiac Patients](2024年04月07日/Enhancing_Clinical_Efficiency_through_LLM_Discharge_Note_Generation_for_Cardiac_Patients.md)

    - [翻译: 利用大型语言模型优化临床工作流程：自动撰写心脏病患者出院小结。](2024年04月07日/Enhancing_Clinical_Efficiency_through_LLM_Discharge_Note_Generation_for_Cardiac_Patients.md)

- [Plug and Play with Prompts: A Prompt Tuning Approach for Controlling Text Generation](2024年04月07日/Plug_and_Play_with_Prompts_A_Prompt_Tuning_Approach_for_Controlling_Text_Generation.md)

    - [翻译: 玩转提示：巧用提示调整技术驾驭文本生成](2024年04月07日/Plug_and_Play_with_Prompts_A_Prompt_Tuning_Approach_for_Controlling_Text_Generation.md)

- [LLM-BT: Performing Robotic Adaptive Tasks based on Large Language Models and Behavior Trees](2024年04月07日/LLM-BT_Performing_Robotic_Adaptive_Tasks_based_on_Large_Language_Models_and_Behavior_Trees.md)

    - [翻译: 利用大型语言模型与行为树，实现机器人的自适应任务执行。](2024年04月07日/LLM-BT_Performing_Robotic_Adaptive_Tasks_based_on_Large_Language_Models_and_Behavior_Trees.md)

- [EcoVerse: An Annotated Twitter Dataset for Eco-Relevance Classification, Environmental Impact Analysis, and Stance Detection](2024年04月07日/EcoVerse_An_Annotated_Twitter_Dataset_for_Eco-Relevance_Classification,_Environmental_Impact_Analysis,_and_Stance_Detection.md)

    - [翻译: EcoVerse: 一个针对生态相关性分类、环境影响评估和立场识别的推特数据集注释项目](2024年04月07日/EcoVerse_An_Annotated_Twitter_Dataset_for_Eco-Relevance_Classification,_Environmental_Impact_Analysis,_and_Stance_Detection.md)

- [StockGPT: A GenAI Model for Stock Prediction and Trading](2024年04月07日/StockGPT_A_GenAI_Model_for_Stock_Prediction_and_Trading.md)

    - [翻译: StockGPT：一款股票预测与交易的智能AI模型](2024年04月07日/StockGPT_A_GenAI_Model_for_Stock_Prediction_and_Trading.md)

- [Advancing Geometric Problem Solving: A Comprehensive Benchmark for Multimodal Model Evaluation](2024年04月07日/Advancing_Geometric_Problem_Solving_A_Comprehensive_Benchmark_for_Multimodal_Model_Evaluation.md)

    - [翻译: 在几何问题求解领域取得新进展：构建全方位多模态模型评测的权威基准](2024年04月07日/Advancing_Geometric_Problem_Solving_A_Comprehensive_Benchmark_for_Multimodal_Model_Evaluation.md)

- [A Note on LoRA](2024年04月07日/A_Note_on_LoRA.md)

    - [翻译: LoRA浅析](2024年04月07日/A_Note_on_LoRA.md)

- [HaVTR: Improving Video-Text Retrieval Through Augmentation Using Large Foundation Models](2024年04月07日/HaVTR_Improving_Video-Text_Retrieval_Through_Augmentation_Using_Large_Foundation_Models.md)

    - [翻译: HaVTR：借助大型基础模型的增强功能，提升视频与文本的检索效能](2024年04月07日/HaVTR_Improving_Video-Text_Retrieval_Through_Augmentation_Using_Large_Foundation_Models.md)

- [RoboMP$^2$: A Robotic Multimodal Perception-Planning Framework with Multimodal Large Language Models](2024年04月07日/RoboMP$^2$_A_Robotic_Multimodal_Perception-Planning_Framework_with_Multimodal_Large_Language_Models.md)

    - [翻译: RoboMP$^2$：融合多模态大型语言模型的机器人感知与规划架构](2024年04月07日/RoboMP$^2$_A_Robotic_Multimodal_Perception-Planning_Framework_with_Multimodal_Large_Language_Models.md)

- [LLM-Based Multi-Agent Systems for Software Engineering: Vision and the Road Ahead](2024年04月07日/LLM-Based_Multi-Agent_Systems_for_Software_Engineering_Vision_and_the_Road_Ahead.md)

    - [翻译: 软件工程领域的多智能体系统基于大型语言模型（LLM），展望未来的发展蓝图。](2024年04月07日/LLM-Based_Multi-Agent_Systems_for_Software_Engineering_Vision_and_the_Road_Ahead.md)

- [X-VARS: Introducing Explainability in Football Refereeing with Multi-Modal Large Language Model](2024年04月07日/X-VARS_Introducing_Explainability_in_Football_Refereeing_with_Multi-Modal_Large_Language_Model.md)

    - [翻译: X-VARS: 融合多模态大型语言模型，为足球裁判决策带来可解释性](2024年04月07日/X-VARS_Introducing_Explainability_in_Football_Refereeing_with_Multi-Modal_Large_Language_Model.md)

- [Information Retrieval with Entity Linking](2024年04月07日/Information_Retrieval_with_Entity_Linking.md)

    - [翻译: 通过实体链接进行信息检索](2024年04月07日/Information_Retrieval_with_Entity_Linking.md)

2024年04月06日

- [Q-PEFT: Query-dependent Parameter Efficient Fine-tuning for Text Reranking with Large Language Models](2024年04月06日/Q-PEFT_Query-dependent_Parameter_Efficient_Fine-tuning_for_Text_Reranking_with_Large_Language_Models.md)

    - [翻译: Q-PEFT 技术：为大型语言模型在文本重排序任务中提供基于查询的高效参数调整方法](2024年04月06日/Q-PEFT_Query-dependent_Parameter_Efficient_Fine-tuning_for_Text_Reranking_with_Large_Language_Models.md)

- [IITK at SemEval-2024 Task 2: Exploring the Capabilities of LLMs for Safe Biomedical Natural Language Inference for Clinical Trials](2024年04月06日/IITK_at_SemEval-2024_Task_2_Exploring_the_Capabilities_of_LLMs_for_Safe_Biomedical_Natural_Language_Inference_for_Clinical_Trials.md)

    - [翻译: IITK 参与 SemEval-2024 的第二项任务，旨在挖掘大型语言模型在临床试验领域进行安全生物医学自然语言推理的潜力。](2024年04月06日/IITK_at_SemEval-2024_Task_2_Exploring_the_Capabilities_of_LLMs_for_Safe_Biomedical_Natural_Language_Inference_for_Clinical_Trials.md)

- [Challenges Faced by Large Language Models in Solving Multi-Agent Flocking](2024年04月06日/Challenges_Faced_by_Large_Language_Models_in_Solving_Multi-Agent_Flocking.md)

    - [翻译: 大型语言模型在处理多智能体群体行为问题时遭遇的难题](2024年04月06日/Challenges_Faced_by_Large_Language_Models_in_Solving_Multi-Agent_Flocking.md)

- [MACM: Utilizing a Multi-Agent System for Condition Mining in Solving Complex Mathematical Problems](2024年04月06日/MACM_Utilizing_a_Multi-Agent_System_for_Condition_Mining_in_Solving_Complex_Mathematical_Problems.md)

    - [翻译: MACM：通过多智能体系统进行条件挖掘，以应对复杂的数学难题。](2024年04月06日/MACM_Utilizing_a_Multi-Agent_System_for_Condition_Mining_in_Solving_Complex_Mathematical_Problems.md)

- [Autonomous Artificial Intelligence Agents for Clinical Decision Making in Oncology](2024年04月06日/Autonomous_Artificial_Intelligence_Agents_for_Clinical_Decision_Making_in_Oncology.md)

    - [翻译: 在肿瘤学领域，我们运用自主性人工智能代理来辅助临床决策过程。](2024年04月06日/Autonomous_Artificial_Intelligence_Agents_for_Clinical_Decision_Making_in_Oncology.md)

- [Do We Really Need a Complex Agent System? Distill Embodied Agent into a Single Model](2024年04月06日/Do_We_Really_Need_a_Complex_Agent_System_Distill_Embodied_Agent_into_a_Single_Model.md)

    - [翻译: 我们真的需要构建复杂的代理系统吗？不如将具身智能体简化为一个模型。](2024年04月06日/Do_We_Really_Need_a_Complex_Agent_System_Distill_Embodied_Agent_into_a_Single_Model.md)

- [GenEARL: A Training-Free Generative Framework for Multimodal Event Argument Role Labeling](2024年04月06日/GenEARL_A_Training-Free_Generative_Framework_for_Multimodal_Event_Argument_Role_Labeling.md)

    - [翻译: GenEARL：一种无需训练的多模态事件角色标注生成框架](2024年04月06日/GenEARL_A_Training-Free_Generative_Framework_for_Multimodal_Event_Argument_Role_Labeling.md)

- [Interpretable Multimodal Learning for Cardiovascular Hemodynamics Assessment](2024年04月06日/Interpretable_Multimodal_Learning_for_Cardiovascular_Hemodynamics_Assessment.md)

    - [翻译: 心血管血流动力学评估中的可解释性多模态学习](2024年04月06日/Interpretable_Multimodal_Learning_for_Cardiovascular_Hemodynamics_Assessment.md)

- [Joint Visual and Text Prompting for Improved Object-Centric Perception with Multimodal Large Language Models](2024年04月06日/Joint_Visual_and_Text_Prompting_for_Improved_Object-Centric_Perception_with_Multimodal_Large_Language_Models.md)

    - [翻译: 通过结合视觉和文本提示，我们利用多模态大型语言模型，显著提升了对物体中心的感知能力。](2024年04月06日/Joint_Visual_and_Text_Prompting_for_Improved_Object-Centric_Perception_with_Multimodal_Large_Language_Models.md)

- [A Multi-Level Framework for Accelerating Training Transformer Models](2024年04月06日/A_Multi-Level_Framework_for_Accelerating_Training_Transformer_Models.md)

    - [翻译: 为了加快变换模型的训练速度，我们提出了一个多层次的框架。](2024年04月06日/A_Multi-Level_Framework_for_Accelerating_Training_Transformer_Models.md)

- [PMG : Personalized Multimodal Generation with Large Language Models](2024年04月06日/PMG__Personalized_Multimodal_Generation_with_Large_Language_Models.md)

    - [翻译: PMG：借助大型语言模型实现个性化的多模态创作](2024年04月06日/PMG__Personalized_Multimodal_Generation_with_Large_Language_Models.md)

2024年04月05日

- [Physical Property Understanding from Language-Embedded Feature Fields](2024年04月05日/Physical_Property_Understanding_from_Language-Embedded_Feature_Fields.md)

    - [翻译: 通过语言嵌入的特征场来掌握物理属性理解](2024年04月05日/Physical_Property_Understanding_from_Language-Embedded_Feature_Fields.md)

- [Cleared for Takeoff? Compositional & Conditional Reasoning may be the Achilles Heel to (Flight-Booking) Language Agents](2024年04月05日/Cleared_for_Takeoff_Compositional_&_Conditional_Reasoning_may_be_the_Achilles_Heel_to_(Flight-Booking)_Language_Agents.md)

    - [翻译: 起飞在即？组合与条件推理或许会成为机票预订语言助手的软肋。](2024年04月05日/Cleared_for_Takeoff_Compositional_&_Conditional_Reasoning_may_be_the_Achilles_Heel_to_(Flight-Booking)_Language_Agents.md)

- [Unlocking Parameter-Efficient Fine-Tuning for Low-Resource Language Translation](2024年04月05日/Unlocking_Parameter-Efficient_Fine-Tuning_for_Low-Resource_Language_Translation.md)

    - [翻译: 探索低资源语言翻译的高效参数微调方法](2024年04月05日/Unlocking_Parameter-Efficient_Fine-Tuning_for_Low-Resource_Language_Translation.md)

- [Social Skill Training with Large Language Models](2024年04月05日/Social_Skill_Training_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型开展社交技巧培训](2024年04月05日/Social_Skill_Training_with_Large_Language_Models.md)

- [Chinese Tiny LLM: Pretraining a Chinese-Centric Large Language Model](2024年04月05日/Chinese_Tiny_LLM_Pretraining_a_Chinese-Centric_Large_Language_Model.md)

    - [翻译: 中文迷你巨模：打造一个专注于中文的超大语言预训练模型](2024年04月05日/Chinese_Tiny_LLM_Pretraining_a_Chinese-Centric_Large_Language_Model.md)

- [Large language models as oracles for instantiating ontologies with domain-specific knowledge](2024年04月05日/Large_language_models_as_oracles_for_instantiating_ontologies_with_domain-specific_knowledge.md)

    - [翻译: 大型语言模型充当领域专业知识本体的即插即用式智能顾问。](2024年04月05日/Large_language_models_as_oracles_for_instantiating_ontologies_with_domain-specific_knowledge.md)

- [Robust Preference Optimization with Provable Noise Tolerance for LLMs](2024年04月05日/Robust_Preference_Optimization_with_Provable_Noise_Tolerance_for_LLMs.md)

    - [翻译: 在大型语言模型中，我们研发了一种鲁棒偏好优化算法，它能够有效抵御噪声干扰，确保了算法的稳定性和可靠性。](2024年04月05日/Robust_Preference_Optimization_with_Provable_Noise_Tolerance_for_LLMs.md)

- [Assessing the quality of information extraction](2024年04月05日/Assessing_the_quality_of_information_extraction.md)

    - [翻译: 对信息提取品质进行评定](2024年04月05日/Assessing_the_quality_of_information_extraction.md)

- [CLUE: A Clinical Language Understanding Evaluation for LLMs](2024年04月05日/CLUE_A_Clinical_Language_Understanding_Evaluation_for_LLMs.md)

    - [翻译: CLUE：一套针对大型语言模型的临床级语言理解评估体系](2024年04月05日/CLUE_A_Clinical_Language_Understanding_Evaluation_for_LLMs.md)

- [VoicePilot: Harnessing LLMs as Speech Interfaces for Physically Assistive Robots](2024年04月05日/VoicePilot_Harnessing_LLMs_as_Speech_Interfaces_for_Physically_Assistive_Robots.md)

    - [翻译: VoicePilot：将大型语言模型 (LLM) 作为物理辅助机器人的语音交互界面](2024年04月05日/VoicePilot_Harnessing_LLMs_as_Speech_Interfaces_for_Physically_Assistive_Robots.md)

- [A Comparison of Methods for Evaluating Generative IR](2024年04月05日/A_Comparison_of_Methods_for_Evaluating_Generative_IR.md)

    - [翻译: 本研究对比了不同的生成式信息检索评估方法。](2024年04月05日/A_Comparison_of_Methods_for_Evaluating_Generative_IR.md)

- [Teaching Llama a New Language Through Cross-Lingual Knowledge Transfer](2024年04月05日/Teaching_Llama_a_New_Language_Through_Cross-Lingual_Knowledge_Transfer.md)

    - [翻译: 借助跨语言知识迁移，教会 Llama 掌握新的语言技能。](2024年04月05日/Teaching_Llama_a_New_Language_Through_Cross-Lingual_Knowledge_Transfer.md)

- [BuDDIE: A Business Document Dataset for Multi-task Information Extraction](2024年04月05日/BuDDIE_A_Business_Document_Dataset_for_Multi-task_Information_Extraction.md)

    - [翻译: BuDDIE：专为多任务信息提取打造的商业文档数据集](2024年04月05日/BuDDIE_A_Business_Document_Dataset_for_Multi-task_Information_Extraction.md)

- [SEME at SemEval-2024 Task 2: Comparing Masked and Generative Language Models on Natural Language Inference for Clinical Trials](2024年04月05日/SEME_at_SemEval-2024_Task_2_Comparing_Masked_and_Generative_Language_Models_on_Natural_Language_Inference_for_Clinical_Trials.md)

    - [翻译: SemEval-2024 任务 2 探讨了 SEME，通过对比遮蔽式和生成式语言模型在临床试验自然语言推理任务上的效果。](2024年04月05日/SEME_at_SemEval-2024_Task_2_Comparing_Masked_and_Generative_Language_Models_on_Natural_Language_Inference_for_Clinical_Trials.md)

- [Simple Techniques for Enhancing Sentence Embeddings in Generative Language Models](2024年04月05日/Simple_Techniques_for_Enhancing_Sentence_Embeddings_in_Generative_Language_Models.md)

    - [翻译: 生成型语言模型中，提升句子嵌入的简易技巧。](2024年04月05日/Simple_Techniques_for_Enhancing_Sentence_Embeddings_in_Generative_Language_Models.md)

- [Can only LLMs do Reasoning?: Potential of Small Language Models in Task Planning](2024年04月05日/Can_only_LLMs_do_Reasoning_Potential_of_Small_Language_Models_in_Task_Planning.md)

    - [翻译: 难道只有大型语言模型才具备推理能力吗？其实不然，小型语言模型在任务规划领域同样拥有不可忽视的潜力。](2024年04月05日/Can_only_LLMs_do_Reasoning_Potential_of_Small_Language_Models_in_Task_Planning.md)

- [SAAS: Solving Ability Amplification Strategy for Enhanced Mathematical Reasoning in Large Language Models](2024年04月05日/SAAS_Solving_Ability_Amplification_Strategy_for_Enhanced_Mathematical_Reasoning_in_Large_Language_Models.md)

    - [翻译: SAAS：为大型语言模型注入数学推理的强化策略](2024年04月05日/SAAS_Solving_Ability_Amplification_Strategy_for_Enhanced_Mathematical_Reasoning_in_Large_Language_Models.md)

- [Assisting humans in complex comparisons: automated information comparison at scale](2024年04月05日/Assisting_humans_in_complex_comparisons_automated_information_comparison_at_scale.md)

    - [翻译: 本文探讨了如何在海量数据中，通过自动化技术辅助人类进行细致入微的比较分析。](2024年04月05日/Assisting_humans_in_complex_comparisons_automated_information_comparison_at_scale.md)

- [Exploring Autonomous Agents through the Lens of Large Language Models: A Review](2024年04月05日/Exploring_Autonomous_Agents_through_the_Lens_of_Large_Language_Models_A_Review.md)

    - [翻译: 从大型语言模型的视角探究自主智能体：一篇综述性研究](2024年04月05日/Exploring_Autonomous_Agents_through_the_Lens_of_Large_Language_Models_A_Review.md)

- [Increased LLM Vulnerabilities from Fine-tuning and Quantization](2024年04月05日/Increased_LLM_Vulnerabilities_from_Fine-tuning_and_Quantization.md)

    - [翻译: 微调和量化过程中，大型语言模型的脆弱性有所增加。](2024年04月05日/Increased_LLM_Vulnerabilities_from_Fine-tuning_and_Quantization.md)

- [Idea-2-3D: Collaborative LMM Agents Enable 3D Model Generation from Interleaved Multimodal Inputs](2024年04月05日/Idea-2-3D_Collaborative_LMM_Agents_Enable_3D_Model_Generation_from_Interleaved_Multimodal_Inputs.md)

    - [翻译: Idea-2-3D：协同工作的LMM智能代理通过混合多模态输入实现3D模型的创建。](2024年04月05日/Idea-2-3D_Collaborative_LMM_Agents_Enable_3D_Model_Generation_from_Interleaved_Multimodal_Inputs.md)

2024年04月04日

- [OpenNeRF: Open Set 3D Neural Scene Segmentation with Pixel-Wise Features and Rendered Novel Views](2024年04月04日/OpenNeRF_Open_Set_3D_Neural_Scene_Segmentation_with_Pixel-Wise_Features_and_Rendered_Novel_Views.md)

    - [翻译: OpenNeRF 通过利用像素级别的细节特征和渲染出全新的视角，实现了对3D场景的开放集神经分割，为三维场景理解提供了一种全新的方法。](2024年04月04日/OpenNeRF_Open_Set_3D_Neural_Scene_Segmentation_with_Pixel-Wise_Features_and_Rendered_Novel_Views.md)

- [AutoWebGLM: Bootstrap And Reinforce A Large Language Model-based Web Navigating Agent](2024年04月04日/AutoWebGLM_Bootstrap_And_Reinforce_A_Large_Language_Model-based_Web_Navigating_Agent.md)

    - [翻译: AutoWebGLM：利用自助法和强化策略，打造一款基于大型语言模型的智能网络浏览助手。](2024年04月04日/AutoWebGLM_Bootstrap_And_Reinforce_A_Large_Language_Model-based_Web_Navigating_Agent.md)

- [Capabilities of Large Language Models in Control Engineering: A Benchmark Study on GPT-4, Claude 3 Opus, and Gemini 1.0 Ultra](2024年04月04日/Capabilities_of_Large_Language_Models_in_Control_Engineering_A_Benchmark_Study_on_GPT-4,_Claude_3_Opus,_and_Gemini_1.0_Ultra.md)

    - [翻译: 大型语言模型在控制工程领域的能力探究：对 GPT-4、Claude 3 Opus 及 Gemini 1.0 Ultra 进行的基准比较研究。](2024年04月04日/Capabilities_of_Large_Language_Models_in_Control_Engineering_A_Benchmark_Study_on_GPT-4,_Claude_3_Opus,_and_Gemini_1.0_Ultra.md)

- [Training LLMs over Neurally Compressed Text](2024年04月04日/Training_LLMs_over_Neurally_Compressed_Text.md)

    - [翻译: 通过对神经网络压缩的文本进行训练，提升了大型语言模型（LLM）的能力。](2024年04月04日/Training_LLMs_over_Neurally_Compressed_Text.md)

- [Unveiling LLMs: The Evolution of Latent Representations in a Temporal Knowledge Graph](2024年04月04日/Unveiling_LLMs_The_Evolution_of_Latent_Representations_in_a_Temporal_Knowledge_Graph.md)

    - [翻译: 探究大型语言模型：时间知识库中潜在表达的进化之旅](2024年04月04日/Unveiling_LLMs_The_Evolution_of_Latent_Representations_in_a_Temporal_Knowledge_Graph.md)

- [Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models](2024年04月04日/Visualization-of-Thought_Elicits_Spatial_Reasoning_in_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，通过思维可视化能够激发空间推理能力。](2024年04月04日/Visualization-of-Thought_Elicits_Spatial_Reasoning_in_Large_Language_Models.md)

- [DeViDe: Faceted medical knowledge for improved medical vision-language pre-training](2024年04月04日/DeViDe_Faceted_medical_knowledge_for_improved_medical_vision-language_pre-training.md)

    - [翻译: DeViDe：面向医学视觉-语言预训练的全方位医学知识架构](2024年04月04日/DeViDe_Faceted_medical_knowledge_for_improved_medical_vision-language_pre-training.md)

- [Sailor: Open Language Models for South-East Asia](2024年04月04日/Sailor_Open_Language_Models_for_South-East_Asia.md)

    - [翻译: Sailor：面向东南亚地区的开放语言模型](2024年04月04日/Sailor_Open_Language_Models_for_South-East_Asia.md)

- [Evaluating LLMs at Detecting Errors in LLM Responses](2024年04月04日/Evaluating_LLMs_at_Detecting_Errors_in_LLM_Responses.md)

    - [翻译: 探究大型语言模型识别自身回应错误的能力](2024年04月04日/Evaluating_LLMs_at_Detecting_Errors_in_LLM_Responses.md)

- [Intent Detection and Entity Extraction from BioMedical Literature](2024年04月04日/Intent_Detection_and_Entity_Extraction_from_BioMedical_Literature.md)

    - [翻译: 在生物医学文献中识别意图与抽取关键信息](2024年04月04日/Intent_Detection_and_Entity_Extraction_from_BioMedical_Literature.md)

- [ReFT: Representation Finetuning for Language Models](2024年04月04日/ReFT_Representation_Finetuning_for_Language_Models.md)

    - [翻译: ReFT 代表「表示微调」，是一种针对语言模型的优化技术。](2024年04月04日/ReFT_Representation_Finetuning_for_Language_Models.md)

- [SemGrasp: Semantic Grasp Generation via Language Aligned Discretization](2024年04月04日/SemGrasp_Semantic_Grasp_Generation_via_Language_Aligned_Discretization.md)

    - [翻译: SemGrasp：利用语言对齐离散化技术实现语义抓取的生成](2024年04月04日/SemGrasp_Semantic_Grasp_Generation_via_Language_Aligned_Discretization.md)

- [Untangle the KNOT: Interweaving Conflicting Knowledge and Reasoning Skills in Large Language Models](2024年04月04日/Untangle_the_KNOT_Interweaving_Conflicting_Knowledge_and_Reasoning_Skills_in_Large_Language_Models.md)

    - [翻译: 拨乱反正：大型语言模型中融合知识冲突与推理能力的交织艺术](2024年04月04日/Untangle_the_KNOT_Interweaving_Conflicting_Knowledge_and_Reasoning_Skills_in_Large_Language_Models.md)

- [Embodied AI with Two Arms: Zero-shot Learning, Safety and Modularity](2024年04月04日/Embodied_AI_with_Two_Arms_Zero-shot_Learning,_Safety_and_Modularity.md)

    - [翻译: 双臂机器人的具身人工智能：探索零-shot 学习能力、安全性能与模块化设计。](2024年04月04日/Embodied_AI_with_Two_Arms_Zero-shot_Learning,_Safety_and_Modularity.md)

- [Personalized LLM Response Generation with Parameterized Memory Injection](2024年04月04日/Personalized_LLM_Response_Generation_with_Parameterized_Memory_Injection.md)

    - [翻译: 通过参数化记忆注入，实现大型语言模型（LLM）的个性化响应生成。](2024年04月04日/Personalized_LLM_Response_Generation_with_Parameterized_Memory_Injection.md)

- [Select and Summarize: Scene Saliency for Movie Script Summarization](2024年04月04日/Select_and_Summarize_Scene_Saliency_for_Movie_Script_Summarization.md)

    - [翻译: 精选与概述：电影剧本摘要中的场景焦点](2024年04月04日/Select_and_Summarize_Scene_Saliency_for_Movie_Script_Summarization.md)

- [How does Multi-Task Training Affect Transformer In-Context Capabilities? Investigations with Function Classes](2024年04月04日/How_does_Multi-Task_Training_Affect_Transformer_In-Context_Capabilities_Investigations_with_Function_Classes.md)

    - [翻译: 多任务训练对变换器模型的上下文理解能力有何影响？本研究通过探索不同函数类别，深入探讨了这一问题。](2024年04月04日/How_does_Multi-Task_Training_Affect_Transformer_In-Context_Capabilities_Investigations_with_Function_Classes.md)

- [CodeEditorBench: Evaluating Code Editing Capability of Large Language Models](2024年04月04日/CodeEditorBench_Evaluating_Code_Editing_Capability_of_Large_Language_Models.md)

    - [翻译: CodeEditorBench：探究大型语言模型在代码编辑方面的表现](2024年04月04日/CodeEditorBench_Evaluating_Code_Editing_Capability_of_Large_Language_Models.md)

- [Evaluating Generative Language Models in Information Extraction as Subjective Question Correction](2024年04月04日/Evaluating_Generative_Language_Models_in_Information_Extraction_as_Subjective_Question_Correction.md)

    - [翻译: 在信息提取领域，探究生成型语言模型在主观问题纠正任务中的表现。](2024年04月04日/Evaluating_Generative_Language_Models_in_Information_Extraction_as_Subjective_Question_Correction.md)

- [Learn When (not) to Trust Language Models: A Privacy-Centric Adaptive Model-Aware Approach](2024年04月04日/Learn_When_(not)_to_Trust_Language_Models_A_Privacy-Centric_Adaptive_Model-Aware_Approach.md)

    - [翻译: 探索信任与否：一种以隐私为核心，适应性的语言模型感知策略](2024年04月04日/Learn_When_(not)_to_Trust_Language_Models_A_Privacy-Centric_Adaptive_Model-Aware_Approach.md)

- [AI and the Problem of Knowledge Collapse](2024年04月04日/AI_and_the_Problem_of_Knowledge_Collapse.md)

    - [翻译: 人工智能面临的知识崩溃挑战](2024年04月04日/AI_and_the_Problem_of_Knowledge_Collapse.md)

- [Integrating Large Language Models with Multimodal Virtual Reality Interfaces to Support Collaborative Human-Robot Construction Work](2024年04月04日/Integrating_Large_Language_Models_with_Multimodal_Virtual_Reality_Interfaces_to_Support_Collaborative_Human-Robot_Construction_Work.md)

    - [翻译: 融合大型语言模型和多模态虚拟现实接口，助力人机协作建筑任务。](2024年04月04日/Integrating_Large_Language_Models_with_Multimodal_Virtual_Reality_Interfaces_to_Support_Collaborative_Human-Robot_Construction_Work.md)

- [A Cause-Effect Look at Alleviating Hallucination of Knowledge-grounded Dialogue Generation](2024年04月04日/A_Cause-Effect_Look_at_Alleviating_Hallucination_of_Knowledge-grounded_Dialogue_Generation.md)

    - [翻译: 本文通过因果分析，探讨了如何减轻知识引导对话生成中的知识幻觉问题。](2024年04月04日/A_Cause-Effect_Look_at_Alleviating_Hallucination_of_Knowledge-grounded_Dialogue_Generation.md)

- [Generative AI and Teachers - For Us or Against Us? A Case Study](2024年04月04日/Generative_AI_and_Teachers_-_For_Us_or_Against_Us_A_Case_Study.md)

    - [翻译: 生成性人工智能：助力教育还是竞争者？案例分析揭秘](2024年04月04日/Generative_AI_and_Teachers_-_For_Us_or_Against_Us_A_Case_Study.md)

- [Reevaluating Bias Detection in Language Models: The Role of Implicit Norm](2024年04月04日/Reevaluating_Bias_Detection_in_Language_Models_The_Role_of_Implicit_Norm.md)

    - [翻译: 重新审视语言模型中的偏见识别：探究隐性规范的角色](2024年04月04日/Reevaluating_Bias_Detection_in_Language_Models_The_Role_of_Implicit_Norm.md)

- [Scaffolding Language Learning via Multi-modal Tutoring Systems with Pedagogical Instructions](2024年04月04日/Scaffolding_Language_Learning_via_Multi-modal_Tutoring_Systems_with_Pedagogical_Instructions.md)

    - [翻译: 利用融入教学指导的多模态辅导系统，为语言学习提供有效支撑。](2024年04月04日/Scaffolding_Language_Learning_via_Multi-modal_Tutoring_Systems_with_Pedagogical_Instructions.md)

- [Edisum: Summarizing and Explaining Wikipedia Edits at Scale](2024年04月04日/Edisum_Summarizing_and_Explaining_Wikipedia_Edits_at_Scale.md)

    - [翻译: Edisum：面向大规模的维基百科编辑，实现内容概括与阐释。](2024年04月04日/Edisum_Summarizing_and_Explaining_Wikipedia_Edits_at_Scale.md)

- [Can Small Language Models Help Large Language Models Reason Better?: LM-Guided Chain-of-Thought](2024年04月04日/Can_Small_Language_Models_Help_Large_Language_Models_Reason_Better_LM-Guided_Chain-of-Thought.md)

    - [翻译: 小型语言模型能否助力大型语言模型提升推理能力？——通过LM引导的思维链条探究](2024年04月04日/Can_Small_Language_Models_Help_Large_Language_Models_Reason_Better_LM-Guided_Chain-of-Thought.md)

- [MiniGPT4-Video: Advancing Multimodal LLMs for Video Understanding with Interleaved Visual-Textual Tokens](2024年04月04日/MiniGPT4-Video_Advancing_Multimodal_LLMs_for_Video_Understanding_with_Interleaved_Visual-Textual_Tokens.md)

    - [翻译: MiniGPT4-Video：利用交错的视觉与文本元素，推动多模态大型语言模型在视频理解方面的发展。](2024年04月04日/MiniGPT4-Video_Advancing_Multimodal_LLMs_for_Video_Understanding_with_Interleaved_Visual-Textual_Tokens.md)

- [Red Teaming GPT-4V: Are GPT-4V Safe Against Uni/Multi-Modal Jailbreak Attacks?](2024年04月04日/Red_Teaming_GPT-4V_Are_GPT-4V_Safe_Against_UniMulti-Modal_Jailbreak_Attacks.md)

    - [翻译: 针对 GPT-4V 的红队测试：这款 AI 能否抵御单模态或多模态的攻击逃逸？](2024年04月04日/Red_Teaming_GPT-4V_Are_GPT-4V_Safe_Against_UniMulti-Modal_Jailbreak_Attacks.md)

- [Scaling Up Video Summarization Pretraining with Large Language Models](2024年04月04日/Scaling_Up_Video_Summarization_Pretraining_with_Large_Language_Models.md)

    - [翻译: 借助大型语言模型，我们正在扩大视频摘要预训练的规模。](2024年04月04日/Scaling_Up_Video_Summarization_Pretraining_with_Large_Language_Models.md)

- [LongVLM: Efficient Long Video Understanding via Large Language Models](2024年04月04日/LongVLM_Efficient_Long_Video_Understanding_via_Large_Language_Models.md)

    - [翻译: LongVLM 通过运用大型语言模型，高效地解读长视频内容。](2024年04月04日/LongVLM_Efficient_Long_Video_Understanding_via_Large_Language_Models.md)

- [nicolay-r at SemEval-2024 Task 3: Using Flan-T5 for Reasoning Emotion Cause in Conversations with Chain-of-Thought on Emotion States](2024年04月04日/nicolay-r_at_SemEval-2024_Task_3_Using_Flan-T5_for_Reasoning_Emotion_Cause_in_Conversations_with_Chain-of-Thought_on_Emotion_States.md)

    - [翻译: 在 SemEval-2024 的第三项任务中，nicolay-r 利用 Flan-T5 模型，通过情绪状态的思维链推理对话中的情绪成因。](2024年04月04日/nicolay-r_at_SemEval-2024_Task_3_Using_Flan-T5_for_Reasoning_Emotion_Cause_in_Conversations_with_Chain-of-Thought_on_Emotion_States.md)

- [Towards Pareto Optimal Throughput in Small Language Model Serving](2024年04月04日/Towards_Pareto_Optimal_Throughput_in_Small_Language_Model_Serving.md)

    - [翻译: 追求在小型语言模型服务中的帕累托最优吞吐量](2024年04月04日/Towards_Pareto_Optimal_Throughput_in_Small_Language_Model_Serving.md)

- [How Easily do Irrelevant Inputs Skew the Responses of Large Language Models?](2024年04月04日/How_Easily_do_Irrelevant_Inputs_Skew_the_Responses_of_Large_Language_Models.md)

    - [翻译: 大型语言模型对无关输入的敏感程度如何？](2024年04月04日/How_Easily_do_Irrelevant_Inputs_Skew_the_Responses_of_Large_Language_Models.md)

- [Probing Large Language Models for Scalar Adjective Lexical Semantics and Scalar Diversity Pragmatics](2024年04月04日/Probing_Large_Language_Models_for_Scalar_Adjective_Lexical_Semantics_and_Scalar_Diversity_Pragmatics.md)

    - [翻译: 深入研究大型语言模型中的标量形容词词义和标量多样性语用现象。](2024年04月04日/Probing_Large_Language_Models_for_Scalar_Adjective_Lexical_Semantics_and_Scalar_Diversity_Pragmatics.md)

- [DELTA: Decomposed Efficient Long-Term Robot Task Planning using Large Language Models](2024年04月04日/DELTA_Decomposed_Efficient_Long-Term_Robot_Task_Planning_using_Large_Language_Models.md)

    - [翻译: DELTA：借助大型语言模型，实现高效分解的机器人长期任务规划](2024年04月04日/DELTA_Decomposed_Efficient_Long-Term_Robot_Task_Planning_using_Large_Language_Models.md)

- [RALL-E: Robust Codec Language Modeling with Chain-of-Thought Prompting for Text-to-Speech Synthesis](2024年04月04日/RALL-E_Robust_Codec_Language_Modeling_with_Chain-of-Thought_Prompting_for_Text-to-Speech_Synthesis.md)

    - [翻译: RALL-E：采用链式思维引导的编解码器语言模型，增强文本至语音合成的鲁棒性](2024年04月04日/RALL-E_Robust_Codec_Language_Modeling_with_Chain-of-Thought_Prompting_for_Text-to-Speech_Synthesis.md)

- [Do Large Language Models Rank Fairly? An Empirical Study on the Fairness of LLMs as Rankers](2024年04月04日/Do_Large_Language_Models_Rank_Fairly_An_Empirical_Study_on_the_Fairness_of_LLMs_as_Rankers.md)

    - [翻译: 大型语言模型的排名是否公正？一项针对LLMs作为排名器的公平性经验性研究](2024年04月04日/Do_Large_Language_Models_Rank_Fairly_An_Empirical_Study_on_the_Fairness_of_LLMs_as_Rankers.md)

- [The Probabilities Also Matter: A More Faithful Metric for Faithfulness of Free-Text Explanations in Large Language Models](2024年04月04日/The_Probabilities_Also_Matter_A_More_Faithful_Metric_for_Faithfulness_of_Free-Text_Explanations_in_Large_Language_Models.md)

    - [翻译: 概率的权重：构建更精确衡量大型语言模型自由文本解释准确性的指标](2024年04月04日/The_Probabilities_Also_Matter_A_More_Faithful_Metric_for_Faithfulness_of_Free-Text_Explanations_in_Large_Language_Models.md)

- [Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction](2024年04月04日/Extract,_Define,_Canonicalize_An_LLM-based_Framework_for_Knowledge_Graph_Construction.md)

    - [翻译: 基于大型语言模型，构建知识图谱的新框架：提取信息、明确定义、统一规范。](2024年04月04日/Extract,_Define,_Canonicalize_An_LLM-based_Framework_for_Knowledge_Graph_Construction.md)

- [FFN-SkipLLM: A Hidden Gem for Autoregressive Decoding with Adaptive Feed Forward Skipping](2024年04月04日/FFN-SkipLLM_A_Hidden_Gem_for_Autoregressive_Decoding_with_Adaptive_Feed_Forward_Skipping.md)

    - [翻译: FFN-SkipLLM：自回归解码的隐秘利器，通过灵活的前馈网络跳过技术实现。](2024年04月04日/FFN-SkipLLM_A_Hidden_Gem_for_Autoregressive_Decoding_with_Adaptive_Feed_Forward_Skipping.md)

- [Verifiable by Design: Aligning Language Models to Quote from Pre-Training Data](2024年04月04日/Verifiable_by_Design_Aligning_Language_Models_to_Quote_from_Pre-Training_Data.md)

    - [翻译: 设计之初即验证：确保语言模型能够引用预训练数据](2024年04月04日/Verifiable_by_Design_Aligning_Language_Models_to_Quote_from_Pre-Training_Data.md)

- [PARIS3D: Reasoning-based 3D Part Segmentation Using Large Multimodal Model](2024年04月04日/PARIS3D_Reasoning-based_3D_Part_Segmentation_Using_Large_Multimodal_Model.md)

    - [翻译: PARIS3D：借助庞大的多模态模型，实现基于推理的三维部件识别。](2024年04月04日/PARIS3D_Reasoning-based_3D_Part_Segmentation_Using_Large_Multimodal_Model.md)

- [An Investigation into Misuse of Java Security APIs by Large Language Models](2024年04月04日/An_Investigation_into_Misuse_of_Java_Security_APIs_by_Large_Language_Models.md)

    - [翻译: 探究大型语言模型不当使用 Java 安全接口问题](2024年04月04日/An_Investigation_into_Misuse_of_Java_Security_APIs_by_Large_Language_Models.md)

- [Understanding Language Modeling Paradigm Adaptations in Recommender Systems: Lessons Learned and Open Challenges](2024年04月04日/Understanding_Language_Modeling_Paradigm_Adaptations_in_Recommender_Systems_Lessons_Learned_and_Open_Challenges.md)

    - [翻译: 深入探索推荐系统内语言建模范式的调整：吸取的经验与待解难题](2024年04月04日/Understanding_Language_Modeling_Paradigm_Adaptations_in_Recommender_Systems_Lessons_Learned_and_Open_Challenges.md)

- [GenQREnsemble: Zero-Shot LLM Ensemble Prompting for Generative Query Reformulation](2024年04月04日/GenQREnsemble_Zero-Shot_LLM_Ensemble_Prompting_for_Generative_Query_Reformulation.md)

    - [翻译: GenQREnsemble：零-shot 技术打造的大型语言模型集成，为生成式查询改写而生。](2024年04月04日/GenQREnsemble_Zero-Shot_LLM_Ensemble_Prompting_for_Generative_Query_Reformulation.md)

- [Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations](2024年04月04日/Fakes_of_Varying_Shades_How_Warning_Affects_Human_Perception_and_Engagement_Regarding_LLM_Hallucinations.md)

    - [翻译: 虚假的多样性：警示如何改变人们对大型语言模型幻觉的认知和互动](2024年04月04日/Fakes_of_Varying_Shades_How_Warning_Affects_Human_Perception_and_Engagement_Regarding_LLM_Hallucinations.md)

- [SHROOM-INDElab at SemEval-2024 Task 6: Zero- and Few-Shot LLM-Based Classification for Hallucination Detection](2024年04月04日/SHROOM-INDElab_at_SemEval-2024_Task_6_Zero-_and_Few-Shot_LLM-Based_Classification_for_Hallucination_Detection.md)

    - [翻译: SHROOM-INDElab 参与 SemEval-2024 第六任务：基于大型语言模型的零样本和少样本分类技术，以检测文本中的虚构信息。](2024年04月04日/SHROOM-INDElab_at_SemEval-2024_Task_6_Zero-_and_Few-Shot_LLM-Based_Classification_for_Hallucination_Detection.md)

- [Direct Nash Optimization: Teaching Language Models to Self-Improve with General Preferences](2024年04月04日/Direct_Nash_Optimization_Teaching_Language_Models_to_Self-Improve_with_General_Preferences.md)

    - [翻译: 通过直接纳什优化方法，我们引导语言模型学会根据普遍偏好进行自我优化和提升。](2024年04月04日/Direct_Nash_Optimization_Teaching_Language_Models_to_Self-Improve_with_General_Preferences.md)

- [No "Zero-Shot" Without Exponential Data: Pretraining Concept Frequency Determines Multimodal Model Performance](2024年04月04日/No_Zero-Shot_Without_Exponential_Data_Pretraining_Concept_Frequency_Determines_Multimodal_Model_Performance.md)

    - [翻译: 脱离大量数据谈"零-shot"不现实：预训练中概念的出现频率是提升多模态模型表现的关键因素。](2024年04月04日/No_Zero-Shot_Without_Exponential_Data_Pretraining_Concept_Frequency_Determines_Multimodal_Model_Performance.md)

- [CBR-RAG: Case-Based Reasoning for Retrieval Augmented Generation in LLMs for Legal Question Answering](2024年04月04日/CBR-RAG_Case-Based_Reasoning_for_Retrieval_Augmented_Generation_in_LLMs_for_Legal_Question_Answering.md)

    - [翻译: CBR-RAG：案例推理辅助生成，提升大型语言模型在法律问答中的检索能力](2024年04月04日/CBR-RAG_Case-Based_Reasoning_for_Retrieval_Augmented_Generation_in_LLMs_for_Legal_Question_Answering.md)

- [Using Large Language Models to Enrich the Documentation of Datasets for Machine Learning](2024年04月04日/Using_Large_Language_Models_to_Enrich_the_Documentation_of_Datasets_for_Machine_Learning.md)

    - [翻译: ](2024年04月04日/Using_Large_Language_Models_to_Enrich_the_Documentation_of_Datasets_for_Machine_Learning.md)

2024年04月03日

- [DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement](2024年04月03日/DIBS_Enhancing_Dense_Video_Captioning_with_Unlabeled_Videos_via_Pseudo_Boundary_Enrichment_and_Online_Refinement.md)

    - [翻译: DIBS 技术：借助伪边界扩展和实时优化，利用未标注视频提升密集视频字幕质量。](2024年04月03日/DIBS_Enhancing_Dense_Video_Captioning_with_Unlabeled_Videos_via_Pseudo_Boundary_Enrichment_and_Online_Refinement.md)

- [Harnessing the Power of Large Vision Language Models for Synthetic Image Detection](2024年04月03日/Harnessing_the_Power_of_Large_Vision_Language_Models_for_Synthetic_Image_Detection.md)

    - [翻译: 借助大型视觉语言模型的力量，我们可以有效检测合成图像。](2024年04月03日/Harnessing_the_Power_of_Large_Vision_Language_Models_for_Synthetic_Image_Detection.md)

- [Automatic Prompt Selection for Large Language Models](2024年04月03日/Automatic_Prompt_Selection_for_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，自动化的提示筛选机制](2024年04月03日/Automatic_Prompt_Selection_for_Large_Language_Models.md)

- [Scalable Model Editing via Customized Expert Networks](2024年04月03日/Scalable_Model_Editing_via_Customized_Expert_Networks.md)

    - [翻译: 本文介绍了一种通过定制专家网络来实现模型编辑的可扩展方法。](2024年04月03日/Scalable_Model_Editing_via_Customized_Expert_Networks.md)

- [Attention is Naturally Sparse with Gaussian Distributed Input](2024年04月03日/Attention_is_Naturally_Sparse_with_Gaussian_Distributed_Input.md)

    - [翻译: 当输入呈现高斯分布时，注意力机制自然而然地表现出稀疏性。](2024年04月03日/Attention_is_Naturally_Sparse_with_Gaussian_Distributed_Input.md)

- [Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models](2024年04月03日/Rethinking_Kullback-Leibler_Divergence_in_Knowledge_Distillation_for_Large_Language_Models.md)

    - [翻译: 在大型语言模型的知识蒸馏过程中，对Kullback-Leibler散度的再认识与应用。](2024年04月03日/Rethinking_Kullback-Leibler_Divergence_in_Knowledge_Distillation_for_Large_Language_Models.md)

- [Calibrating the Confidence of Large Language Models by Eliciting Fidelity](2024年04月03日/Calibrating_the_Confidence_of_Large_Language_Models_by_Eliciting_Fidelity.md)

    - [翻译: 本文探讨了如何通过激发忠诚度来调整大型语言模型的自信度，以提高其预测的准确性。](2024年04月03日/Calibrating_the_Confidence_of_Large_Language_Models_by_Eliciting_Fidelity.md)

- [Towards detecting unanticipated bias in Large Language Models](2024年04月03日/Towards_detecting_unanticipated_bias_in_Large_Language_Models.md)

    - [翻译: 探索发现大型语言模型中的潜在偏见。](2024年04月03日/Towards_detecting_unanticipated_bias_in_Large_Language_Models.md)

- [On the Importance of Uncertainty in Decision-Making with Large Language Models](2024年04月03日/On_the_Importance_of_Uncertainty_in_Decision-Making_with_Large_Language_Models.md)

    - [翻译: 在运用大型语言模型进行决策时，不确定性的角色不容忽视。](2024年04月03日/On_the_Importance_of_Uncertainty_in_Decision-Making_with_Large_Language_Models.md)

- [Vocabulary Attack to Hijack Large Language Model Applications](2024年04月03日/Vocabulary_Attack_to_Hijack_Large_Language_Model_Applications.md)

    - [翻译: 通过词汇攻击，大型语言模型的应用可能被劫持。](2024年04月03日/Vocabulary_Attack_to_Hijack_Large_Language_Model_Applications.md)

- [Improving Topic Relevance Model by Mix-structured Summarization and LLM-based Data Augmentation](2024年04月03日/Improving_Topic_Relevance_Model_by_Mix-structured_Summarization_and_LLM-based_Data_Augmentation.md)

    - [翻译: 通过融合多种结构的摘要技巧以及利用大型语言模型进行数据扩充，我们得以提升主题相关性模型的性能。](2024年04月03日/Improving_Topic_Relevance_Model_by_Mix-structured_Summarization_and_LLM-based_Data_Augmentation.md)

- [Large Language Models for Expansion of Spoken Language Understanding Systems to New Languages](2024年04月03日/Large_Language_Models_for_Expansion_of_Spoken_Language_Understanding_Systems_to_New_Languages.md)

    - [翻译: 借助大型语言模型，拓展口语理解系统至全新语言领域](2024年04月03日/Large_Language_Models_for_Expansion_of_Spoken_Language_Understanding_Systems_to_New_Languages.md)

- [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](2024年04月03日/Language_Models_as_Compilers_Simulating_Pseudocode_Execution_Improves_Algorithmic_Reasoning_in_Language_Models.md)

    - [翻译: 将语言模型视作编译器，通过模拟伪代码的执行，我们能够显著提升模型在算法推理上的能力。](2024年04月03日/Language_Models_as_Compilers_Simulating_Pseudocode_Execution_Improves_Algorithmic_Reasoning_in_Language_Models.md)

- [AI-Tutoring in Software Engineering Education](2024年04月03日/AI-Tutoring_in_Software_Engineering_Education.md)

    - [翻译: 人工智能辅导在软件工程教育领域日益发挥着关键作用，它通过个性化指导和及时反馈显著提升了学习成效。要充分发挥其潜力，我们必须深入探索AI辅导的机制，并有效融合到教学实践中。](2024年04月03日/AI-Tutoring_in_Software_Engineering_Education.md)

- [CSEPrompts: A Benchmark of Introductory Computer Science Prompts](2024年04月03日/CSEPrompts_A_Benchmark_of_Introductory_Computer_Science_Prompts.md)

    - [翻译: CSEPrompts：计算机科学基础教学提示的评估标准](2024年04月03日/CSEPrompts_A_Benchmark_of_Introductory_Computer_Science_Prompts.md)

- [Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game](2024年04月03日/Learn_to_Disguise_Avoid_Refusal_Responses_in_LLM's_Defense_via_a_Multi-agent_Attacker-Disguiser_Game.md)

    - [翻译: 掌握伪装技巧：借助多智能体间的攻击者与伪装者博弈，规避大型语言模型（LLM）防御时的拒绝式回应。](2024年04月03日/Learn_to_Disguise_Avoid_Refusal_Responses_in_LLM's_Defense_via_a_Multi-agent_Attacker-Disguiser_Game.md)

- [Large Language Model for Vulnerability Detection and Repair: Literature Review and Roadmap](2024年04月03日/Large_Language_Model_for_Vulnerability_Detection_and_Repair_Literature_Review_and_Roadmap.md)

    - [翻译: 大型语言模型在漏洞检测与修复领域的文献综述及发展蓝图](2024年04月03日/Large_Language_Model_for_Vulnerability_Detection_and_Repair_Literature_Review_and_Roadmap.md)

- [Towards Large Language Model driven Reference-less Translation Evaluation for English and Indian Languages](2024年04月03日/Towards_Large_Language_Model_driven_Reference-less_Translation_Evaluation_for_English_and_Indian_Languages.md)

    - [翻译: 面向英语和印度语言的大型语言模型驱动的无参考翻译评估研究。](2024年04月03日/Towards_Large_Language_Model_driven_Reference-less_Translation_Evaluation_for_English_and_Indian_Languages.md)

- [VIAssist: Adapting Multi-modal Large Language Models for Users with Visual Impairments](2024年04月03日/VIAssist_Adapting_Multi-modal_Large_Language_Models_for_Users_with_Visual_Impairments.md)

    - [翻译: VIAssist：为视障用户定制的多模态大型语言模型](2024年04月03日/VIAssist_Adapting_Multi-modal_Large_Language_Models_for_Users_with_Visual_Impairments.md)

- [Measuring Social Norms of Large Language Models](2024年04月03日/Measuring_Social_Norms_of_Large_Language_Models.md)

    - [翻译: 探究大型语言模型的社会规范认知](2024年04月03日/Measuring_Social_Norms_of_Large_Language_Models.md)

- [Prompting for Numerical Sequences: A Case Study on Market Comment Generation](2024年04月03日/Prompting_for_Numerical_Sequences_A_Case_Study_on_Market_Comment_Generation.md)

    - [翻译: 数字序列提示：市场评论生成案例分析](2024年04月03日/Prompting_for_Numerical_Sequences_A_Case_Study_on_Market_Comment_Generation.md)

- [PhonologyBench: Evaluating Phonological Skills of Large Language Models](2024年04月03日/PhonologyBench_Evaluating_Phonological_Skills_of_Large_Language_Models.md)

    - [翻译: PhonologyBench：探究大型语言模型的音系能力](2024年04月03日/PhonologyBench_Evaluating_Phonological_Skills_of_Large_Language_Models.md)

- [Task Agnostic Architecture for Algorithm Induction via Implicit Composition](2024年04月03日/Task_Agnostic_Architecture_for_Algorithm_Induction_via_Implicit_Composition.md)

    - [翻译: 这种架构能够通过隐式组合的方式，适用于各种任务的算法归纳，不受特定任务的限制。](2024年04月03日/Task_Agnostic_Architecture_for_Algorithm_Induction_via_Implicit_Composition.md)

- [Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation: A Systematic Comparison](2024年04月03日/Retrieving_Examples_from_Memory_for_Retrieval_Augmented_Neural_Machine_Translation_A_Systematic_Comparison.md)

    - [翻译: 为了提升神经机器翻译的检索性能，本研究系统地比较了从记忆中检索示例的方法。](2024年04月03日/Retrieving_Examples_from_Memory_for_Retrieval_Augmented_Neural_Machine_Translation_A_Systematic_Comparison.md)

- [uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?](2024年04月03日/uTeBC-NLP_at_SemEval-2024_Task_9_Can_LLMs_be_Lateral_Thinkers.md)

    - [翻译: uTeBC-NLP 参与 SemEval-2024 的第 9 项任务，探讨大型语言模型是否能够进行横向思考。](2024年04月03日/uTeBC-NLP_at_SemEval-2024_Task_9_Can_LLMs_be_Lateral_Thinkers.md)

- [I-Design: Personalized LLM Interior Designer](2024年04月03日/I-Design_Personalized_LLM_Interior_Designer.md)

    - [翻译: I-Design：打造个性化空间，您的专属 LLM 室内设计师。](2024年04月03日/I-Design_Personalized_LLM_Interior_Designer.md)

- [Empowering Biomedical Discovery with AI Agents](2024年04月03日/Empowering_Biomedical_Discovery_with_AI_Agents.md)

    - [翻译: 借助人工智能代理，推动生物医学研究的新发现](2024年04月03日/Empowering_Biomedical_Discovery_with_AI_Agents.md)

- [ALOHa: A New Measure for Hallucination in Captioning Models](2024年04月03日/ALOHa_A_New_Measure_for_Hallucination_in_Captioning_Models.md)

    - [翻译: ALOHa：字幕模型幻觉现象的新衡量标准](2024年04月03日/ALOHa_A_New_Measure_for_Hallucination_in_Captioning_Models.md)

- [MatAtlas: Text-driven Consistent Geometry Texturing and Material Assignment](2024年04月03日/MatAtlas_Text-driven_Consistent_Geometry_Texturing_and_Material_Assignment.md)

    - [翻译: MatAtlas：通过文本驱动，实现一致的几何纹理和材质赋予](2024年04月03日/MatAtlas_Text-driven_Consistent_Geometry_Texturing_and_Material_Assignment.md)

- [ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline](2024年04月03日/ChatGLM-Math_Improving_Math_Problem-Solving_in_Large_Language_Models_with_a_Self-Critique_Pipeline.md)

    - [翻译: ChatGLM-Math：运用自我批评机制，提升大型语言模型解决数学问题的能力](2024年04月03日/ChatGLM-Math_Improving_Math_Problem-Solving_in_Large_Language_Models_with_a_Self-Critique_Pipeline.md)

- [Linear Attention Sequence Parallelism](2024年04月03日/Linear_Attention_Sequence_Parallelism.md)

    - [翻译: 通过线性方法实现注意力机制的序列并行处理](2024年04月03日/Linear_Attention_Sequence_Parallelism.md)

- [Integrating Explanations in Learning LTL Specifications from Demonstrations](2024年04月03日/Integrating_Explanations_in_Learning_LTL_Specifications_from_Demonstrations.md)

    - [翻译: 在学习LTL规范的过程中融合解释](2024年04月03日/Integrating_Explanations_in_Learning_LTL_Specifications_from_Demonstrations.md)

- [Toward Inference-optimal Mixture-of-Expert Large Language Models](2024年04月03日/Toward_Inference-optimal_Mixture-of-Expert_Large_Language_Models.md)

    - [翻译: 为实现最优化推理性能，我们探索了专家混合型大型语言模型的构建。](2024年04月03日/Toward_Inference-optimal_Mixture-of-Expert_Large_Language_Models.md)

- [Cherry on Top: Parameter Heterogeneity and Quantization in Large Language Models](2024年04月03日/Cherry_on_Top_Parameter_Heterogeneity_and_Quantization_in_Large_Language_Models.md)

    - [翻译: 锦上添花：探究大型语言模型中的参数多样性与量化技术](2024年04月03日/Cherry_on_Top_Parameter_Heterogeneity_and_Quantization_in_Large_Language_Models.md)

- [BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models](2024年04月03日/BAdam_A_Memory_Efficient_Full_Parameter_Training_Method_for_Large_Language_Models.md)

    - [翻译: BAdam 为大型语言模型提供了一种内存占用小且高效的全参数训练方式。](2024年04月03日/BAdam_A_Memory_Efficient_Full_Parameter_Training_Method_for_Large_Language_Models.md)

- [Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models](2024年04月03日/Conifer_Improving_Complex_Constrained_Instruction-Following_Ability_of_Large_Language_Models.md)

    - [翻译: Conifer：增强大型语言模型执行复杂指令的能力](2024年04月03日/Conifer_Improving_Complex_Constrained_Instruction-Following_Ability_of_Large_Language_Models.md)

- [A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches](2024年04月03日/A_Survey_of_Optimization-based_Task_and_Motion_Planning_From_Classical_To_Learning_Approaches.md)

    - [翻译: 本综述探讨了从传统到现代基于优化的任务和运动规划方法，特别关注学习方法的应用和发展。](2024年04月03日/A_Survey_of_Optimization-based_Task_and_Motion_Planning_From_Classical_To_Learning_Approaches.md)

- [The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers](2024年04月03日/The_RealHumanEval_Evaluating_Large_Language_Models'_Abilities_to_Support_Programmers.md)

    - [翻译: RealHumanEval：探究大型语言模型在辅助编程方面的实际效能](2024年04月03日/The_RealHumanEval_Evaluating_Large_Language_Models'_Abilities_to_Support_Programmers.md)

- [Efficient Multi-Vector Dense Retrieval Using Bit Vectors](2024年04月03日/Efficient_Multi-Vector_Dense_Retrieval_Using_Bit_Vectors.md)

    - [翻译: 通过位向量实现的多向量密集检索，既高效又精准。](2024年04月03日/Efficient_Multi-Vector_Dense_Retrieval_Using_Bit_Vectors.md)

- [AI and personalized learning: bridging the gap with modern educational goals](2024年04月03日/AI_and_personalized_learning_bridging_the_gap_with_modern_educational_goals.md)

    - [翻译: 通过现代教育目标，人工智能与个性化学习之间的鸿沟得以桥接。](2024年04月03日/AI_and_personalized_learning_bridging_the_gap_with_modern_educational_goals.md)

- [CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech](2024年04月03日/CLaM-TTS_Improving_Neural_Codec_Language_Model_for_Zero-Shot_Text-to-Speech.md)

    - [翻译: CLaM-TTS：优化神经编解码器语言模型，提升零-shot 文本到语音的转换效果](2024年04月03日/CLaM-TTS_Improving_Neural_Codec_Language_Model_for_Zero-Shot_Text-to-Speech.md)

- [FPT: Feature Prompt Tuning for Few-shot Readability Assessment](2024年04月03日/FPT_Feature_Prompt_Tuning_for_Few-shot_Readability_Assessment.md)

    - [翻译: FPT，即特征提示调整技术，旨在提升少样本情境下的文本可读性评估效果。](2024年04月03日/FPT_Feature_Prompt_Tuning_for_Few-shot_Readability_Assessment.md)

- [UniAV: Unified Audio-Visual Perception for Multi-Task Video Localization](2024年04月03日/UniAV_Unified_Audio-Visual_Perception_for_Multi-Task_Video_Localization.md)

    - [翻译: UniAV：集视听感知于一体，实现多任务视频精准定位](2024年04月03日/UniAV_Unified_Audio-Visual_Perception_for_Multi-Task_Video_Localization.md)

- [Multi-modal Learning for WebAssembly Reverse Engineering](2024年04月03日/Multi-modal_Learning_for_WebAssembly_Reverse_Engineering.md)

    - [翻译: 通过多模态学习方法，探索WebAssembly逆向工程的新途径。](2024年04月03日/Multi-modal_Learning_for_WebAssembly_Reverse_Engineering.md)

- [Diverse and Tailored Image Generation for Zero-shot Multi-label Classification](2024年04月03日/Diverse_and_Tailored_Image_Generation_for_Zero-shot_Multi-label_Classification.md)

    - [翻译: 为零-shot多标签分类打造多样化且针对性的图像生成方法。](2024年04月03日/Diverse_and_Tailored_Image_Generation_for_Zero-shot_Multi-label_Classification.md)

- [Robust Pronoun Use Fidelity with English LLMs: Are they Reasoning, Repeating, or Just Biased?](2024年04月03日/Robust_Pronoun_Use_Fidelity_with_English_LLMs_Are_they_Reasoning,_Repeating,_or_Just_Biased.md)

    - [翻译: 英语大型语言模型的代词使用准确度：它们真的在进行逻辑推理，还是仅仅在重复或受到偏见的驱使？](2024年04月03日/Robust_Pronoun_Use_Fidelity_with_English_LLMs_Are_they_Reasoning,_Repeating,_or_Just_Biased.md)

- [Towards Standards-Compliant Assistive Technology Product Specifications via LLMs](2024年04月03日/Towards_Standards-Compliant_Assistive_Technology_Product_Specifications_via_LLMs.md)

    - [翻译: 借助大型语言模型（LLMs），迈向符合标准的辅助技术产品规范。](2024年04月03日/Towards_Standards-Compliant_Assistive_Technology_Product_Specifications_via_LLMs.md)

- [LVLM-Intrepret: An Interpretability Tool for Large Vision-Language Models](2024年04月03日/LVLM-Intrepret_An_Interpretability_Tool_for_Large_Vision-Language_Models.md)

    - [翻译: LVLM-解读：为大型视觉-语言模型打造的可解释性工具](2024年04月03日/LVLM-Intrepret_An_Interpretability_Tool_for_Large_Vision-Language_Models.md)

- [Testing the Effect of Code Documentation on Large Language Model Code Understanding](2024年04月03日/Testing_the_Effect_of_Code_Documentation_on_Large_Language_Model_Code_Understanding.md)

    - [翻译: 探究代码注释在提升大型语言模型对代码理解方面的作用](2024年04月03日/Testing_the_Effect_of_Code_Documentation_on_Large_Language_Model_Code_Understanding.md)

- [Auditing the Use of Language Models to Guide Hiring Decisions](2024年04月03日/Auditing_the_Use_of_Language_Models_to_Guide_Hiring_Decisions.md)

    - [翻译: 本文探讨了运用语言模型辅助招聘决策的实践，并评估其有效性与潜在影响。](2024年04月03日/Auditing_the_Use_of_Language_Models_to_Guide_Hiring_Decisions.md)

- [Construction of Functional Materials Knowledge Graph in Multidisciplinary Materials Science via Large Language Model](2024年04月03日/Construction_of_Functional_Materials_Knowledge_Graph_in_Multidisciplinary_Materials_Science_via_Large_Language_Model.md)

    - [翻译: 借助大型语言模型，跨学科材料科学领域正致力于构建功能材料的知识图谱。](2024年04月03日/Construction_of_Functional_Materials_Knowledge_Graph_in_Multidisciplinary_Materials_Science_via_Large_Language_Model.md)

- [Mai Ho'omāuna i ka 'Ai: Language Models Improve Automatic Speech Recognition in Hawaiian](2024年04月03日/Mai_Ho'omāuna_i_ka_'Ai_Language_Models_Improve_Automatic_Speech_Recognition_in_Hawaiian.md)

    - [翻译: 借助语言模型，夏威夷语的自动语音识别技术得到提升](2024年04月03日/Mai_Ho'omāuna_i_ka_'Ai_Language_Models_Improve_Automatic_Speech_Recognition_in_Hawaiian.md)

- [JailBreakV-28K: A Benchmark for Assessing the Robustness of MultiModal Large Language Models against Jailbreak Attacks](2024年04月03日/JailBreakV-28K_A_Benchmark_for_Assessing_the_Robustness_of_MultiModal_Large_Language_Models_against_Jailbreak_Attacks.md)

    - [翻译: JailBreakV-28K：针对越狱攻击，评估多模态大型语言模型鲁棒性的基准测试。](2024年04月03日/JailBreakV-28K_A_Benchmark_for_Assessing_the_Robustness_of_MultiModal_Large_Language_Models_against_Jailbreak_Attacks.md)

- [CONFLARE: CONFormal LArge language model REtrieval](2024年04月03日/CONFLARE_CONFormal_LArge_language_model_REtrieval.md)

    - [翻译: CONFLARE：一种适应性强的大型语言模型检索系统](2024年04月03日/CONFLARE_CONFormal_LArge_language_model_REtrieval.md)

- [Language Model Evolution: An Iterated Learning Perspective](2024年04月03日/Language_Model_Evolution_An_Iterated_Learning_Perspective.md)

    - [翻译: 语言模型的进化：从迭代学习的角度看](2024年04月03日/Language_Model_Evolution_An_Iterated_Learning_Perspective.md)

- [MIMIR: A Streamlined Platform for Personalized Agent Tuning in Domain Expertise](2024年04月03日/MIMIR_A_Streamlined_Platform_for_Personalized_Agent_Tuning_in_Domain_Expertise.md)

    - [翻译: MIMIR：领域专家专用，打造个性化智能代理的高效平台](2024年04月03日/MIMIR_A_Streamlined_Platform_for_Personalized_Agent_Tuning_in_Domain_Expertise.md)

- [Concept-Guided LLM Agents for Human-AI Safety Codesign](2024年04月03日/Concept-Guided_LLM_Agents_for_Human-AI_Safety_Codesign.md)

    - [翻译: ](2024年04月03日/Concept-Guided_LLM_Agents_for_Human-AI_Safety_Codesign.md)

2024年04月02日

- [Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack](2024年04月02日/Great,_Now_Write_an_Article_About_That_The_Crescendo_Multi-Turn_LLM_Jailbreak_Attack.md)

    - [翻译: 好极了，那就来谈谈这个主题：《高潮》—— 一种针对多轮大型语言模型的突破性攻击手法](2024年04月02日/Great,_Now_Write_an_Article_About_That_The_Crescendo_Multi-Turn_LLM_Jailbreak_Attack.md)

- [Sentiment Analysis of Citations in Scientific Articles Using ChatGPT: Identifying Potential Biases and Conflicts of Interest](2024年04月02日/Sentiment_Analysis_of_Citations_in_Scientific_Articles_Using_ChatGPT_Identifying_Potential_Biases_and_Conflicts_of_Interest.md)

    - [翻译: 通过 ChatGPT 对科学论文引用的情感分析，揭示可能存在的偏见与利益冲突。](2024年04月02日/Sentiment_Analysis_of_Citations_in_Scientific_Articles_Using_ChatGPT_Identifying_Potential_Biases_and_Conflicts_of_Interest.md)

- [PATCH -- Psychometrics-AssisTed benCHmarking of Large Language Models: A Case Study of Mathematics Proficiency](2024年04月02日/PATCH_--_Psychometrics-AssisTed_benCHmarking_of_Large_Language_Models_A_Case_Study_of_Mathematics_Proficiency.md)

    - [翻译: PATCH——通过心理测量技术辅助的大规模语言模型性能基准测试：以数学能力为例的深入案例分析](2024年04月02日/PATCH_--_Psychometrics-AssisTed_benCHmarking_of_Large_Language_Models_A_Case_Study_of_Mathematics_Proficiency.md)

- [Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation](2024年04月02日/Auditing_Large_Language_Models_for_Enhanced_Text-Based_Stereotype_Detection_and_Probing-Based_Bias_Evaluation.md)

    - [翻译: 通过对大型语言模型进行审查，我们可以提高基于文本的刻板印象检测能力，并进行更为深入的偏见评估。](2024年04月02日/Auditing_Large_Language_Models_for_Enhanced_Text-Based_Stereotype_Detection_and_Probing-Based_Bias_Evaluation.md)

- [Class-Incremental Few-Shot Event Detection](2024年04月02日/Class-Incremental_Few-Shot_Event_Detection.md)

    - [翻译: 在少样本学习环境下，我们提出了一种新颖的事件检测方法，即类增量策略。该方法通过逐步引入新的类别信息，有效地提升了模型在面对类别不断变化的事件中的检测性能。](2024年04月02日/Class-Incremental_Few-Shot_Event_Detection.md)

- [Peer-aided Repairer: Empowering Large Language Models to Repair Advanced Student Assignments](2024年04月02日/Peer-aided_Repairer_Empowering_Large_Language_Models_to_Repair_Advanced_Student_Assignments.md)

    - [翻译: 同伴辅助修复器：赋予大型语言模型修复高级学生作业的能力，旨在提升模型对复杂任务的处理能力。](2024年04月02日/Peer-aided_Repairer_Empowering_Large_Language_Models_to_Repair_Advanced_Student_Assignments.md)

- [M2SA: Multimodal and Multilingual Model for Sentiment Analysis of Tweets](2024年04月02日/M2SA_Multimodal_and_Multilingual_Model_for_Sentiment_Analysis_of_Tweets.md)

    - [翻译: M2SA：一款针对推文情感分析的多模态、多语言模型](2024年04月02日/M2SA_Multimodal_and_Multilingual_Model_for_Sentiment_Analysis_of_Tweets.md)

- [Unleash the Potential of CLIP for Video Highlight Detection](2024年04月02日/Unleash_the_Potential_of_CLIP_for_Video_Highlight_Detection.md)

    - [翻译: 挖掘 CLIP 技术在视频精彩瞬间识别上的潜在力量](2024年04月02日/Unleash_the_Potential_of_CLIP_for_Video_Highlight_Detection.md)

- [Octopus v2: On-device language model for super agent](2024年04月02日/Octopus_v2_On-device_language_model_for_super_agent.md)

    - [翻译: 章鱼 v2：超级智能代理的移动设备语言模型](2024年04月02日/Octopus_v2_On-device_language_model_for_super_agent.md)

- [Transfer Learning from Whisper for Microscopic Intelligibility Prediction](2024年04月02日/Transfer_Learning_from_Whisper_for_Microscopic_Intelligibility_Prediction.md)

    - [翻译: 通过 Whisper 的迁移学习能力来预测细节层面的可理解性。](2024年04月02日/Transfer_Learning_from_Whisper_for_Microscopic_Intelligibility_Prediction.md)

- [Asymptotics of Language Model Alignment](2024年04月02日/Asymptotics_of_Language_Model_Alignment.md)

    - [翻译: 探讨语言模型对齐的极限行为](2024年04月02日/Asymptotics_of_Language_Model_Alignment.md)

- [Self-Improvement Programming for Temporal Knowledge Graph Question Answering](2024年04月02日/Self-Improvement_Programming_for_Temporal_Knowledge_Graph_Question_Answering.md)

    - [翻译: 通过自改进编程技术，提升时序知识图谱的问答能力。](2024年04月02日/Self-Improvement_Programming_for_Temporal_Knowledge_Graph_Question_Answering.md)

- [On the Role of Summary Content Units in Text Summarization Evaluation](2024年04月02日/On_the_Role_of_Summary_Content_Units_in_Text_Summarization_Evaluation.md)

    - [翻译: 文本摘要评估中，摘要内容单元的重要性。](2024年04月02日/On_the_Role_of_Summary_Content_Units_in_Text_Summarization_Evaluation.md)

- [MotionChain: Conversational Motion Controllers via Multimodal Prompts](2024年04月02日/MotionChain_Conversational_Motion_Controllers_via_Multimodal_Prompts.md)

    - [翻译: MotionChain：借助多模态提示实现的交互式动作控制方案](2024年04月02日/MotionChain_Conversational_Motion_Controllers_via_Multimodal_Prompts.md)

- [Towards Generalizable and Faithful Logic Reasoning over Natural Language via Resolution Refutation](2024年04月02日/Towards_Generalizable_and_Faithful_Logic_Reasoning_over_Natural_Language_via_Resolution_Refutation.md)

    - [翻译: 通过解决反驳，我们朝着实现自然语言逻辑推理的普适性和忠实性迈进。](2024年04月02日/Towards_Generalizable_and_Faithful_Logic_Reasoning_over_Natural_Language_via_Resolution_Refutation.md)

- [METAL: Towards Multilingual Meta-Evaluation](2024年04月02日/METAL_Towards_Multilingual_Meta-Evaluation.md)

    - [翻译: METAL：探索多语言间的元评估方法](2024年04月02日/METAL_Towards_Multilingual_Meta-Evaluation.md)

- [CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models](2024年04月02日/CMAT_A_Multi-Agent_Collaboration_Tuning_Framework_for_Enhancing_Small_Language_Models.md)

    - [翻译: CMAT：专为提升小型语言模型性能而设计的多智能体协同优化框架](2024年04月02日/CMAT_A_Multi-Agent_Collaboration_Tuning_Framework_for_Enhancing_Small_Language_Models.md)

- [Release of Pre-Trained Models for the Japanese Language](2024年04月02日/Release_of_Pre-Trained_Models_for_the_Japanese_Language.md)

    - [翻译: 日语预训练模型现已发布。](2024年04月02日/Release_of_Pre-Trained_Models_for_the_Japanese_Language.md)

- [InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis](2024年04月02日/InsightLens_Discovering_and_Exploring_Insights_from_Conversational_Contexts_in_Large-Language-Model-Powered_Data_Analysis.md)

    - [翻译: InsightLens：在大型语言模型支持的数据分析中，挖掘并探究对话语境的深层见解。](2024年04月02日/InsightLens_Discovering_and_Exploring_Insights_from_Conversational_Contexts_in_Large-Language-Model-Powered_Data_Analysis.md)

- [Voice EHR: Introducing Multimodal Audio Data for Health](2024年04月02日/Voice_EHR_Introducing_Multimodal_Audio_Data_for_Health.md)

    - [翻译: 语音电子健康记录（Voice EHR）：为健康领域带来多模态音频数据的新探索。](2024年04月02日/Voice_EHR_Introducing_Multimodal_Audio_Data_for_Health.md)

- [CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions for RAG systems](2024年04月02日/CLAPNQ_Cohesive_Long-form_Answers_from_Passages_in_Natural_Questions_for_RAG_systems.md)

    - [翻译: CLAPNQ：针对RAG系统，从自然语言问题中提取段落，打造连贯且详尽的长篇幅回答。](2024年04月02日/CLAPNQ_Cohesive_Long-form_Answers_from_Passages_in_Natural_Questions_for_RAG_systems.md)

- [Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts](2024年04月02日/Improving_Retrieval_Augmented_Open-Domain_Question-Answering_with_Vectorized_Contexts.md)

    - [翻译: 利用向量化上下文技术，我们旨在提升开放领域问答系统中的检索增强功能。](2024年04月02日/Improving_Retrieval_Augmented_Open-Domain_Question-Answering_with_Vectorized_Contexts.md)

- [Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization](2024年04月02日/Towards_Better_Generalization_in_Open-Domain_Question_Answering_by_Mitigating_Context_Memorization.md)

    - [翻译: 为了在开放领域问答中获得更佳的泛化效果，本研究致力于减轻上下文记忆的影响。](2024年04月02日/Towards_Better_Generalization_in_Open-Domain_Question_Answering_by_Mitigating_Context_Memorization.md)

- [Iterated Learning Improves Compositionality in Large Vision-Language Models](2024年04月02日/Iterated_Learning_Improves_Compositionality_in_Large_Vision-Language_Models.md)

    - [翻译: 通过迭代学习，大型视觉-语言模型的组合能力得到了显著提升。](2024年04月02日/Iterated_Learning_Improves_Compositionality_in_Large_Vision-Language_Models.md)

- [A Survey on Large Language Model-Based Game Agents](2024年04月02日/A_Survey_on_Large_Language_Model-Based_Game_Agents.md)

    - [翻译: 本文综述了基于大型语言模型的游戏代理的研究现状。](2024年04月02日/A_Survey_on_Large_Language_Model-Based_Game_Agents.md)

- [Large Language Models for Orchestrating Bimanual Robots](2024年04月02日/Large_Language_Models_for_Orchestrating_Bimanual_Robots.md)

    - [翻译: 通过大型语言模型，我们能够精准地指挥双手机器人的协同工作。](2024年04月02日/Large_Language_Models_for_Orchestrating_Bimanual_Robots.md)

- [Segment Any 3D Object with Language](2024年04月02日/Segment_Any_3D_Object_with_Language.md)

    - [翻译: 通过语言指令，轻松分割任意三维物体](2024年04月02日/Segment_Any_3D_Object_with_Language.md)

- [Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks](2024年04月02日/Bridging_Language,_Vision_and_Action_Multimodal_VAEs_in_Robotic_Manipulation_Tasks.md)

    - [翻译: 多模态变分自编码器（VAEs）在机器人操控任务中架起了语言、视觉与动作之间的桥梁。尽管如此，我们对于这些多模态VAEs在现实操作中的表现及其成效仍知之甚少。](2024年04月02日/Bridging_Language,_Vision_and_Action_Multimodal_VAEs_in_Robotic_Manipulation_Tasks.md)

- [Topic-based Watermarks for LLM-Generated Text](2024年04月02日/Topic-based_Watermarks_for_LLM-Generated_Text.md)

    - [翻译: 本文介绍了一种为大型语言模型（LLM）生成的文本设计的主题水印方法。](2024年04月02日/Topic-based_Watermarks_for_LLM-Generated_Text.md)

- [ViTamin: Designing Scalable Vision Models in the Vision-Language Era](2024年04月02日/ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era.md)

    - [翻译: ViTamin: 为视觉-语言时代打造可伸缩的视觉模型](2024年04月02日/ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era.md)

- [FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning](2024年04月02日/FLawN-T5_An_Empirical_Examination_of_Effective_Instruction-Tuning_Data_Mixtures_for_Legal_Reasoning.md)

    - [翻译: FLawN-T5：探究法律推理中高效指令调整数据组合的实证分析](2024年04月02日/FLawN-T5_An_Empirical_Examination_of_Effective_Instruction-Tuning_Data_Mixtures_for_Legal_Reasoning.md)

- [Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models](2024年04月02日/Exploring_Automated_Distractor_Generation_for_Math_Multiple-choice_Questions_via_Large_Language_Models.md)

    - [翻译: 本研究利用大型语言模型，探索自动生成数学多项选择题干扰项的方法。](2024年04月02日/Exploring_Automated_Distractor_Generation_for_Math_Multiple-choice_Questions_via_Large_Language_Models.md)

- [Pre-trained Vision and Language Transformers Are Few-Shot Incremental Learners](2024年04月02日/Pre-trained_Vision_and_Language_Transformers_Are_Few-Shot_Incremental_Learners.md)

    - [翻译: 预先训练好的视觉与语言转换器，能够作为少量样本的逐步学习器。](2024年04月02日/Pre-trained_Vision_and_Language_Transformers_Are_Few-Shot_Incremental_Learners.md)

- [GINopic: Topic Modeling with Graph Isomorphism Network](2024年04月02日/GINopic_Topic_Modeling_with_Graph_Isomorphism_Network.md)

    - [翻译: GINopic：借助图同构网络进行主题挖掘与分析](2024年04月02日/GINopic_Topic_Modeling_with_Graph_Isomorphism_Network.md)

- [CameraCtrl: Enabling Camera Control for Text-to-Video Generation](2024年04月02日/CameraCtrl_Enabling_Camera_Control_for_Text-to-Video_Generation.md)

    - [翻译: CameraCtrl：实现文本输入到视频输出的相机操控功能](2024年04月02日/CameraCtrl_Enabling_Camera_Control_for_Text-to-Video_Generation.md)

- [Advancing LLM Reasoning Generalists with Preference Trees](2024年04月02日/Advancing_LLM_Reasoning_Generalists_with_Preference_Trees.md)

    - [翻译: 借助偏好树，我们能够增强大型语言模型的推理能力，使其在处理各种问题时表现得更加全面。](2024年04月02日/Advancing_LLM_Reasoning_Generalists_with_Preference_Trees.md)

- [Digital Forgetting in Large Language Models: A Survey of Unlearning Methods](2024年04月02日/Digital_Forgetting_in_Large_Language_Models_A_Survey_of_Unlearning_Methods.md)

    - [翻译: 大型语言模型中的数字遗忘：对遗忘方法的综述。](2024年04月02日/Digital_Forgetting_in_Large_Language_Models_A_Survey_of_Unlearning_Methods.md)

- [Long-context LLMs Struggle with Long In-context Learning](2024年04月02日/Long-context_LLMs_Struggle_with_Long_In-context_Learning.md)

    - [翻译: 长篇幅的语境对于大型语言模型来说，在进行长距离的情境学习时显得颇为棘手。](2024年04月02日/Long-context_LLMs_Struggle_with_Long_In-context_Learning.md)

- [Deconstructing In-Context Learning: Understanding Prompts via Corruption](2024年04月02日/Deconstructing_In-Context_Learning_Understanding_Prompts_via_Corruption.md)

    - [翻译: 探究上下文学习之谜：通过干扰手段剖析提示的本质](2024年04月02日/Deconstructing_In-Context_Learning_Understanding_Prompts_via_Corruption.md)

- [MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages](2024年04月02日/MultiParaDetox_Extending_Text_Detoxification_with_Parallel_Data_to_New_Languages.md)

    - [翻译: MultiParaDetox：利用并行文本数据，将文本净化技术推广至更多语言。](2024年04月02日/MultiParaDetox_Extending_Text_Detoxification_with_Parallel_Data_to_New_Languages.md)

- [MuxServe: Flexible Multiplexing for Efficient Multiple LLM Serving](2024年04月02日/MuxServe_Flexible_Multiplexing_for_Efficient_Multiple_LLM_Serving.md)

    - [翻译: MuxServe 通过灵活的多路复用技术，为多个大型语言模型（LLM）提供高效服务。](2024年04月02日/MuxServe_Flexible_Multiplexing_for_Efficient_Multiple_LLM_Serving.md)

- [HyperCLOVA X Technical Report](2024年04月02日/HyperCLOVA_X_Technical_Report.md)

    - [翻译: 《超能CLOVA X》技术研究报告](2024年04月02日/HyperCLOVA_X_Technical_Report.md)

- [Towards Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation](2024年04月02日/Towards_Better_Understanding_of_Cybercrime_The_Role_of_Fine-Tuned_LLMs_in_Translation.md)

    - [翻译: 探索网络犯罪的深层含义：精细化调整的大型语言模型在翻译工作中的角色。](2024年04月02日/Towards_Better_Understanding_of_Cybercrime_The_Role_of_Fine-Tuned_LLMs_in_Translation.md)

- [SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation](2024年04月02日/SGSH_Stimulate_Large_Language_Models_with_Skeleton_Heuristics_for_Knowledge_Base_Question_Generation.md)

    - [翻译: SGSH：运用骨架启发式策略激活大型语言模型，助力知识库提问生成。](2024年04月02日/SGSH_Stimulate_Large_Language_Models_with_Skeleton_Heuristics_for_Knowledge_Base_Question_Generation.md)

- [Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack](2024年04月02日/Humanizing_Machine-Generated_Content_Evading_AI-Text_Detection_through_Adversarial_Attack.md)

    - [翻译: 机器内容拟人化：通过对抗性策略规避AI文本识别技术。](2024年04月02日/Humanizing_Machine-Generated_Content_Evading_AI-Text_Detection_through_Adversarial_Attack.md)

- [Minimize Quantization Output Error with Bias Compensation](2024年04月02日/Minimize_Quantization_Output_Error_with_Bias_Compensation.md)

    - [翻译: 采用偏差校正法降低量化输出误差](2024年04月02日/Minimize_Quantization_Output_Error_with_Bias_Compensation.md)

- [Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey](2024年04月02日/Beyond_Accuracy_Evaluating_the_Reasoning_Behavior_of_Large_Language_Models_--_A_Survey.md)

    - [翻译: 探究大型语言模型的推理表现：准确性之外的评估视角 -- 一项全面调查](2024年04月02日/Beyond_Accuracy_Evaluating_the_Reasoning_Behavior_of_Large_Language_Models_--_A_Survey.md)

- [Poro 34B and the Blessing of Multilinguality](2024年04月02日/Poro_34B_and_the_Blessing_of_Multilinguality.md)

    - [翻译: 探索 Poro 34B：多语言能力的优势与挑战](2024年04月02日/Poro_34B_and_the_Blessing_of_Multilinguality.md)

- [Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation](2024年04月02日/Where_to_Move_Next_Zero-shot_Generalization_of_LLMs_for_Next_POI_Recommendation.md)

    - [翻译: 下一站去哪儿：大型语言模型的零-shot 泛化技术助力下一个热门景点推荐](2024年04月02日/Where_to_Move_Next_Zero-shot_Generalization_of_LLMs_for_Next_POI_Recommendation.md)

- [RESSA: Repair Sparse Vision-Language Models via Sparse Cross-Modality Adaptation](2024年04月02日/RESSA_Repair_Sparse_Vision-Language_Models_via_Sparse_Cross-Modality_Adaptation.md)

    - [翻译: RESSA：通过稀疏交叉模态适配技术，完善视觉-语言模型的稀疏性问题。](2024年04月02日/RESSA_Repair_Sparse_Vision-Language_Models_via_Sparse_Cross-Modality_Adaptation.md)

- [Enhancing Low-Resource LLMs Classification with PEFT and Synthetic Data](2024年04月02日/Enhancing_Low-Resource_LLMs_Classification_with_PEFT_and_Synthetic_Data.md)

    - [翻译: 通过 PEFT 和合成数据提升低资源大型语言模型的分类表现。](2024年04月02日/Enhancing_Low-Resource_LLMs_Classification_with_PEFT_and_Synthetic_Data.md)

- [Revisiting subword tokenization: A case study on affixal negation in large language models](2024年04月02日/Revisiting_subword_tokenization_A_case_study_on_affixal_negation_in_large_language_models.md)

    - [翻译: 深入探讨子词切分：以大型语言模型中的词缀否定现象为例](2024年04月02日/Revisiting_subword_tokenization_A_case_study_on_affixal_negation_in_large_language_models.md)

- [What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases](2024年04月02日/What_Are_We_Measuring_When_We_Evaluate_Large_Vision-Language_Models_An_Analysis_of_Latent_Factors_and_Biases.md)

    - [翻译: 评估大型视觉-语言模型时，我们究竟关注哪些指标？本文深入探讨了其中的潜在因素与偏见问题。](2024年04月02日/What_Are_We_Measuring_When_We_Evaluate_Large_Vision-Language_Models_An_Analysis_of_Latent_Factors_and_Biases.md)

- [Exploring Backdoor Vulnerabilities of Chat Models](2024年04月02日/Exploring_Backdoor_Vulnerabilities_of_Chat_Models.md)

    - [翻译: 深入研究聊天机器人的安全漏洞](2024年04月02日/Exploring_Backdoor_Vulnerabilities_of_Chat_Models.md)

- [Benchmarking Large Language Models for Persian: A Preliminary Study Focusing on ChatGPT](2024年04月02日/Benchmarking_Large_Language_Models_for_Persian_A_Preliminary_Study_Focusing_on_ChatGPT.md)

    - [翻译: 探索波斯语大型语言模型：以ChatGPT为焦点的初步研究](2024年04月02日/Benchmarking_Large_Language_Models_for_Persian_A_Preliminary_Study_Focusing_on_ChatGPT.md)

- [Token Trails: Navigating Contextual Depths in Conversational AI with ChatLLM](2024年04月02日/Token_Trails_Navigating_Contextual_Depths_in_Conversational_AI_with_ChatLLM.md)

    - [翻译: Token Trails: 利用ChatLLM探索会话AI中的语境深度](2024年04月02日/Token_Trails_Navigating_Contextual_Depths_in_Conversational_AI_with_ChatLLM.md)

- [Low-resource neural machine translation with morphological modeling](2024年04月02日/Low-resource_neural_machine_translation_with_morphological_modeling.md)

    - [翻译: 在资源有限的情况下，通过形态建模来提升神经机器翻译的性能。](2024年04月02日/Low-resource_neural_machine_translation_with_morphological_modeling.md)

- [On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL](2024年04月02日/On_Linearizing_Structured_Data_in_Encoder-Decoder_Language_Models_Insights_from_Text-to-SQL.md)

    - [翻译: 探究编码器-解码器语言模型中结构化数据的线性化处理：文本转换为SQL的洞见。](2024年04月02日/On_Linearizing_Structured_Data_in_Encoder-Decoder_Language_Models_Insights_from_Text-to-SQL.md)

- [Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors](2024年04月02日/Two_Heads_are_Better_than_One_Nested_PoE_for_Robust_Defense_Against_Multi-Backdoors.md)

    - [翻译: 双脑并用，胜于单机：采用嵌套PoE策略，构筑抵御多重后门攻击的坚实防线。](2024年04月02日/Two_Heads_are_Better_than_One_Nested_PoE_for_Robust_Defense_Against_Multi-Backdoors.md)

- [Multi-BERT: Leveraging Adapters and Prompt Tuning for Low-Resource Multi-Domain Adaptation](2024年04月02日/Multi-BERT_Leveraging_Adapters_and_Prompt_Tuning_for_Low-Resource_Multi-Domain_Adaptation.md)

    - [翻译: Multi-BERT：借助适配器与提示调优，实现低资源条件下的多领域适配。](2024年04月02日/Multi-BERT_Leveraging_Adapters_and_Prompt_Tuning_for_Low-Resource_Multi-Domain_Adaptation.md)

- [Comparative Study of Domain Driven Terms Extraction Using Large Language Models](2024年04月02日/Comparative_Study_of_Domain_Driven_Terms_Extraction_Using_Large_Language_Models.md)

    - [翻译: 本研究通过大型语言模型，对领域驱动的术语提取进行了比较分析。](2024年04月02日/Comparative_Study_of_Domain_Driven_Terms_Extraction_Using_Large_Language_Models.md)

- [Heat Death of Generative Models in Closed-Loop Learning](2024年04月02日/Heat_Death_of_Generative_Models_in_Closed-Loop_Learning.md)

    - [翻译: 闭环学习中生成模型的热寂困境](2024年04月02日/Heat_Death_of_Generative_Models_in_Closed-Loop_Learning.md)

- [Toward Informal Language Processing: Knowledge of Slang in Large Language Models](2024年04月02日/Toward_Informal_Language_Processing_Knowledge_of_Slang_in_Large_Language_Models.md)

    - [翻译: 迈向非正式语言处理：探究大型语言模型中的俚语理解](2024年04月02日/Toward_Informal_Language_Processing_Knowledge_of_Slang_in_Large_Language_Models.md)

- [Prompts As Programs: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization](2024年04月02日/Prompts_As_Programs_A_Structure-Aware_Approach_to_Efficient_Compile-Time_Prompt_Optimization.md)

    - [翻译: 将提示视作程序，本研究提出了一种结构感知的方法，用以在编译时期高效地优化提示。](2024年04月02日/Prompts_As_Programs_A_Structure-Aware_Approach_to_Efficient_Compile-Time_Prompt_Optimization.md)

- [ZeroCAP: Zero-Shot Multi-Robot Context Aware Pattern Formation via Large Language Models](2024年04月02日/ZeroCAP_Zero-Shot_Multi-Robot_Context_Aware_Pattern_Formation_via_Large_Language_Models.md)

    - [翻译: ZeroCAP 利用大型语言模型，实现了零-shot学习下的多机器人系统能够感知上下文并进行模式形成。](2024年04月02日/ZeroCAP_Zero-Shot_Multi-Robot_Context_Aware_Pattern_Formation_via_Large_Language_Models.md)

- [Constrained Robotic Navigation on Preferred Terrains Using LLMs and Speech Instruction: Exploiting the Power of Adverbs](2024年04月02日/Constrained_Robotic_Navigation_on_Preferred_Terrains_Using_LLMs_and_Speech_Instruction_Exploiting_the_Power_of_Adverbs.md)

    - [翻译: 借助副词的威力，通过大型语言模型和语音指令实现机器人在理想地形上的精准导航。](2024年04月02日/Constrained_Robotic_Navigation_on_Preferred_Terrains_Using_LLMs_and_Speech_Instruction_Exploiting_the_Power_of_Adverbs.md)

- [LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages](2024年04月02日/LLMs_in_the_Loop_Leveraging_Large_Language_Model_Annotations_for_Active_Learning_in_Low-Resource_Languages.md)

    - [翻译: 大型语言模型（LLM）循环应用：借助其注释功能，为低资源语言的主动学习提供支持。](2024年04月02日/LLMs_in_the_Loop_Leveraging_Large_Language_Model_Annotations_for_Active_Learning_in_Low-Resource_Languages.md)

- [: A Simple Society of Language Models Solves Complex Reasoning](2024年04月02日/_A_Simple_Society_of_Language_Models_Solves_Complex_Reasoning.md)

    - [翻译: 简单的语言模型集合轻松应对复杂推理挑战](2024年04月02日/_A_Simple_Society_of_Language_Models_Solves_Complex_Reasoning.md)

- [Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices](2024年04月02日/Exploring_How_Multiple_Levels_of_GPT-Generated_Programming_Hints_Support_or_Disappoint_Novices.md)

    - [翻译: 研究多层次 GPT 编程提示对新手的助力与挫败感。](2024年04月02日/Exploring_How_Multiple_Levels_of_GPT-Generated_Programming_Hints_Support_or_Disappoint_Novices.md)

- [Emergent Abilities in Reduced-Scale Generative Language Models](2024年04月02日/Emergent_Abilities_in_Reduced-Scale_Generative_Language_Models.md)

    - [翻译: 在简化版的生成型语言模型中，涌现出了一些新的能力。](2024年04月02日/Emergent_Abilities_in_Reduced-Scale_Generative_Language_Models.md)

- [Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization](2024年04月02日/Self-Organized_Agents_A_LLM_Multi-Agent_Framework_toward_Ultra_Large-Scale_Code_Generation_and_Optimization.md)

    - [翻译: 自组织的智能代理：构建面向极大规模代码生成与优化的多代理大型语言模型框架。](2024年04月02日/Self-Organized_Agents_A_LLM_Multi-Agent_Framework_toward_Ultra_Large-Scale_Code_Generation_and_Optimization.md)

- [CATP: Cross-Attention Token Pruning for Accuracy Preserved Multimodal Model Inference](2024年04月02日/CATP_Cross-Attention_Token_Pruning_for_Accuracy_Preserved_Multimodal_Model_Inference.md)

    - [翻译: CATP 技术通过跨注意力机制对令牌进行剪枝，实现了在多模态模型推理中保持准确度的同时，提高了效率。](2024年04月02日/CATP_Cross-Attention_Token_Pruning_for_Accuracy_Preserved_Multimodal_Model_Inference.md)

2024年04月01日

- [Large Language Model Evaluation Via Multi AI Agents: Preliminary results](2024年04月01日/Large_Language_Model_Evaluation_Via_Multi_AI_Agents_Preliminary_results.md)

    - [翻译: 借助众多AI助手，我们对大型语言模型展开了评估，目前取得了一些初步成果。](2024年04月01日/Large_Language_Model_Evaluation_Via_Multi_AI_Agents_Preliminary_results.md)

- [Source-Aware Training Enables Knowledge Attribution in Language Models](2024年04月01日/Source-Aware_Training_Enables_Knowledge_Attribution_in_Language_Models.md)

    - [翻译: 通过源感知训练，我们能够在语言模型中对知识进行追溯和归属。](2024年04月01日/Source-Aware_Training_Enables_Knowledge_Attribution_in_Language_Models.md)

- [Harnessing Large Language Models for Training-free Video Anomaly Detection](2024年04月01日/Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection.md)

    - [翻译: 通过运用大型语言模型，我们可以实现无需额外训练的视频异常检测技术。](2024年04月01日/Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection.md)

- [Query Performance Prediction using Relevance Judgments Generated by Large Language Models](2024年04月01日/Query_Performance_Prediction_using_Relevance_Judgments_Generated_by_Large_Language_Models.md)

    - [翻译: 通过大型语言模型生成的相关性评估来预测查询性能](2024年04月01日/Query_Performance_Prediction_using_Relevance_Judgments_Generated_by_Large_Language_Models.md)

- [Transforming the Synthesis of Carbon Nanotubes with Machine Learning Models and Automation](2024年04月01日/Transforming_the_Synthesis_of_Carbon_Nanotubes_with_Machine_Learning_Models_and_Automation.md)

    - [翻译: 利用机器学习模型和自动化技术革新碳纳米管的制备过程](2024年04月01日/Transforming_the_Synthesis_of_Carbon_Nanotubes_with_Machine_Learning_Models_and_Automation.md)

- [LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation](2024年04月01日/LLM-RadJudge_Achieving_Radiologist-Level_Evaluation_for_X-Ray_Report_Generation.md)

    - [翻译: LLM-RadJudge：在生成X光报告方面达到放射科医生的评估水准](2024年04月01日/LLM-RadJudge_Achieving_Radiologist-Level_Evaluation_for_X-Ray_Report_Generation.md)

- [Exploring the Nexus of Large Language Models and Legal Systems: A Short Survey](2024年04月01日/Exploring_the_Nexus_of_Large_Language_Models_and_Legal_Systems_A_Short_Survey.md)

    - [翻译: 浅谈大型语言模型与法律体系的交汇点](2024年04月01日/Exploring_the_Nexus_of_Large_Language_Models_and_Legal_Systems_A_Short_Survey.md)

- [Prior Constraints-based Reward Model Training for Aligning Large Language Models](2024年04月01日/Prior_Constraints-based_Reward_Model_Training_for_Aligning_Large_Language_Models.md)

    - [翻译: 通过先验约束引导的奖励模型训练，实现大型语言模型的精准对齐。](2024年04月01日/Prior_Constraints-based_Reward_Model_Training_for_Aligning_Large_Language_Models.md)

- [VideoDistill: Language-aware Vision Distillation for Video Question Answering](2024年04月01日/VideoDistill_Language-aware_Vision_Distillation_for_Video_Question_Answering.md)

    - [翻译: VideoDistill：为视频问答而设计的，融合语言理解的视觉蒸馏技术](2024年04月01日/VideoDistill_Language-aware_Vision_Distillation_for_Video_Question_Answering.md)

- [Exploring and Evaluating Hallucinations in LLM-Powered Code Generation](2024年04月01日/Exploring_and_Evaluating_Hallucinations_in_LLM-Powered_Code_Generation.md)

    - [翻译: 探究与评价由大型语言模型（LLM）驱动的代码生成过程中的虚构现象。](2024年04月01日/Exploring_and_Evaluating_Hallucinations_in_LLM-Powered_Code_Generation.md)

- [AISPACE at SemEval-2024 task 8: A Class-balanced Soft-voting System for Detecting Multi-generator Machine-generated Text](2024年04月01日/AISPACE_at_SemEval-2024_task_8_A_Class-balanced_Soft-voting_System_for_Detecting_Multi-generator_Machine-generated_Text.md)

    - [翻译: AISPACE 参与 SemEval-2024 第 8 项任务：构建一个平衡类别的软投票系统，用于识别由多种生成器产生的机器文本。](2024年04月01日/AISPACE_at_SemEval-2024_task_8_A_Class-balanced_Soft-voting_System_for_Detecting_Multi-generator_Machine-generated_Text.md)

- [Evalverse: Unified and Accessible Library for Large Language Model Evaluation](2024年04月01日/Evalverse_Unified_and_Accessible_Library_for_Large_Language_Model_Evaluation.md)

    - [翻译: Evalverse：为大型语言模型评估打造的一体化、易用资源库](2024年04月01日/Evalverse_Unified_and_Accessible_Library_for_Large_Language_Model_Evaluation.md)

- [Evaluating the Factuality of Large Language Models using Large-Scale Knowledge Graphs](2024年04月01日/Evaluating_the_Factuality_of_Large_Language_Models_using_Large-Scale_Knowledge_Graphs.md)

    - [翻译: 通过大规模知识图谱来评估大型语言模型的真实性。](2024年04月01日/Evaluating_the_Factuality_of_Large_Language_Models_using_Large-Scale_Knowledge_Graphs.md)

- [How Can Large Language Models Enable Better Socially Assistive Human-Robot Interaction: A Brief Survey](2024年04月01日/How_Can_Large_Language_Models_Enable_Better_Socially_Assistive_Human-Robot_Interaction_A_Brief_Survey.md)

    - [翻译: 大型语言模型助力人机社交互动：一项简明调查](2024年04月01日/How_Can_Large_Language_Models_Enable_Better_Socially_Assistive_Human-Robot_Interaction_A_Brief_Survey.md)

- [ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback](2024年04月01日/ChatGLM-RLHF_Practices_of_Aligning_Large_Language_Models_with_Human_Feedback.md)

    - [翻译: ChatGLM-RLHF：探索大型语言模型与人类反馈融合的实践之道](2024年04月01日/ChatGLM-RLHF_Practices_of_Aligning_Large_Language_Models_with_Human_Feedback.md)

- [PSYDIAL: Personality-based Synthetic Dialogue Generation using Large Language Models](2024年04月01日/PSYDIAL_Personality-based_Synthetic_Dialogue_Generation_using_Large_Language_Models.md)

    - [翻译: PSYDIAL：利用大型语言模型生成个性化合成对话](2024年04月01日/PSYDIAL_Personality-based_Synthetic_Dialogue_Generation_using_Large_Language_Models.md)

- [A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias](2024年04月01日/A_Survey_on_Multilingual_Large_Language_Models_Corpora,_Alignment,_and_Bias.md)

    - [翻译: 本文综述了多语言大型语言模型的研究现状，探讨了构建多语言模型所需的语料库资源、不同语言间的对齐问题，以及模型中潜在的偏见问题。](2024年04月01日/A_Survey_on_Multilingual_Large_Language_Models_Corpora,_Alignment,_and_Bias.md)

- [LLMs are Good Sign Language Translators](2024年04月01日/LLMs_are_Good_Sign_Language_Translators.md)

    - [翻译: 大型语言模型擅长于手语翻译。](2024年04月01日/LLMs_are_Good_Sign_Language_Translators.md)

- [Token-Efficient Leverage Learning in Large Language Models](2024年04月01日/Token-Efficient_Leverage_Learning_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的高效利用标记学习，旨在优化学习效率。](2024年04月01日/Token-Efficient_Leverage_Learning_in_Large_Language_Models.md)

- [Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning](2024年04月01日/Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_Reasoning.md)

    - [翻译: 学习通过修正：为零-shot生成性视觉语言推理任务打造高效的调优方案。](2024年04月01日/Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_Reasoning.md)

- [ARAGOG: Advanced RAG Output Grading](2024年04月01日/ARAGOG_Advanced_RAG_Output_Grading.md)

    - [翻译: ARAGOG：精进的RAG成果评定](2024年04月01日/ARAGOG_Advanced_RAG_Output_Grading.md)

- [LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models](2024年04月01日/LLM_as_a_Mastermind_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models.md)

    - [翻译: 大型语言模型：策略性推理的探索之旅](2024年04月01日/LLM_as_a_Mastermind_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models.md)

- [Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward](2024年04月01日/Direct_Preference_Optimization_of_Video_Large_Multimodal_Models_from_Language_Model_Reward.md)

    - [翻译: 通过语言模型奖励，直接对视频大型多模态模型进行偏好优化。](2024年04月01日/Direct_Preference_Optimization_of_Video_Large_Multimodal_Models_from_Language_Model_Reward.md)

- [LITE: Modeling Environmental Ecosystems with Multimodal Large Language Models](2024年04月01日/LITE_Modeling_Environmental_Ecosystems_with_Multimodal_Large_Language_Models.md)

    - [翻译: LITE：借助多模态大型语言模型，构建环境生态系统模型](2024年04月01日/LITE_Modeling_Environmental_Ecosystems_with_Multimodal_Large_Language_Models.md)

- [Prompt Learning for Oriented Power Transmission Tower Detection in High-Resolution SAR Images](2024年04月01日/Prompt_Learning_for_Oriented_Power_Transmission_Tower_Detection_in_High-Resolution_SAR_Images.md)

    - [翻译: 针对高分辨率SAR图像中的定向输电塔检测，本研究采用提示学习方法进行探索。](2024年04月01日/Prompt_Learning_for_Oriented_Power_Transmission_Tower_Detection_in_High-Resolution_SAR_Images.md)

- [Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models](2024年04月01日/Towards_Safety_and_Helpfulness_Balanced_Responses_via_Controllable_Large_Language_Models.md)

    - [翻译: 本研究致力于通过可调控的大型语言模型，实现既安全又有益的智能回应。](2024年04月01日/Towards_Safety_and_Helpfulness_Balanced_Responses_via_Controllable_Large_Language_Models.md)

- [Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided](2024年04月01日/Large_Language_Models_are_Capable_of_Offering_Cognitive_Reappraisal,_if_Guided.md)

    - [翻译: 在适当的引导下，大型语言模型具备进行认知重估的能力。](2024年04月01日/Large_Language_Models_are_Capable_of_Offering_Cognitive_Reappraisal,_if_Guided.md)

- [TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model](2024年04月01日/TWIN-GPT_Digital_Twins_for_Clinical_Trials_via_Large_Language_Model.md)

    - [翻译: TWIN-GPT：借助大型语言模型，为临床试验打造数字孪生技术](2024年04月01日/TWIN-GPT_Digital_Twins_for_Clinical_Trials_via_Large_Language_Model.md)

- [Mapping the Increasing Use of LLMs in Scientific Papers](2024年04月01日/Mapping_the_Increasing_Use_of_LLMs_in_Scientific_Papers.md)

    - [翻译: 科学论文中大型语言模型（LLM）使用频率的增长已被详细记录。](2024年04月01日/Mapping_the_Increasing_Use_of_LLMs_in_Scientific_Papers.md)

- [FABLES: Evaluating faithfulness and content selection in book-length summarization](2024年04月01日/FABLES_Evaluating_faithfulness_and_content_selection_in_book-length_summarization.md)

    - [翻译: FABLES：探究书籍摘要的真实度与内容筛选](2024年04月01日/FABLES_Evaluating_faithfulness_and_content_selection_in_book-length_summarization.md)

- [UniArk: Improving Generalisation and Consistency for Factual Knowledge Extraction through Debiasing](2024年04月01日/UniArk_Improving_Generalisation_and_Consistency_for_Factual_Knowledge_Extraction_through_Debiasing.md)

    - [翻译: UniArk 通过去偏技术，增强了事实知识提取的泛化与一致性，提升了整体性能。](2024年04月01日/UniArk_Improving_Generalisation_and_Consistency_for_Factual_Knowledge_Extraction_through_Debiasing.md)

- [A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](2024年04月01日/A_Statistical_Framework_of_Watermarks_for_Large_Language_Models_Pivot,_Detection_Efficiency_and_Optimal_Rules.md)

    - [翻译: 针对大型语言模型，本文提出了一个水印的统计学框架，探讨了水印的枢纽作用、检测效率以及如何制定最优规则。](2024年04月01日/A_Statistical_Framework_of_Watermarks_for_Large_Language_Models_Pivot,_Detection_Efficiency_and_Optimal_Rules.md)

- [Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models](2024年04月01日/Privacy_Backdoors_Enhancing_Membership_Inference_through_Poisoning_Pre-trained_Models.md)

    - [翻译: 通过在预训练模型中植入污染信息，我们能够增强对模型成员身份的推断能力，从而打开隐私保护的后门。](2024年04月01日/Privacy_Backdoors_Enhancing_Membership_Inference_through_Poisoning_Pre-trained_Models.md)

- [Machine Unlearning for Traditional Models and Large Language Models: A Short Survey](2024年04月01日/Machine_Unlearning_for_Traditional_Models_and_Large_Language_Models_A_Short_Survey.md)

    - [翻译: 本综述简要探讨了传统模型与大型语言模型中的机器去学习技术。](2024年04月01日/Machine_Unlearning_for_Traditional_Models_and_Large_Language_Models_A_Short_Survey.md)

- [The Fine Line: Navigating Large Language Model Pretraining with Down-streaming Capability Analysis](2024年04月01日/The_Fine_Line_Navigating_Large_Language_Model_Pretraining_with_Down-streaming_Capability_Analysis.md)

    - [翻译: 《探寻平衡：借助下游能力分析来引导大型语言模型的预训练》](2024年04月01日/The_Fine_Line_Navigating_Large_Language_Model_Pretraining_with_Down-streaming_Capability_Analysis.md)

- [Getting it Right: Improving Spatial Consistency in Text-to-Image Models](2024年04月01日/Getting_it_Right_Improving_Spatial_Consistency_in_Text-to-Image_Models.md)

    - [翻译: 精准把握：提升文本转图像模型的空间连贯性](2024年04月01日/Getting_it_Right_Improving_Spatial_Consistency_in_Text-to-Image_Models.md)

- [Green AI: Exploring Carbon Footprints, Mitigation Strategies, and Trade Offs in Large Language Model Training](2024年04月01日/Green_AI_Exploring_Carbon_Footprints,_Mitigation_Strategies,_and_Trade_Offs_in_Large_Language_Model_Training.md)

    - [翻译: 绿色AI：研究大型语言模型训练过程中的碳排放、减排措施及其平衡之道。](2024年04月01日/Green_AI_Exploring_Carbon_Footprints,_Mitigation_Strategies,_and_Trade_Offs_in_Large_Language_Model_Training.md)

- [SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining](2024年04月01日/SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining.md)

    - [翻译: SyncMask：为时尚导向视觉-语言预训练设计的同步注意力屏蔽技术](2024年04月01日/SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining.md)

- [Do LLMs Find Human Answers To Fact-Driven Questions Perplexing? A Case Study on Reddit](2024年04月01日/Do_LLMs_Find_Human_Answers_To_Fact-Driven_Questions_Perplexing_A_Case_Study_on_Reddit.md)

    - [翻译: 在Reddit上的案例研究：大型语言模型真的搞不懂人类对事实问题的答案吗？](2024年04月01日/Do_LLMs_Find_Human_Answers_To_Fact-Driven_Questions_Perplexing_A_Case_Study_on_Reddit.md)

- [Enhancing Reasoning Capacity of SLM using Cognitive Enhancement](2024年04月01日/Enhancing_Reasoning_Capacity_of_SLM_using_Cognitive_Enhancement.md)

    - [翻译: 通过认知增强技术，我们能够提升小型语言模型（SLM）的推理能力。](2024年04月01日/Enhancing_Reasoning_Capacity_of_SLM_using_Cognitive_Enhancement.md)

- [Structured Information Matters: Incorporating Abstract Meaning Representation into LLMs for Improved Open-Domain Dialogue Evaluation](2024年04月01日/Structured_Information_Matters_Incorporating_Abstract_Meaning_Representation_into_LLMs_for_Improved_Open-Domain_Dialogue_Evaluation.md)

    - [翻译: 结构化信息至关重要：在大型语言模型中整合抽象意义表示，以优化开放领域对话的评估效果。](2024年04月01日/Structured_Information_Matters_Incorporating_Abstract_Meaning_Representation_into_LLMs_for_Improved_Open-Domain_Dialogue_Evaluation.md)

- [What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety](2024年04月01日/What's_in_Your_Safe_Data_Identifying_Benign_Data_that_Breaks_Safety.md)

    - [翻译: 揭秘“安全”数据：发现看似无害却危害安全的数据。](2024年04月01日/What's_in_Your_Safe_Data_Identifying_Benign_Data_that_Breaks_Safety.md)

- [Enabling Memory Safety of C Programs using LLMs](2024年04月01日/Enabling_Memory_Safety_of_C_Programs_using_LLMs.md)

    - [翻译: 通过大型语言模型 (LLM) 保障 C 程序的内存安全。](2024年04月01日/Enabling_Memory_Safety_of_C_Programs_using_LLMs.md)

- [Efficient Prompting Methods for Large Language Models: A Survey](2024年04月01日/Efficient_Prompting_Methods_for_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型的高效提示技巧：全面调查研究](2024年04月01日/Efficient_Prompting_Methods_for_Large_Language_Models_A_Survey.md)

- [Chat Modeling: Natural Language-based Procedural Modeling of Biological Structures without Training](2024年04月01日/Chat_Modeling_Natural_Language-based_Procedural_Modeling_of_Biological_Structures_without_Training.md)

    - [翻译: 聊天建模：利用自然语言进行生物结构的程序化设计，无需经过训练过程。](2024年04月01日/Chat_Modeling_Natural_Language-based_Procedural_Modeling_of_Biological_Structures_without_Training.md)

- [Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment](2024年04月01日/Regularized_Best-of-N_Sampling_to_Mitigate_Reward_Hacking_for_Language_Model_Alignment.md)

    - [翻译: 为确保语言模型对齐，我们采用正则化的最优 N 选一抽样策略，以降低奖励操纵行为的风险。](2024年04月01日/Regularized_Best-of-N_Sampling_to_Mitigate_Reward_Hacking_for_Language_Model_Alignment.md)

- [Can LLMs get help from other LLMs without revealing private information?](2024年04月01日/Can_LLMs_get_help_from_other_LLMs_without_revealing_private_information.md)

    - [翻译: 大型语言模型能否在保护隐私的前提下互相协助？](2024年04月01日/Can_LLMs_get_help_from_other_LLMs_without_revealing_private_information.md)

- [LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models](2024年04月01日/LLM-ABR_Designing_Adaptive_Bitrate_Algorithms_via_Large_Language_Models.md)

    - [翻译: LLM-ABR：借助大型语言模型打造智能自适应码率算法](2024年04月01日/LLM-ABR_Designing_Adaptive_Bitrate_Algorithms_via_Large_Language_Models.md)

- [Transforming LLMs into Cross-modal and Cross-lingual RetrievalSystems](2024年04月01日/Transforming_LLMs_into_Cross-modal_and_Cross-lingual_RetrievalSystems.md)

    - [翻译: 将大型语言模型打造成跨界的检索系统，实现跨模态与跨语言的无缝对接。](2024年04月01日/Transforming_LLMs_into_Cross-modal_and_Cross-lingual_RetrievalSystems.md)

- [Helmsman of the Masses? Evaluate the Opinion Leadership of Large Language Models in the Werewolf Game](2024年04月01日/Helmsman_of_the_Masses_Evaluate_the_Opinion_Leadership_of_Large_Language_Models_in_the_Werewolf_Game.md)

    - [翻译: 引领民意？探究大型语言模型在狼人游戏中的舆论引导作用。](2024年04月01日/Helmsman_of_the_Masses_Evaluate_the_Opinion_Leadership_of_Large_Language_Models_in_the_Werewolf_Game.md)

- [Classifying Cancer Stage with Open-Source Clinical Large Language Models](2024年04月01日/Classifying_Cancer_Stage_with_Open-Source_Clinical_Large_Language_Models.md)

    - [翻译: 本研究探讨了运用开源临床大型语言模型对癌症阶段进行精确分类的方法。](2024年04月01日/Classifying_Cancer_Stage_with_Open-Source_Clinical_Large_Language_Models.md)

- [Hallucination Diversity-Aware Active Learning for Text Summarization](2024年04月01日/Hallucination_Diversity-Aware_Active_Learning_for_Text_Summarization.md)

    - [翻译: 在文本摘要中，我们采用一种幻觉多样性感知的主动学习方法。](2024年04月01日/Hallucination_Diversity-Aware_Active_Learning_for_Text_Summarization.md)

- [Evaluating Large Language Models Using Contrast Sets: An Experimental Approach](2024年04月01日/Evaluating_Large_Language_Models_Using_Contrast_Sets_An_Experimental_Approach.md)

    - [翻译: 通过对比集对大型语言模型进行评估：探索性实验途径](2024年04月01日/Evaluating_Large_Language_Models_Using_Contrast_Sets_An_Experimental_Approach.md)

- [Automated User Story Generation with Test Case Specification Using Large Language Model](2024年04月01日/Automated_User_Story_Generation_with_Test_Case_Specification_Using_Large_Language_Model.md)

    - [翻译: 借助大型语言模型，实现自动化的用户故事创建，并配备测试用例规范。](2024年04月01日/Automated_User_Story_Generation_with_Test_Case_Specification_Using_Large_Language_Model.md)

- [Octopus: On-device language model for function calling of software APIs](2024年04月01日/Octopus_On-device_language_model_for_function_calling_of_software_APIs.md)

    - [翻译: 章鱼：一款适用于软件API功能调用的设备端语言模型](2024年04月01日/Octopus_On-device_language_model_for_function_calling_of_software_APIs.md)

- [Syntactic Robustness for LLM-based Code Generation](2024年04月01日/Syntactic_Robustness_for_LLM-based_Code_Generation.md)

    - [翻译: 在大型语言模型（LLM）支持下，代码生成的句法鲁棒性研究](2024年04月01日/Syntactic_Robustness_for_LLM-based_Code_Generation.md)

- [Set-Aligning Framework for Auto-Regressive Event Temporal Graph Generation](2024年04月01日/Set-Aligning_Framework_for_Auto-Regressive_Event_Temporal_Graph_Generation.md)

    - [翻译: 自回归事件时序图的生成采用集合对齐框架](2024年04月01日/Set-Aligning_Framework_for_Auto-Regressive_Event_Temporal_Graph_Generation.md)

- [A Study on Scaling Up Multilingual News Framing Analysis](2024年04月01日/A_Study_on_Scaling_Up_Multilingual_News_Framing_Analysis.md)

    - [翻译: 本研究探讨了如何扩展多语言新闻框架分析的规模，旨在提高跨语言和文化背景下新闻报道的理解和分析能力。](2024年04月01日/A_Study_on_Scaling_Up_Multilingual_News_Framing_Analysis.md)

- [TraveLER: A Multi-LMM Agent Framework for Video Question-Answering](2024年04月01日/TraveLER_A_Multi-LMM_Agent_Framework_for_Video_Question-Answering.md)

    - [翻译: TraveLER：面向视频问答任务的多语言模型代理框架](2024年04月01日/TraveLER_A_Multi-LMM_Agent_Framework_for_Video_Question-Answering.md)

- [Are large language models superhuman chemists?](2024年04月01日/Are_large_language_models_superhuman_chemists.md)

    - [翻译: 大型语言模型能否媲美超级化学家？](2024年04月01日/Are_large_language_models_superhuman_chemists.md)

- [Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs](2024年04月01日/Will_the_Real_Linda_Please_Stand_up...to_Large_Language_Models_Examining_the_Representativeness_Heuristic_in_LLMs.md)

    - [翻译: 琳达能否勇敢地面对大型语言模型？探究LLMs中的代表性启发式原理。](2024年04月01日/Will_the_Real_Linda_Please_Stand_up...to_Large_Language_Models_Examining_the_Representativeness_Heuristic_in_LLMs.md)

- [Unveiling Divergent Inductive Biases of LLMs on Temporal Data](2024年04月01日/Unveiling_Divergent_Inductive_Biases_of_LLMs_on_Temporal_Data.md)

    - [翻译: 探究大型语言模型处理时间数据时的多样化归纳偏好](2024年04月01日/Unveiling_Divergent_Inductive_Biases_of_LLMs_on_Temporal_Data.md)

- [Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing Positional Bias in LLMs](2024年04月01日/Position-Aware_Parameter_Efficient_Fine-Tuning_Approach_for_Reducing_Positional_Bias_in_LLMs.md)

    - [翻译: 为了降低大型语言模型中的位置偏见，我们采用了一种位置感知的高效微调策略。](2024年04月01日/Position-Aware_Parameter_Efficient_Fine-Tuning_Approach_for_Reducing_Positional_Bias_in_LLMs.md)

- [A Preliminary Roadmap for LLMs as Assistants in Exploring, Analyzing, and Visualizing Knowledge Graphs](2024年04月01日/A_Preliminary_Roadmap_for_LLMs_as_Assistants_in_Exploring,_Analyzing,_and_Visualizing_Knowledge_Graphs.md)

    - [翻译: 探索、分析及可视化知识图谱的大型语言模型助手的初步指南。](2024年04月01日/A_Preliminary_Roadmap_for_LLMs_as_Assistants_in_Exploring,_Analyzing,_and_Visualizing_Knowledge_Graphs.md)

- [OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation](2024年04月01日/OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation.md)

    - [翻译: OVFoodSeg: 利用图像信息增强文本表达，提升食品图像的开放词汇量分割技术](2024年04月01日/OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation.md)

- [Developing Safe and Responsible Large Language Models -- A Comprehensive Framework](2024年04月01日/Developing_Safe_and_Responsible_Large_Language_Models_--_A_Comprehensive_Framework.md)

    - [翻译: 构建安全可靠的大型语言模型：全方位框架探究](2024年04月01日/Developing_Safe_and_Responsible_Large_Language_Models_--_A_Comprehensive_Framework.md)

- [Prompt-prompted Mixture of Experts for Efficient LLM Generation](2024年04月01日/Prompt-prompted_Mixture_of_Experts_for_Efficient_LLM_Generation.md)

    - [翻译: 通过专家混合的提示-提示策略，我们能够有效地生成大型语言模型。](2024年04月01日/Prompt-prompted_Mixture_of_Experts_for_Efficient_LLM_Generation.md)

- [LLM Attributor: Interactive Visual Attribution for LLM Generation](2024年04月01日/LLM_Attributor_Interactive_Visual_Attribution_for_LLM_Generation.md)

    - [翻译: LLM 属性归因器：为大型语言模型生成提供交互式视觉归因功能。](2024年04月01日/LLM_Attributor_Interactive_Visual_Attribution_for_LLM_Generation.md)

- [Leveraging YOLO-World and GPT-4V LMMs for Zero-Shot Person Detection and Action Recognition in Drone Imagery](2024年04月01日/Leveraging_YOLO-World_and_GPT-4V_LMMs_for_Zero-Shot_Person_Detection_and_Action_Recognition_in_Drone_Imagery.md)

    - [翻译: 通过运用 YOLO-World 与 GPT-4V 语言模型，实现无人机图像中的零-shot 人员探测与行为识别。](2024年04月01日/Leveraging_YOLO-World_and_GPT-4V_LMMs_for_Zero-Shot_Person_Detection_and_Action_Recognition_in_Drone_Imagery.md)

- [Automated Assessment of Encouragement and Warmth in Classrooms Leveraging Multimodal Emotional Features and ChatGPT](2024年04月01日/Automated_Assessment_of_Encouragement_and_Warmth_in_Classrooms_Leveraging_Multimodal_Emotional_Features_and_ChatGPT.md)

    - [翻译: ](2024年04月01日/Automated_Assessment_of_Encouragement_and_Warmth_in_Classrooms_Leveraging_Multimodal_Emotional_Features_and_ChatGPT.md)