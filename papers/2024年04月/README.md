# 2024年04月

2024年04月03日

- [DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement](2024年04月03日/DIBS_Enhancing_Dense_Video_Captioning_with_Unlabeled_Videos_via_Pseudo_Boundary_Enrichment_and_Online_Refinement.md)

    - [翻译: DIBS 技术：借助伪边界扩展和实时优化，利用未标注视频提升密集视频字幕质量。](2024年04月03日/DIBS_Enhancing_Dense_Video_Captioning_with_Unlabeled_Videos_via_Pseudo_Boundary_Enrichment_and_Online_Refinement.md)

- [Harnessing the Power of Large Vision Language Models for Synthetic Image Detection](2024年04月03日/Harnessing_the_Power_of_Large_Vision_Language_Models_for_Synthetic_Image_Detection.md)

    - [翻译: 借助大型视觉语言模型的力量，我们可以有效检测合成图像。](2024年04月03日/Harnessing_the_Power_of_Large_Vision_Language_Models_for_Synthetic_Image_Detection.md)

- [Automatic Prompt Selection for Large Language Models](2024年04月03日/Automatic_Prompt_Selection_for_Large_Language_Models.md)

    - [翻译: 在大型语言模型中，自动化的提示筛选机制](2024年04月03日/Automatic_Prompt_Selection_for_Large_Language_Models.md)

- [Scalable Model Editing via Customized Expert Networks](2024年04月03日/Scalable_Model_Editing_via_Customized_Expert_Networks.md)

    - [翻译: 本文介绍了一种通过定制专家网络来实现模型编辑的可扩展方法。](2024年04月03日/Scalable_Model_Editing_via_Customized_Expert_Networks.md)

- [Attention is Naturally Sparse with Gaussian Distributed Input](2024年04月03日/Attention_is_Naturally_Sparse_with_Gaussian_Distributed_Input.md)

    - [翻译: 当输入呈现高斯分布时，注意力机制自然而然地表现出稀疏性。](2024年04月03日/Attention_is_Naturally_Sparse_with_Gaussian_Distributed_Input.md)

- [Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models](2024年04月03日/Rethinking_Kullback-Leibler_Divergence_in_Knowledge_Distillation_for_Large_Language_Models.md)

    - [翻译: 在大型语言模型的知识蒸馏过程中，对Kullback-Leibler散度的再认识与应用。](2024年04月03日/Rethinking_Kullback-Leibler_Divergence_in_Knowledge_Distillation_for_Large_Language_Models.md)

- [Calibrating the Confidence of Large Language Models by Eliciting Fidelity](2024年04月03日/Calibrating_the_Confidence_of_Large_Language_Models_by_Eliciting_Fidelity.md)

    - [翻译: 本文探讨了如何通过激发忠诚度来调整大型语言模型的自信度，以提高其预测的准确性。](2024年04月03日/Calibrating_the_Confidence_of_Large_Language_Models_by_Eliciting_Fidelity.md)

- [Towards detecting unanticipated bias in Large Language Models](2024年04月03日/Towards_detecting_unanticipated_bias_in_Large_Language_Models.md)

    - [翻译: 探索发现大型语言模型中的潜在偏见。](2024年04月03日/Towards_detecting_unanticipated_bias_in_Large_Language_Models.md)

- [On the Importance of Uncertainty in Decision-Making with Large Language Models](2024年04月03日/On_the_Importance_of_Uncertainty_in_Decision-Making_with_Large_Language_Models.md)

    - [翻译: 在运用大型语言模型进行决策时，不确定性的角色不容忽视。](2024年04月03日/On_the_Importance_of_Uncertainty_in_Decision-Making_with_Large_Language_Models.md)

- [Vocabulary Attack to Hijack Large Language Model Applications](2024年04月03日/Vocabulary_Attack_to_Hijack_Large_Language_Model_Applications.md)

    - [翻译: 通过词汇攻击，大型语言模型的应用可能被劫持。](2024年04月03日/Vocabulary_Attack_to_Hijack_Large_Language_Model_Applications.md)

- [Improving Topic Relevance Model by Mix-structured Summarization and LLM-based Data Augmentation](2024年04月03日/Improving_Topic_Relevance_Model_by_Mix-structured_Summarization_and_LLM-based_Data_Augmentation.md)

    - [翻译: 通过融合多种结构的摘要技巧以及利用大型语言模型进行数据扩充，我们得以提升主题相关性模型的性能。](2024年04月03日/Improving_Topic_Relevance_Model_by_Mix-structured_Summarization_and_LLM-based_Data_Augmentation.md)

- [Large Language Models for Expansion of Spoken Language Understanding Systems to New Languages](2024年04月03日/Large_Language_Models_for_Expansion_of_Spoken_Language_Understanding_Systems_to_New_Languages.md)

    - [翻译: 借助大型语言模型，拓展口语理解系统至全新语言领域](2024年04月03日/Large_Language_Models_for_Expansion_of_Spoken_Language_Understanding_Systems_to_New_Languages.md)

- [Language Models as Compilers: Simulating Pseudocode Execution Improves Algorithmic Reasoning in Language Models](2024年04月03日/Language_Models_as_Compilers_Simulating_Pseudocode_Execution_Improves_Algorithmic_Reasoning_in_Language_Models.md)

    - [翻译: 将语言模型视作编译器，通过模拟伪代码的执行，我们能够显著提升模型在算法推理上的能力。](2024年04月03日/Language_Models_as_Compilers_Simulating_Pseudocode_Execution_Improves_Algorithmic_Reasoning_in_Language_Models.md)

- [AI-Tutoring in Software Engineering Education](2024年04月03日/AI-Tutoring_in_Software_Engineering_Education.md)

    - [翻译: 人工智能辅导在软件工程教育领域日益发挥着关键作用，它通过个性化指导和及时反馈显著提升了学习成效。要充分发挥其潜力，我们必须深入探索AI辅导的机制，并有效融合到教学实践中。](2024年04月03日/AI-Tutoring_in_Software_Engineering_Education.md)

- [CSEPrompts: A Benchmark of Introductory Computer Science Prompts](2024年04月03日/CSEPrompts_A_Benchmark_of_Introductory_Computer_Science_Prompts.md)

    - [翻译: CSEPrompts：计算机科学基础教学提示的评估标准](2024年04月03日/CSEPrompts_A_Benchmark_of_Introductory_Computer_Science_Prompts.md)

- [Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game](2024年04月03日/Learn_to_Disguise_Avoid_Refusal_Responses_in_LLM's_Defense_via_a_Multi-agent_Attacker-Disguiser_Game.md)

    - [翻译: 掌握伪装技巧：借助多智能体间的攻击者与伪装者博弈，规避大型语言模型（LLM）防御时的拒绝式回应。](2024年04月03日/Learn_to_Disguise_Avoid_Refusal_Responses_in_LLM's_Defense_via_a_Multi-agent_Attacker-Disguiser_Game.md)

- [Large Language Model for Vulnerability Detection and Repair: Literature Review and Roadmap](2024年04月03日/Large_Language_Model_for_Vulnerability_Detection_and_Repair_Literature_Review_and_Roadmap.md)

    - [翻译: 大型语言模型在漏洞检测与修复领域的文献综述及发展蓝图](2024年04月03日/Large_Language_Model_for_Vulnerability_Detection_and_Repair_Literature_Review_and_Roadmap.md)

- [Towards Large Language Model driven Reference-less Translation Evaluation for English and Indian Languages](2024年04月03日/Towards_Large_Language_Model_driven_Reference-less_Translation_Evaluation_for_English_and_Indian_Languages.md)

    - [翻译: 面向英语和印度语言的大型语言模型驱动的无参考翻译评估研究。](2024年04月03日/Towards_Large_Language_Model_driven_Reference-less_Translation_Evaluation_for_English_and_Indian_Languages.md)

- [VIAssist: Adapting Multi-modal Large Language Models for Users with Visual Impairments](2024年04月03日/VIAssist_Adapting_Multi-modal_Large_Language_Models_for_Users_with_Visual_Impairments.md)

    - [翻译: VIAssist：为视障用户定制的多模态大型语言模型](2024年04月03日/VIAssist_Adapting_Multi-modal_Large_Language_Models_for_Users_with_Visual_Impairments.md)

- [Measuring Social Norms of Large Language Models](2024年04月03日/Measuring_Social_Norms_of_Large_Language_Models.md)

    - [翻译: ](2024年04月03日/Measuring_Social_Norms_of_Large_Language_Models.md)

- [Prompting for Numerical Sequences: A Case Study on Market Comment Generation](2024年04月03日/Prompting_for_Numerical_Sequences_A_Case_Study_on_Market_Comment_Generation.md)

    - [翻译: ](2024年04月03日/Prompting_for_Numerical_Sequences_A_Case_Study_on_Market_Comment_Generation.md)

- [PhonologyBench: Evaluating Phonological Skills of Large Language Models](2024年04月03日/PhonologyBench_Evaluating_Phonological_Skills_of_Large_Language_Models.md)

    - [翻译: ](2024年04月03日/PhonologyBench_Evaluating_Phonological_Skills_of_Large_Language_Models.md)

- [Task Agnostic Architecture for Algorithm Induction via Implicit Composition](2024年04月03日/Task_Agnostic_Architecture_for_Algorithm_Induction_via_Implicit_Composition.md)

    - [翻译: ](2024年04月03日/Task_Agnostic_Architecture_for_Algorithm_Induction_via_Implicit_Composition.md)

- [Retrieving Examples from Memory for Retrieval Augmented Neural Machine Translation: A Systematic Comparison](2024年04月03日/Retrieving_Examples_from_Memory_for_Retrieval_Augmented_Neural_Machine_Translation_A_Systematic_Comparison.md)

    - [翻译: ](2024年04月03日/Retrieving_Examples_from_Memory_for_Retrieval_Augmented_Neural_Machine_Translation_A_Systematic_Comparison.md)

- [uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?](2024年04月03日/uTeBC-NLP_at_SemEval-2024_Task_9_Can_LLMs_be_Lateral_Thinkers.md)

    - [翻译: ](2024年04月03日/uTeBC-NLP_at_SemEval-2024_Task_9_Can_LLMs_be_Lateral_Thinkers.md)

- [I-Design: Personalized LLM Interior Designer](2024年04月03日/I-Design_Personalized_LLM_Interior_Designer.md)

    - [翻译: ](2024年04月03日/I-Design_Personalized_LLM_Interior_Designer.md)

- [Empowering Biomedical Discovery with AI Agents](2024年04月03日/Empowering_Biomedical_Discovery_with_AI_Agents.md)

    - [翻译: ](2024年04月03日/Empowering_Biomedical_Discovery_with_AI_Agents.md)

- [ALOHa: A New Measure for Hallucination in Captioning Models](2024年04月03日/ALOHa_A_New_Measure_for_Hallucination_in_Captioning_Models.md)

    - [翻译: ](2024年04月03日/ALOHa_A_New_Measure_for_Hallucination_in_Captioning_Models.md)

- [MatAtlas: Text-driven Consistent Geometry Texturing and Material Assignment](2024年04月03日/MatAtlas_Text-driven_Consistent_Geometry_Texturing_and_Material_Assignment.md)

    - [翻译: ](2024年04月03日/MatAtlas_Text-driven_Consistent_Geometry_Texturing_and_Material_Assignment.md)

- [ChatGLM-Math: Improving Math Problem-Solving in Large Language Models with a Self-Critique Pipeline](2024年04月03日/ChatGLM-Math_Improving_Math_Problem-Solving_in_Large_Language_Models_with_a_Self-Critique_Pipeline.md)

    - [翻译: ](2024年04月03日/ChatGLM-Math_Improving_Math_Problem-Solving_in_Large_Language_Models_with_a_Self-Critique_Pipeline.md)

- [Linear Attention Sequence Parallelism](2024年04月03日/Linear_Attention_Sequence_Parallelism.md)

    - [翻译: ](2024年04月03日/Linear_Attention_Sequence_Parallelism.md)

- [Integrating Explanations in Learning LTL Specifications from Demonstrations](2024年04月03日/Integrating_Explanations_in_Learning_LTL_Specifications_from_Demonstrations.md)

    - [翻译: ](2024年04月03日/Integrating_Explanations_in_Learning_LTL_Specifications_from_Demonstrations.md)

- [Toward Inference-optimal Mixture-of-Expert Large Language Models](2024年04月03日/Toward_Inference-optimal_Mixture-of-Expert_Large_Language_Models.md)

    - [翻译: ](2024年04月03日/Toward_Inference-optimal_Mixture-of-Expert_Large_Language_Models.md)

- [Cherry on Top: Parameter Heterogeneity and Quantization in Large Language Models](2024年04月03日/Cherry_on_Top_Parameter_Heterogeneity_and_Quantization_in_Large_Language_Models.md)

    - [翻译: ](2024年04月03日/Cherry_on_Top_Parameter_Heterogeneity_and_Quantization_in_Large_Language_Models.md)

- [BAdam: A Memory Efficient Full Parameter Training Method for Large Language Models](2024年04月03日/BAdam_A_Memory_Efficient_Full_Parameter_Training_Method_for_Large_Language_Models.md)

    - [翻译: ](2024年04月03日/BAdam_A_Memory_Efficient_Full_Parameter_Training_Method_for_Large_Language_Models.md)

- [Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models](2024年04月03日/Conifer_Improving_Complex_Constrained_Instruction-Following_Ability_of_Large_Language_Models.md)

    - [翻译: ](2024年04月03日/Conifer_Improving_Complex_Constrained_Instruction-Following_Ability_of_Large_Language_Models.md)

- [A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches](2024年04月03日/A_Survey_of_Optimization-based_Task_and_Motion_Planning_From_Classical_To_Learning_Approaches.md)

    - [翻译: ](2024年04月03日/A_Survey_of_Optimization-based_Task_and_Motion_Planning_From_Classical_To_Learning_Approaches.md)

- [The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers](2024年04月03日/The_RealHumanEval_Evaluating_Large_Language_Models'_Abilities_to_Support_Programmers.md)

    - [翻译: ](2024年04月03日/The_RealHumanEval_Evaluating_Large_Language_Models'_Abilities_to_Support_Programmers.md)

- [Efficient Multi-Vector Dense Retrieval Using Bit Vectors](2024年04月03日/Efficient_Multi-Vector_Dense_Retrieval_Using_Bit_Vectors.md)

    - [翻译: ](2024年04月03日/Efficient_Multi-Vector_Dense_Retrieval_Using_Bit_Vectors.md)

- [AI and personalized learning: bridging the gap with modern educational goals](2024年04月03日/AI_and_personalized_learning_bridging_the_gap_with_modern_educational_goals.md)

    - [翻译: ](2024年04月03日/AI_and_personalized_learning_bridging_the_gap_with_modern_educational_goals.md)

- [CLaM-TTS: Improving Neural Codec Language Model for Zero-Shot Text-to-Speech](2024年04月03日/CLaM-TTS_Improving_Neural_Codec_Language_Model_for_Zero-Shot_Text-to-Speech.md)

    - [翻译: ](2024年04月03日/CLaM-TTS_Improving_Neural_Codec_Language_Model_for_Zero-Shot_Text-to-Speech.md)

- [FPT: Feature Prompt Tuning for Few-shot Readability Assessment](2024年04月03日/FPT_Feature_Prompt_Tuning_for_Few-shot_Readability_Assessment.md)

    - [翻译: ](2024年04月03日/FPT_Feature_Prompt_Tuning_for_Few-shot_Readability_Assessment.md)

2024年04月02日

- [Great, Now Write an Article About That: The Crescendo Multi-Turn LLM Jailbreak Attack](2024年04月02日/Great,_Now_Write_an_Article_About_That_The_Crescendo_Multi-Turn_LLM_Jailbreak_Attack.md)

    - [翻译: 好极了，那就来谈谈这个主题：《高潮》—— 一种针对多轮大型语言模型的突破性攻击手法](2024年04月02日/Great,_Now_Write_an_Article_About_That_The_Crescendo_Multi-Turn_LLM_Jailbreak_Attack.md)

- [Sentiment Analysis of Citations in Scientific Articles Using ChatGPT: Identifying Potential Biases and Conflicts of Interest](2024年04月02日/Sentiment_Analysis_of_Citations_in_Scientific_Articles_Using_ChatGPT_Identifying_Potential_Biases_and_Conflicts_of_Interest.md)

    - [翻译: 通过 ChatGPT 对科学论文引用的情感分析，揭示可能存在的偏见与利益冲突。](2024年04月02日/Sentiment_Analysis_of_Citations_in_Scientific_Articles_Using_ChatGPT_Identifying_Potential_Biases_and_Conflicts_of_Interest.md)

- [PATCH -- Psychometrics-AssisTed benCHmarking of Large Language Models: A Case Study of Mathematics Proficiency](2024年04月02日/PATCH_--_Psychometrics-AssisTed_benCHmarking_of_Large_Language_Models_A_Case_Study_of_Mathematics_Proficiency.md)

    - [翻译: PATCH——通过心理测量技术辅助的大规模语言模型性能基准测试：以数学能力为例的深入案例分析](2024年04月02日/PATCH_--_Psychometrics-AssisTed_benCHmarking_of_Large_Language_Models_A_Case_Study_of_Mathematics_Proficiency.md)

- [Auditing Large Language Models for Enhanced Text-Based Stereotype Detection and Probing-Based Bias Evaluation](2024年04月02日/Auditing_Large_Language_Models_for_Enhanced_Text-Based_Stereotype_Detection_and_Probing-Based_Bias_Evaluation.md)

    - [翻译: 通过对大型语言模型进行审查，我们可以提高基于文本的刻板印象检测能力，并进行更为深入的偏见评估。](2024年04月02日/Auditing_Large_Language_Models_for_Enhanced_Text-Based_Stereotype_Detection_and_Probing-Based_Bias_Evaluation.md)

- [Class-Incremental Few-Shot Event Detection](2024年04月02日/Class-Incremental_Few-Shot_Event_Detection.md)

    - [翻译: 在少样本学习环境下，我们提出了一种新颖的事件检测方法，即类增量策略。该方法通过逐步引入新的类别信息，有效地提升了模型在面对类别不断变化的事件中的检测性能。](2024年04月02日/Class-Incremental_Few-Shot_Event_Detection.md)

- [Peer-aided Repairer: Empowering Large Language Models to Repair Advanced Student Assignments](2024年04月02日/Peer-aided_Repairer_Empowering_Large_Language_Models_to_Repair_Advanced_Student_Assignments.md)

    - [翻译: 同伴辅助修复器：赋予大型语言模型修复高级学生作业的能力，旨在提升模型对复杂任务的处理能力。](2024年04月02日/Peer-aided_Repairer_Empowering_Large_Language_Models_to_Repair_Advanced_Student_Assignments.md)

- [M2SA: Multimodal and Multilingual Model for Sentiment Analysis of Tweets](2024年04月02日/M2SA_Multimodal_and_Multilingual_Model_for_Sentiment_Analysis_of_Tweets.md)

    - [翻译: M2SA：一款针对推文情感分析的多模态、多语言模型](2024年04月02日/M2SA_Multimodal_and_Multilingual_Model_for_Sentiment_Analysis_of_Tweets.md)

- [Unleash the Potential of CLIP for Video Highlight Detection](2024年04月02日/Unleash_the_Potential_of_CLIP_for_Video_Highlight_Detection.md)

    - [翻译: 挖掘 CLIP 技术在视频精彩瞬间识别上的潜在力量](2024年04月02日/Unleash_the_Potential_of_CLIP_for_Video_Highlight_Detection.md)

- [Octopus v2: On-device language model for super agent](2024年04月02日/Octopus_v2_On-device_language_model_for_super_agent.md)

    - [翻译: 章鱼 v2：超级智能代理的移动设备语言模型](2024年04月02日/Octopus_v2_On-device_language_model_for_super_agent.md)

- [Transfer Learning from Whisper for Microscopic Intelligibility Prediction](2024年04月02日/Transfer_Learning_from_Whisper_for_Microscopic_Intelligibility_Prediction.md)

    - [翻译: 通过 Whisper 的迁移学习能力来预测细节层面的可理解性。](2024年04月02日/Transfer_Learning_from_Whisper_for_Microscopic_Intelligibility_Prediction.md)

- [Asymptotics of Language Model Alignment](2024年04月02日/Asymptotics_of_Language_Model_Alignment.md)

    - [翻译: 探讨语言模型对齐的极限行为](2024年04月02日/Asymptotics_of_Language_Model_Alignment.md)

- [Self-Improvement Programming for Temporal Knowledge Graph Question Answering](2024年04月02日/Self-Improvement_Programming_for_Temporal_Knowledge_Graph_Question_Answering.md)

    - [翻译: 通过自改进编程技术，提升时序知识图谱的问答能力。](2024年04月02日/Self-Improvement_Programming_for_Temporal_Knowledge_Graph_Question_Answering.md)

- [On the Role of Summary Content Units in Text Summarization Evaluation](2024年04月02日/On_the_Role_of_Summary_Content_Units_in_Text_Summarization_Evaluation.md)

    - [翻译: 文本摘要评估中，摘要内容单元的重要性。](2024年04月02日/On_the_Role_of_Summary_Content_Units_in_Text_Summarization_Evaluation.md)

- [MotionChain: Conversational Motion Controllers via Multimodal Prompts](2024年04月02日/MotionChain_Conversational_Motion_Controllers_via_Multimodal_Prompts.md)

    - [翻译: MotionChain：借助多模态提示实现的交互式动作控制方案](2024年04月02日/MotionChain_Conversational_Motion_Controllers_via_Multimodal_Prompts.md)

- [Towards Generalizable and Faithful Logic Reasoning over Natural Language via Resolution Refutation](2024年04月02日/Towards_Generalizable_and_Faithful_Logic_Reasoning_over_Natural_Language_via_Resolution_Refutation.md)

    - [翻译: 通过解决反驳，我们朝着实现自然语言逻辑推理的普适性和忠实性迈进。](2024年04月02日/Towards_Generalizable_and_Faithful_Logic_Reasoning_over_Natural_Language_via_Resolution_Refutation.md)

- [METAL: Towards Multilingual Meta-Evaluation](2024年04月02日/METAL_Towards_Multilingual_Meta-Evaluation.md)

    - [翻译: METAL：探索多语言间的元评估方法](2024年04月02日/METAL_Towards_Multilingual_Meta-Evaluation.md)

- [CMAT: A Multi-Agent Collaboration Tuning Framework for Enhancing Small Language Models](2024年04月02日/CMAT_A_Multi-Agent_Collaboration_Tuning_Framework_for_Enhancing_Small_Language_Models.md)

    - [翻译: CMAT：专为提升小型语言模型性能而设计的多智能体协同优化框架](2024年04月02日/CMAT_A_Multi-Agent_Collaboration_Tuning_Framework_for_Enhancing_Small_Language_Models.md)

- [Release of Pre-Trained Models for the Japanese Language](2024年04月02日/Release_of_Pre-Trained_Models_for_the_Japanese_Language.md)

    - [翻译: 日语预训练模型现已发布。](2024年04月02日/Release_of_Pre-Trained_Models_for_the_Japanese_Language.md)

- [InsightLens: Discovering and Exploring Insights from Conversational Contexts in Large-Language-Model-Powered Data Analysis](2024年04月02日/InsightLens_Discovering_and_Exploring_Insights_from_Conversational_Contexts_in_Large-Language-Model-Powered_Data_Analysis.md)

    - [翻译: InsightLens：在大型语言模型支持的数据分析中，挖掘并探究对话语境的深层见解。](2024年04月02日/InsightLens_Discovering_and_Exploring_Insights_from_Conversational_Contexts_in_Large-Language-Model-Powered_Data_Analysis.md)

- [Voice EHR: Introducing Multimodal Audio Data for Health](2024年04月02日/Voice_EHR_Introducing_Multimodal_Audio_Data_for_Health.md)

    - [翻译: 语音电子健康记录（Voice EHR）：为健康领域带来多模态音频数据的新探索。](2024年04月02日/Voice_EHR_Introducing_Multimodal_Audio_Data_for_Health.md)

- [CLAPNQ: Cohesive Long-form Answers from Passages in Natural Questions for RAG systems](2024年04月02日/CLAPNQ_Cohesive_Long-form_Answers_from_Passages_in_Natural_Questions_for_RAG_systems.md)

    - [翻译: CLAPNQ：针对RAG系统，从自然语言问题中提取段落，打造连贯且详尽的长篇幅回答。](2024年04月02日/CLAPNQ_Cohesive_Long-form_Answers_from_Passages_in_Natural_Questions_for_RAG_systems.md)

- [Improving Retrieval Augmented Open-Domain Question-Answering with Vectorized Contexts](2024年04月02日/Improving_Retrieval_Augmented_Open-Domain_Question-Answering_with_Vectorized_Contexts.md)

    - [翻译: 利用向量化上下文技术，我们旨在提升开放领域问答系统中的检索增强功能。](2024年04月02日/Improving_Retrieval_Augmented_Open-Domain_Question-Answering_with_Vectorized_Contexts.md)

- [Towards Better Generalization in Open-Domain Question Answering by Mitigating Context Memorization](2024年04月02日/Towards_Better_Generalization_in_Open-Domain_Question_Answering_by_Mitigating_Context_Memorization.md)

    - [翻译: 为了在开放领域问答中获得更佳的泛化效果，本研究致力于减轻上下文记忆的影响。](2024年04月02日/Towards_Better_Generalization_in_Open-Domain_Question_Answering_by_Mitigating_Context_Memorization.md)

- [Iterated Learning Improves Compositionality in Large Vision-Language Models](2024年04月02日/Iterated_Learning_Improves_Compositionality_in_Large_Vision-Language_Models.md)

    - [翻译: 通过迭代学习，大型视觉-语言模型的组合能力得到了显著提升。](2024年04月02日/Iterated_Learning_Improves_Compositionality_in_Large_Vision-Language_Models.md)

- [A Survey on Large Language Model-Based Game Agents](2024年04月02日/A_Survey_on_Large_Language_Model-Based_Game_Agents.md)

    - [翻译: 本文综述了基于大型语言模型的游戏代理的研究现状。](2024年04月02日/A_Survey_on_Large_Language_Model-Based_Game_Agents.md)

- [Large Language Models for Orchestrating Bimanual Robots](2024年04月02日/Large_Language_Models_for_Orchestrating_Bimanual_Robots.md)

    - [翻译: 通过大型语言模型，我们能够精准地指挥双手机器人的协同工作。](2024年04月02日/Large_Language_Models_for_Orchestrating_Bimanual_Robots.md)

- [Segment Any 3D Object with Language](2024年04月02日/Segment_Any_3D_Object_with_Language.md)

    - [翻译: 通过语言指令，轻松分割任意三维物体](2024年04月02日/Segment_Any_3D_Object_with_Language.md)

- [Bridging Language, Vision and Action: Multimodal VAEs in Robotic Manipulation Tasks](2024年04月02日/Bridging_Language,_Vision_and_Action_Multimodal_VAEs_in_Robotic_Manipulation_Tasks.md)

    - [翻译: 多模态变分自编码器（VAEs）在机器人操控任务中架起了语言、视觉与动作之间的桥梁。尽管如此，我们对于这些多模态VAEs在现实操作中的表现及其成效仍知之甚少。](2024年04月02日/Bridging_Language,_Vision_and_Action_Multimodal_VAEs_in_Robotic_Manipulation_Tasks.md)

- [Topic-based Watermarks for LLM-Generated Text](2024年04月02日/Topic-based_Watermarks_for_LLM-Generated_Text.md)

    - [翻译: 本文介绍了一种为大型语言模型（LLM）生成的文本设计的主题水印方法。](2024年04月02日/Topic-based_Watermarks_for_LLM-Generated_Text.md)

- [ViTamin: Designing Scalable Vision Models in the Vision-Language Era](2024年04月02日/ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era.md)

    - [翻译: ViTamin: 为视觉-语言时代打造可伸缩的视觉模型](2024年04月02日/ViTamin_Designing_Scalable_Vision_Models_in_the_Vision-Language_Era.md)

- [FLawN-T5: An Empirical Examination of Effective Instruction-Tuning Data Mixtures for Legal Reasoning](2024年04月02日/FLawN-T5_An_Empirical_Examination_of_Effective_Instruction-Tuning_Data_Mixtures_for_Legal_Reasoning.md)

    - [翻译: FLawN-T5：探究法律推理中高效指令调整数据组合的实证分析](2024年04月02日/FLawN-T5_An_Empirical_Examination_of_Effective_Instruction-Tuning_Data_Mixtures_for_Legal_Reasoning.md)

- [Exploring Automated Distractor Generation for Math Multiple-choice Questions via Large Language Models](2024年04月02日/Exploring_Automated_Distractor_Generation_for_Math_Multiple-choice_Questions_via_Large_Language_Models.md)

    - [翻译: 本研究利用大型语言模型，探索自动生成数学多项选择题干扰项的方法。](2024年04月02日/Exploring_Automated_Distractor_Generation_for_Math_Multiple-choice_Questions_via_Large_Language_Models.md)

- [Pre-trained Vision and Language Transformers Are Few-Shot Incremental Learners](2024年04月02日/Pre-trained_Vision_and_Language_Transformers_Are_Few-Shot_Incremental_Learners.md)

    - [翻译: 预先训练好的视觉与语言转换器，能够作为少量样本的逐步学习器。](2024年04月02日/Pre-trained_Vision_and_Language_Transformers_Are_Few-Shot_Incremental_Learners.md)

- [GINopic: Topic Modeling with Graph Isomorphism Network](2024年04月02日/GINopic_Topic_Modeling_with_Graph_Isomorphism_Network.md)

    - [翻译: GINopic：借助图同构网络进行主题挖掘与分析](2024年04月02日/GINopic_Topic_Modeling_with_Graph_Isomorphism_Network.md)

- [CameraCtrl: Enabling Camera Control for Text-to-Video Generation](2024年04月02日/CameraCtrl_Enabling_Camera_Control_for_Text-to-Video_Generation.md)

    - [翻译: CameraCtrl：实现文本输入到视频输出的相机操控功能](2024年04月02日/CameraCtrl_Enabling_Camera_Control_for_Text-to-Video_Generation.md)

- [Advancing LLM Reasoning Generalists with Preference Trees](2024年04月02日/Advancing_LLM_Reasoning_Generalists_with_Preference_Trees.md)

    - [翻译: 借助偏好树，我们能够增强大型语言模型的推理能力，使其在处理各种问题时表现得更加全面。](2024年04月02日/Advancing_LLM_Reasoning_Generalists_with_Preference_Trees.md)

- [Digital Forgetting in Large Language Models: A Survey of Unlearning Methods](2024年04月02日/Digital_Forgetting_in_Large_Language_Models_A_Survey_of_Unlearning_Methods.md)

    - [翻译: 大型语言模型中的数字遗忘：对遗忘方法的综述。](2024年04月02日/Digital_Forgetting_in_Large_Language_Models_A_Survey_of_Unlearning_Methods.md)

- [Long-context LLMs Struggle with Long In-context Learning](2024年04月02日/Long-context_LLMs_Struggle_with_Long_In-context_Learning.md)

    - [翻译: 长篇幅的语境对于大型语言模型来说，在进行长距离的情境学习时显得颇为棘手。](2024年04月02日/Long-context_LLMs_Struggle_with_Long_In-context_Learning.md)

- [Deconstructing In-Context Learning: Understanding Prompts via Corruption](2024年04月02日/Deconstructing_In-Context_Learning_Understanding_Prompts_via_Corruption.md)

    - [翻译: 探究上下文学习之谜：通过干扰手段剖析提示的本质](2024年04月02日/Deconstructing_In-Context_Learning_Understanding_Prompts_via_Corruption.md)

- [MultiParaDetox: Extending Text Detoxification with Parallel Data to New Languages](2024年04月02日/MultiParaDetox_Extending_Text_Detoxification_with_Parallel_Data_to_New_Languages.md)

    - [翻译: MultiParaDetox：利用并行文本数据，将文本净化技术推广至更多语言。](2024年04月02日/MultiParaDetox_Extending_Text_Detoxification_with_Parallel_Data_to_New_Languages.md)

- [MuxServe: Flexible Multiplexing for Efficient Multiple LLM Serving](2024年04月02日/MuxServe_Flexible_Multiplexing_for_Efficient_Multiple_LLM_Serving.md)

    - [翻译: MuxServe 通过灵活的多路复用技术，为多个大型语言模型（LLM）提供高效服务。](2024年04月02日/MuxServe_Flexible_Multiplexing_for_Efficient_Multiple_LLM_Serving.md)

- [HyperCLOVA X Technical Report](2024年04月02日/HyperCLOVA_X_Technical_Report.md)

    - [翻译: 《超能CLOVA X》技术研究报告](2024年04月02日/HyperCLOVA_X_Technical_Report.md)

- [Towards Better Understanding of Cybercrime: The Role of Fine-Tuned LLMs in Translation](2024年04月02日/Towards_Better_Understanding_of_Cybercrime_The_Role_of_Fine-Tuned_LLMs_in_Translation.md)

    - [翻译: 探索网络犯罪的深层含义：精细化调整的大型语言模型在翻译工作中的角色。](2024年04月02日/Towards_Better_Understanding_of_Cybercrime_The_Role_of_Fine-Tuned_LLMs_in_Translation.md)

- [SGSH: Stimulate Large Language Models with Skeleton Heuristics for Knowledge Base Question Generation](2024年04月02日/SGSH_Stimulate_Large_Language_Models_with_Skeleton_Heuristics_for_Knowledge_Base_Question_Generation.md)

    - [翻译: SGSH：运用骨架启发式策略激活大型语言模型，助力知识库提问生成。](2024年04月02日/SGSH_Stimulate_Large_Language_Models_with_Skeleton_Heuristics_for_Knowledge_Base_Question_Generation.md)

- [Humanizing Machine-Generated Content: Evading AI-Text Detection through Adversarial Attack](2024年04月02日/Humanizing_Machine-Generated_Content_Evading_AI-Text_Detection_through_Adversarial_Attack.md)

    - [翻译: 机器内容拟人化：通过对抗性策略规避AI文本识别技术。](2024年04月02日/Humanizing_Machine-Generated_Content_Evading_AI-Text_Detection_through_Adversarial_Attack.md)

- [Minimize Quantization Output Error with Bias Compensation](2024年04月02日/Minimize_Quantization_Output_Error_with_Bias_Compensation.md)

    - [翻译: 采用偏差校正法降低量化输出误差](2024年04月02日/Minimize_Quantization_Output_Error_with_Bias_Compensation.md)

- [Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey](2024年04月02日/Beyond_Accuracy_Evaluating_the_Reasoning_Behavior_of_Large_Language_Models_--_A_Survey.md)

    - [翻译: 探究大型语言模型的推理表现：准确性之外的评估视角 -- 一项全面调查](2024年04月02日/Beyond_Accuracy_Evaluating_the_Reasoning_Behavior_of_Large_Language_Models_--_A_Survey.md)

- [Poro 34B and the Blessing of Multilinguality](2024年04月02日/Poro_34B_and_the_Blessing_of_Multilinguality.md)

    - [翻译: 探索 Poro 34B：多语言能力的优势与挑战](2024年04月02日/Poro_34B_and_the_Blessing_of_Multilinguality.md)

- [Where to Move Next: Zero-shot Generalization of LLMs for Next POI Recommendation](2024年04月02日/Where_to_Move_Next_Zero-shot_Generalization_of_LLMs_for_Next_POI_Recommendation.md)

    - [翻译: 下一站去哪儿：大型语言模型的零-shot 泛化技术助力下一个热门景点推荐](2024年04月02日/Where_to_Move_Next_Zero-shot_Generalization_of_LLMs_for_Next_POI_Recommendation.md)

- [RESSA: Repair Sparse Vision-Language Models via Sparse Cross-Modality Adaptation](2024年04月02日/RESSA_Repair_Sparse_Vision-Language_Models_via_Sparse_Cross-Modality_Adaptation.md)

    - [翻译: ](2024年04月02日/RESSA_Repair_Sparse_Vision-Language_Models_via_Sparse_Cross-Modality_Adaptation.md)

- [Enhancing Low-Resource LLMs Classification with PEFT and Synthetic Data](2024年04月02日/Enhancing_Low-Resource_LLMs_Classification_with_PEFT_and_Synthetic_Data.md)

    - [翻译: ](2024年04月02日/Enhancing_Low-Resource_LLMs_Classification_with_PEFT_and_Synthetic_Data.md)

- [Revisiting subword tokenization: A case study on affixal negation in large language models](2024年04月02日/Revisiting_subword_tokenization_A_case_study_on_affixal_negation_in_large_language_models.md)

    - [翻译: ](2024年04月02日/Revisiting_subword_tokenization_A_case_study_on_affixal_negation_in_large_language_models.md)

- [What Are We Measuring When We Evaluate Large Vision-Language Models? An Analysis of Latent Factors and Biases](2024年04月02日/What_Are_We_Measuring_When_We_Evaluate_Large_Vision-Language_Models_An_Analysis_of_Latent_Factors_and_Biases.md)

    - [翻译: ](2024年04月02日/What_Are_We_Measuring_When_We_Evaluate_Large_Vision-Language_Models_An_Analysis_of_Latent_Factors_and_Biases.md)

- [Exploring Backdoor Vulnerabilities of Chat Models](2024年04月02日/Exploring_Backdoor_Vulnerabilities_of_Chat_Models.md)

    - [翻译: ](2024年04月02日/Exploring_Backdoor_Vulnerabilities_of_Chat_Models.md)

- [Benchmarking Large Language Models for Persian: A Preliminary Study Focusing on ChatGPT](2024年04月02日/Benchmarking_Large_Language_Models_for_Persian_A_Preliminary_Study_Focusing_on_ChatGPT.md)

    - [翻译: ](2024年04月02日/Benchmarking_Large_Language_Models_for_Persian_A_Preliminary_Study_Focusing_on_ChatGPT.md)

- [Token Trails: Navigating Contextual Depths in Conversational AI with ChatLLM](2024年04月02日/Token_Trails_Navigating_Contextual_Depths_in_Conversational_AI_with_ChatLLM.md)

    - [翻译: ](2024年04月02日/Token_Trails_Navigating_Contextual_Depths_in_Conversational_AI_with_ChatLLM.md)

- [Low-resource neural machine translation with morphological modeling](2024年04月02日/Low-resource_neural_machine_translation_with_morphological_modeling.md)

    - [翻译: ](2024年04月02日/Low-resource_neural_machine_translation_with_morphological_modeling.md)

- [On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL](2024年04月02日/On_Linearizing_Structured_Data_in_Encoder-Decoder_Language_Models_Insights_from_Text-to-SQL.md)

    - [翻译: ](2024年04月02日/On_Linearizing_Structured_Data_in_Encoder-Decoder_Language_Models_Insights_from_Text-to-SQL.md)

- [Two Heads are Better than One: Nested PoE for Robust Defense Against Multi-Backdoors](2024年04月02日/Two_Heads_are_Better_than_One_Nested_PoE_for_Robust_Defense_Against_Multi-Backdoors.md)

    - [翻译: ](2024年04月02日/Two_Heads_are_Better_than_One_Nested_PoE_for_Robust_Defense_Against_Multi-Backdoors.md)

- [Multi-BERT: Leveraging Adapters and Prompt Tuning for Low-Resource Multi-Domain Adaptation](2024年04月02日/Multi-BERT_Leveraging_Adapters_and_Prompt_Tuning_for_Low-Resource_Multi-Domain_Adaptation.md)

    - [翻译: ](2024年04月02日/Multi-BERT_Leveraging_Adapters_and_Prompt_Tuning_for_Low-Resource_Multi-Domain_Adaptation.md)

- [Comparative Study of Domain Driven Terms Extraction Using Large Language Models](2024年04月02日/Comparative_Study_of_Domain_Driven_Terms_Extraction_Using_Large_Language_Models.md)

    - [翻译: ](2024年04月02日/Comparative_Study_of_Domain_Driven_Terms_Extraction_Using_Large_Language_Models.md)

- [Heat Death of Generative Models in Closed-Loop Learning](2024年04月02日/Heat_Death_of_Generative_Models_in_Closed-Loop_Learning.md)

    - [翻译: ](2024年04月02日/Heat_Death_of_Generative_Models_in_Closed-Loop_Learning.md)

- [Toward Informal Language Processing: Knowledge of Slang in Large Language Models](2024年04月02日/Toward_Informal_Language_Processing_Knowledge_of_Slang_in_Large_Language_Models.md)

    - [翻译: ](2024年04月02日/Toward_Informal_Language_Processing_Knowledge_of_Slang_in_Large_Language_Models.md)

- [Prompts As Programs: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization](2024年04月02日/Prompts_As_Programs_A_Structure-Aware_Approach_to_Efficient_Compile-Time_Prompt_Optimization.md)

    - [翻译: ](2024年04月02日/Prompts_As_Programs_A_Structure-Aware_Approach_to_Efficient_Compile-Time_Prompt_Optimization.md)

- [ZeroCAP: Zero-Shot Multi-Robot Context Aware Pattern Formation via Large Language Models](2024年04月02日/ZeroCAP_Zero-Shot_Multi-Robot_Context_Aware_Pattern_Formation_via_Large_Language_Models.md)

    - [翻译: ](2024年04月02日/ZeroCAP_Zero-Shot_Multi-Robot_Context_Aware_Pattern_Formation_via_Large_Language_Models.md)

- [Constrained Robotic Navigation on Preferred Terrains Using LLMs and Speech Instruction: Exploiting the Power of Adverbs](2024年04月02日/Constrained_Robotic_Navigation_on_Preferred_Terrains_Using_LLMs_and_Speech_Instruction_Exploiting_the_Power_of_Adverbs.md)

    - [翻译: ](2024年04月02日/Constrained_Robotic_Navigation_on_Preferred_Terrains_Using_LLMs_and_Speech_Instruction_Exploiting_the_Power_of_Adverbs.md)

- [LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages](2024年04月02日/LLMs_in_the_Loop_Leveraging_Large_Language_Model_Annotations_for_Active_Learning_in_Low-Resource_Languages.md)

    - [翻译: ](2024年04月02日/LLMs_in_the_Loop_Leveraging_Large_Language_Model_Annotations_for_Active_Learning_in_Low-Resource_Languages.md)

- [: A Simple Society of Language Models Solves Complex Reasoning](2024年04月02日/_A_Simple_Society_of_Language_Models_Solves_Complex_Reasoning.md)

    - [翻译: ](2024年04月02日/_A_Simple_Society_of_Language_Models_Solves_Complex_Reasoning.md)

- [Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices](2024年04月02日/Exploring_How_Multiple_Levels_of_GPT-Generated_Programming_Hints_Support_or_Disappoint_Novices.md)

    - [翻译: ](2024年04月02日/Exploring_How_Multiple_Levels_of_GPT-Generated_Programming_Hints_Support_or_Disappoint_Novices.md)

- [Emergent Abilities in Reduced-Scale Generative Language Models](2024年04月02日/Emergent_Abilities_in_Reduced-Scale_Generative_Language_Models.md)

    - [翻译: ](2024年04月02日/Emergent_Abilities_in_Reduced-Scale_Generative_Language_Models.md)

- [Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization](2024年04月02日/Self-Organized_Agents_A_LLM_Multi-Agent_Framework_toward_Ultra_Large-Scale_Code_Generation_and_Optimization.md)

    - [翻译: ](2024年04月02日/Self-Organized_Agents_A_LLM_Multi-Agent_Framework_toward_Ultra_Large-Scale_Code_Generation_and_Optimization.md)

2024年04月01日

- [Large Language Model Evaluation Via Multi AI Agents: Preliminary results](2024年04月01日/Large_Language_Model_Evaluation_Via_Multi_AI_Agents_Preliminary_results.md)

    - [翻译: 借助众多AI助手，我们对大型语言模型展开了评估，目前取得了一些初步成果。](2024年04月01日/Large_Language_Model_Evaluation_Via_Multi_AI_Agents_Preliminary_results.md)

- [Source-Aware Training Enables Knowledge Attribution in Language Models](2024年04月01日/Source-Aware_Training_Enables_Knowledge_Attribution_in_Language_Models.md)

    - [翻译: 通过源感知训练，我们能够在语言模型中对知识进行追溯和归属。](2024年04月01日/Source-Aware_Training_Enables_Knowledge_Attribution_in_Language_Models.md)

- [Harnessing Large Language Models for Training-free Video Anomaly Detection](2024年04月01日/Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection.md)

    - [翻译: 通过运用大型语言模型，我们可以实现无需额外训练的视频异常检测技术。](2024年04月01日/Harnessing_Large_Language_Models_for_Training-free_Video_Anomaly_Detection.md)

- [Query Performance Prediction using Relevance Judgments Generated by Large Language Models](2024年04月01日/Query_Performance_Prediction_using_Relevance_Judgments_Generated_by_Large_Language_Models.md)

    - [翻译: 通过大型语言模型生成的相关性评估来预测查询性能](2024年04月01日/Query_Performance_Prediction_using_Relevance_Judgments_Generated_by_Large_Language_Models.md)

- [Transforming the Synthesis of Carbon Nanotubes with Machine Learning Models and Automation](2024年04月01日/Transforming_the_Synthesis_of_Carbon_Nanotubes_with_Machine_Learning_Models_and_Automation.md)

    - [翻译: 利用机器学习模型和自动化技术革新碳纳米管的制备过程](2024年04月01日/Transforming_the_Synthesis_of_Carbon_Nanotubes_with_Machine_Learning_Models_and_Automation.md)

- [LLM-RadJudge: Achieving Radiologist-Level Evaluation for X-Ray Report Generation](2024年04月01日/LLM-RadJudge_Achieving_Radiologist-Level_Evaluation_for_X-Ray_Report_Generation.md)

    - [翻译: LLM-RadJudge：在生成X光报告方面达到放射科医生的评估水准](2024年04月01日/LLM-RadJudge_Achieving_Radiologist-Level_Evaluation_for_X-Ray_Report_Generation.md)

- [Exploring the Nexus of Large Language Models and Legal Systems: A Short Survey](2024年04月01日/Exploring_the_Nexus_of_Large_Language_Models_and_Legal_Systems_A_Short_Survey.md)

    - [翻译: 浅谈大型语言模型与法律体系的交汇点](2024年04月01日/Exploring_the_Nexus_of_Large_Language_Models_and_Legal_Systems_A_Short_Survey.md)

- [Prior Constraints-based Reward Model Training for Aligning Large Language Models](2024年04月01日/Prior_Constraints-based_Reward_Model_Training_for_Aligning_Large_Language_Models.md)

    - [翻译: 通过先验约束引导的奖励模型训练，实现大型语言模型的精准对齐。](2024年04月01日/Prior_Constraints-based_Reward_Model_Training_for_Aligning_Large_Language_Models.md)

- [VideoDistill: Language-aware Vision Distillation for Video Question Answering](2024年04月01日/VideoDistill_Language-aware_Vision_Distillation_for_Video_Question_Answering.md)

    - [翻译: VideoDistill：为视频问答而设计的，融合语言理解的视觉蒸馏技术](2024年04月01日/VideoDistill_Language-aware_Vision_Distillation_for_Video_Question_Answering.md)

- [Exploring and Evaluating Hallucinations in LLM-Powered Code Generation](2024年04月01日/Exploring_and_Evaluating_Hallucinations_in_LLM-Powered_Code_Generation.md)

    - [翻译: 探究与评价由大型语言模型（LLM）驱动的代码生成过程中的虚构现象。](2024年04月01日/Exploring_and_Evaluating_Hallucinations_in_LLM-Powered_Code_Generation.md)

- [AISPACE at SemEval-2024 task 8: A Class-balanced Soft-voting System for Detecting Multi-generator Machine-generated Text](2024年04月01日/AISPACE_at_SemEval-2024_task_8_A_Class-balanced_Soft-voting_System_for_Detecting_Multi-generator_Machine-generated_Text.md)

    - [翻译: AISPACE 参与 SemEval-2024 第 8 项任务：构建一个平衡类别的软投票系统，用于识别由多种生成器产生的机器文本。](2024年04月01日/AISPACE_at_SemEval-2024_task_8_A_Class-balanced_Soft-voting_System_for_Detecting_Multi-generator_Machine-generated_Text.md)

- [Evalverse: Unified and Accessible Library for Large Language Model Evaluation](2024年04月01日/Evalverse_Unified_and_Accessible_Library_for_Large_Language_Model_Evaluation.md)

    - [翻译: Evalverse：为大型语言模型评估打造的一体化、易用资源库](2024年04月01日/Evalverse_Unified_and_Accessible_Library_for_Large_Language_Model_Evaluation.md)

- [Evaluating the Factuality of Large Language Models using Large-Scale Knowledge Graphs](2024年04月01日/Evaluating_the_Factuality_of_Large_Language_Models_using_Large-Scale_Knowledge_Graphs.md)

    - [翻译: 通过大规模知识图谱来评估大型语言模型的真实性。](2024年04月01日/Evaluating_the_Factuality_of_Large_Language_Models_using_Large-Scale_Knowledge_Graphs.md)

- [How Can Large Language Models Enable Better Socially Assistive Human-Robot Interaction: A Brief Survey](2024年04月01日/How_Can_Large_Language_Models_Enable_Better_Socially_Assistive_Human-Robot_Interaction_A_Brief_Survey.md)

    - [翻译: 大型语言模型助力人机社交互动：一项简明调查](2024年04月01日/How_Can_Large_Language_Models_Enable_Better_Socially_Assistive_Human-Robot_Interaction_A_Brief_Survey.md)

- [ChatGLM-RLHF: Practices of Aligning Large Language Models with Human Feedback](2024年04月01日/ChatGLM-RLHF_Practices_of_Aligning_Large_Language_Models_with_Human_Feedback.md)

    - [翻译: ChatGLM-RLHF：探索大型语言模型与人类反馈融合的实践之道](2024年04月01日/ChatGLM-RLHF_Practices_of_Aligning_Large_Language_Models_with_Human_Feedback.md)

- [PSYDIAL: Personality-based Synthetic Dialogue Generation using Large Language Models](2024年04月01日/PSYDIAL_Personality-based_Synthetic_Dialogue_Generation_using_Large_Language_Models.md)

    - [翻译: PSYDIAL：利用大型语言模型生成个性化合成对话](2024年04月01日/PSYDIAL_Personality-based_Synthetic_Dialogue_Generation_using_Large_Language_Models.md)

- [A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias](2024年04月01日/A_Survey_on_Multilingual_Large_Language_Models_Corpora,_Alignment,_and_Bias.md)

    - [翻译: 本文综述了多语言大型语言模型的研究现状，探讨了构建多语言模型所需的语料库资源、不同语言间的对齐问题，以及模型中潜在的偏见问题。](2024年04月01日/A_Survey_on_Multilingual_Large_Language_Models_Corpora,_Alignment,_and_Bias.md)

- [LLMs are Good Sign Language Translators](2024年04月01日/LLMs_are_Good_Sign_Language_Translators.md)

    - [翻译: 大型语言模型擅长于手语翻译。](2024年04月01日/LLMs_are_Good_Sign_Language_Translators.md)

- [Token-Efficient Leverage Learning in Large Language Models](2024年04月01日/Token-Efficient_Leverage_Learning_in_Large_Language_Models.md)

    - [翻译: 大型语言模型中的高效利用标记学习，旨在优化学习效率。](2024年04月01日/Token-Efficient_Leverage_Learning_in_Large_Language_Models.md)

- [Learning by Correction: Efficient Tuning Task for Zero-Shot Generative Vision-Language Reasoning](2024年04月01日/Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_Reasoning.md)

    - [翻译: 学习通过修正：为零-shot生成性视觉语言推理任务打造高效的调优方案。](2024年04月01日/Learning_by_Correction_Efficient_Tuning_Task_for_Zero-Shot_Generative_Vision-Language_Reasoning.md)

- [ARAGOG: Advanced RAG Output Grading](2024年04月01日/ARAGOG_Advanced_RAG_Output_Grading.md)

    - [翻译: ARAGOG：精进的RAG成果评定](2024年04月01日/ARAGOG_Advanced_RAG_Output_Grading.md)

- [LLM as a Mastermind: A Survey of Strategic Reasoning with Large Language Models](2024年04月01日/LLM_as_a_Mastermind_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models.md)

    - [翻译: 大型语言模型：策略性推理的探索之旅](2024年04月01日/LLM_as_a_Mastermind_A_Survey_of_Strategic_Reasoning_with_Large_Language_Models.md)

- [Direct Preference Optimization of Video Large Multimodal Models from Language Model Reward](2024年04月01日/Direct_Preference_Optimization_of_Video_Large_Multimodal_Models_from_Language_Model_Reward.md)

    - [翻译: 通过语言模型奖励，直接对视频大型多模态模型进行偏好优化。](2024年04月01日/Direct_Preference_Optimization_of_Video_Large_Multimodal_Models_from_Language_Model_Reward.md)

- [LITE: Modeling Environmental Ecosystems with Multimodal Large Language Models](2024年04月01日/LITE_Modeling_Environmental_Ecosystems_with_Multimodal_Large_Language_Models.md)

    - [翻译: LITE：借助多模态大型语言模型，构建环境生态系统模型](2024年04月01日/LITE_Modeling_Environmental_Ecosystems_with_Multimodal_Large_Language_Models.md)

- [Prompt Learning for Oriented Power Transmission Tower Detection in High-Resolution SAR Images](2024年04月01日/Prompt_Learning_for_Oriented_Power_Transmission_Tower_Detection_in_High-Resolution_SAR_Images.md)

    - [翻译: 针对高分辨率SAR图像中的定向输电塔检测，本研究采用提示学习方法进行探索。](2024年04月01日/Prompt_Learning_for_Oriented_Power_Transmission_Tower_Detection_in_High-Resolution_SAR_Images.md)

- [Towards Safety and Helpfulness Balanced Responses via Controllable Large Language Models](2024年04月01日/Towards_Safety_and_Helpfulness_Balanced_Responses_via_Controllable_Large_Language_Models.md)

    - [翻译: 本研究致力于通过可调控的大型语言模型，实现既安全又有益的智能回应。](2024年04月01日/Towards_Safety_and_Helpfulness_Balanced_Responses_via_Controllable_Large_Language_Models.md)

- [Large Language Models are Capable of Offering Cognitive Reappraisal, if Guided](2024年04月01日/Large_Language_Models_are_Capable_of_Offering_Cognitive_Reappraisal,_if_Guided.md)

    - [翻译: 在适当的引导下，大型语言模型具备进行认知重估的能力。](2024年04月01日/Large_Language_Models_are_Capable_of_Offering_Cognitive_Reappraisal,_if_Guided.md)

- [TWIN-GPT: Digital Twins for Clinical Trials via Large Language Model](2024年04月01日/TWIN-GPT_Digital_Twins_for_Clinical_Trials_via_Large_Language_Model.md)

    - [翻译: TWIN-GPT：借助大型语言模型，为临床试验打造数字孪生技术](2024年04月01日/TWIN-GPT_Digital_Twins_for_Clinical_Trials_via_Large_Language_Model.md)

- [Mapping the Increasing Use of LLMs in Scientific Papers](2024年04月01日/Mapping_the_Increasing_Use_of_LLMs_in_Scientific_Papers.md)

    - [翻译: 科学论文中大型语言模型（LLM）使用频率的增长已被详细记录。](2024年04月01日/Mapping_the_Increasing_Use_of_LLMs_in_Scientific_Papers.md)

- [FABLES: Evaluating faithfulness and content selection in book-length summarization](2024年04月01日/FABLES_Evaluating_faithfulness_and_content_selection_in_book-length_summarization.md)

    - [翻译: FABLES：探究书籍摘要的真实度与内容筛选](2024年04月01日/FABLES_Evaluating_faithfulness_and_content_selection_in_book-length_summarization.md)

- [UniArk: Improving Generalisation and Consistency for Factual Knowledge Extraction through Debiasing](2024年04月01日/UniArk_Improving_Generalisation_and_Consistency_for_Factual_Knowledge_Extraction_through_Debiasing.md)

    - [翻译: UniArk 通过去偏技术，增强了事实知识提取的泛化与一致性，提升了整体性能。](2024年04月01日/UniArk_Improving_Generalisation_and_Consistency_for_Factual_Knowledge_Extraction_through_Debiasing.md)

- [A Statistical Framework of Watermarks for Large Language Models: Pivot, Detection Efficiency and Optimal Rules](2024年04月01日/A_Statistical_Framework_of_Watermarks_for_Large_Language_Models_Pivot,_Detection_Efficiency_and_Optimal_Rules.md)

    - [翻译: 针对大型语言模型，本文提出了一个水印的统计学框架，探讨了水印的枢纽作用、检测效率以及如何制定最优规则。](2024年04月01日/A_Statistical_Framework_of_Watermarks_for_Large_Language_Models_Pivot,_Detection_Efficiency_and_Optimal_Rules.md)

- [Privacy Backdoors: Enhancing Membership Inference through Poisoning Pre-trained Models](2024年04月01日/Privacy_Backdoors_Enhancing_Membership_Inference_through_Poisoning_Pre-trained_Models.md)

    - [翻译: 通过在预训练模型中植入污染信息，我们能够增强对模型成员身份的推断能力，从而打开隐私保护的后门。](2024年04月01日/Privacy_Backdoors_Enhancing_Membership_Inference_through_Poisoning_Pre-trained_Models.md)

- [Machine Unlearning for Traditional Models and Large Language Models: A Short Survey](2024年04月01日/Machine_Unlearning_for_Traditional_Models_and_Large_Language_Models_A_Short_Survey.md)

    - [翻译: 本综述简要探讨了传统模型与大型语言模型中的机器去学习技术。](2024年04月01日/Machine_Unlearning_for_Traditional_Models_and_Large_Language_Models_A_Short_Survey.md)

- [The Fine Line: Navigating Large Language Model Pretraining with Down-streaming Capability Analysis](2024年04月01日/The_Fine_Line_Navigating_Large_Language_Model_Pretraining_with_Down-streaming_Capability_Analysis.md)

    - [翻译: 《探寻平衡：借助下游能力分析来引导大型语言模型的预训练》](2024年04月01日/The_Fine_Line_Navigating_Large_Language_Model_Pretraining_with_Down-streaming_Capability_Analysis.md)

- [Getting it Right: Improving Spatial Consistency in Text-to-Image Models](2024年04月01日/Getting_it_Right_Improving_Spatial_Consistency_in_Text-to-Image_Models.md)

    - [翻译: 精准把握：提升文本转图像模型的空间连贯性](2024年04月01日/Getting_it_Right_Improving_Spatial_Consistency_in_Text-to-Image_Models.md)

- [Green AI: Exploring Carbon Footprints, Mitigation Strategies, and Trade Offs in Large Language Model Training](2024年04月01日/Green_AI_Exploring_Carbon_Footprints,_Mitigation_Strategies,_and_Trade_Offs_in_Large_Language_Model_Training.md)

    - [翻译: 绿色AI：研究大型语言模型训练过程中的碳排放、减排措施及其平衡之道。](2024年04月01日/Green_AI_Exploring_Carbon_Footprints,_Mitigation_Strategies,_and_Trade_Offs_in_Large_Language_Model_Training.md)

- [SyncMask: Synchronized Attentional Masking for Fashion-centric Vision-Language Pretraining](2024年04月01日/SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining.md)

    - [翻译: SyncMask：为时尚导向视觉-语言预训练设计的同步注意力屏蔽技术](2024年04月01日/SyncMask_Synchronized_Attentional_Masking_for_Fashion-centric_Vision-Language_Pretraining.md)

- [Do LLMs Find Human Answers To Fact-Driven Questions Perplexing? A Case Study on Reddit](2024年04月01日/Do_LLMs_Find_Human_Answers_To_Fact-Driven_Questions_Perplexing_A_Case_Study_on_Reddit.md)

    - [翻译: 在Reddit上的案例研究：大型语言模型真的搞不懂人类对事实问题的答案吗？](2024年04月01日/Do_LLMs_Find_Human_Answers_To_Fact-Driven_Questions_Perplexing_A_Case_Study_on_Reddit.md)

- [Enhancing Reasoning Capacity of SLM using Cognitive Enhancement](2024年04月01日/Enhancing_Reasoning_Capacity_of_SLM_using_Cognitive_Enhancement.md)

    - [翻译: 通过认知增强技术，我们能够提升小型语言模型（SLM）的推理能力。](2024年04月01日/Enhancing_Reasoning_Capacity_of_SLM_using_Cognitive_Enhancement.md)

- [Structured Information Matters: Incorporating Abstract Meaning Representation into LLMs for Improved Open-Domain Dialogue Evaluation](2024年04月01日/Structured_Information_Matters_Incorporating_Abstract_Meaning_Representation_into_LLMs_for_Improved_Open-Domain_Dialogue_Evaluation.md)

    - [翻译: 结构化信息至关重要：在大型语言模型中整合抽象意义表示，以优化开放领域对话的评估效果。](2024年04月01日/Structured_Information_Matters_Incorporating_Abstract_Meaning_Representation_into_LLMs_for_Improved_Open-Domain_Dialogue_Evaluation.md)

- [What's in Your "Safe" Data?: Identifying Benign Data that Breaks Safety](2024年04月01日/What's_in_Your_Safe_Data_Identifying_Benign_Data_that_Breaks_Safety.md)

    - [翻译: 揭秘“安全”数据：发现看似无害却危害安全的数据。](2024年04月01日/What's_in_Your_Safe_Data_Identifying_Benign_Data_that_Breaks_Safety.md)

- [Enabling Memory Safety of C Programs using LLMs](2024年04月01日/Enabling_Memory_Safety_of_C_Programs_using_LLMs.md)

    - [翻译: 通过大型语言模型 (LLM) 保障 C 程序的内存安全。](2024年04月01日/Enabling_Memory_Safety_of_C_Programs_using_LLMs.md)

- [Efficient Prompting Methods for Large Language Models: A Survey](2024年04月01日/Efficient_Prompting_Methods_for_Large_Language_Models_A_Survey.md)

    - [翻译: 大型语言模型的高效提示技巧：全面调查研究](2024年04月01日/Efficient_Prompting_Methods_for_Large_Language_Models_A_Survey.md)

- [Chat Modeling: Natural Language-based Procedural Modeling of Biological Structures without Training](2024年04月01日/Chat_Modeling_Natural_Language-based_Procedural_Modeling_of_Biological_Structures_without_Training.md)

    - [翻译: 聊天建模：利用自然语言进行生物结构的程序化设计，无需经过训练过程。](2024年04月01日/Chat_Modeling_Natural_Language-based_Procedural_Modeling_of_Biological_Structures_without_Training.md)

- [Regularized Best-of-N Sampling to Mitigate Reward Hacking for Language Model Alignment](2024年04月01日/Regularized_Best-of-N_Sampling_to_Mitigate_Reward_Hacking_for_Language_Model_Alignment.md)

    - [翻译: 为确保语言模型对齐，我们采用正则化的最优 N 选一抽样策略，以降低奖励操纵行为的风险。](2024年04月01日/Regularized_Best-of-N_Sampling_to_Mitigate_Reward_Hacking_for_Language_Model_Alignment.md)

- [Can LLMs get help from other LLMs without revealing private information?](2024年04月01日/Can_LLMs_get_help_from_other_LLMs_without_revealing_private_information.md)

    - [翻译: 大型语言模型能否在保护隐私的前提下互相协助？](2024年04月01日/Can_LLMs_get_help_from_other_LLMs_without_revealing_private_information.md)

- [LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models](2024年04月01日/LLM-ABR_Designing_Adaptive_Bitrate_Algorithms_via_Large_Language_Models.md)

    - [翻译: LLM-ABR：借助大型语言模型打造智能自适应码率算法](2024年04月01日/LLM-ABR_Designing_Adaptive_Bitrate_Algorithms_via_Large_Language_Models.md)

- [Transforming LLMs into Cross-modal and Cross-lingual RetrievalSystems](2024年04月01日/Transforming_LLMs_into_Cross-modal_and_Cross-lingual_RetrievalSystems.md)

    - [翻译: 将大型语言模型打造成跨界的检索系统，实现跨模态与跨语言的无缝对接。](2024年04月01日/Transforming_LLMs_into_Cross-modal_and_Cross-lingual_RetrievalSystems.md)

- [Helmsman of the Masses? Evaluate the Opinion Leadership of Large Language Models in the Werewolf Game](2024年04月01日/Helmsman_of_the_Masses_Evaluate_the_Opinion_Leadership_of_Large_Language_Models_in_the_Werewolf_Game.md)

    - [翻译: 引领民意？探究大型语言模型在狼人游戏中的舆论引导作用。](2024年04月01日/Helmsman_of_the_Masses_Evaluate_the_Opinion_Leadership_of_Large_Language_Models_in_the_Werewolf_Game.md)

- [Classifying Cancer Stage with Open-Source Clinical Large Language Models](2024年04月01日/Classifying_Cancer_Stage_with_Open-Source_Clinical_Large_Language_Models.md)

    - [翻译: 本研究探讨了运用开源临床大型语言模型对癌症阶段进行精确分类的方法。](2024年04月01日/Classifying_Cancer_Stage_with_Open-Source_Clinical_Large_Language_Models.md)

- [Hallucination Diversity-Aware Active Learning for Text Summarization](2024年04月01日/Hallucination_Diversity-Aware_Active_Learning_for_Text_Summarization.md)

    - [翻译: 在文本摘要中，我们采用一种幻觉多样性感知的主动学习方法。](2024年04月01日/Hallucination_Diversity-Aware_Active_Learning_for_Text_Summarization.md)

- [Evaluating Large Language Models Using Contrast Sets: An Experimental Approach](2024年04月01日/Evaluating_Large_Language_Models_Using_Contrast_Sets_An_Experimental_Approach.md)

    - [翻译: 通过对比集对大型语言模型进行评估：探索性实验途径](2024年04月01日/Evaluating_Large_Language_Models_Using_Contrast_Sets_An_Experimental_Approach.md)

- [Automated User Story Generation with Test Case Specification Using Large Language Model](2024年04月01日/Automated_User_Story_Generation_with_Test_Case_Specification_Using_Large_Language_Model.md)

    - [翻译: 借助大型语言模型，实现自动化的用户故事创建，并配备测试用例规范。](2024年04月01日/Automated_User_Story_Generation_with_Test_Case_Specification_Using_Large_Language_Model.md)

- [Octopus: On-device language model for function calling of software APIs](2024年04月01日/Octopus_On-device_language_model_for_function_calling_of_software_APIs.md)

    - [翻译: 章鱼：一款适用于软件API功能调用的设备端语言模型](2024年04月01日/Octopus_On-device_language_model_for_function_calling_of_software_APIs.md)

- [Syntactic Robustness for LLM-based Code Generation](2024年04月01日/Syntactic_Robustness_for_LLM-based_Code_Generation.md)

    - [翻译: 在大型语言模型（LLM）支持下，代码生成的句法鲁棒性研究](2024年04月01日/Syntactic_Robustness_for_LLM-based_Code_Generation.md)

- [Set-Aligning Framework for Auto-Regressive Event Temporal Graph Generation](2024年04月01日/Set-Aligning_Framework_for_Auto-Regressive_Event_Temporal_Graph_Generation.md)

    - [翻译: 自回归事件时序图的生成采用集合对齐框架](2024年04月01日/Set-Aligning_Framework_for_Auto-Regressive_Event_Temporal_Graph_Generation.md)

- [A Study on Scaling Up Multilingual News Framing Analysis](2024年04月01日/A_Study_on_Scaling_Up_Multilingual_News_Framing_Analysis.md)

    - [翻译: 本研究探讨了如何扩展多语言新闻框架分析的规模，旨在提高跨语言和文化背景下新闻报道的理解和分析能力。](2024年04月01日/A_Study_on_Scaling_Up_Multilingual_News_Framing_Analysis.md)

- [TraveLER: A Multi-LMM Agent Framework for Video Question-Answering](2024年04月01日/TraveLER_A_Multi-LMM_Agent_Framework_for_Video_Question-Answering.md)

    - [翻译: TraveLER：面向视频问答任务的多语言模型代理框架](2024年04月01日/TraveLER_A_Multi-LMM_Agent_Framework_for_Video_Question-Answering.md)

- [Are large language models superhuman chemists?](2024年04月01日/Are_large_language_models_superhuman_chemists.md)

    - [翻译: 大型语言模型能否媲美超级化学家？](2024年04月01日/Are_large_language_models_superhuman_chemists.md)

- [Will the Real Linda Please Stand up...to Large Language Models? Examining the Representativeness Heuristic in LLMs](2024年04月01日/Will_the_Real_Linda_Please_Stand_up...to_Large_Language_Models_Examining_the_Representativeness_Heuristic_in_LLMs.md)

    - [翻译: 琳达能否勇敢地面对大型语言模型？探究LLMs中的代表性启发式原理。](2024年04月01日/Will_the_Real_Linda_Please_Stand_up...to_Large_Language_Models_Examining_the_Representativeness_Heuristic_in_LLMs.md)

- [Unveiling Divergent Inductive Biases of LLMs on Temporal Data](2024年04月01日/Unveiling_Divergent_Inductive_Biases_of_LLMs_on_Temporal_Data.md)

    - [翻译: 探究大型语言模型处理时间数据时的多样化归纳偏好](2024年04月01日/Unveiling_Divergent_Inductive_Biases_of_LLMs_on_Temporal_Data.md)

- [Position-Aware Parameter Efficient Fine-Tuning Approach for Reducing Positional Bias in LLMs](2024年04月01日/Position-Aware_Parameter_Efficient_Fine-Tuning_Approach_for_Reducing_Positional_Bias_in_LLMs.md)

    - [翻译: 为了降低大型语言模型中的位置偏见，我们采用了一种位置感知的高效微调策略。](2024年04月01日/Position-Aware_Parameter_Efficient_Fine-Tuning_Approach_for_Reducing_Positional_Bias_in_LLMs.md)

- [A Preliminary Roadmap for LLMs as Assistants in Exploring, Analyzing, and Visualizing Knowledge Graphs](2024年04月01日/A_Preliminary_Roadmap_for_LLMs_as_Assistants_in_Exploring,_Analyzing,_and_Visualizing_Knowledge_Graphs.md)

    - [翻译: 探索、分析及可视化知识图谱的大型语言模型助手的初步指南。](2024年04月01日/A_Preliminary_Roadmap_for_LLMs_as_Assistants_in_Exploring,_Analyzing,_and_Visualizing_Knowledge_Graphs.md)

- [OVFoodSeg: Elevating Open-Vocabulary Food Image Segmentation via Image-Informed Textual Representation](2024年04月01日/OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation.md)

    - [翻译: OVFoodSeg: 利用图像信息增强文本表达，提升食品图像的开放词汇量分割技术](2024年04月01日/OVFoodSeg_Elevating_Open-Vocabulary_Food_Image_Segmentation_via_Image-Informed_Textual_Representation.md)

- [Developing Safe and Responsible Large Language Models -- A Comprehensive Framework](2024年04月01日/Developing_Safe_and_Responsible_Large_Language_Models_--_A_Comprehensive_Framework.md)

    - [翻译: 构建安全可靠的大型语言模型：全方位框架探究](2024年04月01日/Developing_Safe_and_Responsible_Large_Language_Models_--_A_Comprehensive_Framework.md)

- [Prompt-prompted Mixture of Experts for Efficient LLM Generation](2024年04月01日/Prompt-prompted_Mixture_of_Experts_for_Efficient_LLM_Generation.md)

    - [翻译: 通过专家混合的提示-提示策略，我们能够有效地生成大型语言模型。](2024年04月01日/Prompt-prompted_Mixture_of_Experts_for_Efficient_LLM_Generation.md)

- [LLM Attributor: Interactive Visual Attribution for LLM Generation](2024年04月01日/LLM_Attributor_Interactive_Visual_Attribution_for_LLM_Generation.md)

    - [翻译: LLM 属性归因器：为大型语言模型生成提供交互式视觉归因功能。](2024年04月01日/LLM_Attributor_Interactive_Visual_Attribution_for_LLM_Generation.md)

- [Leveraging YOLO-World and GPT-4V LMMs for Zero-Shot Person Detection and Action Recognition in Drone Imagery](2024年04月01日/Leveraging_YOLO-World_and_GPT-4V_LMMs_for_Zero-Shot_Person_Detection_and_Action_Recognition_in_Drone_Imagery.md)

    - [翻译: 通过运用 YOLO-World 与 GPT-4V 语言模型，实现无人机图像中的零-shot 人员探测与行为识别。](2024年04月01日/Leveraging_YOLO-World_and_GPT-4V_LMMs_for_Zero-Shot_Person_Detection_and_Action_Recognition_in_Drone_Imagery.md)