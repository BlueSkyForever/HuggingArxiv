# 反事实任务的证据表明，大型语言模型中已经出现了类比推理的能力。

发布时间：2024年04月14日

`LLM理论` `人工智能`

> Evidence from counterfactual tasks supports emergent analogical reasoning in large language models

# 摘要

> 近期，我们发现大型语言模型展现出了一种新的能力——无需事先训练即可解决众多基于文本的类比问题。然而，两篇评论对此提出质疑，指出在某些“反事实”任务中，字母表的标准顺序被随机打乱，降低了与模型训练数据中可能出现的材料的相似性。针对这些批评，我们在此进行回应，阐明了对我们原始研究中使用测试材料的一些误解，并进一步证实，语言模型确实能够适应这些新型的反事实任务变体。

> We recently reported evidence that large language models are capable of solving a wide range of text-based analogy problems in a zero-shot manner, indicating the presence of an emergent capacity for analogical reasoning. Two recent commentaries have challenged these results, citing evidence from so-called `counterfactual' tasks in which the standard sequence of the alphabet is arbitrarily permuted so as to decrease similarity with materials that may have been present in the language model's training data. Here, we reply to these critiques, clarifying some misunderstandings about the test materials used in our original work, and presenting evidence that language models are also capable of generalizing to these new counterfactual task variants.

![反事实任务的证据表明，大型语言模型中已经出现了类比推理的能力。](../../../paper_images/2404.13070/x1.png)

![反事实任务的证据表明，大型语言模型中已经出现了类比推理的能力。](../../../paper_images/2404.13070/x2.png)

![反事实任务的证据表明，大型语言模型中已经出现了类比推理的能力。](../../../paper_images/2404.13070/x3.png)

![反事实任务的证据表明，大型语言模型中已经出现了类比推理的能力。](../../../paper_images/2404.13070/x4.png)

[Arxiv](https://arxiv.org/abs/2404.13070)