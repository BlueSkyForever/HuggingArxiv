# 为皮肤科AI中的零样本概念生成实现数据对齐。

发布时间：2024年04月19日

`分类：LLM应用` `皮肤科` `人工智能`

> Data Alignment for Zero-Shot Concept Generation in Dermatology AI

# 摘要

> 随着人工智能在皮肤科领域的飞速发展，其面临的主要挑战是缺乏具有精确概念标签的数据，这些标签对人类而言具有语义上的意义。CLIP 等基础模型通过互联网上的海量图像-标题对，提供了零样本学习的能力，有助于缓解这一问题。CLIP 通过特定领域的图像-标题对进行微调，能够提升分类效果。尽管如此，CLIP 的预训练数据与临床医生使用的医学术语并不完全一致。近年来，大型语言模型（LLMs）的兴起为我们提供了一种可能性，即利用这些模型的表达能力来生成丰富的文本。我们旨在利用这些模型生成既与临床词汇相符，又与 CLIP 预训练数据中使用的自然人类语言相契合的标题文本。我们从 PubMed 文章中的图像标题着手，通过将原始标题输入经过该领域教科书微调的 LLM，进行扩展。研究发现，使用经过精细调优的表达力强的 LLM（如 GPT-3.5）生成的标题，能够显著提升零样本概念分类的性能。

> AI in dermatology is evolving at a rapid pace but the major limitation to training trustworthy classifiers is the scarcity of data with ground-truth concept level labels, which are meta-labels semantically meaningful to humans. Foundation models like CLIP providing zero-shot capabilities can help alleviate this challenge by leveraging vast amounts of image-caption pairs available on the internet. CLIP can be fine-tuned using domain specific image-caption pairs to improve classification performance. However, CLIP's pre-training data is not well-aligned with the medical jargon that clinicians use to perform diagnoses. The development of large language models (LLMs) in recent years has led to the possibility of leveraging the expressive nature of these models to generate rich text. Our goal is to use these models to generate caption text that aligns well with both the clinical lexicon and with the natural human language used in CLIP's pre-training data. Starting with captions used for images in PubMed articles, we extend them by passing the raw captions through an LLM fine-tuned on the field's several textbooks. We find that using captions generated by an expressive fine-tuned LLM like GPT-3.5 improves downstream zero-shot concept classification performance.

![为皮肤科AI中的零样本概念生成实现数据对齐。](../../../paper_images/2404.13043/text.png)

[Arxiv](https://arxiv.org/abs/2404.13043)