# 探索大型语言模型的供应链：制定研究路线图

发布时间：2024年04月19日

`LLM应用` `人工智能` `供应链管理`

> Large Language Model Supply Chain: A Research Agenda

# 摘要

> 预训练的大型语言模型（LLMs）和大型多模态模型（LMMs）的迅猛进步为智能应用的发展带来了新纪元，从自然语言处理到内容创作等多个领域都因此发生了变革。LLM的供应链是当今人工智能领域的一个重要组成部分，它覆盖了预训练模型从起始开发、训练到最终部署和跨领域应用的完整周期。本文对LLM供应链进行了详尽的梳理，特别强调了三个核心要素：模型基础设施（包括训练、优化和部署所需的数据集和工具链）、模型生命周期（涵盖训练、测试、发布和持续维护）以及下游应用生态（推动预训练模型融入多样化的智能应用中）。尽管如此，这个快速演变的领域在关键环节上仍面临多重挑战，如数据隐私与安全、模型的可解释性与公正性、基础设施的可扩展性以及法规遵从性。应对这些挑战对于释放LLM的全部潜力并确保其合理、道德的使用至关重要。本文提出了LLM供应链的未来研究方向，目的是推动这些具有变革性的LLM持续进步并得到负责任的应用。

> The rapid advancements in pre-trained Large Language Models (LLMs) and Large Multimodal Models (LMMs) have ushered in a new era of intelligent applications, transforming fields ranging from natural language processing to content generation. The LLM supply chain represents a crucial aspect of the contemporary artificial intelligence landscape. It encompasses the entire lifecycle of pre-trained models, from its initial development and training to its final deployment and application in various domains. This paper presents a comprehensive overview of the LLM supply chain, highlighting its three core elements: 1) the model infrastructure, encompassing datasets and toolchain for training, optimization, and deployment; 2) the model lifecycle, covering training, testing, releasing, and ongoing maintenance; and 3) the downstream application ecosystem, enabling the integration of pre-trained models into a wide range of intelligent applications. However, this rapidly evolving field faces numerous challenges across these key components, including data privacy and security, model interpretability and fairness, infrastructure scalability, and regulatory compliance. Addressing these challenges is essential for harnessing the full potential of LLMs and ensuring their ethical and responsible use. This paper provides a future research agenda for the LLM supply chain, aiming at driving the continued advancement and responsible deployment of these transformative LLMs.

![探索大型语言模型的供应链：制定研究路线图](../../../paper_images/2404.12736/x1.png)

[Arxiv](https://arxiv.org/abs/2404.12736)