# 合作共赢，还是走向崩溃：探究大型语言模型（LLM）代理社会中可持续行为的兴起

发布时间：2024年04月25日

`LLM应用` `人工智能安全` `战略决策`

> Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents

# 摘要

> 人工智能的迅猛发展带来了一个重大挑战：如何确保大型语言模型（LLMs）做出安全决策。本文提出了“公共治理模拟”（GovSim）平台，它专门设计用于深入研究LLMs在战略互动和合作决策中的行为。该平台让我们得以洞察AI代理间资源共享的机制，并突显了道德考量、战略规划和谈判技巧的关键作用。GovSim的灵活性允许任何基于文本的代理参与，包括LLMs。我们利用生成代理框架开发了一个标准代理，以便于不同LLMs的集成。研究发现，在GovSim平台上测试的15个LLMs中，仅有两个能够实现资源的可持续利用，这暴露了模型在共享资源管理上的明显不足。此外，当代理失去沟通能力时，会出现资源共享的过度消耗，这强调了沟通在促进合作中的核心作用。值得注意的是，大多数LLMs在进行普遍化假设方面存在缺陷，这揭示了它们在推理能力上的一个显著弱点。我们已经将研究成果全面开源，包括模拟环境、代理提示和易于访问的网页界面。

> In the rapidly evolving field of artificial intelligence, ensuring safe decision-making of Large Language Models (LLMs) is a significant challenge. This paper introduces Governance of the Commons Simulation (GovSim), a simulation platform designed to study strategic interactions and cooperative decision-making in LLMs. Through this simulation environment, we explore the dynamics of resource sharing among AI agents, highlighting the importance of ethical considerations, strategic planning, and negotiation skills. GovSim is versatile and supports any text-based agent, including LLMs agents. Using the Generative Agent framework, we create a standard agent that facilitates the integration of different LLMs. Our findings reveal that within GovSim, only two out of 15 tested LLMs managed to achieve a sustainable outcome, indicating a significant gap in the ability of models to manage shared resources. Furthermore, we find that by removing the ability of agents to communicate, they overuse the shared resource, highlighting the importance of communication for cooperation. Interestingly, most LLMs lack the ability to make universalized hypotheses, which highlights a significant weakness in their reasoning skills. We open source the full suite of our research results, including the simulation environment, agent prompts, and a comprehensive web interface.

[Arxiv](https://arxiv.org/abs/2404.16698)