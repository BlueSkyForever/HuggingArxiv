# 合作或崩溃：探究大型语言模型（LLM）代理社会中可持续性行为的兴起

发布时间：2024年04月25日

`Agent` `人工智能` `资源管理`

> Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents

# 摘要

> 在日新月异的人工智能世界中，保障大型语言模型（LLMs）的决策安全无疑是一项艰巨任务。本论文提出了一个名为“公共资源治理模拟”（GovSim）的模拟平台，专门设计用于深入探究LLMs中的战略互动与协作决策过程。该平台让我们得以洞察AI代理间资源共享的机制，同时凸显了道德考量、战略规划和谈判技巧的关键作用。GovSim的通用性使其能够适配所有文本型代理，包括各类LLMs代理。借助生成代理框架，我们开发了一个标准代理，以促进不同LLMs的无缝集成。研究发现，在GovSim平台上，15个受测的LLMs中仅有两个能够达成可持续的成果，这暴露了模型在共享资源管理能力上的显著不足。此外，当剥夺了代理间的沟通能力时，它们往往会过度消耗共享资源，这一发现凸显了沟通在促进合作中的核心作用。值得注意的是，大多数LLMs在进行普遍化假设方面的能力不足，这反映出它们在推理能力上的一个明显缺陷。我们已经将研究成果的全套内容开源，包括模拟环境、代理提示器以及一个详尽的网络界面。

> In the rapidly evolving field of artificial intelligence, ensuring safe decision-making of Large Language Models (LLMs) is a significant challenge. This paper introduces Governance of the Commons Simulation (GovSim), a simulation platform designed to study strategic interactions and cooperative decision-making in LLMs. Through this simulation environment, we explore the dynamics of resource sharing among AI agents, highlighting the importance of ethical considerations, strategic planning, and negotiation skills. GovSim is versatile and supports any text-based agent, including LLMs agents. Using the Generative Agent framework, we create a standard agent that facilitates the integration of different LLMs. Our findings reveal that within GovSim, only two out of 15 tested LLMs managed to achieve a sustainable outcome, indicating a significant gap in the ability of models to manage shared resources. Furthermore, we find that by removing the ability of agents to communicate, they overuse the shared resource, highlighting the importance of communication for cooperation. Interestingly, most LLMs lack the ability to make universalized hypotheses, which highlights a significant weakness in their reasoning skills. We open source the full suite of our research results, including the simulation environment, agent prompts, and a comprehensive web interface.

[Arxiv](https://arxiv.org/abs/2404.16698)