# 本文探讨了解题效率和指令的正负价值如何影响人类及 GPT-4 在执行加法和减法策略时的思维过程。

发布时间：2024年04月25日

`分类：LLM应用` `心理学` `人工智能`

> Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4

# 摘要

> 通过四项预注册实验，我们深入探究了“添加偏差”这一认知倾向，即人们更偏好通过增加元素而非减少来调整初始状态或结构。实验对象包括美国的 588 名参与者和 OpenAI 的 GPT-4 语言模型的 680 轮迭代。任务包括在网格中创造对称（实验 1 和 3）和编辑摘要（实验 2 和 4）。正如预期，我们普遍观察到了添加偏差的存在。解决效率和指令的情感色彩对实验结果有显著影响。相较于加法和减法效率相当的情况，人类参与者在减法更有效时更少采用累加策略。而 GPT-4 则表现出相反的倾向，即使在减法更有效的情况下也展现出强烈的添加偏好。在指令的情感色彩方面，GPT-4 在被要求“改进”时比“编辑”时更倾向于增加词汇，而人类参与者则未表现出这种差异。在不同条件下对添加偏差的观察中，我们发现 GPT-4 比人类参与者有更明显的偏差。研究结果突显了在问题解决过程中考虑减法策略的重要性，并提示我们需要重新审视自己和语言模型的解题行为。

> We explored the addition bias, a cognitive tendency to prefer adding elements over removing them to alter an initial state or structure, by conducting four preregistered experiments examining the problem-solving behavior of both humans and OpenAl's GPT-4 large language model. The experiments involved 588 participants from the U.S. and 680 iterations of the GPT-4 model. The problem-solving task was either to create symmetry within a grid (Experiments 1 and 3) or to edit a summary (Experiments 2 and 4). As hypothesized, we found that overall, the addition bias was present. Solution efficiency (Experiments 1 and 2) and valence of the instruction (Experiments 3 and 4) played important roles. Human participants were less likely to use additive strategies when subtraction was relatively more efficient than when addition and subtraction were equally efficient. GPT-4 exhibited the opposite behavior, with a strong addition bias when subtraction was more efficient. In terms of instruction valence, GPT-4 was more likely to add words when asked to "improve" compared to "edit", whereas humans did not show this effect. When we looked at the addition bias under different conditions, we found more biased responses for GPT-4 compared to humans. Our findings highlight the importance of considering comparable and sometimes superior subtractive alternatives, as well as reevaluating one's own and particularly the language models' problem-solving behavior.

[Arxiv](https://arxiv.org/abs/2404.16692)