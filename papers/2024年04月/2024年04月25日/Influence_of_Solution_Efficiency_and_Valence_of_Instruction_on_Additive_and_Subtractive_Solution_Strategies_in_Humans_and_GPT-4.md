# 指令的效率和情感价值如何影响人类以及 GPT-4 在执行加法和减法策略时的解题方法。

发布时间：2024年04月25日

`LLM应用` `认知科学` `人工智能`

> Influence of Solution Efficiency and Valence of Instruction on Additive and Subtractive Solution Strategies in Humans and GPT-4

# 摘要

> 我们通过四项预注册实验探讨了人们在解决问题时更倾向于添加而非删除元素的认知倾向，即所谓的“添加偏差”。这些实验同时考察了人类参与者和 OpenAI 的 GPT-4 大型语言模型的行为。实验共有 588 名美国参与者和 GPT-4 模型的 680 轮迭代参与。任务包括在网格中创造对称（实验 1 和 3）和编辑摘要（实验 2 和 4）。正如预期，我们普遍观察到了添加偏差的存在。解决效率和指令的情感色彩对结果有显著影响。在减法更为高效的情况下，人类参与者较少采用添加策略。而 GPT-4 则表现出相反的倾向，即使在减法更有效时也强烈偏好添加操作。对于指令的情感色彩，GPT-4 在被要求“改进”时更倾向于增加内容，而“编辑”时则不然，人类参与者则未显示这种差异。在不同条件下分析添加偏差时，我们发现 GPT-4 比人类参与者更有明显的偏差。研究结果提醒我们，在解决问题时，应考虑等效甚至更优的减法策略，并重新审视自己尤其是语言模型的解题方法。

> We explored the addition bias, a cognitive tendency to prefer adding elements over removing them to alter an initial state or structure, by conducting four preregistered experiments examining the problem-solving behavior of both humans and OpenAl's GPT-4 large language model. The experiments involved 588 participants from the U.S. and 680 iterations of the GPT-4 model. The problem-solving task was either to create symmetry within a grid (Experiments 1 and 3) or to edit a summary (Experiments 2 and 4). As hypothesized, we found that overall, the addition bias was present. Solution efficiency (Experiments 1 and 2) and valence of the instruction (Experiments 3 and 4) played important roles. Human participants were less likely to use additive strategies when subtraction was relatively more efficient than when addition and subtraction were equally efficient. GPT-4 exhibited the opposite behavior, with a strong addition bias when subtraction was more efficient. In terms of instruction valence, GPT-4 was more likely to add words when asked to "improve" compared to "edit", whereas humans did not show this effect. When we looked at the addition bias under different conditions, we found more biased responses for GPT-4 compared to humans. Our findings highlight the importance of considering comparable and sometimes superior subtractive alternatives, as well as reevaluating one's own and particularly the language models' problem-solving behavior.

[Arxiv](https://arxiv.org/abs/2404.16692)