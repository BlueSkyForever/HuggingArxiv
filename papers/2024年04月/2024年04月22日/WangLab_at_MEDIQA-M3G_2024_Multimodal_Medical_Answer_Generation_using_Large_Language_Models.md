# 2024年MEDIQA-M3G大赛中，WangLab团队利用大型语言模型，开创了多模态医学答案生成的新篇章。

发布时间：2024年04月22日

`分类：LLM应用

这篇论文的摘要主要介绍了在MEDIQA2024多语种多模态医学答案生成挑战赛中的两种方法，这两种方法都涉及到了大型语言模型（LLM）的应用。第一种方法是连续两次调用Claude 3 Opus API，这表明了LLM在自然语言处理领域的应用。第二种方法是模仿CLIP技术，训练图像与疾病标签的联合嵌入模型以进行图像分类，这表明了LLM在图像分类领域的应用。因此，这篇论文应该被归类为LLM应用。` `图像分类`

> WangLab at MEDIQA-M3G 2024: Multimodal Medical Answer Generation using Large Language Models

# 摘要

> 本论文介绍了我们为 MEDIQA2024 多语种多模态医学答案生成（M3G）挑战赛所提交的研究成果。在该任务的英语领域，我们展示了两种独立方法的成果：第一种方法是连续两次调用 Claude 3 Opus API，第二种方法是模仿 CLIP 技术，训练图像与疾病标签的联合嵌入模型以进行图像分类。这两种方法在竞赛中分别荣获冠亚军，表现远超其他参赛方案。文章还分享了赛后实验的深刻见解。尽管面对任务的复杂性和医学视觉问答的普遍挑战，这两种解决方案尚有提升空间，但我们看好多阶段大型语言模型和 CLIP 图像分类技术在未来研究中的潜力。

> This paper outlines our submission to the MEDIQA2024 Multilingual and Multimodal Medical Answer Generation (M3G) shared task. We report results for two standalone solutions under the English category of the task, the first involving two consecutive API calls to the Claude 3 Opus API and the second involving training an image-disease label joint embedding in the style of CLIP for image classification. These two solutions scored 1st and 2nd place respectively on the competition leaderboard, substantially outperforming the next best solution. Additionally, we discuss insights gained from post-competition experiments. While the performance of these two solutions have significant room for improvement due to the difficulty of the shared task and the challenging nature of medical visual question answering in general, we identify the multi-stage LLM approach and the CLIP image classification approach as promising avenues for further investigation.

[Arxiv](https://arxiv.org/abs/2404.14567)