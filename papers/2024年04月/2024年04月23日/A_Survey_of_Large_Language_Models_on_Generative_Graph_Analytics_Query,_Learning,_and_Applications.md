# 大型语言模型在生成图分析领域的研究综述：探讨查询、学习和应用。

发布时间：2024年04月23日

`LLM应用` `图数据分析`

> A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications

# 摘要

> 图作为核心数据模型，完美捕捉了社会与自然界中实体间的错综复杂联系，如社交、交通、金融乃至生物医学网络。近期，大型语言模型（LLMs）在处理多样化的自然语言处理（NLP）任务和多模态任务方面，展现出了卓越的泛化能力，无论是回答用户的各种问题还是生成特定领域的内容。相较于传统的图学习模型，LLMs在图任务的泛化挑战上更具优势，省去了训练图学习模型的步骤，大幅降低了手动注释的成本。本篇综述深入探讨了LLM在图数据分析研究中的应用，归纳了先进LLM模型解决的图分析任务，并指出了当前面临的挑战与未来可能的研究方向。具体而言，我们聚焦于基于LLM的生成图分析（LLM-GGA）的三个主要问题：图查询处理（LLM-GQP）、图推理与学习（LLM-GIL），以及图与LLM结合的应用。LLM-GQP着眼于图分析技术与LLM提示的融合，涵盖图理解及基于知识图谱的增强检索；LLM-GIL则关注图上的学习与推理，包括图学习、图形态推理和图表示。文章还总结了LLM处理不同图任务时采用的有效提示，并提供了LLM模型评估、基准数据集/任务的概览，以及对LLM模型优缺点的深入分析。同时，我们也对LLM与图分析这一激动人心的跨学科研究领域的未解决问题和未来方向进行了探讨。

> A graph is a fundamental data model to represent various entities and their complex relationships in society and nature, such as social networks, transportation networks, financial networks, and biomedical systems. Recently, large language models (LLMs) have showcased a strong generalization ability to handle various NLP and multi-mode tasks to answer users' arbitrary questions and specific-domain content generation. Compared with graph learning models, LLMs enjoy superior advantages in addressing the challenges of generalizing graph tasks by eliminating the need for training graph learning models and reducing the cost of manual annotation. In this survey, we conduct a comprehensive investigation of existing LLM studies on graph data, which summarizes the relevant graph analytics tasks solved by advanced LLM models and points out the existing remaining challenges and future directions. Specifically, we study the key problems of LLM-based generative graph analytics (LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP), LLM-based graph inference and learning (LLM-GIL), and graph-LLM-based applications. LLM-GQP focuses on an integration of graph analytics techniques and LLM prompts, including graph understanding and knowledge graph (KG) based augmented retrieval, while LLM-GIL focuses on learning and reasoning over graphs, including graph learning, graph-formed reasoning and graph representation. We summarize the useful prompts incorporated into LLM to handle different graph downstream tasks. Moreover, we give a summary of LLM model evaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM models. We also explore open problems and future directions in this exciting interdisciplinary research area of LLMs and graph analytics.

[Arxiv](https://arxiv.org/abs/2404.14809)