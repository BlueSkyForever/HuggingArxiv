# 检索增强型生成式关系提取
发布时间：2024年04月20日
`RAG`
> 信息提取（IE）通过实体和关系提取（RE）技术，将杂乱无章的文本信息转化为有序数据，其中实体间关系的辨识尤为关键。尽管众多关系提取技术已存在，但其效果往往受限于标注数据的可用性和计算资源的充足性。为解决这些问题，大型语言模型（LLMs）崭露头角，尽管有时可能因训练数据产生误导性结果。为此，我们提出了一种新颖的基于检索增强生成的关系提取方法（RAG4RE），旨在提升关系提取的性能。在本研究中，我们通过多个知名大型语言模型（如Flan T5、Llama2和Mistral）测试了RAG4RE方法，并利用TACRED、TACREV、Re-TACRED和SemEval RE等标准数据集进行全面评估。研究结果显示，RAG4RE在TACRED数据集及其衍生版本中的表现尤为出色，超越了仅依赖LLMs的传统关系提取方法。此外，与TACRED和TACREV数据集上的先前方法相比，RAG4RE也展现了卓越的性能，彰显了其在自然语言处理领域推动关系提取任务的潜力和效果。

![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x1.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x2.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x3.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x4.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x5.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x6.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x7.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x8.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x9.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x10.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x11.png)
![](https://raw.githubusercontent.com/HuggingAGI/HuggingArxiv/main/paper_images/2404.13397/x12.png)

[https://wx.zsxq.com/dweb2/index/topic_detail/2855284852488521](https://wx.zsxq.com/dweb2/index/topic_detail/2855284852488521)

[https://arxiv.org/abs/2404.13397](https://arxiv.org/abs/2404.13397)